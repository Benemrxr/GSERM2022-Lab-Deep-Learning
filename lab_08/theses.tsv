Anmeldedatum	JahrAkademisch	Art	Grad	Sprache	Titel	Abstract
28.07.16	2016	extern	Master	DE	Untersuchung und Konzeption des Einsatzes von Cyber-Physischen Systemen am Montageband	Im Fokus dieser Arbeit steht der Einsatz von Cyber-Physischen Systemen in der Montage. Cyber-Physische Systeme gewinnen in den aktuellen Entwicklungen der Industrie 4.0 eine immer wichtigere Rolle. Ihr Einsatz soll dazu dienen, virtuelle und reale Welt zu vernetzen, um speziell in der Montage manuelle und starre Prozesse zu flexibilisieren und automatisieren. In Kooperation mit der Fraunhofer-Arbeitsgruppe für Supply-Chain Services SCS wird erfasst inwieweit deutsche Unternehmen Cyber-Physische Systeme bereits in ihren Produktionen einsetzen. Weiterhin sollen Herausforderungen und Chancen untersucht werden, die sich dabei ergeben sowie Anforderungen der Unternehmen an Cyber-Physische Systeme im Allgemeinen sowie an ein ideales Cyber-Physisches System im Speziellen. Die Informationsgewinnung erfolgt zunächst über die Durchführung einer Literaturrecherche, um die Sicht der gegenwärtigen Theorie zu erfassen. Als Gegenstück zur Theorie wird die Praxis anhand von Expertenbefragungen untersucht und die Ergebnisse der Gespräche nach der Methodik nach Mayring analysiert und ausgewertet (vgl. [Ma16, S.114?121]). Diese Auswertung dient dazu, Theorie und Praxis abzugleichen und auf Basis dessen ein ideales Cyber-Physisches System zu konzipieren. Das Ergebnis dieser Arbeit soll den aktuellen Status-Quo des Einsatzes von Cyber-Physischen Systemen in der Montage wiederspiegeln.
01.08.16	2016	intern	Master	DE	Objekterkennung mit Convolutional Neural Networks auf Basis von TensorFlow und iOS.	Im Rahmen dieser Masterthesis wird die Klassifikation von Objekten, explizit von Verkehrszeichen, mithilfe von Convolutional Neural Networks behandelt. In diesem Zusammenhang wird das Convolutional Neural Network unter Anwendung der Software-Bibliothek TensorFlow entwickelt. Das zur Verkehrszeichenerkennung entwickelte Netzwerk wird in ein bestehendes Geschwindigkeitsassistenzsystem, welches auf einem Smartphone betrieben wird, integriert. Die einführenden Kapitel geben einen Überblick über den aktuellen Stand der Technik und erläutern den Aufbau und die Funktionsweise von Convolutional Neural Networks. Um ein besseres Verständnis für Convolutional Neural Networks zu schaffen, werden zunächst die theoretischen Grundlagen der künstlichen neuronalen Netzwerke genannt. Anschließend werden die verwendeten Hardware- und Software-Komponenten vorgestellt und ein Bezug zu deren Relevanz geschaffen. Die Implementierung des Modells mithilfe von TensorFlow, sowie die prototypische Erweiterung der bestehenden Anwendung wird daraufhin dargelegt. In den nachfolgenden Kapiteln wird auf die Evaluierung des Convolutional Neural Networks, sowie auf bestehende Optimierungs- und Erweiterungsmöglichkeiten eingegangen. Abschließend wird ein Resümee über das entstandene Netzwerk und dessen Klassifikationsrate, sowohl unter TensorFlow als auch unter iOS, gegeben.
04.10.16	2017	extern	Bachelor	DE	Analyse von Technologien zur Desktopbereitstellung - Entwicklung eines zukunftsorientierten Konzepts 	Viele Unternehmen verfügen über etablierte Desktopbereitstellungs-Lösungen. Doch besitzen die klassischen Konzepte die Fähigkeit auch Anforderungen an einen Future Workplace zu erfüllen? Die prognostizierte, zunehmende Verbreitung von mobilen Endgeräten im Unternehmensumfeld ist ein Beispiel für einen aktuellen Treiber der Veränderung des Arbeitsplatzes. Diese Veränderung führt zwangsläufig zu einer Neuausrichtung der Desktop-Verwaltung. Deswegen werden neue gnerische Konzepte benötigt, die es Mitarbeitern ermöglichen endgeräte-, zeit- und ortsunabhängig auf Unternehmensressourcen zuzugreifen. Die Bachelorarbeit liefert einen Überblick über die erwarteten Veränderungen und bietet Lösungsvorschläge zur Auswahl geeigneter Desktopbereitstellungs-Varianten. Nach wissenschaftlicher Ausarbeitung des Themas wird ein Future Workplace konzeptionell entwickelt.
05.10.16	2017	extern	Master	DE	Konzeption und Implementierung einer mobilen Anwendung zur optischen Erfassung von Zählerinformationen	Ziel der Masterarbeit ist es, eine mobile Anwendung zur optischen Erfassung von Zählerinformationen zu konzeptionieren und Implementieren. Dafür sollen Zählerinformationen, wie z. B. Identifikationsnummer und Zählerstand, optisch erfasst und verarbeitet werden. Des Weiteren soll es möglich sein, der Erfassungssoftware IZAR@MOBILE ein Foto vom Einbauort des entsprechenden Zählers zuzuordnen. Nachdem alle relevanten Daten aufgenommen sind, werden sie an die zentrale Erfassungs- und Auswertungssoftware IZAR@NET verschlüsselt übertragen. Dabei ist IZAR@MOBILE eine Software, die eine einfache und wirtschaftliche Auslesung von Funkzählern über mobile Endgeräte ermöglicht. Für die Verwaltung der einzelnen Zähler wird die IZAR@NET verwendet. Zuletzt soll eine Marktanalyse für verschiedene Länder über die aktuelle Verteilung von "intelligenten Messsystemen" und "konventionellen Zählern" durchgeführt werden. Zusätzlich zu der Marktanalyse soll eine Analyse über die ökonomische Verwendung der oben genannten Features durchgeführt werden.
10.10.16	2017	extern	Bachelor	DE	Konzeptionierung und Realisierung einer Anwendung zur Konfiguration der DATEV DMS-Arbeitsplatzintegration	Das Ziel dieser Bachelorarbeit ist die Konzeption und Entwicklung einer datenbankgestützten Anwendung, welche Änderungen an der Konfiguration der DMS-Arbeitsplatzintegration jederzeit und problemlos ermöglicht. Um dieses Ziel zu erfüllen, erfolgte im ersten Schritt die Ist-Analyse. Diese schloss die Beschreibung der Ausgangssituation mit ein. Des Weiteren wurde das Thema DMS-Arbeitsplatzintegration genaue beleuchtet sowie das bestehende Datenbankmodell vorgestellt und analysiert. Basierend auf den gewonnenen Erkenntnissen wurden anwendungsspezifische Anforderungen erarbeitet und definiert. Auf dieser Grundlage konnte entsprechend den DATEV-Richtlinien eine Anwendung konzipiert werden. Als Nächstes wurde die Anwendung gemäß der gegebenen Technologieleitlinie realisiert. Die während dieser Abschlussarbeit entwickelte Anwendung wird zukünftig in der Customizing Abteilung der DATEV eingesetzt und hat sich somit in der Praxis als erfolgreich erwiesen. Auf diese Weise konnte die Erfüllung der gestellten Anforderungen sowie die Richtigkeit und Tragfähigkeit des Konzepts bestätigt werden.
14.10.16	2017	intern	Bachelor	DE	Entwicklung einer Bahnregulierung für einen autonomen, mobilen Roboter	Die Bachelorarbeit befasst sich mit der Entwicklung einer Bahnregulierung für einen autonomen, mobilen und radgetriebenen Roboter, den Carbot. Der Carbot-Roboter und dessen Simulationsumgebung sind Entwicklungen von Prof. Dr. Jörg Roth an der Technischen Hochschule Nürnberg. Der Roboter verfügt über Funktionen zur Selbstlokalisierung, Erkennung von Hindernissen und Kollisionen auf Basis von Sensordaten sowie zur Planung von Routen und Bahnen. Die kontrollierte Bewegung des Roboters wird über ein Antriebs- und Bewegungsmodell realisiert. Das derzeitige Problem ist der Verlust von Traktion bei Fortbewegung des Roboters auf nicht idealem Untergrund und die damit verbundene Abweichung beim Abfahren geplanter Fahrbahnen. In dieser Arbeit wird ein Verfahren vorgestellt, das diese Diskrepanz erkennt, auswertet und den Roboter sanft auf die geplante Bahn zurückführt. Die Realisierung eines Prototypen erfolgte in der Carbot-Umgebung.
15.10.16	2017	extern	Master	DE	RFID-Landmarken basierte Selbstlokalisierung und gleichzeitige Warenortung	In this thesis the feasibility of replacing the positioning, done by a real-time locating system, in an existing RTLS based RFID goods-tracking system, with SLAM is studied. The system consists of a forklift whose position can be obtained via a RTLS. Attached to the forklift is a RFID-reader and a linear-antenna-array, which can determine the angle between RFID-tagged goods and the forklift. By combining both systems the goods in warehouse can be localized. The RTLS can be replaced by using the RFID-tags as landmarks for a SLAM algorithm. The major challenges are unmonitored changes by the staff who often uses a pallet jack for rearranging wares which cause the attached landmarks to change their position and cause an erroneous position estimation of the forklift. The SLAM algorithms FastSLAM and FastSLAM2.0 weres used.Techniques for detecting non-static landmarks were studied and the SLAM Algorithms were extended with a method for detecting changes in the landmark environment. Despite worsening the forklift position accuracy most landmark position changes could be successfully detected. Additionally an integration of the carrier phase shift, that is detected by RFIDantennas into the SLAM-Filter was investigated. Despite yielding comparable results with existing techniques during a static evaluation it failed to improve the localization accuracy when integrated into the SLAM-Filter.
17.10.16	2017	intern	Bachelor	DE	Entwicklung einer vektorbasierten Navigationskomponente für einen autonomen, mobilen Roboter	An der Technischen Hochschule Nürnberg existiert ein autonomer, mobiler Roboter. Für diesen soll eine vektorbasierte Navigationskomponente entwickelt werden. Es wurde sich hierbei für einen Voronoi-Diagramm Ansatz entschieden. Die Kanten eines solchen Voronoi-Diagramms mussten durch ein entwickeltes Verfahren für navigatorische Zwecke nutzbar gemacht werden. Diese Kanten eines modifizierten Voronoi-Diagramms galt es in eine Graph-Repräsentation umzuwandeln. Anschließend musste noch mittels einer vorzunehmenden A *-Algorithmus Implementation der kürzeste Weg von einem Start zu einem Zielknoten gefunden werden.
17.10.16	2017	extern	Bachelor	DE	Entwicklung einer webbasierten Simulationsumgebung für Hardware-Ereignisse im Umfeld von Strahlungskontaminations-Messsystemen	Die Bachelorarbeit befasst sich mit der Entwicklung einer Simulationsumgebung, die es ermöglicht, über eine webbasierte Oberfläche digitale Signale zu erzeugen und zu verarbeiten. Dabei ist es möglich, Abhängigkeiten zwischen eingehenden und ausgehenden Signalen zu berücksichtigen. Für die Entwicklung der Simulationsumgebung wurden Komponenten evaluiert, um alle Anforderungen umsetzen zu können. Hierbei wurden potenzielle Hardwarekomponenten betrachtet, anschließend Python Web Frameworks verglichen, eine geeignete Datenbank gewählt und eine passende Library zur Ansteuerung der Hardware-Schnittstelle evaluiert. Die Evaluierung ergab, dass der Raspberry Pi 3 Model B als Hardwarekomponente, das Python Web Framework Django, die Datenbank SQLite und die RPi.GPIO Library zur Ansteuerung der GPIO-Schnittstellen des Raspberry Pi am besten geeignet sind. Um den digitalen Datenaustausch zwischen dem Raspberry Pi 3 Model B und der Mess- und Steuerungseinheit zu ermöglichen, wurde ein Konzept entworfen, das Inkompatibilitäten zwischen den Schnittstellen ausgleicht.
17.10.16	2017	extern	Master	DE	Umsetzung eines TTCN-3 Interpreters für den Einsatz im Automobilsektor	Im Bereich der Automatisierung von Softwaretests, unter Verwendung von Hardware in the Loop-Testsystemen, kommt die Testing and Test Control Notation Version 3 (TTCN-3) als standardisierte Testsprache zum Einsatz. Diese Sprache stammt ursprünglich aus dem Telekommunikationsbereich. Im Rahmen des ProTecT-Forschungsprojektes (Förderkennzeichen: KF21397041150) wurde der Einsatz dieser Testsprache im Automobil-Bereich geprüft. Dabei wurde im Vorfeld dieser Arbeit ein TTCN-3-Interpreter in Python implementiert. Im Rahmen dieser Abschlussarbeit wurde die Debug-Funktionalität für den TTCN-3-Interpreter für eine Erweiterung der Testmöglichkeiten ergänzt. Weiterhin war die Performance des TTCN-3-Interpreters zu untersuchen und gegebenenfalls zu optimieren. Ziel war die Vervollständigung des TTCN-3-Interpreters für den Einsatz in Software-Testprojekten. Die im Rahmen des ProTecT-Forschungsprojektes eingeführte TTCN-3-Testsprache im Automobilsektor über den Ansatz eines Interpreters wurde durch diese Arbeit entscheidend vorangetrieben. Durch die Umsetzung des Debuggers in dieser Arbeit können Fehler früh im Entwicklungsprozess erkannt und behoben werden.
19.10.16	2017	intern	Bachelor	DE	Vergleich der Modellierung mit Graphdatenbanken und Ontologien anhand einer Fallstudie	Durch die immer weiter steigende Digitalisierung unserer Welt werden immer mehr Da-ten erfasst und gespeichert. Fast keine Anwendung in der Informatik funktioniert noch ohne eine Datenbank. Vor allem in Suchmaschinen oder sozialen Netzwerken spielen Graphdatenbanken eine große Rolle. Deshalb werden diese in dieser Arbeit genauer erklärt. Das Pendant zu den Graphdatenbanken aus dem Bereich der Wissensrepräsenta-tion bilden die Ontologien. Die intelligente Datenverarbeitung wird in aktuellen Infor-mationssystemen immer wichtiger. Daher bilden Ontologien den zweiten Schwerpunkt dieser Abschlussarbeit. Abschließend werden beide Technologien in einer Fallstudie gegenübergestellt.
20.10.16	2017	intern	Bachelor	DE	Sentiment Analyse von Kundenreviews aus einem sozialen Netzwerk zur Produktverbesserung eines ausgewählten Streaming Dienstes	Das Ziel der vorliegenden Bachelorarbeit ist es, aus Nutzerkommentaren Verbesserungsvorschläge für die Angebote des Streaming Dienstes Netflix zu gewinnen sowie die Erkenntnis über die Zufriedenheit der Kunden über das Angebot. Dies geschieht durch eine Sentiment Analyse, bei der die Bewertungen als erstes in die Kategorien ?positiv?, ?negativ? und ?neutral? aufgeteilt werden. Danach werden Produktverbesserungenvorschläge der Kunden sowie der Beliebtheitsgrad des Produktes herausgefiltert. Dies hat den Zweck herauszufinden, was dem Kunden an dem Produkt mehr zusagen würde und ob dieses Produkt überhaupt genutzt wird. Wenn nicht, kann der Grund dafür durch die Produktverbesserungsvorschläge erschlossen werden und an einer Verbesserung gearbeitet werden. Auch soll die Analyse dabei helfen herauszufinden, wie hoch der Benutzungsgrad in einer bestimmten Zeitspanne war, um Trends ablesen zu können.
20.10.16	2017	extern	Bachelor	DE	Automatisierung des Freigabe- und Buchungsprozesses für Eingangsrechnungen in einem ERP-System	Das Ziel dieser Arbeit ist es, den Prozess der Erfassung bzw. Genehmigung von Eingangsrechnungen im Rahmen des ERP-Systems Microsoft Dynamics NAV zu optimieren. Dabei werden zunächst die bereits vorhandenen Prozesse in Micrcsoft Dynamics NAV unter der Berücksichtigung von Kundenanforderungen untersucht. Da der Genehmigungsprozess zu unflexibel und nicht auf den jeweiligen Kunden zuschneidbar ist, wurden nachfolgend die bereits auf dem Markt vorhandenen Lösungen von anderen Partnern bzgl. ihrer Nutzbarkeit analysiert. Die KUMAVISION AG verfügt derzeit über keine eigene Lösung in diesem Bereich, deshalb soll das Potential einer neu entwickelten Lösung in Betracht gezogen werden. Nach einer näheren Analyse der Eignung einer solchen Eigenentwicklung und der bereits vorhandenen Module, wird im Rahmen einer Evaluierung der direkte Vergleich gezogen und als Resultat eine Einsatzempfehlung gegeben. Da in vielen Fällen eine Eigenentwicklung sinnvoll erscheint, wird für diese abschließend eine fachliche Spezifikation ausgearbeitet.
21.10.16	2017	extern	Master	DE	Konzeption und Entwicklung eines REST-basierten Microservices zur Behandlung von Autorisierungs- und Authentifizierungsanfragen im Rahmen der Rechenzentrumskommunikation der DATEV eG	Das Ziel der vorliegenden Masterarbeit ist die Konzeption und Entwicklung eines REST-basierten Microservice, der als Ansprechpartner für Nutzungs- und Zugangskontrollfragen bisheriger verteilter Berechtigungskonzepte des DATEV Anwendungsumfeldes zusammenführt und innerhalb eines zentralen Rechteservice bereitstellt. Hierfür wird nach Klärung grundlegender Begrifflichkeiten und Durchführung einer Anforderungsanalyse die Fragestellung erörtert, wie die Softwarearchitektur des Microservice aufgebaut sein kann, die eine möglichst lose Anbindung an diese in existierenden Fremdsystemen abgebildeten Berechtigungskonzepte ermöglicht. Zu diesem Zweck werden nach Erörterung etablierter Entwurfsprinzipien im Rahmen einer szenariobasierten Architekturbewertung unter Berücksichtigung innerhalb der Anforderungsanalyse definierten Qualitätsszenarien hierarchische Architekturmuster auf ihre Tauglichkeit zur zielführenden Umsetzung bewertet. Basierend aus hieraus gewonnen Erkenntnissen wird der Architekturentwurf in Anlehnung an einen schalenorientierten Architekturansatz konzipiert. Unter Berücksichtigung technologischer Rahmenbedingungen wird eine Technologieanalyse durchgeführt, in welcher Technologiekomponenten erörtert und evaluiert werden, mit welchen der konzipierte Architekturentwurf umsetzbar ist. Abschließend wird der Microservice unter Anwendung des konzipierten Architekturentwurfes sowie den evaluierten Technologiekomponenten in der Form eines Machbarkeitsnachweises umgesetzt.
27.10.16	2017	extern	Bachelor	DE	Entwicklung eines Echtzeitdownloads zur Erweiterung laufender Anlagen	Mit dem Prozessleitsystem von ProLeiT ist es zu jedem Zeitpunkt möglich eine Anlage zu erweitern. Diese Eigenschaft zieht sich durch nahezu alle Produkte des Prozessleitsystems. Einzige Ausnahme bildet das Produkt Plant Batch iT. Hier werden spezielle Batch iT Objekte und Anlagenparameter benötigt und mit einem separaten Download in die Steuerung übertragen. Dieser Download kann nicht durchgeführt werden, während eine Charge in der Steuerung bearbeitet wird. Mit der vorliegenden Bachelorarbeit wird dieser Download untersucht, um herauszufinden, warum er nicht durchgeführt werden kann, wenn eine Charge in der Steuerung bearbeitet wird. Außerdem wird untersucht, warum die Steuerung gestoppt und neu gestartet werden muss, wenn sich Datenbausteine der Anlage geändert haben. Hierbei werden der Code des PCs und der Code der Steuerung analysiert. Das Prozessleitsystem wird analysiert, um herauszufinden, wann es erlaubt ist, Batch iT Objekte zu aktualisieren und wann eine Änderung zu einem Fehler in der Anlage führen würde. Mit den gesammelten Informationen werden zwei neue Downloads konzeptioniert, um Änderungen während der Produktion zu ermöglichen. Bei der Konzeption wird speziell darauf eingegangen, worauf im Umgang mit Echtzeitsystemen zu achten ist. Anschließend werden die beiden Downloads sowohl für den PC als auch für die Steuerung umgesetzt. Hierbei kommen die Sprachen C#, C++ und Anweisungsliste zum Einsatz.
31.10.16	2017	extern	Bachelor	DE	Sichere Datenübertragung von externen Datenträgern in Firmen-Netzwerke	Mitarbeiter von Firmen bekommen des Öfteren externe Datenträger, sei es von Kunden oder Werbegeschenke auf Messen. Auf diesen kann sich leicht Schadsoftware befinden und so bei Benutzung an Firmenrechner großen Schaden anrichten. Deswegen müssen externe Datenträger vor der Benutzung von einer zentralen Stelle geprüft und freigegeben werden. Dieser Prozess kann in der DATEV bis zu drei Tagen dauern. Der Prozess soll nun durch ein System beschleunigt und verbessert werden. Ziel der Bachelorarbeit ist es, ein System zu entwickeln, welches Daten von externen Datenträger sicher (unter dem Aspekt Security) und schnell in ein Firmennetzwerk transportieren kann.
31.10.16	2017	intern	Bachelor	DE	Implementierung einer Überführung eines multi-kriteriellen (nicht-)linearen ganzzahligen Programms in Standard-Eingabeformate für Optimierungssolver	Diese Arbeit ist Teil eines Lösungsansatzes zur system-basierten Optimierung von Software-Architekturen. Um aus einer solchen Software-Architektur optimierungs-relevante Elemente zu erhalten, bedarf es einer standardisierten Architekturbeschreibungssprache. Hierzu bietet sich die EAST-ADL an, eine Architekturbeschreibungssprache, die vorwiegend in der Automobilbranche Anwendung findet. Mithilfe der EAST-ADL können ganze System-Produktlinien, in Form von hierarchisch, strukturierten Features-Modellen, abgebildet werden. Durch Modellierung von Features und den zugehörigen Eigenschaften entsteht ein multikriterielles, lineares oder nichtlineares Programm. Dieses Programm kann in der vorliegenden Form von Optimierungswerkzeugen nicht aufgelöst werden. Moderne Optimierungswerkzeuge lesen und verarbeiten lediglich Standardeingabeformate von algebraischen Modellierungssprachen, die der mathematischen Notation nahe kommen. Aus diesem Grund wird ein Überführungsmechanismus benötigt, welcher diese Umformung durchführt. Auf Basis einer variantenreichen EAST-ADL Beispiel-Architektur werden die optimierungs-relevanten Elemente erzeugt und veranschaulicht. Alle möglichen Ausprägungen dieser Elemente bilden die Argumentationsgrundlage zur Evaluierung der Standardeingabeformate. Das Ergebnis der Evaluierung wird anschließend als Modellgenerator, zur Überführung der optimierungs-relevanten Elemente, in Form einer Software implementiert.
02.11.16	2017	intern	Master	DE	Entwicklung und prototypische Realisierung einer Microservice-Referenzarchitektur zur Einbettung von Spielelementen in Webseiten	Im Rahmen dieser Masterarbeit wird ein Konzept entwickelt, welches die Gamification von Webseiten ermöglicht. Für die Integration, einer auf dem Konzept basierenden Implementierung in die Webseite, sind kaum Änderungen an dieser nötig. Das Hinzufügen und Entfernen von Mustern ist mit wenigen Schritten möglich. Ein einmal hinzugefügtes Muster kann zudem mit einem Klick ein- oder ausgeschaltet werden. Die Muster werden hierfür als eigenständige Microservices implementiert. Für die Webseite bieten sie eine REST-Schnittstelle an. REST ist eine engere Definition von HTTP, welches das Hauptkommunikationsprotokoll des Internets ist. Die Kommunikation mit anderen Microservices erfolgt über einen Messaging-Server. Für die Übersetzung der Nutzerdaten der Webseite und die Gewährleistung der Sicherheit im Gamification-System wird ein zentraler Microservice genutzt. Dieser implementiert kein Muster, sondern dient zum einen als Anticorruption Layer und kümmert sich zum anderen um die Autorisierung und Authentifizierung der Nutzer. Des Weiteren dient er als zentraler Eintrittspunkt in das Gamification-System. Über ihn werden die Muster-Microservices in die Webseite eingebunden. Durch die Realisierung eines Prototyps wird die Architektur praktisch umgesetzt.
02.11.16	2017	extern	Bachelor	DE	Übermittlung von schützenswerten Dokumenten in einem mittelständischen Produktionsbetrieb am Beispiel der Firma Rhodius	Die Arbeit befasst sich mit dem Austausch von schützenswerten Dokumenten in einem mittelständischen Produktionsbetrieb. Einleitend werden für die Thematik relevante Grundlagen des Datenschutzes sowie zur Geheimhaltung von Betriebs- und Geschäftsgeheimnissen behandelt. Weiter werden Anforderungen allgemein, als auch an konkerten Übermittlungsverfahren diskutiert. Im Zweiten Teil wird eine Fallstudie bei der Firma RHODIUS durchgeführt. Hierzu werden zuerst alle relevanten Informationen zu Dokumenten und Übermittlungsverfahren zusammengetragen und anschließend mit Hilfe vorheriger Grundlagen analysiert und bewertet. Abschließend wird aufgezeigt, wie andere Unternehmen Defizite bei der Übermittlung von schützenswerten Dokumenten festestellen und bewerten können.
03.11.16	2017	extern	Bachelor	DE	Entwicklung intuitiver Interaktionsmöglichkeiten für die graphischen Auswertungen in der Software IngSoft InterWatt	?Intuitive Interaktion? gewinnt in den letzten Jahren als Qualitätsmerkmal von Soft-ware immer mehr an Bedeutung, dies gilt auch für die Energiemanagementsoftware IngSoft InterWatt. In der vorliegenden Bachelorarbeit wird zunächst auf die Bedeu-tung von intuitiver Interaktion und deren Merkmale eingegangen. Anschließend werden Vorgehensmodelle vorgestellt, die die Entwicklung von intuitiv bedienbarer Software sicherstellen sollen. Basierend auf diesen Erkenntnissen werden die beste-henden Interaktionsformen in den graphischen Auswertungen von IngSoft InterWatt optimiert und weitere Interaktionsmöglichkeiten umgesetzt. Abschließend werden Testverfahren aufgezeigt, die Probleme bei der Bedienung der Software im laufen-den Entwicklungsprozess aufzeigen und somit die Möglichkeit bieten, diese frühzei-tig zu beheben.
08.11.16	2017	intern	Master	DE	Prototypische Entwicklung einer Android App für ortsbasierte Dienste für mobiles Bezahlen in Stadien	Die Masterthesis bearbeitet die Thematik des mobilen Bezahlens in Stadien mit Mehrwertdiensten unter Android. Sie besteht im Wesentlichen aus zwei Teilen. Zunächst soll der Markt in Deutschland hinsichtlich anderer Applikationen, die das mobile Bezahlen ermöglichen, untersucht und die generelle Verbreitung dieser Bezahlmethode beleuchtet werden. Anschließend wird der Fokus auf das Stadion und dessen Stakeholder gesetzt. Eine Analyse wird Aufschluss darüber geben, inwiefern im Umfeld des Stadions die Bereitschaft bzw. die Infrastruktur gegeben ist, um ein derartiges System einführen zu können. Im zweiten Teil der Masterthesis wird auf Basis der Ergebnisse des ersten Teils ein Konzept erstellt. In diesem werden u. a. Anforderungen definiert, anhand derer die entsprechenden Technologien bewertet werden, um diese umsetzen zu können. Abschließend wird eine Applikation entwickelt, in der die Anforderungen mit Hilfe der evaluierten Technologien realisiert werden. Diese wird im Stadionumfeld das mobile Bezahlen ermöglichen und Mehrwertdienste bereitstellen
09.11.16	2017	extern	Master	DE	Die Konzeption und Validierung eines Entscheidungsmodells zur bedarfsorientierten Auswahl eines Datenbanksystems anhand einer prototypischen Implementierung einer Datenhaltungsschicht für ein Massendatenübermittlungssystem.	Die "Datenübermittlung" der DATEV eG sendet elektronische Meldungen an externe Kommunikationspartner (Banken, Finanzverwaltung, etc.) und holt Rückmeldungen für Steuerberater und Mandanten ab. Die Datenbestände liegen dabei aktuell im DATEV-Rechenzentrum auf einer VSAM-Datensammlung. Das Team möchte auf moderne Datenbanksysteme wechseln. Dabei stellt sich die Frage anhand welcher Entscheidungskriterien soll das bestmögliche Datenbanksystem ausgewählt werden. Die Masterarbeit umfasst die Konzeption und Validierung eines universell einsetzbaren Entscheidungsmodelles zur Auswahl geeigneter Datenbanksysteme. Mithilfe einer prototypischen Implementierung einer Datenhaltungsschicht für ein Massendatenübermittlungssystem soll das Entscheidungsmodell validiert werden. Die Validierung dessen stellt dabei keine allgemeingültige Aussage über das Entscheidungsmodell auf. Vielmehr dient die Validierung als Indikation, dass Anhand dieses Modells eine Entscheidung getroffen werden kann.
10.11.16	2017	extern	Bachelor	DE	Konzeption eines Proof of Concept-Modells für einen internationalen Softwarehersteller von In-Memory-Datenbanken.	Ein Proof of Concept ist für viele Unternehmen der erste Schritt, wenn es um die Evaluierung passender Software geht. Dabei ist es vor allem wichtig, dass die geprüfte Lösung richtig eingesetzt und integriert wird. Im Zuge der Bachelorarbeit wird deshalb für einen Softwarehersteller einer In-Memory-Datenbank ein Modell für einen durchgeführten Proof of Concept erarbeitet. Im Vordergrund steht dabei die Analyse der einzelnen Elemente eines Proof of Concept, sowie die Gestaltung möglicher Anwendungsfälle. Zu den betrachteten Bestandteilen gehört beispielsweise die Auswahl eines passenden Datenbankschemas oder das Erstellen von Methoden zur Performancemessung. Das Muster soll als Grundlage für Vertriebspartner sowie Mitarbeiter verwendet werden und über das User-Portal zur Verfügung gestellt werden.
11.11.16	2017	extern	Bachelor	DE	Beurteilung des Betriebsprüfungsrisikos anhand einer E-Bilanz: Konzeption und prototypische Realisierung eines Prüf- und Hinweissystems bei der DATEV eG	Seit spätestens 2013 sind bilanzierende Unternehmen verpflichtet ihre Jahresabschlussdaten elektronisch an das Finanzamt zu übermitteln. Durch eine automatisierte Analyse der gewonnenen Daten soll auch die Auswahl der Unternehmen für eine Betriebsprüfung seitens der Finanzverwaltung erheblich vereinfacht werden. Das Ziel der Bachelorarbeit ist die prototypische Realisierung eines Prüf- und Hinweissystems. Das System soll dem Anwender auf Basis einer E-Bilanz Hinweise geben, ob infolge bestimmter Konstellationen ein erhöhtes Betriebsprüfungsrisiko bei einem Unternehmen vorliegt. Dazu nimmt der Prototyp eine E-Bilanz entgegen und führt darauf Analysen auf Basis von Experten entwickelten Risikofaktoren durch. Durch die Ausgabe der Prüfungsergebnisse wird der Anwender über die potenziellen Risikofaktoren informiert. Der Prototyp dient als Vorstudie für eine spätere Implementierung.
11.11.16	2017	extern	Bachelor	DE	Arbeitsplatz 4.0 und digitales Arbeiten: Anforderungen an die IT-Landschaft einer Direktbank beim Transformationsprozess zum Digital Workspace	Im Rahmen der Digitalisierung der Arbeitswelt soll bei einer Direktbank die Flexibilisierung von Arbeitsorten, Arbeitsmitteln sowie Arbeitszeiten erfolgen. Das Ziel der Bachelorarbeit ist es, die Anforderungen an digitales Arbeiten und die dafür erforderliche technische und organisatorische Infrastruktur darzustellen. Hierfür sollen einzelne IT-Lösungen evaluiert und am Ende im Rahmen einer ganzheitlichen Systemlandschaft vorgestellt werden. Im Fokus stehen vor allem die Strategie einer individuellen und adäquaten Mitarbeiter-Cloud, die Sicherstellung von reibungslosen und ortsunabhängigen Zusammenarbeitsmöglichkeiten und die Einführung von Unified-Communications-Lösungen. Des Weiteren sollen zur Ergänzung der Thematik Umsetzungen des Digital Workspace am Beispiel ausgewählter Unternehmen vorgestellt sowie die psychologischen Anforderungen, Chancen und Risiken durch digitales Arbeiten betrachtet werden.
14.11.16	2017	extern	Master	DE	Evaluierung und Vergleich von Verfahren für einen Realtime-Recommendation Service 	Im Rahmen dieser Arbeit wurde ein Verfahren für einen Realtime-Recommendation Service in Zusammenarbeit mit dem Big Data Team der Immowelt AG entwickelt. Ziel dieser Entwicklung war es, neue Objektangebote in Echtzeit an passende Benutzer vermitteln zu können. Hierdurch sollten Benutzer noch schneller für sie passende Objektangebote empfohlen bekommen, als es bisher der Fall war. Zu diesem Zweck wurde nach einer Analyse der Anforderungen und Ziele ein Ansatz über ähnliche Objektangebote gewählt. Hierbei werden Objektangebote ermittelt, welche zu einem neuen Objektangebot ähnlich sind. Zu den ähnlichen Objektangeboten wiederrum werden Benutzer ermittelt, die ein hohes Interesse an diesen gezeigt haben. Dies folgt der Annahme, dass Benutzer, welche ein großes Interesse an den ähnlichen Objekten zeigen, auch an dem neuen Objektangebot ein hohes Interesse zeigen werden. Um ähnliche Objektangebote möglichst performant und zuverlässig ermitteln zu können, wurden verschiedene Ähnlichkeits- und Distanzmaße auf ihre Verwendbarkeit, sowie ihre Performance hin untersucht. Ebenso sind die Erkenntnisse, wie die Ausgangsdaten für möglichst gute Ergebnisse vorverarbeitet werden müssen, sowie die Auswahl der geeigneten Attribute dargestellt. Um den gewählten Ansatz kritisch zu hinterfragen, sind andere Ansätze dargestellt und werden mit dem gewählten Ansatz verglichen.
16.11.16	2017	extern	Bachelor	DE	Evaluierung und Analyse von CRM Systemen in einem KMU	Die effiziente Analyse und Verwaltung von Kundendaten gewinnt für kleine und mittelständische Unternehmen (KMU) zunehmend an Bedeutung. Die Kundenbeziehung kann auf diese Weise positiv beeinflusst werden und dies spiegelt sich mit steigendem Absatz wieder. Im Rahmen der Arbeit wird nach einer geeigneten Softwareunterstützung für das Verwalten und Analysieren der Kundendaten für die KMU geforscht. Im Zuge der Evaluierung werden verschiedene Open Source und kommerzielle CRM-Systeme miteinander verglichen. Dabei sollen unter anderem die firmeninternen Prozesse berücksichtigt werden. Des Weiteren sind wichtige Auswahlkriterien in Bezug auf die Funktionalität und die Beschaffenheit vom Unternehmen vorgegeben.
24.11.16	2017	extern	Bachelor	DE	Integration von Product Lifecycle Management und Application Lifecycle Management am Beispiel der Softwareprodukte Teamcenter PLM und Polarion ALM	Das Ziel der vorliegenden Bachelorarbeit ist es, die beiden Systeme Teamcenter PLM und Polarion ALM miteinander zu integrieren. Hierfür wird in erster Linie deutlich gemacht, wie die beiden Konzepte PLM und ALM zu verstehen sind und welche Rolle sie in der technisch fortgeschrittenen und automatisierten Welt der Produktentwicklung einnehmen. Es wird außerdem aufgezeigt, wie sich diese Konzepte unterscheiden und wie sie voneinander profitieren können, woraus Ansatzpunkte für eine erfolgreiche Integration der beiden Systeme abgeleitet werden können. Als nächstes wird der Wunsch des Auftraggebers nach dem Ausbau des Prozessverständnisses im Bereich PLM-ALM erfüllt. Hierfür werden ein spezifischer Prozess und eine Reihe von unterstützenden Prozessen konzipiert, welche den Informationsaustausch zwischen den beiden Systemen wiedergeben. Da sich diese Prozesse dank der Workflow-Designer in die beiden Systeme aufnehmen lassen, wird auf diese bei der Integration Bezug genommen. So lässt sich der Datenaustausch zwischen den beiden Systemen nach dem gewünschten Schema gestalten.
25.11.16	2017	extern	Bachelor	DE	 Evaluierung von Apache Flink und Apache Spark im Kontext der Echtzeitanalyse von Weblogdaten auf Fraud bei der ING-DiBa AG. 	Fraud und Betrüge über digitale Dienste sind für Finanzinstitute ein ernstes Problem. Im Zuge des Wandels der Bankenlandschaft werden digitale Dienste in Zukunft weiter in den Vordergrund für Banken rücken. Banken möchten hier so schnell wie möglich betrügerische Transaktionen stoppen können, um Kundenauswirkungen oder finanziellen Schäden der Bank und des Kunden entegegenzuwirken. Eine maschinelle Analyse von Transaktionsdaten ist hierbei aufgrund der Menge an Daten unerlässlich. Diese Arbeit beschäftigt sich mit der Analyse von Logdaten aus dem Online Banking der ING-DiBa AG und wie eine Frauderkennung mithilfe der Big Data Streaming APIs Apache Flink und Apache Spark ermöglicht werden könnte. Elementar ist hierbei die Implementation von Session Windows durch die genannten Applikationen. Es wird zunächst ein Überblick über nötige Kenntnisse für Big-Data-Systeme geschaffen und Fraud im Kontext der ING-DiBa AG spezifiziert, bevor ein Beweis der Umsetzungsfähigkeit der beiden Frameworks betrachtet wird. Darüber hinaus wird ein Vorschlag zur Visualisierung der Daten in Echtzeit gegeben, und vorgestellt wie ein produktiver Aufbau eines Systems aussehen könnte. Die Evaluation wurde mit einem Benchmark und verschiedener Konfigurationen von Multi-Node Clustern durchgeführt, wobei Apache Flink schneller Abschnitt als Apache Spark.
29.11.16	2017	extern	Bachelor	DE	Optimierte Verteilung von Speisen auf genormte Behälter in Großküchen	Während in der Logistikbranche Algorithmen zur Verteilung von Paketen in zum Beispiel LKW-Anhänger zur Optimierung und Kosteneinsparung zum Alltag gehören, ist es in Großküchen, wenn es darum geht Lebensmittel in genormte Gastro-Behälter optimiert und kostensparend zu transportieren ein Fremdwort. Im Rahmen dieser Bachelorarbeit, wird ein Algorithmus entwickelt und implementiert, der die Verteilung von Speisen aus Großküchen auf unterschiedlich genormte Gastro-Behälter (DIN EN 631 oder DIN 66075) optimiert. Da es sich hierbei um ein kombinatorisches Optimierungsproblem handelt wird als Basis hierfür das Bin-Packing-Problem herangezogen und analysiert. Es stellt sich heraus, dass der Approximationsalgorithmus ?Best-Fit-Decreasing? für das weitere Vorgehen sich am besten eignet. Dieser wird aufgrund der entsprechenden Bedingungen im realen Anwendungsfall in Großküchen modifiziert. Die anschließende Analyse zeigt die Merkmale zur Optimierung der Verteilung der Speisen über die Behälter auf. Aus den gewonnenen Erkenntnissen der theoretischen Untersuchungen wird der Algorithmus formuliert und implementiert. Zur weiteren Verbesserung der Verteilung als auch der Kostensenkung im Laufe des Einsatzes des Algorithmus im Großküchen wird ein Empfehlungssystem ausgearbeitet und ebenfalls zum Algorithmus implementiert. Damit die Ergebnisse des erarbeiteten Algorithmus rational bewertet werden können, wird eine Gütefunktion, die zur Bewertung der mehreren Lösungen, die der Algorithmus liefe
06.12.16	2017	intern	Bachelor	DE	Extraktion von 2d-Features aus Punktwolken	Durch Auswertung von optischen Signalen werden Hindernisse erkannt und in Punktwolken dargestellt. Für höhere Funktionen, beispielsweise die Klassifikation von Objekten ist diese Darstellung ungeeignet, da sie auf einem zu niedrigen Niveau befindet. In dieser Arbeit sollen die Hindernispunkte zu höherwertigen Objekten zusammengefasst werden. Solche Objekte werden auch Features genannt. Damit ist eine einfachere Repräsentation der Umwelt möglich. In dieser Arbeit sollen mindestens linienförmige Objekte und gekrümmte Objekte als Features extrahiert werden. Die Arbeit soll auf 2D-Daten operieren. Teil der Arbeit ist eine Recherche über existierende Arbeiten. Basierend auf dem Recherche-Ergebnis soll ein Ansatz für die Carbot-Umgebung realisiert und bewertet werden.
15.12.16	2017	extern	Bachelor	DE	Erweiterung eines XML-Diff-Algorithmus unter Berücksichtigung eines RELAX NG-Schemas 	In der vorliegenden Arbeit war das Ziel, einen XML-Diff-Algorithmus so zu erweitern dass es zusätzlich ein RELAX NG (Regular Language for XML New Generation) Schema berücksichtigt. Des Weiteren sollte ein Prototyp in der Programmiersprache Python implementiert werden, um ein bestehendes XML-Diff-Programm mit einem RELAX NG Schema zu ergänzen. Es sollte untersucht werden, welche Eigenschaften eines RELAX NG Schemas für einen XML-Diff-Algorithmus ausgenutzt werden können, um dessen Ausgabe zu optimieren. Die Ergebnisse zeigten, dass Standardwerte in Attributen einen Einfluss auf die Ausgabe eines XML-Diff-Algorithmus haben, wenn diese im Diff eingefügt oder gelöscht werden. Als zu untersuchender XML-Diff-Algorithmus wurde der Fast Match Edit Script (FMES)-Algorithmus ausgewählt. Hierzu wurde ein Konzept zur Erweiterung der Insert- und Delete-Phase des FMES-Algorithmus erstellt und dies in einem Prototypen implementiert. Eine Fallstudie hat gezeigt, dass der Prototyp erfolgreich falsche Ausgaben in der XML-Diff-Ausgabe ignoriert hat. Diese Bachelorarbeit ist für Studierende in Fachrichtung Informatik wie auch für Personen von Interesse, die ihre XML-Dokumente mit einem RELAX NG Schema strukturieren.
09.01.17	2017	extern	Bachelor	DE	Effiziente Voxelisierung von Dreiecksnetzen	In dieser Arbeit wird ein Algorithmus zur Umwandlung von Dreiecksnetzen in Voxelvolumen entwickelt. Dieser kann sowohl eine Oberflächen- als auch eine solide Voxelisierung (engl. Surface / Solid Voxelization) des Netzes erstellen. Hierfür wird ein dünner Abschnitt schichtweise entlang einer Achsenrichtung durch das Dreiecksnetz verschoben. Dieser Abschnitt dient als Sichtbereich für einen OpenGLViewport, dessen Frame Buffer ausgelesen und die Pixel-Farbwerte in Voxel umgewandelt werden. Der Algorithmus ist in OpenGL 3.3.0 implementiert und wird anhand verschiedener Dreiecksnetzdatensätze evaluiert.
01.02.17	2017	extern	Master	DE	 Risikomanagement in der IT-Dienstleistungsbranche im Kontext der aktuellen Marktsituation	Risiken besitzen eine ambivalente Bedeutung für Unternehmen, da sie einerseits durch die verbundenen Chancen den Fortschrittbestand sichern und andererseits im Schadensfall unter Umständen die Unternehmensexistenz gefährden. Die IT-Lösungsbranche steht neben den alltäglichen Unternehmensrisiken durch Trends wie Cloud Computing unter steigendem Wettbewerbs- bzw. Preisdruck. Die Arbeit hat die Untersuchung der Auswirkungen der aktuellen Entwicklungen auf Risikomanagementprozesse bei IT-Lösungsanbietern zum Ziel. Der Fokus liegt dabei auf dem Angebotsprozess. Zentrale Fragestellung ist, ob und ferner wie bei IT-Lösungsanbietern der Umgang mit Risikofaktoren durch die Marktsituation beeinflusst wird. Die Untersuchung im Rahmen der Arbeit erfolgt in Kooperation mit der DXC Technology Group durch einen ethnographischen Ansatz und stellt fest, dass das in den Angebotsprozess integrierte Risikomanagement insbesondere durch die Neufassung der Delegation of Authority zukunftsweisend implementiert ist. Nichtsdestotrotz lassen die Erkenntnisse insbesondere im Hinblick auf die Erfassung unscharfer Risikofaktoren erkennen. Die Arbeit schlägt ein in den Angebotsprozess integriertes regelbasiertes Fuzzy-Expertensystem zur Risikobeurteilung und weiterhin zur Entscheidungsunterstützung hinsichtlich Verkaufstransaktionen vor.
01.02.17	2017	extern	Master	DE	 Training eines automatischen Spracherkenners mit Hilfe neuronaler Netze und Integration in ein Dialogsystem	Die Firma Elektrobit Automotive GmbH entwickelt die Software EB GUIDE zur Modellierung von grafischen Benutzerschnittstellen. Durch die Erweiterung EB GUIDE Speech Extension gibt es zusätzlich die Möglichkeit der Modellierung von Sprachdialogen in EB GUIDE. In dieser Arbeit sollen mit Hilfe eines Spracherkennungs-Toolkits akustische Modelle und Sprachmodelle unter Einsatz von neuronalen Netzen trainiert werden und in das Tool als zusätzlicher Spracherkenner integriert werden. Ziel ist es, für einen vorhandenen Trainingskorpus und ein domänenspezifisches Vokabular eine möglichst geringe Wortfehlerrate zu erzielen bzw. durch eine geeignete Abbildung der erkannten Phrasen auf Kommandos die Fehlerrate auf Dialogschrittebene zu minimieren. Darüber hinaus soll der Spracherkenner in eine vorhandene Softwarearchitektur integriert werden.
14.02.17	2017	intern	Bachelor	DE	Konzeption und Entwicklung einer effizienten Datenstruktur für Punktwolken	Ziel dieser Bachelorarbeit ist es, eine Datenstruktur zu entwickeln, die einen zeitlich effizienten Zugriff auf eine zweidimensionale Punktwolke ermöglicht. Im Rahmen dieser Arbeit soll zunächst die aktuelle Verfahrensweise analysiert und anschließend alternative Strukturen recherchiert werden. Die zu entwickelnde Datenstruktur soll anschließend in die Carbot-Umgebung integriert werden. Hierbei sollen geometrische Anfragen, wie z.B. die Suche nach den nächst gelegenen Punkten innerhalb der Punktwolke oder die Suche nach Punkten innerhalb eines Rechtecks beantwortet werden können. Um effiziente geometrische Anfragen zu ermöglichen, ist eine räumliche Indizierung der Punktwolke notwendig. Datenstrukturen für Punktwolken werden in der Carbot-Umgebung für eine Vielzahl von Software-Komponenten benötigt. Eine mögliche Effizienzsteigerung wird abschließend, anhand typischer Aufgaben der Carbot-Umgebung, analysiert und ausgewertet.
20.02.17	2017	intern	Master	DE	Konzeption und prototypische Implementierung einer E-Learning Plattform für Data Science	Innerhalb der Masterthesis soll die Thematik eines E-Learning Einsatzes, innerhalb einer Hochschulvorlesung, im Themenumfeld Data Science behandelt werden. Die Arbeit besteht aus vier Teilen. Im ersten Teil werden die Grundlagen von Data Science und E-Learning behandelt. Im Data Science Teil werden zudem Prozesse für die Umsetzung von Data Science Projekten, sowie einige Analysemodelle vorgestellt. Der E-Learning Teil behandelt Didaktik Grundlagen und stellt einige Module für eine Umsetzung vor. Abschließend werden Evaluationskriterien und -methoden vorgestellt, für die Überprüfung eines erfolgreichen Einsatzes. Im zweiten Teil werden Data Science E-Learning Plattformen verglichen. Hierfür wird ein Scoring Model, mit unterschiedlichen Kriterien, erstellt. Zudem werden sechs E-Learning Plattformen für Data Science vorgestellt und bewertet. Der dritte Teil behandelt die Erstellung eines Konzeptes für den Einsatz. Erst wird die Plattformauswahl, auf Basis des Plattformvergleiches, getroffen. Anschließend wird ein Didaktik Konzept für die Umsetzung auf der gewählten Plattform erstellt. Außerdem wird auf die Bestandteile der Umsetzung eingegangen. Darunter sind die einzelnen Kapitel, sowie die Evaluierung des Lernerfolgs, zu verstehen. Im letzten Teil der Arbeit wird auf die prototypische Implementierung der Plattform eingegangen. Von der Installation der Plattform bis zur Bedienung dieser. Ebenso die Erstellung der einzelnen Kapitel wird näher erläutert.
23.02.17	2017	extern	Master	DE	Konzipierung eines Reifegradmodels für Wissensmanagement nach dem ISO 33000 Standard	Untersuchung und Analyse der Kernbegriffe "Daten", "Information", "Wissen" und "Wissensmanagement". Anschließende Definition der Begriffe für die komplette Ausarbeitung. Untersuchung und Analyse ausgewählter Prozess- und Wissensmanagementmodelle mit anschließender Reflexion der Ergebnisse. Konzipierung eines Reifegradmodells für Wissensmanagement nach dem ISO/IEC 330XX Standard.
01.03.17	2017	intern	Master	DE	Entwurf und prototypische Entwicklung eines natürlichen Dialogsystems im Kontext von Unterhaltung, Websuche und E-Commerce	Der natürliche Dialog ist ein einfach zu lernender und barrierefreier Weg, ein System zu bedienen. Dialogsysteme, auch Konversationsagenten genannt, finden seit Jahren in verschiedenen Formen in den unterschiedlichsten Bereichen Anwendung. Um den Nutzern ein möglichst positives Nutzungserlebnis (UX) zu ermöglichen, soll ein Dialog natürlich wirken. Menschen lernen relativ früh, mit ihrer Umwelt zu kommunizieren und haben dadurch jahrelange Erfahrung mit Dialogen. Sie bemerken sehr schnell, wenn ein Dialog unnatürlich verläuft. Viele Dialogsysteme versorgen den Nutzer mit Informationen, diese basieren auf Daten. Die Quelle dieser Daten kann eine Datenbank, allerdings auch eine Sammlung unstrukturierter Daten (z. B. Text) sein. Um dem Nutzer die gewünschten Daten zu liefern, muss die Anfrage des Nutzers in eine Abfrage (Query) umgewandelt werden. Je konkreter diese Abfrage ist und je genauer sie mit der Intention des Nutzers übereinstimmt, desto hilfreicher ist die Ant-wort des Systems an den Nutzer. Damit ein Dialogsystem Nachfragen eines Nutzers beantworten kann, benötigt es Antworten in Form von Informationen, die als strukturierte Daten abrufbar sein müssen. Eine große Sammlung an Informationen befindet sich in Form von unstrukturierten Daten (Text) auf Webseiten und elektronischen Dokumenten im Internet. Um diese Daten in eine strukturierte Form zu überführen, werden Methoden aus der Computerlinguistik (CL) auf Texte angewendet, welche von Webseiten extrahiert wurden.
01.03.17	2017	intern	Bachelor	DE	Ein Ansatz zur Steigerung der Aussagekraft von Online-Bewertungen von Grafiken 	Die vorliegende Bachelorarbeit beschäftigt sich damit, Möglichkeiten zu ermitteln um den Informationsgehalt und die Qualität von Bewertungen von Grafiken zu erhöhen. Hierzu wurde die Hypothese aufgestellt, dass durch den Einsatz eines mehrdimensionalen Bewertungssystems, eine Steigerung der Bewertungsqualität zu erwarten ist. Um die Hypothese zu überprüfen wurde eine Evaluation durchgeführt, die ein mehrdimensionales mit einem eindimensionalen Bewertungssystem vergleicht. Die Evaluation wurde von ausgewählten Testpersonen ausgeführt, die beide Bewertungssysteme unter bestimmten Vorgaben genutzt haben. Anschließend wurden die Testpersonen einer Befragung unterzogen. Anhand der gewonnenen Daten kann durch den Einsatz eines mehrdimensionalen Bewertungssystems eine Erhöhung der Qualität nachgewiesen werden, welche allerdings durch die kleine Stichprobe eher als Tendenz gewertet werden kann.
01.03.17	2017	intern	Master	DE	Generative Adversarial Networks zur Manipulation von Bildern	Diese Masterarbeit befasst sich mit einem neuartigen Ansatz im Bereich des maschinellen Lernens, welcher von einem Forscherteam um I. Goodfellow im Jahre 2014 vorgestellt wurde. Der dabei veröffentlichte Ansatz der "Generative Adversarial Networks" (kurz GANs) ist dazu in der Lage, den Aufbau und die Struktur von komplexen Elementen aus großen Datenbanken unbeaufsichtigt zu erlernen. Da die Verteilung von Bildern aus großen Datenbanken bisher kaum zu erlernen war, sind GANs durch diese Eigenschaft besonders in der Forschung im Bereich der Bildverarbeitung sehr populär. Dies führte bereits zu einem enormen Schub an Veröffentlichungen und somit auch zu neuen Ein- satzgebieten im Bereich der Bildverarbeitung. Erlernen GANs beispielsweise den Aufbau und die Struktur von Gesichter in einer Gesichts-Datenbank, so kann dieses Wissen anschließend dazu eingesetzt werden, um neue Gesichter zu generieren oder realistische Manipulationen an Gesichts-Attributen durchzuführen. Ziel dieser Arbeit ist es daher ein fundiertes Grundwissen über die Technik der GANs zu vermitteln, einen Überblick über die aktuellen Einsatzbereiche der GANs im Bereich der Bildverarbeitung zu liefern sowie die Umsetzung und Evaluierung der GANs in den Bereichen der Super-Resolution und der Transformation von Häuser-Skizzen in Häuser-Fotos.
01.03.17	2017	extern	Master	DE	Gestenerkennung und virtuelle Eingabemöglichkeiten mittels Myo-Armband in labor- und medizintechnischen Umgebungen	Durch ein EMG-Armband ist es möglich Muskelbewegungen, welche durch Gesten mit der Hand, dem Arm oder auch bei Fingerbewegungen auftreten, zu erfassen. Hierdurch kann eine Anwendung realisiert werden, die ohne Berührungen mit Standard-Eingabegeräten auskommt. Ein äußerst interessanter Anwendungsfall ist hierbei die Verwendung bei Computersystemen in Reinräumen oder ähnlich stark hygienisch reglementierten Standorten, bei denen darauf Wert gelegt wird, möglichst wenige Oberflächen mit den Händen berühren zu müssen. Im Speziellen können dies labor- oder medizintechnische Umgebungen sein. Dieses Konzept wird hierbei anhand eines exemplarischen Showcases in Zusammenarbeit mit der infoteam Software AG umgesetzt.
01.03.17	2017	intern	Master	DE	Entwicklung einer OpenCL-Implementierung für die VideoCore IV GPU des Raspberry Pi	Die VideoCore IV GPU der Raspberry Pi Modelle besitzt im Vergleich zu den Host-CPUs eine sehr viel höhere Rechenleistung. Diese bleibt in vielen Einsatzgebieten von Raspberry Pi größtenteils ungenutzt, da es keine einfach zu verwendende Programmiersprache und Schnittstelle gibt, mit deren Hilfe die GPU für nicht-grafische Anwendungen verwendet werden kann. In dieser Arbeit wird eine OpenCL-Implementierung für die VideoCore IV GPU erstellt, die es ermöglicht, nicht-grafische Berechnungen auf der GPU auszuführen. Implementiert werden die OpenCL-Laufzeitbibliothek für den hostseitigen Zugriff, ein Compiler zum Umwandeln von OpenCL C-Quellcode in Maschinencode und die GPU-seitige Standardbibliothek mit häufig verwendeten Funktionen. Für die Teile dieser Arbeit werden die relevanten Ausschnitte der Vorgaben durch den OpenCL-Standard sowie deren Umsetzung beschrieben, wobei auf interessante Teilbereiche und Problemlösungen besonders eingegangen wird. Anhand von vorhandenen Anwendungen wird gezeigt, dass die entstandenen Implementierung bereits erfolgreich auf OpenCL basierende Programme ausführen kann und wie weit sie für einen produktiven Einsatz geeignet ist. Ebenso wird aufgezeigt, dass diese Implementierung bei rechenaufwendigen Aufgaben die Performance der Host-CPUs weit übertrifft sowie in welchen Fällen die Host-CPU eine bessere Performance bietet.
01.03.17	2017	extern	Bachelor	DE	Evaluation von Methoden zur transparenten Bereitstellung von Daten aus Datenbanken mit unterschiedlichen Schemata	Diese Bachelorarbeit befasst sich mit der Evaluation und prototypischen Implementierung von Verfahren, mit denen einer Anwendung die Daten aus mehreren MySQL-Datenbanken bereitgestellt werden können. Als Anwendungsfall wird dabei eine PHP-Software betrachtet die bisher nur auf eine der Datenbanken zugreift. Aus Anwendungssicht soll sich dies nicht ändern. Eine Modifikation des Quellcodes der Anwendung sowie deren Datenbankabfragen soll nicht vorgenommen werden. Die Datenbanken haben einen teils unterschiedlichen, teils redundanten Datenbestand sowie historisch gewachsene und voneinander abweichende Schemata. In der Bachelorarbeit werden mehrere Softwaresysteme auf die Erfüllung der oben genannten Anforderungen überprüft sowie ein Konzept für die Integration der Daten erarbeitet. Als geeignet stellt sich Software heraus, die über Fähigkeiten aus den Bereichen Data Virtualization sowie Data Federation verfügt. Für das Konzept zur Datenintegration wird je ein Prototyp mit der Software PostgreSQL und teiid erstellt.
01.03.17	2017	extern	Bachelor	DE	Wissensmanagement im Wealth Management einer international agierenden Großbank	Ziel dieser Arbeit ist der prototypische Aufbau eines Wissensmanagementsystems, das als Alternative zur jetzigen suboptimalen Kommunikation eingesetzt werden kann. Durchgeführt wurde die Arbeit zusammen mit dem Geschäftsbereich Wealth Management der BNP Paribas. Dieser Bereich bietet Vermögensberatung und -verwaltung für vermögende Privatkunden an. Durch die aktuelle Verbreitung von Informationen besteht ein hohes Risiko, dass neue Mitarbeiter Prozesse falsch ausführen. Dadurch können sich im Banking-Bereich Verstöße gegen das Aufsichtsrecht ergeben. Diese Problematik verschärft sich durch das starke, dynamische Mitarbeiterwachstum der Abteilung, sowie der schnellen Veränderung der regulatorischen Rahmenbedingungen, insbesondere in der Vermögensberatung. Mithilfe eines Wissensmanagementsystems soll es allen Mitarbeitern des Geschäftsbereichs Wealth Management möglich sein, jederzeit die für sie relevanten Informationen einsehen zu können, um die Fehlerquote auf ein Mindestmaß zu reduzieren und die Qualität der Kundenberatung zu Erhöhen. Es werden aktuelle Kommunikationswege analysiert und ein Soll-Konzept erstellt. Des Weiteren wird zum einen der Ist- und Soll-Zustand modelliert und verglichen, zum anderen wird der aktuelle Beratungsprozess modelliert. Basierend auf den gewonnenen Erkenntnissen wird das erstellte Konzept in einer prototypischen Lösung umgesetzt.
06.03.17	2017	extern	Bachelor	DE	Sicherstellung der einheitlichen Auskunftsfähigkeit des Onsite Supportes.	Thema der Arbeit: Sicherstellung der einheitlichen Auskunftsfähigkeit des Onsite Supportes Zusammenfassung der Arbeit: Ziel dieser Bachelorarbeit ist es, die Auskunftsfähigkeit des Onsite Support (Service Desk von Siemens Healthineers Erlangen) versuchen mit geeigneten Vorschlägen zu verbessern bzw. zu vereinheitlichen. Im Rahmen der Abschlussarbeit wird eine Bewertung, durch systematische Gegenüberstellungen der aktuell eingesetzten Kommunikations- und Informationswerkzeuge für die Eignung der einheitlichen Auskunftsfähigkeit, durchgeführt. Ferner ist ein wichtiger Untersuchungsgegenstand der Arbeit die gründliche Analyse des Soll-Zustandes und Informationsbedarfes des Onsite Supportes und der beteiligten Geschäftsbereiche, mittels (qualitativer) Interviews. Als Abschluss werden drei unterschiedliche Vorschläge gezeigt, welche die Auskunftsfähigkeit vereinheitlichen könnten. Die Einführung eines Geschäftsprozesses, die Reduktion des E-Mail-Verkehrs und die Kombination von Enterprise Social Software ergeben die vorgeschlagenen Möglichkeiten.
09.03.17	2017	extern	Master	DE	Real-Time Data Streaming - prototypischer Vergleich von technischen Lösungen	Diese Master Thesis dient zur Durchführung eines prototypischen Vergleichs von Stream Processing Frameworks. Dieser soll genutzt werden, Auswahlprozesse eines solchen Frameworks transparent zu machen und eine objektive Auswahl im Rahmen einer Entscheidungsfindung zu treffen. Im Rahmen dessen werden im ersten Abschnitt der Arbeit grundlegende Begriffe wie Streaming Daten, Eventzeit und Pattern der Verarbeitung vorgestellt und architektonische Hintergründe beschrieben. Grundlage des prototypischen Vergleichs bilden eine Auswahl von beschriebenen Stream Processing Frameworks. Zum Zweck einer näheren und detaillierteren Betrachtung werden im Folgenden die Frameworks Spark Streaming, Flink und aufgrund von betrieblichen Vorgaben Informatica Intelligent Streaming ausgewählt. Ein konzeptioneller Entwurf einer sogenannten Real-Time Streaming Architektur wird im Anschluss an den Auswahlprozess genutzt, um eine optimale Implementierung der ausgewählten Frameworks zu gewährleisten. Im Weiteren beschreibt diese Arbeit den konzeptionellen Vorgang zur Erstellung einer Bewertungsmatrix, welche eine Evaluierung von Stream Processing Frameworks gewährleistet. Mit Hilfe dieser und der Breitstellung einer Real-Time Streaming Architektur wird in Folge dessen der prototypische Vergleich durchgeführt und die Ergebnisse evaluiert und vorgestellt. Ein Fazit und Ausblick auf mögliche weiterführende Arbeiten und die Entwicklung von Data Streaming in den nächsten Jahren bilden den Abschluss der Arbeit.
10.03.17	2017	intern	Bachelor	DE	Konzeption und Implementierung einer Softwarelösung zur Planung und Durchführung von Handballturnieren	In dieser Arbeit wurde untersucht, wie eine softwareseitige Hilfestellung für die Planung und Durchführung von Beachhandball-Turnieren bei einem Nürnberger Sportverein gewährleistet werden kann. Hierfür sind eine Ist- und Schwachstellenanalyse durchgeführt und ein Anforderungskatalog erstellt worden. Die Arbeit besteht aus einem fachlichen Konzept, welches die die zum Einsatz einer solchen Software relevanten Features aufzeigt und erklärt. Zusätzlich wurde untersucht, wie eine Softwarelösung durch beratende Komponenten über ein obligatorisches Maß hinaus nützlich sein kann. Auch wurde der Versuch unternommen, die konzipierte Softwarelösung zu implementieren und die hierfür eingesetzten Technologien und Methoden ausführlich dokumentiert.
13.03.17	2017	intern	Bachelor	DE	Analyse der Programmiersprache Go	Go ist eine Programmiersprache die vom Unternehmen Google Inc. entworfen wurde, um dessen Probleme im Entwicklungsprozess zu lösen. In dieser Arbeit soll die Programmiersprache Go analysiert werden. Hierfür wird eine Auflistung ausgewählter Features aufgestellt, welche für einer genaueren Analyse vorgesehen sind. Anschließend erfolgt eine Gegenüberstellung der Einträge mit vergleichbaren Features anderer Programmiersprachen, um konzeptionelle und inhaltliche Unterschiede herauszuarbeiten. Zusätzlich wird beschrieben, wie sich konzeptionelle Unterschiede verschiedener Sprachen auf die Architektur der mit Go entwickelten Software auswirken. Bei ausgewählten Features wird genauer auf die konkrete Implementierung eingegangen. Der Schwerpunkt soll auf Nebenläufigkeit und die Speicherverwaltung von Go gelegt werden.
13.03.17	2017	extern	Bachelor	DE	Software Architektur zur Entwicklung von Cross-Plattform Casual Games	Im Rahmen der Arbeit soll eine Software Architektur entstehen, welche auf die verschiedenen Bereiche bei der Erstellung von Cross-Plattform Games eingeht. Die Bereiche unterteilen sich in den Plattform unabhängigen Teil und die von der jeweiligen Plattform abhängigen Teile. Hierfür eignet sich Beispielsweise das Model-View-ViewModel Modell (kurz MVVM). Ziel ist eine Software Architektur und Plattform Spezifische Templates, mit deren Hilfe Entwickler direkt mit der Entwicklung der Spiele beginnen können, ohne erst die Grundlagen schaffen zu müssen.
15.03.17	2017	extern	Bachelor	DE	Entwicklung eines Verfahrens zur Risikoanalyse nach DSGVO im Hinblick auf Rechte und Freiheiten der Betroffenen	Im Mai 2018 wird die am 27. April 2016 durch das Europäische Parlament und dem Europäischen Rat verabschiedete Verordnung 2016/679 zum Schutz der natürlichen Personen bei der Verarbeitung personenbezogener Daten, zum freien Datenverkehr und zur Aufhebung der Richtlinie 95/46/EG (DSGVO) wirksam. Ziel dieser Verordnung ist es, den Datenverkehr in Europa zu vereinfachen und einen Schutz zu schaffen, durch den die Verarbeitung personenbezogener Daten europaweit harmonisiert wird. Ein wesentlicher Teilaspekt der DSGVO sind die Anforderungen an die Risikoanalyse, die den Schutzbedarf bei der Verarbeitung personenbezogener Daten klassifizieren soll. Diese sollen im Rahmen dieser Bachelorarbeit ausgearbeit und mittels einer Software-Lösung für eine Risikoanalyse, Risikobewertung und zur Einhaltung der gesetzlich vorgeschriebenen Nachweispflichten abgebildet werden.
15.03.17	2017	intern	Bachelor	DE	Positionsbestimmung unter Einsatz von Isovist-Merkmalen	Bei dem Carbot handelt es sich um einen autonomen, mobilen Roboter, der eine Plattform zur Entwicklung von Verfahren und Algorithmen im Bereich autonome Robotik bietet. Zu der Hardwareausstattung des Carbots gehört ein 360°-Laserscanner, welcher die Entfernung zu Objekten misst, wie auch eine Ultraschall-basierte Hinderniserkennung. Im Carbot-Projekt soll ein Verfahren zur Positionsbestimmung anhand von ermittelten Isovist-Merkmalen entwickelt werden und als optionale Softwarekomponente im Carbot integriert und bewertet werden. Dazu gehört zum einen die Recherche über bestehende Ansätze zur Positionsbestimmung, die Auswahl sinnvoller Isovist-Merkmale und die Realisierung der Merkmalsextraktion anhand der gelieferten Daten des 360°-Laserscanners. Bei der Umsetzung soll auf Basis der extrahierten Merkmale ein Fingerprint gebildet werden, um die Position des Carbots zu bestimmen.
15.03.17	2017	intern	Bachelor	DE	Analyse von inkrementellen, rasterbasierten Navigationsverfahren für autonome, mobile Roboter	Für den Carbot existiert die Navigationskomponente GAA (Grid-based A* Advanced), die eine Punkt-zu-Punkt-Wegeplanung vorbei an Hindernissen durchführt. In dynamischen Umgebungen ändert sich die wahrgenommene Umwelt ständig, alleine schon dadurch, dass während der Fahrt neue Hindernisse erfasst werden (z.B. weil sie in den Sichtbereich der Kamera kommen). Klassische A*-Ansätze müssen bei Änderung der Hinderniskarte die Planung komplett neu durchführen. Im Gegensatz dazu versuchen inkrementelle Ansätze soviel wie möglich aus einer alten Planung wiederzuverwenden und berechnen eine neue Route auf der Basis der inkrementellen Änderungen. Das kann Ressourcen schonen, allerdings ist die Planung komplexer. In dieser Arbeit sollen in der Literatur beschriebene inkrementelle Ansätze (z.B. D*, Focussed D*, D* Lite) analysiert und teilweise implementiert werden. Eine Auswertung soll diese dann mit nicht-inkrementellen Ansätzen (A* oder GAA) vergleichen.
15.03.17	2017	intern	Bachelor	DE	Konzept und Implementierung der Simulation grundlegender Smart-Home-Konzepte	Im Rahmen dieser Arbeit wird ein Prototyp entwickelt und beurteilt. Thema ist das Feld Heimautomatisierung, mit einer Zielgruppe von wenig technik-affinen Nutzern. Ziel des Prototyps ist es, interaktiv zu veranschaulichen worauf es bei Smart Homes und insbesondere der Heimautomatisierung ankommt. Dazu wird dazu zusätzlich eine Nutzerstudie durchgeführt. Es werden Designentscheidungen und Vorgehensweise erörtert und die Ergebnisse einer eigenen Bewertung sowie die Ergebnisse und Anregungen aus der Nutzerstudie diskutiert. Der entstandene Prototyp wurde von den Nutzern positiv entgegengenommen und könnte eine gute Basis für eine Weiterentwicklung bzw. einen zweiten Prototyp dienen.
18.03.17	2017	extern	Bachelor	DE	Erkennung von Zählerständen statischer Verbrauchszähler mittels einer mobilen Applikation	Die vorliegende Bachelorarbeit beschäftigt sich mit der automatischen Mustererkennung und Auswertung der Zählerstände von statischen Gas- und Stromzählern mit Hilfe einer Smartphone Applikation. Durch verschiedenste Störfaktoren, wie z.B. Lichtverhältnisse oder Typenvielfalt der Zähler, ist das manuelle Ablesen der Zählerstände langsam und fehleranfällig. Hier wäre eine schnelle, genaue und automatisierte Erfassung der Zählerstände von großem Nutzen. Einerseits für die Energieversorger durch Kosteneinsparung, andererseits für Privatpersonen durch eine einfache Überwachung des Verbrauchs. Ziel ist es die Zählerstände zu erkennen, eine einfache Handhabung der Applikation zu erreichen, die fehlerrelevanten Faktoren zu präzisieren und mögliche Lösungen zu skizzieren. In Zusammenarbeit mit den Stadtwerken Erlangen AG und der Firma Method Park soll eine mobile Softwareanwendung entworfen und implementiert werden. Sie soll auf den vorhandenen Bibliotheken "OpenCV", für die Bildverarbeitung, und "Tesseract", für die Texterkennung, basieren. Als Ergebnis sollen die Bildverarbeitungsschritte aufgezeigt sein, die zur möglichst besten Texterkennung benötigt werden. Außerdem sollen die am häufigsten in der Praxis vorkommenden Störfaktoren mit Hilfe der Applikation sowie mögliche Lösungsansätze zur Behebung dieser erarbeitet werden. Diese Arbeit soll durch die automatisierte Erkennung von Zählerständen einen Beitrag für den Bereich der zukunftsweisenden Heimautomatisierung leisten.
18.03.17	2017	extern	Bachelor	DE	Neukonzeption und -implementierung einer bestehenden Client-Server-Anwendung mit aktuellen Web-Technologien 	Diese Arbeit befasst sich mit der Neu- bzw. Weiterentwicklung einer bestehenden Client-Server-Anwendung mit aktuellen Web-Technologien. Als Anwendungsfall dient hier die Zeiterfassungs-Anwendung der Firma mediendesign AG. Ziel soll es sein diese Anwendung für die Mitarbeiter mobil nutzbar zu machen, also primär für Android- und iOS-Geräte. Hierfür sollen Abwägungen getroffen werden, welche der derzeit gängigen oder auch der neuesten Web-Technologien sich am Besten dafür eignen. Dabei werden unter Anderen die Kosten und die User Experience der zur Verfügung stehenden Techniken eine Rolle spielen. Mit der ausgewählten Technologie soll die Anwendung dann implementiert und evaluiert werden. Hierbei stehen eine bessere Usability der Anwendung und eine mögliche Zeitersparnis bei der Nutzung im Vordergrund.
21.03.17	2017	extern	Master	DE	Inhalts- und Stimmungsanalyse von Kundenfeedback im Automotiveumfeld	Diese Arbeit beschreibt eine Vorgehensweise zur Analyse von Feedback-Daten für den Bereich der Text-Kategorisierung in Bezug auf Stimmung und Inhalt, mit einem Vergleich von unterschiedlichen Lösungen aus dem "as-a-Service"- und Open-Source-Bereich. Die Feedback-Daten sind auf die Automotive-Domäne ausgelegt und werden im Zuge von Natural-Language-Processing-Schritten aufbereitet und jeweils als Ganzes analysiert. Das Trainieren eigener Modelle erfolgte mit unterschiedlichsten Datensätzen, wovon einer nur Automotive-Themen behandelt. Durch das Fehlen von Trainingsdaten im Bereich der Inhaltsanalyse wurden Bootstraping-Methoden und Semi-Supervised-Learning-Algorithmen exploriert, um durch die Hinzunahme von nicht gelabelten Daten einen möglichst guten Klassifikator zu erzeugen. Alle Lösungen wurden sowohl anhand der Feedback-Daten über die Metriken Accuracy, Precision und Recall, als auch über unterschiedliche Eigenschaften wie z.B. den verwendeten Algorithmen, Kosten, Lizenzen und Sprachunterstützungen verglichen. Am Ende wird ein mögliches Konzept anhand einer Lösung dargestellt.
21.03.17	2017	extern	Bachelor	DE	Prozessoptimierung der Wareneingangserfassung und Kontrolle in der Entsorgungswirtschaft am Beispiel der GfM Gruppe und Ihrer Unternehmen	Die Arbeit beschäftigt sich auf Grundlage des Kreislaufwirtschaftsgesetzes im Allgemeinen mit dem Wareneingang in der Entsorgungswirtschaft und im speziellen mit den Schwachstellen und dem Ziel der daraus resultierenden Optimierungsmöglichkeiten. Bei der Beschreibung und Analyse der Teilschritte Erfassung, Kontrolle und Dokumentation des Wareneingangsprozesses in einem Unternehmen werden gängige Methoden aus der Fachliteratur angeführt. Nach der Analyse der Ist-Situation bei der GfM Gruppe werden Schwachstellen ermittelt und in Korrelation mit den bereits angeführten Methoden gesetzt. Anhand der aussagekräftigen Bewertungen der Methoden in Bezug auf die erarbeiteten Kriterien und analysierten Schwachstellen durch die Nutzung von Scoring-Modellen, wird eine konkrete Handlungsempfehlung erarbeitet. Dabei ergibt sich, dass sowohl Optimierungspotenziale möglich sind, aber auch teilweise durch vorherrschende Rahmenbedingungen verhindert werden. Durch eine anschließende prototypische Entwicklung dieser Empfehlung in Form eines webbasierten IT-Systems wird das zuvor erarbeitete technische Konzept umgesetzt. Auch mögliche weitere Integrationsansätze werden dabei exemplarisch dargestellt. Durch das prototypische System ist ein anschließender direkter Vergleich mit der bisherigen Situation im Wareneingang der GfM Gruppe möglich und belegte, dass erhebliche zeitliche Einsparungen durch eine Prozessoptimierung im Wareneingang realisierbar sind.
22.03.17	2017	extern	Bachelor	DE	Konzeption und Entwicklung eines Dashboards zur Visualisierung von Protokollbäumen bei Siemens Healthcare	Kurzzusammenfassung Die vorliegende Arbeit befasst sich mit der Konzeption und Entwicklung eines Dashboards zur dynamischen Visualisierung von Protokollbäumen bei Siemens Healthcare GmbH. Den Hauptteil dieser Arbeit bildet ein Vergleich der Levenshtein Distanz, Jaro Distanz, Longest Common Subsequence und Longest Common Substring Algorithmen für Zeichenkettenvergleiche. Ziel hierbei ist es diese Algorithmen zu klassifizieren und zu vergleichen, um den geeignetsten Algorithmus für Vergleichsanalysen zu finden. Ein weiterer Fokus liegt auf der Suche nach Implementierungsmöglichkeiten des ausgewählten Algorithmus für eine dynamische Ausführung spontaner Benutzerabfragen. Im praktischen Teil dieser Abschlussarbeit wurde ein Dashboard im Business Intelligence Tool QlikView implementiert. Nach einer Ausgangssituationsanalyse wurden zunächst die Anforderungen festgelegt, die im Dashboard erfüllt werden sollten. Um die benötigten Daten zu integrieren, wurde ein ETL-Prozess verwendet. Für benutzerfreundliche Datenauswertungen wurden verschiedene Visualisierungsmöglichkeiten in das Dashboard eingesetzt.
22.03.17	2017	intern	Bachelor	DE	Maschinelles Lernverfahren zur Strukturierung von Stellenanzeigen	Diese Arbeit ist eine Bachelorarbeit über das Thema: Maschinelles Lernverfahren zur Strukturierung von Stellenanzeigen. Zuerst wird im ersten Kapitel das Thema eingeleitet. Dabei wird die Motivation erläutert und das Ziel der Arbeit festgehalten. Der Aufbau der Arbeit wird angesprochen und Voraussetzungen zum Verständnis dieser werden spezifiziert. Im nächsten Kapitel wird das Anwendungsszenario beschrieben. Darin wird der Ablauf wiedergegeben, der notwendig ist, damit Unternehmen ihre Stellenanzeigen bei der Hochschuljobbörse einstellen können. Außerdem wird auf das Datenbankschema eingegangen in dem die Stellenanzeigen und Zusatzinformationen in der Datenbank abgespeichert werden. Anwendungsbeispiele, die das Einsetzen von maschinellen Lernverfahren rechtfertigen, werden auch erläutert. Das dritte Kapitel handelt von verschiedenen Grundlagen des maschinellen Lernens. Sowohl, regelbasierte Lernverfahren, als auch maschinelle Lernverfahren sind enthalten. Im vierten Kapitel werden Ansätze aufgelistet, die in der Literatur beschrieben sind, um ähnliche Problemstellungen zu lösen. Kapitel fünf beschreibt eigene Ansätze der Problemstellung und das sechste Kapitel somit auch Software, die dabei eingesetzt wurde. Zu guter Letzt wird eine Evaluierung durchgeführt und ein Ausblick gegeben.
22.03.17	2017	extern	Master	DE	Untersuchung verschiedener BYOD-Szenarien in einem mittelständischen Betrieb mit anschließendem Umsetzungsvorschlag	Heutzutage wird der Ruf nach modernen Arbeitskonzepte, die flexibles und mobiles Arbeiten ermöglichen, immer lauter. Diese können beispielhaft durch den Einsatz mobiler Endgeräte ermöglicht werden. Dabei können die Geräte nach diversen Szenarien im Unternehmen eingesetzt werden. Im Rahmen dieser Masterarbeit kommt es zu einer Betrachtung der verschiedenen BYOD-Szenarien in einem mittelständischen Betrieb. Dabei werden rechtliche Aspekte und organisatorische Aufwände der unterschiedlichen Szenarien untersucht sowie eine Nutzungs- und Kostenbetrachtung durchgeführt, deren Ergebnisse in eine Nutzwertanalyse einfließen. Auf Basis der so erlangten Erkenntnisse erfolgt ein Umsetzungsvorschlag sowohl für die IT- als auch für die Personalabteilung der N-ERGIE IT GmbH.
24.03.17	2017	extern	Bachelor	DE	Prototypische Implementierung eines Kennzahlensystems zur Verbesserung der Unternehmensziele bei der Siemens AG	Eine systematische Verknüpfung von Kennzahlen in ein Kennzahlensystem. In Zukunft soll das Kennzahlensystem helfen Probleme rechtzeitig zu erkennen. Die Ergebnisse aus denn Kennzahlen sollen dann als Grundlage für strategische Entscheidungen dienen. Dies könnte besonders wichtig werden für zukünftige Verhandlungen um Ziele und Sollvorgaben. Aufgrund starker Konkurrenz werden in Zukunft neue Vorgaben vom Management zur Reduzierung der Kosten und der Durchlaufzeit entstehen. Somit wird durch das Kennzahlensystem eine Grundlage geschaffen um in den Fertigungsschritten Chancen und Gefahren zu erkennen. Ein weiteres Ziel der Einführung eines Kennzahlensystems soll die Standardisie- rung von Kennzahlen sein. Die Vorgaben und Daten sollen klar vordefiniert sein. Dadurch soll die Anzahl der Auswertungen und die Interpretationsmöglichkeiten minimiert werden.
28.03.17	2017	extern	Bachelor	DE	Auswahl und Einführung eines externen Online-Portals für Veranstaltungsbuchungen mit Anbindung an SAP	Die vorliegende Bachelorarbeit behandelt die Auswahl und Einführung eines Portals für Veranstaltungsbuchungen für die Firma DATEV eG. Hierzu wird in dieser Arbeit zunächst ein allgemeines Verständnis für die sogenannte MICE-Branche und MICE-Portale geschaffen und anschließend anhand der Anforderungen der DATEV eG ein passender Anbieter für ein Online-Portal gesucht. Ein wichtiger Bestandteil der Analyse der angebotenen Portale war außerdem das Thema Datenschutz und wie die Anbieter den Datenschutz sicherstellen. Nach der Auswahl eines passenden Anbieters wurde das MICE-Portal an die SAP-Systeme der Firma DATEV angebunden und ein Genehmigungswork?ow implementiert. Ziel dabei war ein einheitlicher Bescha?ungsprozess von Veranstaltungen unter Einhaltung der Bescha?ungskompetenzen der Veranstaltungsplaner.
29.03.17	2017	intern	Bachelor	DE	Modulares Konzept und Umsetzung von Videoanleitungen für Inserenten der Hochschuljobbörse	Im Rahmen dieser Bachelorarbeit wird ein modulares Konzept für die Erstellung von Videotutorials erarbeitet. Diese werden für die Firmenkunden der Hochschul-Jobbörse erstellt. Weiterhin soll das Konzept in einem ersten Testlauf umgesetzt werden. Zunächst werden die Problemstellung und Zielsetzung der Bachelorarbeit erörtert. Danach werden die zugehörigen Anforderungen diskutiert. Hier werden die Grundbegriffe definiert und erläutert. Danach werden abschließend noch die funktionalen und qualitativen Anforderungen erarbeitet. Die Analyse von verwandten Werken wird im Anschluss durchgeführt. Diese umfassen Videoformate von Konkurrenten und explizite Videotutorials. Daraufhin befasst sich diese Bachelorarbeit mit den Bestandteilen des modularen Konzepts im Rahmen der Videotutorials. Hier werden die Elemente für die Audio- und Videomaterialien analysiert. Eine weitere Thematik ist die Präsentation der Information. Danach wird die erste Umsetzung des modularen Konzeptes abgehandelt. Zunächst werden die Design Entwürfe erörtert und danach die einzelnen Schritte der Umsetzung diskutiert. Abschließend wird ein Fazit gezogen. Dieses beinhaltet die Zielerreichung und Grenzen, sowie einen Ausblick.
30.03.17	2017	extern	Bachelor	DE	Prototypische Entwicklung eines analytischen Modells für die Klassifizierung und Vorhersage von Bestellabbrüchen	Nicht immer gelingt der Verkauf eines Produktes, weil der Kunde die Bestellung abbricht. Um dies zu verhindern, werden Präventivmaßnahmen eingesetzt. Zur Verbesserung der Planung dieser sollen analytische Modelle entwickelt werden, mit den es möglich ist Zeitpunkte für die Maßnahmen besser vorherzusagen und sie kundenindividueller zu gestalten. Im Laufe der Bachelorarbeit wurden zwei Modelle entwickelt. Eines, das in der Lage ist die Anzahl der Bestellabbrüche über einen Zeitraum vorherzusagen, und eines, das Bestellabbrüche kundenindividuell klassifizieren kann. Für die Modellierung wurden Daten aus verschiedenen Datenquellen zusammengeführt und transformiert und Methoden der Regressionsanalyse eingesetzt, die im Zuge der Bachelorarbeit erläutert werden.
30.03.17	2017	extern	Bachelor	DE	Möglichkeiten einer automatisierten Provisionierung Virtueller Server im zLinux-Umfeld	Schwerpunkt dieser Arbeit ist die Evaluierung von Möglichkeiten der Automatisierung von Prozessen Virtueller Server im Großrechnerbereich. Durch Automatisierung von Prozessen werden manuelle Eingriffe reduziert, menschliche Fehlhandlungen begrenzt und teilweise komplett vermieden. Darüber hinaus werden Prozesse effizienter gestaltet, indem automatisierte Abläufe keine Verzögerungen mit sich bringen, personelle Ressourcen eingespart werden und automatisierte Prozesse qualitätsgesichert werden können. Die Effektivität kann gesteigert werden, indem Prozesse klar definiert und entsprechend automatisiert werden um das gewünschte Ergebnis der Verarbeitung zu erreichen. Bereiche, in denen bereits Automatisierung etabliert ist, sollen weiter in Betracht gezogen werden um Optimierung vorzunehmen und Effektivität, Effizienz sowie Prozess-Sicherheit weiter zu steigern und zu optimieren. Diese Bachelorarbeit wird bei SDV-IT in Nürnberg durchgeführt. SDV-IT ist seit 1983 IT-Dienstleister der Sparda-Banken sowie der Netbank. Grundlegende Technik für Transaktionen im Bankgeschäft bildet die Großrechner Architektur von IBM. Zu Beginn 2017 wurden zwei neue Großrechner angeschafft, genannt LinuxONE. Die Besonderheit dieser Maschinen liegt in der überwiegenden Nutzung des Linux Betriebssystems. Die Anschaffung der Maschinen wird als Anlass genommen erneut über die Automatisierung von Prozessen für Virtuelle Server nachzudenken und bereits vorhandene Automatisierung zu optimieren.
30.03.17	2017	intern	Bachelor	DE	Automatische Konfiguration der Zugriffskontrolle zur Datenbank einer Webanwendung	Die Insecure Direct Object References (OWASP Top 10, A4) ist eine der häufigsten Sicherheitslücken in Webanwendung. Dabei manipuliert der Angreifer die Parameter im URL-String, um so einen Zugriff auf Objekte zu bekommen, für die er nicht autorisiert ist. Ein Schutz bietet die Security-Appliance mit feingranularen Zugriffskontrollen durch parametrisierte Views. Diese parametrisierten Views werden über Zugriffsregeln definiert, welche die angeforderten Datenmengen für jeden Benutzer individuell eingrenzen. Diese Bachelorarbeit beschäftigt sich mit der Fragestellung wie die Erzeugung der Zugriffsregeln teil- bzw. voll automatisiert werden kann. Mit der Hilfe von zwei Proxys werden User-IDs im HTTP-Request dem auslösenden SQL-Statement zugeordnet. Die Zugriffsregeln für die parametrisierten Views lassen sich aus diesen Zuordnungen generieren. Die Automatisierung bedient sich der Methode vom unterstützenden Lernen durch Beobachten (statisches Lernen). Dabei protokolliert die Security-Appliance sowohl den HTTP-Verkehr, als auch den SQL-Verkehr, um daraus eine lückenlose Sammlung von Zugriffsregeln generieren zu können. Diese Sammlung dient als Konfiguration der Security-Appliance.
01.04.17	2017	extern	Master	DE	Prototype Implementation and Evaluation of Scenarios for an Adaptive Automotive Personal Assistant	Da immer mehr Sprachassistenten Einzug in den Automotive-Bereich halten, entwickelt die Firma Elektrobit Automotive GmbH einen eigenen Ansatz um einen intelligenten persönlichen Assistenten (IPA) im HMI-Umfeld produktreif zu etablieren. Innerhalb dieses Projekts sollen drei prototypische Szenarien implementiert und ausgewertet werden, um deren Praxistauglichkeit zu erforschen. Zu diesem Zweck wurden ein Learning Classifier System (LCS) und ein Clustering Algorithmus eingesetzt und dementsprechend angepasst. Die umgesetzten Szenarien werden anhand einer Umfrage evaluiert. Abschließend werden die Ergebnisse ausgewertet und aufgrund dessen eine Empfehlung für das weitere Vorgehen ausgesprochen.
01.04.17	2017	intern	Bachelor	DE	Rekonstruktion von relativen Kameraparametern aus Bildsequenzen und deren Verwendung zur Berechnung einer dreidimensionalen Punktwolke	Im Rahmen der vorliegenden Bachelorarbeit wird eine Verarbeitungskette zur Rekonstruktion dreidimensionaler Punktwolken aus einer Reihe von Bildern implementiert. Mittels Matching von SIFT-Merkmalen werden die Relationen der einzelnen Aufnahmen untereinander ermittelt und anschließend im Rahmen eines inkrementellen SfM-Verfahrens zur Berechnung der (relativen) Kamerapositionen und Orientierungen herangezogen. Die gewonnenen extrinsischen und intrinsischen Parameter werden anschließend zur Durchführung des PMVS-Verfahrens zur Gewinnung einer dichten Punktwolke verwendet. Abschließend wird die gewonnene Oberflächenrekonstruktion durch die Anwendung von Filteroperationen und dem Schließen von Löchern optimiert.
01.04.17	2017	intern	Bachelor	DE	Entwicklung eines interaktiven Spiels mit einem humanoiden Roboter als Spielpartner	Diese Arbeit stellt einen neuen Ansatz zur Umsetzung des Spiels "Tic- Tac- Toe" zwischen einem Menschen und einem humanoiden Roboter vor. Durch wissenschaftliches Vergleichen diverser Bildverarbeitungsverfahren und dem Einsatz der so bestimmten effizientesten Verfahren wird eine stabile Spielumgebungserkennung durch den Roboter garantiert. Die praktische Umsetzung des Spiels nutzt mit Außnahme des Roboters gebräuchliche, kostengünstige Mittel zur Realisierung. Entstehende Hindernisse werden hierbei weitgehend durch optionale Lösungswege umgangen. Bei unumgehbaren Behinderungen der Umsetzung wird eine hypothetische Lösung vorgestellt. Durch eine Nutzerstudie mit freiwilligen Probanden wird das umgesetzte Spiel auf Benutzerfreundlichkeit und Qualität im Allgemeinen geprüft. Eine Auswertung der dadurch ehobenen Daten gibt sowohl Auskunft über die Repräsentation der Probandengruppe als auch über diverse Qualitätsaspekte des getesteten Spiels.
01.04.17	2017	extern	Bachelor	DE	Optimierung der Datenvisualisierung in der mediendesign AG mit Hilfe der Software Tableau	In der mediendesign werden Daten zu Projekten und Mitarbeitern mit der Software Projektor erfasst. Zur Analyse der Daten, stehen derzeit der Projektor, und mit Eclipse BIRT erstellte Reports, zur Verfügung. Beide Varianten werden in Form einer statischen Tabelle ausgegeben und können schnell unübersichtlich werden. Deshalb wurde in einer vorherigen Bachelorarbeit nach alternativen Business Intelligence Produkten eruiert. Tableau stellte sich dabei als passende Software für ein mittelständisches Unternehmen heraus. Projekt- und Teamleiter sollen eine bessere Übersicht über Projekte und Mitarbeiter erhalten und auch die Detailanalyse soll erleichtert werden. Ziel der Bachelorarbeit ist es die Daten zu zentralisieren und die Visualisierung so zu optimieren, dass neue Erkenntnisse zum Vorschein kommen oder bereits bekannte Informationen schneller erfasst werden können. Diese Informationen können somit als Grundlage für weitere Entscheidungen genutzt werden. Es kann beispielsweise entschieden werden, ob ein Projekt weiterhin rentabel oder ein Mitarbeiter angemessen ausgelastet ist oder ob ein Projekt- oder Teamleiter eingreifen muss.
01.04.17	2017	extern	Bachelor	DE	Evaluation des Einsatzes von Systemen zur Datenanalyse im Fertigungsprozess anhand von Bosch PPM	Das Sammeln und Auswerten großer Datenmengen nimmt vor allem im industriellen Umfeld eine wachsende Rolle ein. Im Zuge des Konzeptes Industrie 4.0 werden Unternehmen ermutigt, Prozess- und Produktdaten in der Fertigung zu sammeln. Mit dem Production Performance Manager (PPM) und dem Production Performance Management Protocol (PPMP) will Bosch seinen Kunden eine Plattform und ein Übertragungsprotokoll bieten, welche dies erleichtern sollen. In dieser Bachelorarbeit wird eine Simulation für Fertigungsprozesse entwickelt, die Daten produziert und sie mit Hilfe des PPMP in eine Installation des PPM übermittelt. Anschlie- ßend werden mit den Werkzeugen des PPM Auswertungen und Berichte über diese Daten generiert. Anhand dessen wird die Eignung der Platt- form für das Sammeln von Daten und das Erzeugen von Berichten für produzierende Unternehmen evaluiert.
01.04.17	2017	intern	Bachelor	DE	Einsatzmöglichkeiten von agilen Praktiken im Prozessmanagement	Diese Arbeit beschäftigt sich in erster Linie mit klassischen und agilen Vorgehensmodellen zur Entwicklung von Software. Hierbei stehen agile Geschäftsprozesse im Vordergrund. Dabei wird deutlich, dass die Einführung von agilen Geschäftsprozessen durch die Unternehmensstrategie gesteuert werden sollte. Eine Einführung von agilenGeschäftsprozessen bringt den großen Vorteil mit sich, dass schnell und flexibel auf neue Kundenwünsche bzw. auf den Markt reagiert werden kann. Mit der Microservice-Architektur soll eine Möglichkeit dargestellt werden, die die Einführung von agilen Geschäftsprozessen IT-technisch unterstützen kann. Die Vorteile die agile Geschäftsprozesse und Microservices mit sich bringen, können hierbei nur bewältigt werden, wenn ein agiles Mindset im Unternehmen vorhanden ist. Historisch gewachsene Organisationsstrukturen haben hierbei häufig Hierarchie-Strukturen, die mit der agilen Softwareentwicklung und agilen Geschäftsprozessen nicht im Einklang stehen. Auch das Konzept der Microservices ist bei historisch gewachsenen IT-Landschaften häufig schwierig einzuführen. Zusammenfassend lässt sich daher sagen, dass die agilen Geschäftsprozesse im Zeitalter der Digitalisierung Marktvorteile mit sich bringen können, der Weg dorthin ist jedoch schwierig, da historisch gewachsene Strukturen aufgebrochen werden müssen.
01.04.17	2017	extern	Bachelor	DE	Evaluation möglicher Technologien eines Indoor Positioning Systems mit anschließender prototypischen Implementierung auf einem Smartphone.	IPS steht für Indoor Positioning Systems und wird dazu verwendet um den Standort von Gegenstände und Personen in einem Gebäude zu identifizieren. Da die alleinige Verwendung von GPS-Signalen in Gebäuden einen unzureichend genauen Stand ort liefern, werden bei IPS verschiedene Technologien kombiniert, um ein möglichst genaues Ergebnis zu erzielen, beispielsweise WLan, Bluethooth und GPS. Indoor Positioning Systems haben ein weiträumiges Einsatzgebiet von Orientierungshilfen in einem Krankenhaus über die Lokalisierung von Wissensträgern in einem Unter nehmen bis hin zum privaten Gebrauch. Auf dem Markt gibt es bereits Unternehmen die mit proprietärer Software im Bereich IPS vertreten sind. Allerdings gibt es für die Entwicklung von IPS bislang noch kein standardisiertes Vorgehen. Ziel dieser Bachelorarbeit ist es eine Übersicht über mögliche Technologien im Bereich IPS zu geben und diese zu evaluieren. Der Fokus hierbei soll auf Techniken gelegt werden, welche von einem handelsüblichen Smartphone verwendet werden können. Anschließend soll unter Verwendung der vorhergehenden Erkenntnisse eine prototypische Implementierung für ein Smartphone mit dem Betriebssystem Android durchgeführt werden.
03.04.17	2017	extern	Master	DE	Befähigung einer Bank zur Bereitstellung einer Public API für PSD2	Banken sind europaweit davon betroffen, ihre Finanzdienstleistungen zu digitalisieren und im Internet zu veröffentlichen. Dies ist in den Zahlungsdienstrichtlinien PSD2 festgeschrieben, die den digitalen Zahlungsverkehr in Europa vereinheitlichen, erweitern und sicherer gestalten sollen. Die Bereitstellung von Dienstleistungen erfolgt über festgelegte Schnittstellen (sog. Public API). Um den Zugriff darauf zu authentifizieren, autorisieren, analysieren und aktiv steuern zu können, werden Softwarekomponenten benötigt, welche auf die Erfüllung dieser Aufgaben spezialisiert sind. Übergreifend werden die Aufgaben und Herausforderungen in diesem Zusammenhang als API-Management bezeichnet. Aufgrund der Nachfrage nach fertigen Softwarelösungen für erfolgreiches API-Management gibt es derzeit viele Anbieter, die sich dieser Thematik angenommen haben. Diese bieten dabei die notwendigen Softwarekomponenten und deren Vorkonfiguration als sogenannte API-Management-Lösung an. Diese Arbeit verfolgt grundlegend drei Ziele. Zum einen werden neben den notwendigen Hintergründen, Herausforderungen und Chancen für Banken aufgezeigt, die durch eine öffentliche Bereitstellung ihrer Dienstleistungen entstehen. Zum anderen werden branchenunabhängige Aufgaben in Bezug auf ein erfolgreiches API-Management evaluiert. Das dritte Ziel sieht eine prototypische Umsetzung vor, die auf Basis einer eigenen API eine passende API-Management-Lösung aufgesetzt und die Dienstleistungen geregelt bereitstellt.
05.04.17	2017	intern	Bachelor	DE	Vergleich der Entwicklungsplattformen von Chatbot Systemen mit Bezug auf die Einkaufs- und Beschaffungsprozesse in Unternehmen	In dieser Arbeit geht es primär um die sich rasch verbreitenden Chatbot-Computersysteme. Während im privaten Gebrauch ein deutliches Wachstum der Nutzerbasis nachweisbar ist, sieht es auf unternehmerischer Ebene anders aus. Trotz der vielen Anwendungsszenarien, in denen Chatbots großes Potenzial aufweisen, werden sie in der Praxis nicht oft angewandt. Diese Abschlussarbeit legt den Fokus auf die Bereiche Einkauf und Beschaffung von Unternehmen. Anhand der Konstruktion und Beschreibung von Anwendungsfällen sowie des Vergleichs einiger Entwicklungsplattformen für Chatbots soll ein Fazit zur aktuellen Situation gezogen, und ein Ausblick auf die Zukunft geworfen werden. Es wird festgestellt, dass die Entwicklungsplattformen viele Ähnlichkeiten aufweisen. Von daher muss je nach Anwendungsszenario eine individuelle Entscheidung getroffen werden, und es können keine universellen Empfehlungen diesbezüglich gegeben werden. Die Entwicklungsumgebungen werden laufend weiterentwickelt und diese Arbeit stellt lediglich eine Momentaufnahme dar.
05.04.17	2017	intern	Master	DE	Entwicklung eines Prototyps zur SolR-basierten Indizierung von mittels RDF repräsentierten relationalen Datenbanken	Das Semantic Web ist eine Vision, ähnlich dem World Wide Web und hat das Ziel nicht nur den Austausch und die Vernetzung von Daten zu ermöglichen, sondern auch ihre Struktur zu vereinheitlichen. Vorzugsweise sollen Daten im RDF-Format gespeichert und durch einen SPARQL-Endpoint auf diese zugegriffen werden. RDF (Resource Description Framework) und SPARQL (SPARQL Protocol and RDF Query Language) gehören zu den semantischen Technologien und wurden vom W3C (World Wide Web Consortium) standardisiert. Die Menge der veröffentlichten RDF-Daten hat in der Vergangenheit stetig zugenommen. Dies könnte dazu führen, dass immer mehr Institutionen die semantischen Technologien nutzen. Falls RDF immer häufiger zum Speichern von Informationen genutzt wird, stellt sich die Frage wie eine solche Informationssammlung mit einer Volltextsuche durchsucht werden kann. Die vorliegende Masterarbeit soll diese Fragestellung im Kontext der Fakultätswebseite erörtern. Daher soll ein Teilbereich der vorhandenen relationalen Datenbanken beispielhaft mittels eines vorhandenen Mapping-Standards des W3C in eine RDF-Datenbank überführt werden. Der hierbei als RDF-Graph entstehende Ausschnitt der relationalen Datenbank bildet die Grundlage für die nachfolgende prototypische Lösung einer Solr-basierten Indizierung für RDF-Graphen.
05.04.17	2017	intern	Master	DE	Entwicklung und Evaluierung von Geschäftsmodellen für einen Online-Marktplatz zum Verkauf von hausgemachten gastronomischen Angeboten	Trotz seiner Wichtigkeit für eine gesunde Ernährung investieren die Leute heutzutage für das Kochen wenig Zeit, obwohl sie die Fähigkeit dafür haben. Demgegenüber gibt es noch Leute, die sich der Essenszubereitung leidenschaftlich widmen. Daher wird ein Geschäftmodell für einen Online-Marktplatz, auf dem diese Personengruppen zusammengebracht werden, entwickelt. Mit Rücksicht auf die bestehenden Marktteilnehmer und die geltenden Rechtsvorschriften werden fünf unterschiedliche Geschäftsmodelle dafür entwickelt. Durch eine Reihe von Validierungen lässt sich erkennen, dass die potentiellen Kunden an dem Verkauf ihres selbstgemachten Essens ein geringes Interesse haben. Dies berücksichtigend wurde schließlich ein erfolgversprechendes Modell ausgewählt und verbessert, welches die Kundenbedürfnisse erfüllen kann.
06.04.17	2017	extern	Bachelor	DE	"Konzeption einer Testmethodik für den "Feature Driven Development" - Prozess am Beispiel einer Webentwicklung"	Bekannte Techniken wie Continuous Delivery und Continuous Integration sorgen dafür, die Softwareentwicklung flexibel und schnell zu gestalten und somit den Auslieferungsprozess zu verbessern. Da aber sich die Qualität über die dadurch erreichbare hohe Liefergeschwindigkeit nicht verschlechtern darf, ist eine Testmethodik, welche sich nahtlos in die für kontinuierliche Integration und Lieferung notwendigen Verfahren einfügt, als ein wichtiger Schritt erforderlich. In dieser Abschlussarbeit wird nach Untersuchung und Analyse des "Feature Driven Development" ? Prozesses ein Konzept erstellt, welches sich damit befasst, inwieweit in den einzelnen Prozessschritten die Testaufgabe einfließen muss. Darüber hinaus soll eine Vorgehensweise vorgestellt werden, wie die Features und das Gesamtprodukt kontinuierlich getestet werden können, um die Qualität zu gewährleisten. Dabei soll mit Unterstützung von diversen Techniken durch die Optimierung des Softwareentwicklungsprozesses und die Sicherstellung der Softwarequalität eine qualitativ hochwertige Software erreicht werden.
19.04.17	2017	extern	Master	DE	Konzeption und Entwicklung eines integrierten Qualitätsmanagements für eine Geschäftsdomäne in der DATEV eG	Diese Arbeit ist in drei Hauptteile untergliedert: Analyse, Konzeption und Implementierung. In dem ersten Abschnitt der Arbeit wird zu Beginn der wissenschaftliche als auch der Stand der DATEV eG zu den Themen der QS und QM gesammelt. Darauf folgend wird eine Auswahl an QS-Software anhand definierter Parameter mit einer Nutzwertanalyse untersucht und abschließend eine Empfehlung ausgesprochen. Der zweite Teil der Arbeit befasst sich mit der Konzeption eines QS-Ablaufplans. Ziel dieses ist es einen planbaren QS-Ablauf für Zeit und Kosten der Abteilung KUV zu ermöglichen. Im Anschluss wird die Quantität der Testfälle für die jeweiligen Teststufen untersucht, die Vor- und Nachteile der Gewichtung wird infolgedessen herausgestellt. In dem letzten Teil der MA findet die Implementierung statt. Hierbei liegt der Fokus insbesondere auf den zwei Grundsätzen der EN DIN ISO 9001, dass alle beteiligten Personen einbezogen werden und einer faktengestützten Entscheidungsfindung. Demzufolge beschäftigt sich die Implementierung größtenteils mit der Kommunikation der Testfälle und deren Status. Zum Abschluss der Arbeit wird zurückblickend eine Reflexion durchgeführt, sowie ein Ausblick für die möglichen Anwendungen gestellt.
19.04.17	2017	intern	Bachelor	DE	Vertrauen und Betrug im E-Commerce und E-Payment, Analyse des Nutzerverhaltens	In dieser Arbeit wurde untersucht, wie sich Vertrauen im E-Commerce und E-Payment bildet. Ebenfalls wurden Risiken, wie auch aktuelle Betrugsfälle in Betracht gezogen. Des Weiteren wurde ein Experiment, mit Hilfe von Eyetracking-Technologie und zehn Testpersonen durchgeführt. Hierzu wurden die Ergebnisse dokumentiert und die erfassten Fragebögen ausgewertet.
20.04.17	2017	extern	Bachelor	DE	Auswahl einer Software zur Kalkulation und Preisfindung von IT-Leistungen bei der N-ERGIE Aktiengesellschaft	In der vorliegenden Bachelorarbeit wurde der aktuelle theoretische Stand zum Thema der Softwareauswahl in Unternehmen erarbeitet und mit den gewonnenen Erkenntnissen ein praktischer Auswahlprozess bei der N-ERGIE Aktiengesellschaft durchgeführt. Ziel war es, eine aktuell bereits existierende Lösung zur Kalkulation von IT-Leistungen, basierend auf Excel, abzulösen. Für diesen Fall wurde der Softwareauswahlprozess von der Ist-Analyse bis zur Bewertung der Ausschreibungsrückläufer begleitet und entsprechend benötigte Dokumente wie eine Marktübersicht und ein Anforderungskatalog erstellt. Die Arbeit zieht Schlussfolgerungen zur Anwendbarkeit der allgemeinen Methodik und enthält unternehmensspezifische Handlungsempfehlungen zur Softwareauswahl. Im Voraus werden die Grundlagen der innerbetrieblichen Leistungsverrechnung geklärt und ein mögliches IT-Servicemodell präsentiert, bevor der typische Softwareauswalprozess anhand ausgewerteter und aktueller Literatur beschrieben wird. Diese Arbeit richtet sich in erster Linie an Interessenten und Unternehmen, welche die innerbetriebliche Leistungsverrechnung einführen bzw. verbessern wollen und vor der Problematik der Softwareauswahl stehen.
20.04.17	2017	extern	Master	DE	Ergänzung des SAP Anfrageprozesses mit vordefinierten Warengruppentemplates	Thema dieser Masterthesis an der Technischen Hochschule Nürnberg Georg Simon Ohm ist die Ergänzung des Anfrageprozesses mit vordefinierten Warengruppentemplates. Die Arbeit entstand im Rahmen der Erlangung des akademischen Grades Master of Science in der Wirtschaftsinformatik. Der Vergleich von Angeboten gestaltet sich durch deren vielfach unterschiedliche Struktur sehr langwierig und ineffizient. Der zugrundeliegende Anfrageprozess ist intransparent und durch häufige Absprünge nicht in seiner Gesamtheit erfasst. Das Ziel dieser Arbeit ist das Herausarbeiten einer Vorgehensweise, wie die Implementierung von Warengruppentemplates in den bestehenden Anfrageprozess ausgestaltet werden kann. Hierfür wurde dieser im Rahmen einer Geschäftsprozessanalyse untersucht und für die Implementierung drei Umsetzungskonzepte erstellt. Diese wurden mittels einer Nutzwertanalyse bewertet und das Ergebnis in Form einer Handlungsempfehlung konkretisiert. Die vordefinierten Templates sollten auf einem Server bereitgestellt werden und im Zuge der Anfrageerstellung im SAP-System automatisch mitversendet werden.
24.04.17	2017	extern	Bachelor	DE	Entwurf eines Portals zur Erfassung und Verdichtung qualitätskostenbezogener Daten der Konzerndivision e-mobility bei der ZF Friedrichshafen AG 	Die ZF Friedrichshafen AG ist mit 29,2 Mrd. Euro Umsatz (Stand 2015) einer der größten Automobilzulieferer weltweit. Für das Konzernressort Qualität der Division e-mobility soll ein nachhaltiger, managementorientierter Ansatz zur Erfassung, Strukturierung und Kategorisierung qualitätsbezogener, fehlerkostenrelevanter Daten und deren Verdichtung in berichtbare Kennzahlen etabliert werden. Dazu sollen Daten aus den Bereichen Umsatz, Kunde, Produktion und Lieferant von Standorten weltweit gesammelt, zentral gespeichert und auswertbar gemacht werden. Es gilt die Anforderungen an das eingesetzte System formal zu spezifizieren, ein schlüssiges Datenmodell zu entwickeln, die Aussagekraft bereits definierter Kennzahlen zu prüfen und Auswertungsmöglichkeiten bereitzustellen.
27.04.17	2017	extern	Bachelor	DE	Konzeption eines Identity Access Management zur Automatisierung der Berechtigungsvergabe	Das Ziel der Bachelor Thesis war es, einen praktischen Leitfaden für die Implementierung eines Identity Access Management (IAM) zu entwickeln. Hierbei handelt es sich um die Verwaltung von Identitäten und deren Zugri?e in der gesamten IT Infrastruktur. Dazu wird im ersten Schritt die aktuelle Situation hinsichtlich der Berechtigungsvergabe und der Systemlandschaft analysiert. Anhand der gewonnenen Ergebnissen aus der Schwachstellenanlyse wird ein geeignetes Berechtigungskonzept entworfen, welches sich durch Workflows automatisieren lässt. Außerdem wird für die technische Umsetzung eine Roadmap aufgestellt, welche alle wichtigen Punkte für die Einführung einer Benutzer- und Berechtigungsverwaltung behandelt. Diese enthält unter anderem neu definierte Prozesse und Richtlinien, sowie eine Betrachtung der Schnittstellen zu den Einzelsystemen, die angebunden werden sollen. Im Zuge der Roadmap für die Umsetzung des IAM wurde ein Stufenplan für die Realisierung ausgearbeitet.
27.04.17	2017	intern	Master	DE	Deep Learning als Ansatz für Empfehlungssysteme	Empfehlungssysteme nehmen sowohl in der Forschung als auch in der Industrie eine kontinuierlich an Relevanz gewinnende Rolle ein. Mit Deep Learning rückte in den letzten Jahren ein Lernverfahren ins Rampenlicht der Forschung, welches aufgrund seiner bemerkenswerten Erfolge in den Bereichen der Computer Vision und Spracherkennung verstärkte Anwendung in weiteren Themenfeldern findet. Die vorliegende Arbeit beschäftigt sich zu diesem Zweck mit der Analyse und Anwendung von Deep Learning in einem Recommender-Kontext. Nach einem Überblick über grundlegende Konzepte und Verfahren innerhalb von Empfehlungssystemen wird eine Themeneinführung zu Deep Learning erörtert. Diese inkludiert sowohl eine fundierte Funktionsanalyse von neuronalen Netzstrukturen als auch eine Darlegung darauf aufbauender Deep-Learning-Architekturen. Eine anschließende Literaturrecherche bringt hervor, in welcher Form Deep Learning bereits in Empfehlungssystemen zur Anwendung kommt. In einer abschließenden Simulationsstudie wird unter Verwendung eines TensorFlow Frameworks die Anwendung eines eigenen Deep-Learning-Modells präsentiert. Hierzu erfolgt neben der Ergebnisinterpretation eine Ergebnisgegenüberstellung zu "State-of-the-Art"-CF-Recommender-Algorithmen. Basierend auf den gewonnenen Erkenntnissen der Simulationsstudie werden im Ausblick mögliche Erweiterungen thematisiert.
28.04.17	2017	extern	Bachelor	DE	Evaluation unterschiedlicher Methoden zur intelligenten Verknüpfung heterogener Datenbanken zur Optimierung von Geschäftsprozessen in einem Fertigungsumfeld	Die Zusammenführung von Daten aus verschiedenen Quellen ist bereits seit den achtziger Jahren Gegenstand der Forschung und es wurden bereits mehrere Vorgehensweisen zur Überwindung von Heterogenität entwickelt. Im Rahmen der vorliegenden Bachelorarbeit werden verschiedene Möglichkeiten für eine Datenverknüpfung vorgestellt und evaluiert. Ziel dieser Arbeit ist es einen Ansatz für die Verknüpfung von Daten eines Fertigungsunternehmens zu erstellen und diesen auch praktisch zu erproben. Zu diesem Zweck wird anhand des gewählten Ansatzes ein Prototyp erstellt. Der Prototyp soll als Grundlage für spätere Implementierungen dienen und eine einfache Möglichkeit zur Datenverknüpfung bieten.
28.04.17	2017	intern	Bachelor	DE	Entwicklung eines Systems zur Erkennung eines Streckenverlaufs mit Hilfe einer 2D-Kamera	In Arbeit wird ein System entwickelt zur Erkennung eines Streckenverlaufs mit Hilfe einer 2D Kamera. Als Strecke kommt die Strecke des NXP Cups zum Einsatz und das System soll es ermöglichen Modellautos autonom durch diese Strecke zu navigieren. Hierfür wurde eine Erkennung für die zwei wichtigsten Streckenabschnitte, Gerade und Kurve, implementiert. Die Erkennung erfolgt durch eine Berechnung des Streckenwinkels und kann somit voraussagen wie der zukünftige Streckenverlauf aussieht. Dieser Winkel wird über eine USB Kommunikation nach außen kommuniziert.
01.05.17	2017	intern	Bachelor	DE	Interaktive und dynamische Visualisierung von Antwortdaten aus Online-Self-Assesments der TH-Nürnberg mit Hilfe der "Data-Driven Documents" JavaScript Bibliothek	Das Ziel der vorliegenden Bachelorarbeit besteht darin, eine interaktive Anwendung zu implementieren, die eine Visualisierung der Antwortdaten aus den Online-Self-Assessments (OSAs) der TH Nürnberg ermöglicht. Diese Daten sollen in grafischer Form aufbereitet und dargestellt werden. Durch die Bedienung dieses Tools lassen sich Zusammenhänge zwischen verschiedenen Testkriterien und Ergebnissen erkennen und wertvolle Informationen über die einzelnen Tests und die Testteilnehmer sammeln können. Das Ergebnis der Arbeit ist ein vollfunktionstüchtiges Auswertungstool, welches sich intuitiv bedienen lässt und die gewünschten Abhängigkeiten und Zusammenhänge offenlegen kann. Die Bachelorarbeit umfasst die Konzeption und Implementierung der Anwendung, beschreibt die notwendigen theoretischen Grundlagen und zeigt am Beispiel zweier Anwendungsfälle die Funktionsweise und die Vorteile dieser Art der Visualisierung.
01.05.17	2017	intern	Bachelor	DE	Rasterbasierte SLAM-Verfahren für Laser-Entfernungssensoren	Forschungsgegenstand dieser Bachelorarbeit ist die Recherche rasterbasierter SLAM-Verfahren im Vergleich zur vektorbasierten Methodik. Im diesem Rahmen wird der rasterbasierte Hector SLAM als Untersuchungsobjekt verwendet. Dieser wurde in der Umgebung des an der Technischen Hochschule Nürnberg entwickelten Carbots implementiert. Dabei handelt es sich um einen Roboter der auf der Grundlage des vektorbasierten ICP SLAMs arbeitet. Um die Güte dieser beiden SLAM-Alternativen zu vergleichen, wurden virtuelle Test-Fahrten durch verschiedene Simulationsumgebungen durchgeführt. Zur Auswertung der Testreihe wurden sowohl die resultierenden Karten, als auch die hierbei erfassten Zeiten herangezogen. Bei der Auswertung der Daten erwies sich Hector SLAM als effektivere Lösung. Dies gründet einerseits in den realitätsnahen Kartierungen, andererseits in der schnelleren Durchführung des SLAMs. Daraus wird geschlossen, dass Hector SLAM sowohl effektiver ist, als auch weniger Rechenleistung erfordert. Die hierbei gewonnenen Erkenntnisse lassen sich jedoch nicht auf alle SLAM-Verfahren übertragen. Diese müssen vor dem Hintergrund der bestehenden Umstände analysiert werden. Zusammenfassend wird festgehalten, dass diese Arbeit einen tiefergehenden Einblick in SLAM-Systeme bietet. Sie ist für Leser von Interesse, die sich für rasterbasierte SLAM-Verfahren interessieren. Zudem für die Studenten und Professoren der Fakultät Informatik der Technischen Hochschule, die sich mit dem Carbot befassen.
01.05.17	2017	intern	Bachelor	DE	Zeichenbasierte Generierung von Texten mithilfe von Recurrent Neural Networks (RNN).	Die vorliegende Bachelorarbeit befasst sich mit dem Thema der zeichenbasierten Generierung von Texten mithilfe von Rekurrenten Neuronalen Netzwerken, kurz RNN. Sie gibt einen Überblick über die Funktionsweise von Künstlichen Neuronalen Netzen und untersucht den aktuellen Stand der Technik auf diesem Gebiet. Zudem werden die gewählten Methoden und die daraus gewonnenen Ergebnisse miteinander verglichen. Mithilfe eines Open Source Codes von Andrej Karpathy, der ein Neuronales Netz auf Buchstabenebene trainiert und anschließend Text generiert, wurden Experimente mit verschiedenen Inputdaten durchgeführt. Ziel dieser Arbeit ist, Text so zu generieren, dass er der Form des Inputs in größtmöglicher Weiße ähnelt, wobei der Semantik keine hohe Priorität beigemessen wird. Der Code wurde auf vier unterschiedliche Inputdaten angewandt, wobei verschiedene RNN Architekturen trainiert wurden. Die Ergebnisse zeigen, dass die Generierung eines Textes nicht nur möglich ist, sondern sogar bemerkenswert gut funktioniert. Die gewonnenen Resultate ähneln den Vorgaben in Inhalt, Struktur und Form erheblich. Die Erstellung von Fließtext im Vergleich zu einem Code ist weitaus komplizierter, dies beruht auf der markanteren Form die Code mit sich bringt. Aufgrund der unterschiedlichen Codevarianten, die Herr Karpathy veröffentlichte, wurden unterschiedliche Betriebssysteme (Windows und Ubuntu) zur Generierung der Ergebnisse verwendet.
01.05.17	2017	extern	Master	DE	Evaluation verschiedener Softwarelösungen zur Analyse der syngo.via Installed-Base	Das Ziel der vorliegenden Arbeit war es, eine zukunftsfähige Softwarelösung zur Ana-lyse der syngo.via Installed-Base zu erarbeiten. Dazu wurden die wichtigsten Anforde-rungen spezifiziert und die Daten, die von einer solchen Softwarelösung ausgewertet werden sollen, im Detail analysiert. Auf dieser Basis wurden zunächst die zwei bereits existierenden Lösungen zur Analyse der syngo.via Installed-Base evaluiert. Diese zwei Softwarelösungen basieren beide auf einer klassischen Data-Warehouse-Architektur. Im Anschluss wurde der Einsatz eines Big-Data-Systems zur Analyse der syngo.via In-stalled-Base untersucht. Dazu wurde ein auf Big-Data-Technologien basierender Proto-typ zur Analyse der syngo.via Installed-Base konzipiert und entwickelt. Um die richti-gen Entscheidungen bei der Technologie-Auswahl zu treffen, wurden auf Basis von den zuvor definierten Anforderungen die verschiedenen in Frage kommenden Big-Data-Technologien evaluiert und miteinander verglichen. Das Ziel dabei war, die Tauglichkeit eines Big-Data-Systems zur Analyse der syngo.via Installed-Base nachzuweisen und gleichzeitigt zu veranschaulichen, wie so ein System bestmöglich umzusetzen ist. Der so entstandene Prototyp zeigt auf, wie eine zukunftsfähige Softwarelösung zur Analyse der syngo.via Installed-Base umgesetzt werden kann und auf welche Punkte bei der Umsetzung geachtet werden muss.
01.05.17	2017	extern	Bachelor	DE	Entwicklung eines Methodenbaukastens zum aktiven Einbezug von Mitarbeitern in der Gestaltung der agilen Transition innerhalb des Geschaftsfelds Personalwirtschaft der DATEV eG	Die angestrebte Bachelorarbeit bewegt sich im Rahmen der agilen Transition innerhalb des Geschäftsfelds Personalwirtschaft der DATEV eG. Der Fokus der Arbeit liegt dabei auf den Einbezug der rund 308 Mitarbeiter in die Gestaltung des agilen Wandels und auf den definierten kulturellen Werten. Das Ziel ist es, durch die aktive Begleitung der agilen Transition, Handlungsfelder (z.B. "Selbstorganisation und Eigenverantwortung") aufzudecken und diese zu definieren. Auf Basis der unterschiedlichen Handlungsfelder soll ein Methodenbaukasten entwickelt werden, der geeignete Methoden pro Handlungsfeld für den aktiven Einbezug von Mitarbeitern bereitstellt. Die ausgewählten Methoden sollen helfen alle Mitarbeiter in die agile Transition miteinzubinden sowie helfen die gewünschten Werte zu verinnerlichen und zu leben. Die Mitarbeiter sollen dadurch erfolgreich an das agile Vorgehen herangeführt und Unsicherheiten bei ihnen beseitigt werden. Der erarbeitete Methodenbaukasten soll einen Überblick über mögliche Handlungsfelder in einer agilen Transition liefern und durch die entwickelten Methoden einen Orientierungsrahmen für Teams, Abteilungen und Unternehmen darstellen, die sich mit der agilen Softwareentwicklung beschäftigen.
01.05.17	2017	extern	Bachelor	DE	Identifikation von Dokumentenähnlichkeiten zur Qualitätssteigerung des Wissens-Projektmanagements in Attlassian Jira	In dieser Bachelorarbeit werden textuelle Ähnlichkeiten, mittels kontextuell gewichteter Wortvektoren und Ähnlichkeitsmaße, zur Optimierung des Projekt- und Wissensmanagements innerhalb Atlassian Jira eingesetzt. Indem die in dieser Software enthaltenen Tickets, welche Arbeitsaufträge beschreiben und dadurch die Strukturierung von Projekten ermöglichen, anhand ihrer thematischen und semantischen Ähnlichkeiten verglichen werden, sollen Duplikate zur Bereinigung des Systems identifiziert werden. Weiterhin werden die Bearbeiter der so berechneten ähnlichsten Tickets jeweils als geeigneter Ansprechpartner zur Hilfestellung vorgeschlagen. Durch eine In-Memory Datenbank wird unter Einsatz eines Webhook die Echtzeitaktualisierung des statistischen Modells ermöglicht. Über den Einsatz des Optical Cipher Recognition Tools Tesseract von Google, oder PDFMiner, werden auch Dateianhänge wie Screenshots und PDF-Dateien auf relevante Textuell vorliegende Daten untersucht. Die in der Arbeit entstandene Wortgewichtung sowie ihre Kombination mit der Cosinus-Ähnlichkeit wird mit bestehenden verglichen.
04.05.17	2017	extern	Master	DE	Konzeption eines Cyber-Threat-Modells mit beispielhafter Umsetzung bei DATEV	Bei der DATEV eG werden aus Sicherheitgründen Informationen aus verschiedenen Quellen gesammelt und an einer zentraler Stelle, einem Security Information and Event Management (SIEM)-System, gespeichert. Das SIEM prüft die Informationen gegen bestehende Kompromittierungsindikatoren und alarmiert die Verantwortlichen, falls eine räumliche oder zeitliche Korrelation auf eine Bedrohung hinweist. Man spricht von einem Security Incident wenn dabei definierte Schwellwerte überschritten oder kritische Indikatoren erkannt werden. In dieser Arbeit wurde ein Modell für Cyber Threats (digitale Bedrohungen) konzipiert. Das Modell stellt die Grundlage für die Umsetzung eines Verwaltungssystems für Informationen rund um Cyber Threats dar. Die resultierende Sammlung dieser Daten wird als Security Use Case bezeichnet. Auf Basis der gestellten Anforderungen wurden bereits existierende Standards und Plattformen auf ihre Eignung zur Verwaltung von Security Use Cases geprüft und die Datenfelder definiert, die zur ihrer Abbildung benötigt werden. Schließlich wurden dem Konzept noch weitere Funktionalitäten hinzugefügt, z.B. eine Nutzerverwaltung oder die Anbindung an Datenbanken mit wertvollen Kontextinformationen. Mit dem fertigen Konzept erfolgte zuletzt eine beispielhafte Umsetzung bei der DATEV eG. Dafür wurde eine Datenbank mit zugehöriger Weboberfläche entworfen. Mit der entwickelten Verwaltungsanwendung können nun Security Use Cases angelegt, eingesehen bearbeitet und koordiniert werden.
04.05.17	2017	extern	Master	DE	Konzipierung und Realisierung einer Quality-of-Service-Unterstützung in einem Computernetzwerk auf Basis von Software-defined Networking	In der Abschlussarbeit wird ein Konzept sowie die prototypische Realisierung einer Quality-of-Service-Unterstützung auf Basis des digitalen Kommunikationsnetzwerks der LEONI AG vorgestellt. Dabei wird zunächst eine strategische Vorgehensmethodik beschrieben, um die Strukturierung der benötigten Arbeitspakete zu fördern und die existierende Themenkomplexität zu reduzieren. Außerdem beinhaltet die Projektdurchführung die Ist-Aufnahme des betroffenen Kommunikationsnetzwerks und die Konzipierung einer QoS-Unterstützung, die auf dem DiffServ-Modell basiert. Aufbauend auf dem Konzept erfolgt die prototypische Realisierung der QoS-Unterstützung, die ebenso im Rahmen einer Testumgebung zu verifizieren ist. Zum Abschluss der Arbeit wird der aktuelle Trend "Software-defined Networking" (kurz: SDN) in Anlehnung an den Anwendungsfall "Einführung und Wartung einer Quality-of-Service-Unterstützung" bewertet. Zur Bildung einer Bewertungsgrundlage werden zunächst kritische Erfolgsfaktoren identifiziert, um im Anschluss eine SDN-Referenzimplementierung, die aus dem Produktportfolio des Netzwerkgeräteherstellers Cisco stammt, auf Einsetzbarkeit prüfen zu können.
05.05.17	2017	intern	Bachelor	DE	Untersuchung des Zusammenhangs zwischen Krebs und Ernährung mit dem Einsatz von Machine Learning	In den letzten Jahrzehnten sind die Krebsneuerkrankungen weltweit drastisch angestiegen. Vor allem aufstrebende Entwicklungsländer sind davon deutlich betroffen. Dabei ist besonders auffallend, dass einige Länder zunehmend westliche Lebensweisen annehmen und die damit oftmals verbundenen Ernährungsweisen. Ebenfalls ist der Zuckerkonsum in vielen Ländern weltweit erheblich angestiegen. Laut einigen wissenschaftlichen Studien besteht dabei ein ordentlicher Zusammenhang zwischen Ernährung und Krebs, insbesondere des Zuckerkonsums. Aufgrund der modernen Methoden des Machine Learnings können diese Zusammenhänge anhand eines ausgewählten Verfahrens betrachtet sowie Prognosen für die zukünftige Entwicklung abgegeben werden. Für die gesamte Arbeit wurden dabei intensive Datensammlung zu Krebs und ausgewählten Ernährungsfaktoren betrieben und anschließend aufbereitet. Auf Basis dieser Datenbestände wurde ein zugrundeliegendes Modell konfiguriert, welches später für die Umsetzung im Vorfeld ausgesuchter Softwareprodukte diente. Vor der eigentlichen Umsetzung erfolgte die Durchführung einer linearen Regression, anhand welcher die spätere Bewertung der Ergebnisse stattfand. Auch wurden jeweils die Klassifizierungsergebnisse der Tools genauer betrachtet und bewertet. Abschließend fand eine Prognosedurchführung statt, um einen zukünftigen Vergleich im Jahr 2020 zu ermöglichen, um damit auf zusätzliche Weise eine Bewertungsgrundlage zu ermöglichen.
08.05.17	2017	extern	Bachelor	DE	Konzeption einer Datensicherungsstrategie für Object-Storage-Systeme	Die Arbeit befasst sich mit der Erarbeitung eines Datensicherungskonzepts für Object-Storage-Systeme. Diese werden aufgrund des immer höher werdenden Datenaufkommens vor allem im Bereich der Onlinedienste verwendet und sind dementsprechend beliebig skalierbar. Dank der Architektur des Systems soll Ausfallsicherheit garantiert werden. Sobald es sich um sensible Daten im Unternehmensumfeld handelt, ist allerdings mindestens eine Notfallsicherung des Datenbestandes unabdingbar. In dieser Arbeit werden verschiedene Vorgehensweisen zur Sicherung von Daten verglichen und ein konkretes Konzept für eine Sicherung von Object-Storage-Systemen erstellt. Daraufhin soll dieses Konzept auf das produktive Umfeld eines Nürnberger Softwarehauses angewandt werden.
08.05.17	2017	intern	Master	DE	Prognose von volkswirtschaftlichen Faktoren unter Einsatz von Machine Learning 	Wirtschaftliche Freiheit wurde in der Vergangenheit als wichtiger volkswirtschaftlicher Faktor angesehen, doch es stellt sich die Frage, in welcher Form sich diese auf eine Bevölkerung auswirkt. Wohlstand und Lebensqualität soll durch wirtschaftliche Freiheit steigen und letztlich gesellschaftliche Freiheit, auch in repressiven Staaten, etablieren. Die Komplexität eines globalen Wirtschaftssystems lässt sich nur beschränkt abbilden, eine punktuelle Abstraktion auf Basis von volkswirtschaftlichen Daten und modernen Machine-Learning-Algorithmen könnte jedoch möglich sein. Die wirtschaftliche Freiheit stellt einen zentralen Punkt dieser Arbeit dar. Auf ihrer Basis ist es das Ziel, deren mögliche Relevanz für Wohlstand und Lebensqualität einer Bevölkerung zu beurteilen. Untersucht werden hierfür volkswirtschaftliche Indizes: Ökonomische Freiheit repräsentiert durch den "Economic Freedom of the World"-Index (EFW) sowie Wohlstand und Lebensqualität durch den Human Development Index (HDI) der Vereinten Nationen. Neben der grundlegenden Relevanz sind auch weitere mögliche Erkenntnisse über Zusammenhänge der untersuchten Daten von Interesse. Im Verlauf dieser Arbeit gilt es zusätzlich, ein taugliches Auswertungs-Werkzeug für den Anwendungszweck als auch passende Machine-Learning-Algorithmen für eine zielführende Analyse zu identifizieren und einzusetzen. Es zeigte sich, dass beide Indizes stark korrelieren und eine Prognose des HDI auf Basis des EFW zuverlässig möglich ist.
15.05.17	2017	extern	Bachelor	DE	Evaluation des Potentials von virtuellen Maschinen in einer Cloud-Computing-Plattform im Softwareentwicklungsumfeld bei der NÜRNBERGER Versicherung	Die IT nutzt seit Jahren das gleiche Modell zur Bereitstellung von Computern in Form von Rechnern, welche je nach gewünschter Leistung gekauft und physikalisch einem Platz zugewiesen werden. Mit dem voranschreiten der Technik etablieren sich immer neuere Modelle und Konzepte. In dieser Arbeit geht es primär um die sich rasch verbreitende Technologie der virtuellen Maschinen im Bereich des Cloud-Computings, welches auch unter dem Begriff der Desktop-Virtualisierung zu finden ist. Es wird im Rahmen dieser Abschlussarbeit ein Anwendungsszenario in Bezug zur Softwareentwicklungsabteilung der Nürnberger Versicherung erstellt, auf dessen Grundlage untersucht werden soll, in wie fern das neue Modell sinnvoll für den Einsatz ist. Mit Hilfe von Literaturrecherchen und dem Testen der Bedingungen im praktischen Umfeld werden verschiedene Chancen und Risiken aufgedeckt, sowie Maßnahmen erstellt, dieses Modell optimal zu nutzen. Es hat sich herausgestellt, dass der Einsatz dieses Modells nicht die erhofften Vorteile mit sich bringt, um die Risiken zu überwinden. Die Empfehlung ist daher kein breiter Einsatz dieses Modells, sondern eine individuelle Bereitstellung an Mitarbeiter, die einen Vorteil daraus erhalten würden.
18.05.17	2017	extern	Bachelor	DE	Konzeption und prototypische Realisierung eines Dienstes zur Erfassung, Übertragung und Zuordnung von Anwendungstestergebnissen.	Im Rahmen der Bachelorarbeit wurde ein Dienst zur Erfassung, Übertragung und Zuordnung von Anwendungstestergebnissen konzipiert und prototypisch entwickelt. Die Ausgangslage der Arbeit liegt der Tatsache zugrunde, dass in der DATEV eG momentan abteilungsübergreifend ein zentralisierter, standardisierter Prozess mit dem Ziel Continuous Delivery für alle Entwicklungsbereiche realisiert wird. Gegenwärtig wird sowohl die Testdurchführung, als auch das Rückspielen der Testergebnisse auf den Testsystemen ausgeführt. Durch die Entkopplung von Testdurchführung und Verarbeitung von Testergebnissen, sollen sich die Testsysteme ausschließlich auf die Testdurchführung beschränken. Das Ziel ist es, eine hohe Testüberdeckung zu erreichen, indem das Rückspielen von Testergebnissen zentralisiert von dem Dienst übernommen wird.
30.05.17	2017	extern	Master	DE	Einsatz des IBM Watson im Qualitätsmanagement bei Mercedes-Benz Vans	Der Fehlerabstellprozess wird in der Daimler AG auf Basis der CITAN-Fahrzeugdaten und geeigneter KI-Komponenten von IBM Watson innerhalb eines Pilotprojekts optimiert. Werkstattfälle zu intransparenten Fehlerdokumentationen können mit dem WEX Content Analytics Miner vom 1st Level Support über angebundene Quellsensoren erleichtert, schneller und zuverlässiger bearbeitet werden. Zudem hat das 2nd Level mit dem WEX Application Builder die Möglichkeit, gesamtheitlich sowie global Fehleranalysen, deren Ursachen und Wirkungen an Fahrzeugen vorzunehmen. Das Zahnriemen-Fehlerbeispiel zeigt Anwendungsfälle in den dafür erstellten Benutzeroberflächen. Durch das neue Fundament entwickeln sich Mehrwerte: integrierte Quellsensoren, konsolidierte Dateneinsicht und ein manuell zeitlich reduzierter Fehleranalyseaufwand. Visionäre Optimierungen ergeben Weiterentwicklungen, wie simultan laufende Fehlerprognosen, Teileoptimierung in der Frühentwicklung sowie von Watson selbsterkannte Hinweise/Vorschläge. Die prädiktive Fahrzeuganalyse mit einbezogener Daten-Präskription auf Basis der explizit angepassten KI erweitert die bisherige deskriptive und diagnostische Analyse. In den Werkstätten wird das gesamte Vorhaben mit einem zusätzlichen Knotenpunkt zu Watson effizient ausgeweitet. Kürzere Reparaturzeiten und ein höherer Fahrzeugdurchsatz sind Folgen, die auch Daimler-Kunden begrüßen. Das Zielszenario der verbesserten Fehlerfallbearbeitung erreicht eine nochmal leistungsstärkere Analysesituation.
01.06.17	2017	extern	Bachelor	DE	Optimierung von Bestellprognosen mit Hilfe von Deep Learning und TensorFlow	In dieser Arbeit wird der Einsatz von Deep Learning zur Verbesserung der Bestellvorhersagen analysiert. Die Vorhersagen des dabei erstellten Prototyps werden mit den Vorhersagen des Unternehmens und den Vorhersagen basierend auf Zeitreihenanalyse verglichen. Zur Erstellung des Prototyps müssen bereitgestellten Daten in eine numerische Form umgewandelt werden. Die Daten teilen sich dabei in Unternehmensdaten und in externe Daten auf. Unternehmensdaten teilen sich in Endprodukte und Zwischenprodukte auf. Wetterdaten, Feiertage und Saisondaten zählen zu den externen Daten. Ein Zusammenhang zwischen Wetter und Bestellung konnte nicht festgestellt werden, die Beeinflussung durch Feiertage wurde dagegen nachgewiesen. Eine Verbesserung der Vorhersagequalität aufgrund der Saisondaten konnte nicht eindeutig belegt werden. Zur automatisierten Parametrisierung des Prototyps wurden zwei Algorithmen implementiert genutzt. Der Vergleich ergab eine Verbesserung der Endprodukte Vorhersagegenauigkeit um 45,1 % gegenüber der Unternehmensprognose. Im Falle von Deep Learning in Gegenüberstellung zur Zeitreihenanalyse verbesserte sich die Vorhersagequalität der Zwischenprodukte um 2,1 % und die Vorhersagequalität der Endprodukte um 5 %.
01.06.17	2017	intern	Bachelor	DE	Erstellung interaktiver Szenen aus 360°-Aufnahmen	Das Thema der Arbeit liegt im Rahmen von bildbasiertem Rendering in Zusammenhang mit Interaktionskonzeption und Medienimmersion. Die Herausforderung in diesem Themenkomplex liegt insbesondere darin, Vorteile heutiger Visualisierungsmöglichkeiten, wie die verbreitete Rundumsicht in Panoramaaufnahmen, mit einem intuitiven Bedienungskonzept zu verbinden, um ein praktisches Werkzeug für individuelle Szenen-Editierung zu schaffen. Ziel ist es mit der Entwicklungsumgebung Unity einen Editor bereitzustellen, der es dem Anwender ermöglicht eigene 360°-Szenen zu erstellen und an beliebig gewählten Bildpunkten mit interaktiven Medieninhalten, wie Bildmaterial, Texten und Sounds zu füllen. Ein praktisches Anwendungsbeispiel wird in einer prototypisch umzusetzenden virtuellen Umgebung vorgeführt, in welcher in begrenztem, aber repräsentativem Umfang selbst gewonnene 360°-Realaufnahmen abgebildet und miteinander verknüpft werden. Die erstellten Szenen werden durch abrufbare interaktive Inhalte mit textuellen Informationen sowie Audio- und Bildaufnahmen erweitert.
01.06.17	2017	extern	Master	DE	Virtual-Reality-optimierte Sensor Fusion für eine langzeitstabile Gestenerkennung der oberen Extremität	Die Gruppe "Sensorfusion und Ereignisverarbeitung" am Fraunhofer-Institut für Integrierte Schaltungen (IIS) in Nürnberg, arbeitet an der Generierung und Verarbeitung von Sensor- und Positionsdatenströmen und deren statistischer Auswertung und Analyse auf verständlicher und abstrakter Ebene in Echtzeit. Dabei stellen die vorliegenden handelsüblichen Head-Mounted-Displays (HMD), zum Beispiel Samsung Gear VR und Oculus Rift, unter anderem relative Beschleunigungen, Drehraten und kurzzeitstabile Kopforientierung bereit, welche in Kombination mit dem bereits existierenden und erprobten Fraunhofer Holodeck VR System um absolute Positionen erweitert werden. Diese Positionen werden mit Hilfe geeigneter Bewegungsmodelle so in das Virtual Reality System (VR-System) eingepflegt, dass eine mögliche Simulatorkrankheit reduziert und vorgebeugt werden kann (sog. VR-optimierte Sensorfusion). Somit ermöglicht das Holodeck VR System immersive und frei begehbare virtuelle Welten. Im Rahmen dieser Arbeit wird die Einsatztauglichkeit von Hand-Tracking-Systemen untersucht, beispielsweise von Leap Motion oder uSense, um die momentane Position und Stellung der Hand zu erfassen und möglichst latenzarm und präzise in der VR abzubilden. Neben Hand-Tracking-Systemen, die zentral am Kopf angebracht werden, werden auch Systeme untersucht, wie beispielsweise das Myo System oder die Eingabegeräte von Samsungs Gear VR und Googles Daydream Controller, das an den Händen oder Armen angebracht wird, um ...
08.06.17	2017	intern	Bachelor	DE	CRM-Systeme: Chancen und Grenzen der Automatisierung 	Das Ziel der Bachelorarbeit war es, die Architektur und Funktion von CRM-Systemen zu systematisieren. Aus den Risiken und Chancen der Automatisierung im CRM wurde herausgearbeitet, wie sich CRM mit den neuen IT-Technologien verbessern, automatisieren und beschleunigen lässt. Und es wurde aufgezeigt, welche Grenzen bei der Automatisierung vorkommen.
12.06.17	2017	extern	Bachelor	DE	Entwicklung einer Software zur Bestimmung der Qualität von merkmalsorientierter Bildverarbeitungsalgorithmik	Im Rahmen der Bachelorarbeit wird eine Software entwickelt, mit deren Hilfe eine Aussage über die Qualität von Bildverarbeitungsalgorithmen zur Merkmalsdetektion an dreidimensionalen Prüfstücken getroffen werden kann. Die Software soll sowohl während der Entwicklung neuer Bildverarbeitungsalgorithmen, als auch zum Testen fertiger Programme verwendet werden können. Zur Einstufung der Qualität werden Ergebnisse der Bildverarbeitungsalgorithmen mit händisch annotierten Bilddaten verglichen. In den Vergleich fließen Eigenschaften gekennzeichneter Merkmalsbereiche, wie Merkmalstyp, Flächenabdeckung, Form und relative Lage zueinander ein. Ebenso werden die Nichterkennung von Merkmalsbereichen und das Auftreten fälschlich detektierter Merkmalsbereiche berücksichtigt.
20.06.17	2017	intern	Bachelor	DE	Konzeption und Realisierung eines TLS-Demonstrators für die Lehre mit Open SSL	Konzeption und Realisierung eines TLS-Demonstrators für die Lehre mit Open SSL Der Demonstrator soll Studierenden ermöglichen, im Laborversuch den Aufbau und Ablauf von mit TLS (Transport Layer Security) gesicherten Punkt-zu-Punkt-Verbindungen zu beobachten. Der Ablauf des TLS-Handshakes kann schrittweise verfolgt werden. Es werden wesentliche TLS-Varianten unterstützt (z.B. mit/ohne Client-Authentifizierung, RSA-basierte und Diffie-Hellman-basierte Ciphersuites). Als Anwendungsszenarien werden die Kommunikation zwischen einem Webbrowser und einem Webserver und die Kommunikation zwischen einer allgemeinen Client- und einer allgemeinen Server-Anwendung bereitgestellt. Kommuniziert wird zwischen zwei virtuellen Maschinen, die auf einem physischen Rechner installiert werden können.
01.07.17	2017	intern	Master	DE	Analyse und Vergleich aktueller JavaScript-Anwendungsframeworks	In den letzten Jahren sind zahlreiche JavaScript-Anwendungsframeworks entstanden, die die Entwicklung moderner Webseiten und sogenannter Single-Page- oder Rich Internet Applications vereinfachen sollen. Obgleich diese Frameworks eine bestimmte Softwarearchitektur erzwingen und damit zumindest dazu beitragen, komplexe JavaScript-Anwendungen besser zu strukturieren, führen sie meist auch eigene Paradigmen und domänenspezifische Sprachen oder Sprachbestandteile ein, die ihrerseits dem Entwicklungsprozess wieder zusätzliche Komplexität hinzufügen. Darüber hinaus entstehen häufig weitere Abhängigkeiten zu zahlreichen zusätzlichen Bibliotheken, die nicht nur die Lade- und Ausführungsgeschwindigkeit der damit erstellten Webseiten beeinflussen, sondern möglicherweise ein Sicherheitsrisiko darstellen. Im Rahmen dieser Arbeit soll daher zunächst ein Überblick über die wichtigsten aktuellen JavaScript-Anwendungsframeworks geschaffen und deren Aufbau sowie die zugrundeliegende Softwarearchitektur untersucht und diese mit den Möglichkeiten aktueller Web-Technologien (ES6, Web-Components) verglichen werden. Darauf aufbauend wird anhand einer Beispielanwendung der Einfluss verschiedener Entwicklungsansätze auf die Performanz und Sicherheit einer Web-Anwendung untersucht. Schließlich soll unter Berücksichtigung der gewonnenen Erkenntnisse eine Aussage darüber getroffen werden, für welche Zwecke der Einsatz komplexer JavaScript-Frameworks sinnvoll bzw. nicht empfehlenswert ist.
04.07.17	2017	intern	Master	DE	Prototypische Erstellung einer Plattform zur Visualisierung, Auswertung und Analyse von anonymisierten Personendaten	Im Rahmen dieser Masterarbeit wurde eine Plattform zur Erfassung und Auswertung von Studentendaten in Fach Programmieren I entwickelt. Dafür wurden zunächst verschiedenen Arten von Daten ermittelt die für diese Anwendung relevant sind und anschließend ein darauf basierendes Datenbankomdell erstellt. Danach wurden ausgewählte Technologien auf Vor- und Nachteile geprüft, welche für die schlussendliche Nutzung relevant waren. Anschließend wurde eine Systemarchitektur entworfen, die zum Schluss auch realisiert wurde.
14.07.17	2017	intern	Bachelor	DE	Entwurfsmuster - Design Patterns	Entwurfsmuster, im englischen Sprachraum auch Design Patterns genannt, sind gängige, geeignete Lösungswege für sich ständig wiederholende Entwurfsprobleme bzw. Gestaltungsaufgaben aus fast allen Bereichen des Lebens. Ein Muster dient als Vorlage zur Lösung eines Problems in einem bestimmten Anwendungszusammenhang. Dabei wird auf bewährtes Expertenwissen aus der Praxis zurückgegriffen und angewendet. Ziel dieser Bachelorarbeit ist es, nach der Mustertheorie von Christopher Alexander, herauszufinden, in welchen Bereichen, mit welchen Detail- oder Reifegrad, bereits Mustersprachen verwendet, wie solche Patterns entdeckt und dokumentiert wurden. Dabei wird auch auf die grundlegende Formalisierung und Beschreibung der Patterns näher eingegangen. Interessant sind hierbei die Methoden zu betrachten, die angewendet wurden, um derartige Muster zu entdecken sowie herauszufinden, welche weiteren Methoden noch existieren und welche mehr oder weniger vorteilhaft sind. Hierbei wird ebenfalls auf die Frage näher eingegangen, wie man in den einzelnen Bereichen vorgegangen ist, um diese Muster zu entdecken. Im weiteren Verlauf geht die Arbeit auch der Frage nach, welche Qualitätskriterien Patterns erfüllen müssen, damit sie beispielsweise auf Konferenzen vorgestellt werden dürfen.
18.07.17	2017	intern	Master	DE	Einsatz maschineller Lernverfahren zur Erkennung von Spielmechanismen in Spielanleitungen	Diese Arbeit zeigt, dass es durch den Einsatz maschineller Lernverfahren möglich ist, die in Brettspielen eingesetzten Mechanismen, in ihrer Repräsentation als Pattern, aus deren textuellen Spielanleitungen zu extrahieren. Durch die hierfür verwendeten überwachten Lernverfahren werden erfolgreich Modelle erzeugt, welche automatisiert trainierte Spiel- mechanismen in Spielanleitungen erkennen. Verglichen werden hierfür Support-Vector Machines (SVM), mit k-Nearest Neighbor (kNN) und Naïve Bayes-Klassifizierern (NB), wobei SVMs Accuracy-Werte von über 80% erreichen. Das Schwierigkeit der Textklassifikation von nicht nativ digitalen Daten, wird durch die Anwendung genauer Datenexploration und -bereinigung gelöst. Dabei wird eine neue Metrik vorgestellt, welche eine genaue Bewertung der durchgeführten Datenbereinigungsmaßnahmen erlaubt. Dieser Ansatz bewertet nicht, wie üblich, die Qualität eines bereinigten Textes anhand des Unterschieds zu einer Abbildung des Originaltextes, sondern verwendet zur Bewertung eine Bag-of-Words Repräsentation beider Texte.
19.07.17	2017	extern	Bachelor	DE	Untersuchung einer Blockchain Technik in Hinblick auf Anwendungen im Umfeld Internet der Dinge	Ziel dieser Bachelorarbeit war es, die Anforderungen einer Blockchain Technik an die benötigte Infrastruktur anhand eines praktischen Beispiels im Umfeld Internet der Dinge zu ermitteln. Dabei wurde zunächst auf die Theoretischen Grundlagen und die Funktionsweise von Blockchain eingegangen um. Anschließend wurde ein Prototyp konzipiert und implementiert mithilfe dessen die Hyperledger Fabric Blockchain zum Speichern von Sensordaten verwendet wurde um somit Anforderungen, Vor- und Nachteile und Limitationen der Blockchain Technologie in diesem Anwendungsbereich ermitteln zu können. Und schlussendlich eine Aussage treffen zu können ob sich eine weitere Betrachtung des Themas Blockchain in diesem Bereich lohnt.
26.07.17	2017	extern	Master	DE	Vorgehensmodelle und Softwarearchitekturen zur Entwicklung interaktiver Chatbot-Systeme	Das Kommunizieren mit Computern via Bots ist eine bereits ältere Idee, doch jüngste Fortschritte im Bereich Machine Learning und Conversational User Interfaces, wie den Sprachassistenten Alexa, Siri und Cortana, haben Potentiale für alternative Kommunikationswege gezeigt. Mit diesem Hintergrund soll in der Masterarbeit untersucht werden, welche Elemente ein Chatbot mit sich bringen muss, um als Mehrwert gegenüber herkömmlichen User Interfaces angesehen zu werden. Um dieses Ziel zu erreichen soll ein empirischer Ansatz verfolgt werden. Dazu wird zunächst eine Analyse von Chatbots in Hinblick auf deren Alleinstellungsmerkmale und Funktionen im Vergleich zu klassischen Web- und Mobile-Kommunikationsschnittstellen erstellt. Zusätzlich sollen die weit verbreitetsten Chatbot-Plattformen und -Architekturen analysiert verglichen werden. Diese Schritte sollen als Basis fu?r den weiteren Verlauf der Arbeit genutzt werden und eine Übersicht der Thematik liefern. Mithilfe dieser Grundlagen soll ein erster Prototyp erstellt werden, den Testnutzer im Rahmen eines Use-Case auf die implementierten Funktionen überprüfen sollen. Grundlegend ist hierbei die Veranschaulichung von erweiterten und neuen Ansätzen die verwendet wurden um die Kernfunktionen des Chatbots zu bauen.
08.08.17	2017	extern	Master	DE	Verbesserung der Prozessautomatisierung - Robotic Process Automation - mit Methoden der künstlichen Intelligenz	Die vorliegende Arbeit befasst sich mit der Verbesserung der Technologie Robotic Process Automation (RPA) anhand von Methoden und Lösungen der künstlichen Intelligenz (KI). Prozesse, die einen unstrukturierten Dateninput, komplexe Entscheidungen oder einen veränderbaren Prozessablauf haben, lassen sich mit RPA nicht automatisieren. Diese Probleme könnten jedoch mit Methoden der KI gelöst werden, so dass punktuell RPA durch KI unterstützt werden könnte. Um mögliche Prozesse herauszufinden, die sich durch die Kombination der Techniken RPA und KI automatisieren lassen, wird in dieser Arbeit ein Bewertungsmodell erstellt. Die prototypische Realisierung des Prozesses Warenreklamation per E-Mail zeigt auf, dass sich nicht jede KI-Lösung für eine korrekte und vollständige Automatisierung von Prozessen eignet. Durch die Realisierung wird allerdings auch aufgezeigt, dass in der gemeinsamen Anwendung von RPA und KI großes Potential steckt, um in Zukunft eine größere Prozessbreite automatisieren zu können.
16.08.17	2017	extern	Bachelor	DE	Konzeptionierung und Implementierung eines Frameworks zur Darstellung von Phantomen innerhalb einer Simulationskomponente für Computertomographen	Im Rahmen dieser Bachelorarbeit wurde ein Framework zur Erzeugung und Darstellung von Phantomen innerhalb einer Anwendung entwickelt, die einen Computertomographen simuliert. Die Ausgangsanalyse ergab, dass die aktuell verwendete Implementierung nicht geeignet war um kommende Anforderungen an Phantome gerecht zu werden. Neue Phantome konnten nur unter großem Zeitaufwand entwickelt werden. Die Entwicklung des Konzepts begann mit der Idee, die einzelnen Elemente eines Phantoms als geometrische Objekte zu definieren. Dadurch wird es ermöglicht, ein Phantom als ein Objekt aus einzelnen Bauteilen zu betrachten. Die einzelnen Elemente können für neue Phantome wiederverwendet werden und bieten mathematische Operationen um sich im Raum zu positionieren. Um diese Elemente zu gestalten, werden zunächst zwei primäre Grundobjekte verwendet: Quader und Kreis. Aus diesen Objekten lassen sich alle aktuell verwendeten Bauteile zusammensetzen. Die Objekte bieten eine umfangreiche Parametrisierung für ihre Dimensionen und ihre Zusammensetzung. Sollten in der Zukunft noch weitere Objekte benötigt werden, bietet das Framework ausreichend Schnittstellen um Erweiterungen einzubauen. Das Framework wird in der Programmiersprache C# von Microsoft entwickelt. Die beispielhafte Implementierung eines Phantoms sowie Schnittstellen und ausgewählte Klassen werden vorgestellt und erläutert. Schlussendlich werden die Bilder eines realen und simulierten Phantomes verglichen.
24.08.17	2017	intern	Bachelor	DE	Implementierung einer Microservice-Referenzarchitektur für die Gamifizierung von Webseiten	Im Rahmen einer Masterarbeit wurde eine Microservice-Referenzarchitektur für die Gamification von Webseiten, die jedes Gamification-Element in einen eigenen Microservice kapselt, entworfen und prototypisch unter Verwendung von Java als serverseitige Programmiertechnologie verwendet. Im Rahmen dieser Bachelorarbeit wurde überpüft, in wie fern die Microservice-Referenzarchitektur unter Verwendung von PHP als serverseitiger Programmiertechnologie implementierbar ist. Hierzu war eine Anwendung mit fünf Gamification-Elementen zu implementieren. Diese fünf Gamification-Elemente schließen die drei Gamification-Elemente aus der prototypischen Implementierung in der Masterarbeit ein. Vorgegeben waren also die Implementierung der Elemente Punkte, Level und Abzeichen. Als die zwei weiteren zu implementierenden Elemente wurden Fortschrittsanzeige und Leaderboard gewählt. Die Microservice-Referenzarchitektur sieht zur Kommunikation zwischen der Webseite und einem Microservice REST und zur Kommunikation zwischen den Microservices Messaging vor. Da in PHP die Webanwendung mit jedem Webaufruf neu gestartet wird, ist eine Implementierung einer Microservice-Architektur, die zur Kommunikation zwischen den Microservices Messaging vorsieht, nicht trivial. Die im Rahmen dieser Arbeit implementiererte Anwendung zeigt jedoch, das dies sehr wohl möglich ist.
27.08.17	2017	extern	Bachelor	DE	Rechnungsprüfung und Verbuchung mit Dokumentenmanagement für Baubetriebe	In der Industrie ist die Digitalisierung bereits in vollem Gange, dies bedeutet, was automatisiert werden kann, wird automatisiert. Tendenziell handwerklich geprägte, kleine und mittelständische, Unternehmen tun sich jedoch schwer die entsprechenden Schritte einzuleiten, da hierfür in den Betrieben weder Kompetenzen im Sinne spezialisierter Fachabteilungen existieren noch zeitliche oder finanzielle Ressourcen für den Veränderungsprozess wie in den Industriebetrieben bereitgestellt werden können. Durch veränderte Bedingungen im Umfeld, wie die zunehmende Anzahl der elektronischen Rechnungen sowie dem ständig zunehmenden Kosten- und somit Wettbewerbsdruck besteht jedoch auch hier die Erfordernis, die Verwaltungs- und dabei auch insbesondere die Belegprozesse zu optimieren. Diese Arbeit soll für einen abgegrenzten Anwendungsfall eine Lösungsmöglichkeit für handwerklich orientierte Bauunternehmen aufzeigen und durch die gleichzeitig aufgestellte Prozessmodellierung mit Verfahrensdokumentation gemäß GoBD den praktischen Anwendungsfall in den Vordergrund stellen.
01.09.17	2017	intern	Bachelor	DE	Simulation der Kinematik von Arthropoden	Im Rahmen dieser Arbeit wird untersucht, ob die Physik-Komponente der Simulationsumgebung des BugBot-Kinematics-Projekts durch die Java-Portierung jBullet der Physik-Engine Bullet Physics ersetzt werden kann. Daher wird beispielhaft eine Simulation eines Hexapoden basierend auf jBullet implementiert. Diese umfasst zum einen die Modellierung des Hexapoden als Mehrkörpersystem und zum anderen die Modellierung der Umgebung, die den Hexapoden beinhaltet. Zudem wird ein Ansatz demonstriert, um die alternierende tripode Gangart von Arthropoden zu realisieren. Anhand dieser Implementierung wird der erweiterte Funktionsumfang von jBullet gegenüber der bisherigen Physik-Komponente deutlich und zudem wird eine Schätzung des Änderungsaufwands für die Integration in den bestehenden Simulator getroffen. Die Visualisierung der Simulationsergebnisse erfolgt mit JavaFX.
01.09.17	2017	intern	Bachelor	DE	Konzeption und Entwicklung einer interaktiven Sicherheitsunterweisung unter Einbezug des realen Umgebungskontextes	Sicherheitsunterweisungen spielen in Unternehmen eine wichtige Rolle, damit Arbeitsunfälle vermieden werden können und Mitarbeiter möglichen Gefahrensituationen nicht hilflos ausgeliefert sind. In dieser Arbeit wird eine Lehrmethode vorgestellt, die Sicherheitsunterweisungen von einer neuen Seite betrachtet. Der reale Umgebungskontext des Lernenden wird bei der neuen Methode in dessen Lernprozess einbezogen. Diese Lehrmethode, die mittels einer mobilen Applikation umgesetzt wurde, soll einen höheren Lernerfolg ermöglichen. Um die Methode in der Praxis umsetzen zu können, sollen Objekte mit Hilfe von QR-Codes ausgestattet werden und bei Verknüpfung durch die mobile Applikation angezeigt werden. Im Rahmen einer kleinen Evaluation an Mitarbeitern und Studenten der Technischen Hochschule Nürnberg wurde die Methode untersucht. Das Ergebnis der Evaluation zeigt eine grobe Tendenz dazu, dass die neue Methode einen höheren Lernerfolg hervorruft.
01.09.17	2017	extern	Bachelor	DE	Full-HD Voice Conferencing im Browser mit Javascript	Für die Betriebssysteme iOS und Android entwickelte Fraunhofer bereits eine Anwendung zur Full-HD Voice Gruppenkommunikation. Damit diese aber auch Desktop-PCs zur Verfügung gestellt werden kann, wurde in dieser Abschlussarbeit untersucht, ob ein Browser-Support der Anwendung mit den zurzeit verfügbaren Mitteln möglich wäre. Hierbei hat sich herausgestellt, dass die verwendeten C++-Bibliotheken der Anwendung mit Hilfe von Emscripten nach JavaScript portiert werden können. Es wurde eine Lösung zum Streamen von Audio gefunden, bei der zum Testen einer Verbindung zwischen einem Client und einem Server, ein UDP-Server über den Browser mittels WebSockets angepingt wird. Hierfür wurde ein Proxy genutzt, der die Nachricht des Clients über UDP an den Server weiterleitet und dessen Antwort über ein WebSocket an den Client zurückschickt. Des Weiteren wurde ein Performance-Vergleich durchgeführt bei dem sich herausgestellt hat, dass asm.js noch viel langsamer ist als nativer Code. Im Gegensatz ist WebAssembly jedoch schon sehr nah an einer nativen Ausführung dran. Als Audio API wurde die Media Stream API von WebRTC ausgewählt, die unter anderem einfache Funktionen zum Ausführen eines Mikrofon Playbacks zur Verfügung stellt. Bei der Bearbeitung dieser Bachelorarbeit wurde festgestellt, dass es generell möglich wäre, die Gruppenkommunikationsanwendung im Browser ausführen zu lassen, sobald unter anderem benötigte Technologien, wie zum Beispiel WebAssembly, einen Thread-Support besitzen.
01.09.17	2017	extern	Bachelor	DE	Entwicklung einer mobilen Anwendung zur Erkennung und Suche von Produkten mittels künstlicher neuronaler Netze	In dieser Arbeit wurde eine mobile Anwendung zur Klassifizierung von Produkten der Dentalbranche implementiert. Hierzu kamen Convolution Neural Networks zum Einsatz, welche am Endgerät selbst ausgeführt wurden. Zur Umsetzung des Klassifikators wurden Lern-, Validierungs- und Teststichproben für 100 verschiedene Produkte erstellt. Bei der Wahl der Produkte wurden verschiedene optisch ähnliche Produkte berücksichtigt. Zudem wurden zwei Ansätze verglichen: Ein selbst erstelltes CNN mit 8 Schichten, sowie ein auf den ImageNet-Datensatz vortrainiertes Inception-V3-Netz. Die höchste Erkennungsrate von 96,51 % konnte mit 50 Stichproben pro Klasse für das Inception-V3-Netz erzielt werden. Des Weiteren wurde eine Auswirkung der Stichprobengröße auf die Erkennungsrate untersucht. Eine Einschränkung für den Klassifikator stellten Produkte dar, welche sich lediglich anhand leichter Farbvariationen voneinander unterschieden. In diesen Fällen empfiehlt sich eine manuelle Auswahl des Farbtons durch den Anwender. Je nach Endgerät war ein durchschnittlicher Zeitaufwand von 0,73 s bis 2,04 s für die Klassifikation nötig.
01.09.17	2017	extern	Bachelor	DE	Einführung von Software-defined networking bei der N-ERGIE	Die Einführung eines neuen Zonenkonzepts im Rechenzentrum der N-ERGIE bedingt den Einsatz einer softwarebasierten Steuerung der Netzwerkkommunikation. Die vorliegende Bachelorarbeit gibt zunächst einen Überblick über die Funktionsweise und Möglichkeiten von Software-defined networking. Im weiteren Verlauf wird der Einsatz dieser Technologie bei der N-ERGIE AG in Form eines konkreten Produkts evaluiert. Dabei wird anfangs der momentane Arbeitsablauf analysiert, danach werden die Anforderungen im Hinblick auf den gewünschten Zielzustand festgehalten. Anhand des festgestellten Bedarfs werden marktübliche Vertreter von Software-defined networking gegenübergestellt und der am besten geeignete ausgewählt. Durch eine prototypische Testinstallation und zuvor definierte Fallstudien werden die Vorteile der gewählten Lösung gegenüber dem alten Verfahren präsentiert. Das Ergebnis dieser Arbeit ist eine Handlungsempfehlung mit zugehöriger Bewertungsmatrix zur Auswahl und Implementierung einer Software-defined networking Lösung bei der N-ERGIE.
01.09.17	2017	extern	Bachelor	DE	Head-tracked Spatial Conferencing	Das Fraunhofer IIS entwickelte eine Applikation für Spatial Conferencing, welche es ermöglicht, die Teilnehmer einer Audiokonferenz akustisch in einem virtuellen Raum zu positionieren und unter Verwendung von Stereo-Headsets aus ihrer entsprechenden Richtung wahrzunehmen. Eine Problematik dabei ist, dass sich bei herkömmlichen Kopfhörern die Lautsprecher mit dem Kopf mitbewegen. Dadurch fühlen sich die Telefonkonferenzen unnatürlich an. Um dieses Problem zu beheben, wurde im Rahmen dieser Arbeit die Anwendung mit Hilfe von Head-Tracking erweitert, damit die Kopfbewegungen des Nutzers kompensiert und der Raumklang entsprechend angepasst wird. Da die Audiosignale der Konferenzteilnehmer in der MCU gerendet werden, stellt sich die Frage, ob die zusätzliche Latenz, die durch das Streamen der Head-Tracking-Daten entsteht, das Hörerlebnis des Nutzers beeinflusst. Ein Tool wird entwickelt, um diese "Motion-to-Sound"-Latenz messen zu können. Damit wird festgestellt, dass diese Latenz niedrig genug ist, um das Hörerlebnis des Hörers nicht beeinflussen zu können. Darauffolgend werden die Head-Tracking-Daten durch die OpenVR API implementiert und in der ACE integriert. Danach wird ein Hörtest vorbereitet und durchgeführt, um den Nutzen von "Head-tracked Spatial Conferencing" beurteilen zu können. Die Ergebnisse des Hörtests zeigen, dass Konferenzen mit Head-Tracking sich natürlicher anfühlen und der Hörer das Gefühl bekommt, sich mit den Konferenzteilnehmern in einem Raum zu befinden.
01.09.17	2017	extern	Bachelor	DE	Konzeption und Entwicklung einer sprachgesteuerten Anwendung zur Steuerung von Robotic Process Automation Software	Die Zielsetzung der Bachelorarbeit ist die Konzeption und Entwicklung einer sprachgesteuerten Anwendung, die es ermöglicht, mithilfe von Robotic Process Automation Software automatisierte Prozesse zu starten, stoppen und überwachen. In der Arbeit wird zunächst auf Robotic Process Automation (RPA) sowie UiPath, einen Anbieter von Robotic Process Automation Software eingegangen. Im Anschluss werden die Spracherkennungsdienste Bing-Spracheingabe-API, Google Speech und IBM Watson analysiert und verglichen. Die Bing-Spracheingabe-API stellte sich als geeignetste Spracherkennung heraus. Anschließend werden verschiedene Ansätze zur Interpretation von Sprachbefehlen diskutiert. Hier zeigte sich, dass Natural Language Understanding den besten Ansatz darstellt, der den Benutzer zudem die Befehlsstruktur frei wählen lässt. Es folgt eine Analyse möglicher kontextbasierter Kriterien, anhand derer dem Benutzer Prozesse zur Ausführung vorgeschlagen werden können. Zudem wird eine Benutzeroberfläche entworfen. Basierend auf diesen Ergebnissen wird die sprachgesteuerte Anwendung mit C# und WPF umgesetzt. Zur Interpretation der Spracheingaben wird LUIS, ein von Microsoft angebotener Natural Language Understanding Service eingesetzt. Abschließend wird eine Benutzerevaluation durchgeführt.
01.09.17	2017	extern	Bachelor	DE	Flexible Parametrisierung der Fehlernachrichten eines REST-basierten Backends	Diese Arbeit beschäftigt sich mit den verschiedenen Definitionssprachen für REST-Schnittstellen. Im Detail wurde näher auf die Spezifikation der Fehlernachrichten eingegangen, um ein Konzept zu entwickeln, diese flexibel zu parametrisieren. Dafür ist zunächst ein Referenzbackend und dessen Ausnahmebehandlung näher betrachtet worden. Anschließend wurden die Sprachen RAML, API Blueprint und OpenApi näher behandelt und deren Umsetzungsmöglichkeiten für das Konstrukt der Polymorphie. Diese Ergebnisse wurden zum Schluss in das Referenzbackend eingebaut, um eine Nutzwertanalyse durchzuführen.
01.09.17	2017	intern	Bachelor	DE	Evaluation der Programmiersprache Kotlin bezüglich Sprachfeatures und Effizienz der Softwareentwicklung gegenüber Java anhand einer Android App	Kotlin ist eine von JetBrains entwickelte, objektorientierte, statisch typisierte Programmiersprache mit funktionalen Elementen. Sie wird zu Java Bytecode kompiliert und ist somit auf der Java Virtual Machine lauffähig. Dies ist die Grundlage für ein potentiell breites Feld von Anwendungen. Darüber hinaus hat Google am 19.05.2017 auf der Developer Conference Google I/O bekannt gegeben, dass Kotlin neben Java und C++ eine offiziell unterstützte Sprache für Android wird. Im Zuge dieser Arbeit werden die Sprachfeatures hinsichtlich ihrer prägnanten Syntax und zeitsparenden Eigenschaften genauer untersucht. Soweit vorhanden, werden sie mit ihren gleichwertigen Gegenstücken in Java verglichen. Der Schwerpunkt dieser Arbeit liegt in diesem Vergleich und der Analyse dieser neuen Sprachkonzepte. Zum besseren praktischen Verständnis wird zudem eine Android Tacho-App entwickelt, mit der einige Kotlin spezifische Neuerungen in einfacher Weise dargestellt werden. Die App wird für Fahrrad- und Autofahrer angepasst. Neben der Anzeige von Geschwindigkeit, Tageskilometer und Durchschnittsgeschwindigkeit sind auch eine Reset-Funktion, eine animierte Oberfläche, ein Nachtmodus sowie ein Graph für eine statistische Visualisierung implementiert.
04.09.17	2017	extern	Bachelor	DE	Analyse von Grafikbibliotheken für die interaktive Visualisierung von 2D-/3D-CAD-Daten	In Zusammenarbeit mit endobit software solutions soll für die Robert Bosch GmbH ein neues CAD-Tool entwickelt werden, welches ein momentan verwendetes Tool namens "NCCAD" ersetzen soll. Als Entscheidungsgrundlage werden im Rahmen der Bachelorarbeit mehrere Grafikbibliotheken auf folgende kritische Aspekte untersucht und anschließend verglichen: Einfachheit der Benutzung der Bibliothek, 3D Renderung un einem Viewer und Hardwarebeschleunigtes Rendering. Es sollen zudem Prototypen mit ausgewählten Grafikbibliotheken implementiert werden. Somit wird praktische Erfahrung gesammelt, womit die Bibliotheken besser eingeschätzt werden können. Das Ziel ist eine geeignete Grafikbibliothek für ein CAD-Tool zu finden. Jedoch werden auch andere Anwendungsfälle von Grafikbibliotheken bedacht, für welche Empfehlungen ausgesprochen werden.
05.09.17	2017	intern	Bachelor	DE	WebGL-basiertes Volume-Raycasting 	Das Ziel der vorliegenden Bachelorarbeit war es, einen WebGL-basierten Volume-Raycaster in JavaScript zu implementieren. Dabei sollte überprüft werden, ob diese Technologie für das direkte Volume-Rendering-Verfahren eignet ist. Des Weiteren sollten verschiedene WebGL-Implementierungen auf ihre Leistung evaluiert werden. Zusammenfassend kann gesagt werden, dass die Technologie für das direkte Volume-Rendering-Verfahren geeignet ist, solange die 3D-Datensätze nicht all zu groß sind.
05.09.17	2017	extern	Bachelor	DE	Ermittlung und Umsetzung einer Methode zur automatisierten Bereitstellung kundenspezifischer Linuxserver im Rahmen eines Entwicklungsprojektes	Im Rahmen eines größeren Softwareentwicklungsprojekts stellt die Voigtmann GmbH eine Rahmeninfrastruktur für ein Softwaremodul eines Kunden bereit. Diese beinhaltet die Programmierung einer App als Benutzerschnittstelle für mobile Endgeräte, eines webbasierten Backend als Benutzerschnittstelle zur Administration und den Betrieb der hierfür pro Mandant (Kunde des Kunden) benötigten Server. Die Vorliegende Arbeit beschäftigt sich im Kern mit der Automatisierung der Bereitstellung der benötigten Infrastruktur zum Betrieb des Backend für verschiedene Kunden in Form von Speziell angepassten Linuxservern. Es wurden hierzu Kriterien erarbeitet, anhand derer verschiedene Methoden des automatisierten Deployment bewertet werden konnten. Die präferierte Methode wurde im Anschluss umgesetzt.
07.09.17	2017	extern	Bachelor	DE	Konzeption und Umsetzung einer Testmethode für PPTX-Dateien	Die SCHEMA Holding GmbH in Nürnberg entwickelt das XML-basierte Redaktionssystem SCHEMA ST4 DocuManager. Es dient zur Erstellung und Verwaltung modularer Inhalte. Zum Funktionsumfang der Software gehört auch, dass Anwender ihre MS PowerPoint Präsentationen im PPTX-Format als einzelne Folien in ST4 importieren können. Hier können diese nach eigenen Vorstellungen wieder zu Präsentationen zusammengeführt und produziert werden. Eine geeignete, automatisierte Methode zum Testen der exportierten Dateien ist aktuell nicht vorhanden. Im Rahmen dieser Bachelorarbeit soll eine geeignete Testmethode für PPTX-Dateien evaluiert und entwickelt werden.
14.09.17	2017	intern	Bachelor	DE	Einsatz von Machine Learning im Bereich Human Resources	Zielsetzung: Personalauswahl und Potenzialbeurteilung gehören zu den wichtigsten Aspekten des Personalmanagements in Unternehmen wie z.B. bei Einstellungen. Besonders größere Unternehmen, die sehr viele Bewerbungen erhalten, setzen auf computerbasierte Bewerberauswahl, um den Bewerbungsprozess effizienter zu gestalten. Im Rahmen dieser Bachelorarbeit wird gezeigt, wie anhand des Machine Learning Verfahrens die Bewerbungsunterlagen elektronisch analysiert werden und eine Vorauswahl getroffen wird. Dabei wird das Stellenanforderungsprofil mit dem Profil, das aus den Bewerbungsunterlagen, insbesondere dem Lebenslauf, hervorgeht mit Hilfe von MatchingAlgorithmen abgeglichen. Schließlich wird die Machine Learning Verfahren den klassischen Methoden gegenübergestellt, um die möglichen Vorteile bzw. Nachteile festzustellen.
14.09.17	2017	extern	Bachelor	DE	Vergleich skalierbarer Speicherlösungen für Binärdaten variabler Größe mit Fokus auf schnelle Zugriffszeiten	"	Das Ziel dieser Arbeit ist der Vergleich von Speicherlösungen, bei dem die Skalierbarkeit eine entscheidende Rolle spielt. Als Hilfselement hierfür wird ein Testframework zum Load-Testing entwickelt. Das Framework dient zur Messung von Zugriffszeiten auf Binärdaten variabler Größe, unter der Verwendung verschiedener Technologien und Parameter. Die Erweiterbarkeit und das damit verbundene Hinzufügen weiterer Technologien soll für die Zukunft gesichert sein. 	 	Ein selbstgeschriebener BLOB-Generator dient dazu Testdaten zu generieren. Zusätzlich wird ein File Manager zur Verwaltung von BLOBs integriert. Sowohl BLOB Generator, als auch File Manager sind lediglich Hilfstools und haben keinen Bezug zu den Testergebnissen. Für das Testframework kommt als Programmiersprache Java zum Einsatz. 	 	Das Hauptaugenmerk der zu testenden Umgebungen liegt auf relationalen- und NoSQL-Datenbanken, sowie auf verteilten Dateisystemen. Als Vertreter dienen hierfür PostgreSQL, Cassandra und GlusterFS. Das Ergebnis soll Messwerte für die Zugriffszeiten unter der Bedingung verschiedener Variablen, wie zum Beispiel Dateigröße oder Dateimenge beinhalten. Es wird von der Verwendung von Bilddateien ausgegangen, welche eine maximale Größe von bis zu zwei Megabyte haben können. Dies beschränkt sich lediglich auf die Messungen, die diese Arbeit beinhaltet. Größere Dateien sind für das Framework ebenfalls denkbar."
18.09.17	2017	intern	Bachelor	DE	WebAssembly	WebAssembly ist ein neues Binärformat für portable und effiziente Web-Anwendungen, für das seit kurzem erste Implementierungen in aktuellen Browsern verfügbar sind. Im Rahmen dieser Bachelorarbeit sollen die Architektur und die Implementierung der Wasm-Plattform untersucht werden. Insbesondere soll auf die aktuellen Möglichkeiten sowie Limitierungen der Technologie eingegangen werden. Anhand verschiedener Beispiele soll die erreichbare Performance im Vergleich zu herkömmlichen JavaScript sowie nativen Implementierungen in C++ untersucht werden.
28.09.17	2017	extern	Bachelor	DE	Konzeption und Entwicklung eines generischen Messaging Service mit webbasierter Visualisierung für die Continental Engineering Service GmbH	Es werden Themen in den Gebieten des Messaging und Usability untersucht, welche die Konzipierung und Entwicklung unterstützen werden. Die Anforderungsanalysen werden mit Hilfe der UML Modelliersprache dokumentiert und in der Implementierungsphase umgesetzt. Mit der Konzeption einiger Prototypen werden die Anforderungen an die Weboberfläche genauer spezifiziert. Anhand der Beobachtung von aktuell angewandeten Technologien wird die Umsetzung ausgearbeitet und später durch einfache Funktionale Test geprüft.
01.10.17	2018	intern	Master	DE	Assoziationsanalyse der eingesetzten Spielemechaniken in prämierten Gesellschaftsspielen	"Gamification bezeichnet das Einbringen von Spielmechaniken in spielfremde Prozesse mit der Absicht, zusammen mit den Mechaniken auch deren motivationale Wirkung zu transferieren. Im Rahmen des EMPAMOS-Forschungsprojektes werden Mechaniken und ihr Kontext abstrakt als Gamification-Muster beschrieben, um ein Expertensystem zur Entwicklung von Gamification-Konzepten zu schaffen. 	Ziel dieser Arbeit war es, Methoden der Assoziationsanalyse auf ihre Eignung für die Analyse des Beziehungsnetzwerkes der Muster zu testen. Dazu sollte versucht werden, datengetrieben Hypothesen zur Struktur der Beziehungen der Gamification-Muster aufzustellen. Als Datengrundlage wurden 210 mit dem Preis ""Spiel des Jahres"" prämierte Gesellschaftsspiele auf in ihnen enthaltene Muster untersucht und eine Datenbank mit den Zuordnungen von Mustern zu Spielen erstellt. 	Die Algorithmen FP-Growth und MagnumOpus wurden angewandt, um Frequent Itemsets sowie Assoziationsregeln zu finden. Der Vergleich der Ergebnisse ergab, dass MagnumOpus interessantere Ergebnisse liefert. Es wurde gezeigt, wie prototypische Visualisierungen des Netzwerkes erstellt werden können. 	Aufgrund des geringen Datenbestands sowie durch Einschränkungen der Datenqualität bedürfen die inhaltlichen Ergebnisse dieser Arbeit einer Nachuntersuchung. Die Eignung der angewandten Methoden zur Gewinnung von nützlichen Assoziationsregeln und Untersuchung der Musterbeziehungen konnte aber bestätigt werden. "
01.10.17	2018	intern	Bachelor	DE	Konzeptionierung und Umsetzung eines Webauftritts für einen Fakultätsjahresbericht mittels WordPress	Die Fakultät Informatik der technischen Hochschule Nürnberg veröffentlicht jedes Jahr im November einen Jahresbericht in Form einer gebundenen Broschüre. Dieser informiert auf rund 60 Seiten über die Projekte und Unternehmungen des vergangenen Jahres und bietet außerdem eine Übersicht der Zahlen und Fakten, wie die Anzahl der eingeschriebenen Studierenden und Dozenten. Eine solche analoge Form der Informationsvermittlung verliert allerdings immer mehr an Nutzen und bringt unangenehme Probleme mit sich. Diese umfassen sowohl hohe Kosten, als auch einen erhöhten Aufwand. Ziel dieser Arbeit ist es ein System zu konzipieren, sowie zu implementieren, welches die Probleme eines veralteten Jahresberichts löst und eine neue Plattform bietet, welche sowohl der vorhandenen Papierversion gerecht wird, als auch neue Möglichkeiten bietet, enthaltene Informationen zu präsentieren. Dies geschieht in Form eines Webauftritts, der als Basis das WordPress Blogsystem nutzt, welches für die gewünschten Funktionalitäten entsprechend angepasst wurde. Diese Arbeit wird dabei auf die zu behandelnden Problemstellungen und deren Lösungsversuche eingehen, sowie die bei Konzeption und Implementierung entstandenen Herausforderungen erörtern. Des Weiteren werden Alternativen und Erweiterungen zu den genannten Lösungen aufgezeigt. Das Projekt wurde in enger Zusammenarbeit mit Herrn Wienkop, dem Erstbetreuer, sowie Frau Sörgel, Frau Theelke und Herrn Ulrich durchgeführt.
01.10.17	2018	intern	Bachelor	DE	IT-basiertes Innovationsmanagement zur Steigerung der Prozesseffizienz: Bewertung unterschiedlicher Innovationsverfahren	Das klassische Innovationsmanagement hat eine klare Grenze: Die unternehmensinterne Grenze in den Markt. Damit das Innovationsmanagement ein Unternehmen grundsätzlich bei der Prozesseffizienz unterstützen kann, müssen Unternehmen ihre Innovationsprozesse nach außen hin öffnen. Durch den steigenden globalen Wettbewerb sowie kürzere Produktlebenszyklen und zugleich sinkenden F&E-Budget müssen Unternehmen ihre Prozesse beschleunigen. Im Rahmen dieser Bachelorarbeit war es zu prüfen, inwieweit eine erhöhte Effizienz erreicht werden kann, wenn Unternehmen Innovationsverfahren anwenden. Hierbei wurden die Ansätze Open Innovation, Design Thinking und Crowdsourcing bewertet. Auch der Aspekt der Einbindung von externen Dienstleistern in den Innovationsprozess wurde in die Bewertung integriert. Hierbei hat sich heraus kristallisiert, dass die Einbeziehung externer Dienstleister von Vorteil ist. Crowdsourcing lässt sich optimal als Erweiterung für das Projekt einsetzen. Ein Vorteil von Design Thinking ist die Verknüpfung zwischen den Kundenwünschen und der Machbarkeit, sowie die Wirtschaftlichkeit des Produktes. Bei dem Verfahren Open Innovation stellen der größte Nachteil und gleichzeitig der größte Vorteil die Zusammenarbeit mit externen Partnern dar. Schlussendlich lässt sich sagen, dass Unternehmen die Balance zwischen internen und externen Innovationsimpulsen finden müssen. Bei optimaler Anwendung können die Verfahren ein fester Bestandteil des Innovationsmanagements werden.
01.10.17	2018	extern	Bachelor	DE	Entwurf einer effizienten Kategorisierung von Transaktionsdaten zur Schaffung eines Mehrwerts für Bankkunden	Durch die Einfu?hrung der Payment Services Directive 2 bricht das Monopol der Banken beim Zugriff auf die Kontodaten ihrer Kunden. Gerade Drittanbieter profitieren davon und bieten Bankkunden Anwendung zur zentralen Verwaltung unterschiedlicher Konten an. Auch die Kategorisierung der Transaktionen ist dabei ein wichtiger Bestandteil, um Ausgaben u?bersichtlicher darzustellen. In dieser Arbeit wird untersucht, wie mit Hilfe etablierter Verfahren aus den Gebieten Information Retrieval und Textanalyse eine effiziente Kategorisierung von Banktransaktionen umgesetzt werden kann. Dazu werden sowohl Mittel der Computerlinguistik, als auch des Maschinellen Lernens (Machine Learning) betrachtet. Ziel ist es, eine Kategorisierung von Banktransaktionen zu entwerfen und in einem Prototypen umzusetzen. Nach Erla?uterung der Funktionsweise unterschiedlicher Textklassifikationsverfahren folgt eine Evaluation der Leistungsfa?higkeit. Gleichzeitig wird eine Vorverarbeitung der Daten und Optimierung auf Banktransaktionen durchgefu?hrt. Dabei wird gezeigt, welche Parametrisierung fu?r eine Kategorisierung von Banktransaktionen optimale Ergebnisse liefert. Auf Basis dieser Erkenntnisse wird ein Modell fu?r die spa?tere Implementierung gebildet. Die anschließende Umsetzung geschieht in Form eines Prototypen, welcher das optimierte Modell nutzt. Dieser bildet ein eigensta?ndiges Kategorisierungssystem und es wird gezeigt, wie dieser in spa?teren Anwendung zur Finanzplanung eingebunden werden kann.
01.10.17	2018	extern	Bachelor	DE	Automatische Klassifikation digitalisierter Dokumente durch Verwendung eines neuronalen Netzes 	Das Ziel der vorliegenden Bachelorarbeit ist es, für die Firma mediendesign AG eine prototypische Anwendung zu entwickeln, um automatisiert digitale Dokumente zu sortieren. Wurden in der Vergangenheit oftmals Methoden der Textanalyse bei der Klassifikation von Dokumenten eingesetzt, soll in dieser Arbeit dagegen die Machbarkeit auf Basis eines künstlichen neuronalen Netzes untersucht werden. Um ein bestmögliches Ergebnis zu erzielen, werden zwei unterschiedliche Lösungsstrategien verfolgt. Für den ersten Ansatz wird auf Transferlearning zurückgegriffen, für den zweiten werden eigene Modelle erstellt. Nachdem an das Problem herangeführt wurde, werden die wesentlichen Aspekte künstliche neuronale Netze und speziell Convolutional Neural Networks im Detail erläutert. Die Vorgehensweise bei der Implementierung der Anwendung in der Programmierspra- che Python, und dabei insbesondere die Erstellung der Klassifikatoren mit Tensorflow und Keras sowie deren Evaluation, bilden den Schwerpunkt dieser Arbeit. Dabei wird gezeigt, dass durch iterative Optimierung der Klassifikatoren ein vergleichbar gutes Ergebnis mit beiden Lösungsansätzen erzielt wird. Im Anschluss an die Evaluation wird eine Einschätzung zu den sehr guten Ergebnissen beider Lösungsstrategien sowie eine Empfehlung für den produktiven Einsatz gegeben.
01.10.17	2018	extern	Bachelor	DE	Entwurf eines Berichtstools mit korrigierbarer Datengrundlage auf Basis von SAP BOE und SAP PI. 	Das neu eingeführte Business Intelligence Tool SAP Business Objects Enterprise der Firma Grenzebach Maschinenbau GmbH bietet keine Möglichkeit, Berichte so zu erstellen, dass Korrekturen oder Aktualisierungen der zugrundeliegenden Datenbasis durchgeführt werden können. Im Rahmen dieser Arbeit sollen mögliche Konzepte erstellt und anhand eines prototypischen Berichtstools erstellt und evaluiert werden. Dieses soll soweit möglich mit dem in BOE integrierten Berichtstools Web Intelligence vergleichbare Performance und Bedienkomfort erreichen.
01.10.17	2018	extern	Bachelor	DE	Werkzeuggestützte, automatisierte Auswertung von Usability-Tests	Usability-Tests stellen eine zeit- und kostenintensive Methode dar, um Nutzungsprobleme, welche bei der Bedienung eines interaktiven Systems auftreten, aufzudecken. Ziel der vorliegenden Arbeit war es deshalb zu untersuchen, ob eine Reduzierung des manuellen Aufwands, welcher im Rahmen der Auswertung betrieben werden muss, durch Automatisierung möglich ist. Im Zuge dessen wurde basierend auf den vorangegangenen Recherchen ein Evaluations-Tool konzipiert und prototypisch umgesetzt. Da für die systematische Auswertung von Daten bereits die Erfassung dieser Daten strukturiert und gezielt erfolgen sollte, soll das Tool ein Beobachtungsprotokoll im Rahmen der Test-Durchführung anbieten, welches eine problemorientierte Dateneingabe ermöglichen soll. Um die Auswertungszeit zu verkürzen, bietet das Tool die Möglichkeit die erhobenen Daten in eine tabellarische Struktur zu überführen, sodass diese für die anschließende Analyse bereits übersichtlich aufbereitet vorliegen und im günstigsten Fall nur noch gesichtet und interpretiert werden müssen. Ob der manuelle Aufwand unter Nutzung des Tools im Vergleich zur Auswertung ohne Tool-Unterstützung geringer ist, muss im Rahmen eines Tests noch geprüft werden.
01.10.17	2018	extern	Bachelor	DE	Konzeption und Implementierung eines Frameworks zur Entwicklung von mobilen Anwendungen für IOS und Android auf Basis von Xamarin.Forms.	Im Rahmen dieser Bachelorarbeit soll ein Framework für die Entwicklung von iOS- und Android-Apps konzipiert und implementiert werden, um eine Basis für zukünftige AppProjekte der Firma infoteam Software AG zu bilden. Dieses Framework baut selbst auf Xamarin.Forms auf und wird bestehende Funktionen erweitern oder überschreiben. Ein Schwerpunkt liegt dabei auf einer benutzerfreundlichen Konfiguration der Navigation zwischen Oberflächen, aber auch auf der Unterstützung der eigentlichen Entwicklung von Oberflächen. Zusätzlich soll das Framework den Anwender zum Umsetzen des MVVM-Patterns motivieren, um bei der zu erstellenden App eine saubere Trennung zwischen Oberflächen- und Geschäftslogik zu gewährleisten.
01.10.17	2018	extern	Bachelor	DE	Fotorealistische Visualisierung von räumlich variierenden Materialien durch eine Annäherung der BRDF-Parameter auf Basis des NVIDIA-Tools "Photo To Material: 2shot"	Diese Arbeit befasst sich mit der fotorealistischen Visualisierung von Materialien. Hierfür werden Herangehensweisen zur Ermittlung einer allgemeingültigen Vorschrift für das Reflexionsverhalten verschiedener Oberflächen vorgestellt. Der Schwerpunkt liegt in der Validierung eines automatisierten Materialmodellierungsprozesses, der auf Basis zwei unterschiedlich belichteter Bilder die BRDF-Parameter generiert. Hierfür wurden verschiedene Aufnahmesettings mittels eines iPhone- und einer Spiegelreflexkamera getestet, um den Vorgang zusätzlich zu optimieren. Die Qualität und entsprechende Anwendbarkeit der Resultate wird an zahlreichen Beispielen illustriert.
01.10.17	2018	extern	Bachelor	DE	Eine Webanwendung zur Erstellung neuer Colorways (Farbvarianten) von Schuhen mit dem Framework Three.js und dem WebGL-Interface	Diese Bachelorarbeit adressiert die Optimierung des Prozesses der Erstellung neuer Colorways (Farbgebungen) von Schuhen in der Firma adidas. Es wird eine Webanwendung programmiert, die über einen Deferred-Shading-Ansatz den beleuchteten Schuh anzeigt. Die Schattierung erfolgt mit einem Physically Based Rendering. Die dabei verwendeten Technologien sind das JavaScript-Framework Three.js und die Schnittstelle WebGL.
01.10.17	2018	intern	Bachelor	DE	Analyse der Ansätze von Reflection in C++ und Entwicklung einer eigenen Implementierung	C++ standardisiert keine Reflection, sondern nur eine einfache Runtime Type Information (RTTI). Für Reflection gibt es jedoch einige Anwendungsgebiete, unter anderem Serialisierung von Datenstrukturen, Herstellen von Interoperabilität zwischen Programmiersprachen und Unterstützung von GUI-Programmierung. Im Rahmen der Bachelorarbeit soll daher untersucht werden, welche Mächtigkeit eine standardkonforme Implementierung der RTTI besitzt. Weiter sollen bestehende, umfassendere Implementierungen von Reflection analysiert und verglichen werden. Zudem soll eine eigene Implementierung im Hinblick auf die Serialisierung von Datenstrukturen entwickelt werden.
02.10.17	2018	extern	Bachelor	DE	Erstellung einer Netzwerkschnittstelle zu einem Model Checker für Cyberphysikalische Systeme	Die Siemens AG evaluiert aktuell den Aufbau eines Model Checkers fu?r Cyberphysikalische Systeme auf Basis von symbolischen SMT-Lo?sern. Die Bachelorarbeit behandelt die Frage, wie ein solcher Model-Checker in einer heterogenen IT-Umgebung sinnvoll mit einer Netzwerkschnittstelle ausgestattet werden kann. Hierbei wurden die Anforderungen zur Ausgestaltung einer Netzwerkschnittstelle mithilfe eines modellbasierten Werkzeugs (Capella) und einer architekturzentrierten Vorgehensweise (Arcadia) erhoben. Die aus Arcadia generierten Diagramme und Modelle dienten als Diskussionsgrundlagen und Entscheidungshilfe für eine konkrete API-Technologien. Zur Diskussion standen hierbei SOAP, REST und RPC-mäßige Schnittstellen wie z.B. XML- oder JSON-RPC. Anschließend wurde die Implementierung umgesetzt in Form einer zweistufigen Kommunikation: Zum einen kommuniziert der Client mit einem in nodeJS implementieren Webserver und zum anderen kommuniziert der Webserver mit dem in OCaml implementierten Model Checker. Also Protokolle kamen hier HTTP und TCP zum Einsatz, wobei jede Kommunikationsstufe der JSON-RPC 2.0 Spezifikation folgt.
02.10.17	2018	intern	Bachelor	DE	Digitale Dokumentenverwaltung im Bürobereich durch den Einsatz von IT-Systemen	Digitale Dokumentenverwaltung im Bürobereich durch den Einsatz von IT-Systemen Im Rahmen meiner Bachelorarbeit, wird die Realisierung eines papierlosen Büros betrachtet. Diese richtet sich an alle Personen, die Verwaltungsprozesse gestalten. Im Rahmen des papierlosen Büros werden die Dokumente digital verwaltet und auf Ausdrucke wird verzichtet. Vorteile sind, dass Kosten gesenkt werden, die Prozesse beschleunigt werden, keine Archivräume benötigt werden, die manuellen Arbeitsschritte reduziert werden und die Wettbewerbsfähigkeit gesteigert wird. Zunächst wurde ein Marktüberblick über derzeit am Markt vorhandene DMS und CRM Systeme aufgezeigt. Anschließend wurden drei DMS Systeme ELOoffice, TagSpaces und CompuDMS testinstalliert und bewertet. CompuDMS erzielte die höchste Punktzahl im Scoring Modell. Des Weiteren wurden drei CRM Systeme Julitec, 1CRM und SuccessControl CRM testinstalliert und bewertet, hierbei erzielte SuccessControl CRM die höchste Punktzahl. Es wurde ebenfalls auf den Einsatz eines digitalen Notizbuches eingegangen. Hierzu wurden OneNote und Evernote getestet. Hierbei kann auf Notizzettel verzichtet werden und die Notizen werden elektronisch verwaltet. Insgesamt lässt sich feststellen, dass durch die digitale Dokumentenverwaltung Kosten für Ausdrucke, Kopien und Aufbewahrung vermieden werden. Allerdings fallen Kosten für die Systeme und dessen Betrieb an. Derzeit am Markt vorhandene DMS- und CRM Systeme ermöglichen eine digitale Dokumentenverwaltung
04.10.17	2018	extern	Bachelor	DE	Mehrmaschinentests und deren Implementierung in openQA am Beispiel der Implementierung einer systemd-networkd Testsuite	Bei openQA handelt es sich um ein System zum Testen von Betriebssysteminstallationen. Das zu testende Betriebssystem wird in einer virtuellen Maschine unter Simulation von Benutzereingaben installiert. In der vorliegenden Arbeit wurden verschiedene Ansätze untersucht, um in openQA Mehrmaschinentests zu realisieren. So können auch Programme und Betriebssystemfunktionen getestet werden, die ein Cluster aus mehreren Maschinen erfordern. Untersucht wurden folgende Ansätze: - openQA Lock API: interaktion der Testmaschinen mehrerer parallel laufender openQA Tests - Verschachtelte Virtualisierung: starten mehrerer VMs innerhalb der Testmaschine - Docker-Container: start mehrerer Container in der Testmaschine - Nspawn-Container: start mehrerer Container in der Testmaschine Die Ansätze wurden nach Wiederverwendbarkeit, Konfigurationsaufwand, Ressourcenverbrauch und Performance, Nachvollziehbarkeit, Portierbarkeit vorhandener Testsuites und Automatisierbarkeit verglichen. Die verschachtelte Virtualisierung schnitt zusammen mit Nspawn-Containern am besten ab. Zudem wurde festgestellt, dass auch Mischformen aus Containern und VMs möglich sind. Unter Einsatz von Nspawn-Containern wurde anschließend eine Testsuite für den Systemd-Networkd-Netzwerkstack implementiert.
05.10.17	2018	intern	Bachelor	DE	Entwicklung eines Serious Game zur Sensibilisierung von Erstsemesterstudenten für die Risiken eines Studienabbruchs in einem technischen Studiengang.	Zielsetzung der Bachelorarbeit ist es, ein Serious Game in Form eines browserbasierten Text Adventures zu entwickeln. Mit diesem sollen Studenten angesprochen werden, die sich im ersten Semester ihres Studiums an der Fakultät Informatik der Technischen Hochschule Nürnberg befinden. Indem sie interaktiv ein virtuelles Studium durchspielen, sollen die Studenten für die typischen Ursachen und Risiken eines Studienabbruches sensibilisiert werden. Die Gründe für einen Studienabbruch sind vielfältig und sollen in dieser Bachelorarbeit näher erläutert und gewichtet werden. Viele der Ursachen sind jedoch abwendbar, wenn sich die Studierenden zu Beginn ihres Studiums intensiv mit den klassischen Gründen und Risiken eines Studienabbruchs beschäftigt hätten. Deshalb soll in Zukunft ein interaktives Spiel namens OHMSim eingesetzt werden, um Studierende über die Risiken und Hürden in einem technischen Studiengang aufzuklären Um die Wirkung eines solchen Serious Game auf Studenten zu ermitteln sowie den Erfolg zu messen, sollen mehrere Probanden im Anschluss an das interaktive Spiel einen UEQ ? Fragebogen zur ihrer User-Experience ausfüllen. Die Bachelorarbeit ist sowohl für Studierende im Bereich Wirtschaftsinformatik als auch für Angehörige im Bereich Medienpädagogik interessant.
05.10.17	2018	extern	Bachelor	DE	Evaluierung der Möglichkeiten und Herausforderungen des Einsatzes von E-Procurement in der Baubranche	Das Ziel der Arbeit war es, Möglichkeiten und Herausforderungen beim Einsatz von E-Procurement in der Baubranche aufzuzeigen. Dafür wurde im ersten Schritt E-Procurement auf Basis einer Literaturanalyse theoretisch betrachtet, um ein grundlegendes Verständnis dieses Themenfelds aufzubauen. Hierbei wurde festgestellt, dass die Einführung von E-Procurement zunächst eine Analyse der elektronisch zu unterstützenden Beschaffungsprozesse voraussetzt. Daher wurde das bisher wenig erforschte Gebiet der Baubeschaffung untersucht und literaturbasierte Annahmen zum Beschaffungsprozess in der Baubranche mit einem Experteninterview überprüft, um so spezifische Merkmale der Baubeschaffung herauszuarbeiten. Dies war die Grundlage für eine anschließende SWOT-Analyse, in der die Perspektive einer fiktiven Baufirma eingenommen wurde und die Rahmenbedingungen für E-Procurement überprüft wurden. Unternehmensbezogene Stärken und Schwächen, wie zum Beispiel das Vorhalten lokaler Artikelstammdaten, aber auch marktseitige Chancen und Risiken, wie die Verwendung von branchenüblichen Datenaustauschstandards, sind dabei aufgezeigt worden. Die Resultate daraus wurden von einem Einkäufer aus der Baubranche evaluiert und im Wesentlichen als praxisrelevant bestätigt. Es konnte aufgezeigt werden, dass Teilbereiche des Einkaufs in Bauunternehmen elektronisch unterstützt werden können. Ein umfassender Einsatz von E-Procurement wird jedoch auch aufgrund der derzeitigen Marktsituation erschwert.
05.10.17	2018	extern	Master	DE	Entwicklung eines Konzepts zur digitalen Transformation bei der IHK Nürnberg für Mittelfranken	Ziel der vorliegenden Arbeit ist es, ein Konzept zur digitalen Transformation der IHK Nürnberg (für Mittelfranken) zu entwickeln. Dieses Konzept soll es ermöglichen, die IHK Nürnberg ganzheitlich und zielgerichtet in eine digital transformierte Organisation zu wandeln. Um dieses Ziel zu erreichen, wird zunächst der theoretische Rahmen erarbeitet. Anschließend wird dieser aufgegriffen und zur Analyse der ermittelten Transformationsdimensionen angewandt. Zunächst erfolgt die Analyse der produktabhängigen Dimensionen der Kundenprozesse und internen Prozesse anhand eines Customer-Journey-Mappingverfahrens. Anschließend wird die produktunabhängige Dimension Organisation mit einer SWOT-Analyse untersucht. Im Anschluss werden die Erkenntnisse aus der Analysephase zusammengefasst und als Maßnahmen zu einer digitalen Landkarte zusammengeführt. Diese Landkarte dient als Konzept zur digitalen Transformation der IHK Nürnberg. Insgesamt kann festgehalten werden, dass das Konzept erfolgreich zur digitalen Transformation eingesetzt werden kann, hierbei jedoch stets die Entwicklungen der VUCA-Umwelt zu berücksichtigen sind.
09.10.17	2018	extern	Bachelor	DE	Analyse, Konzeption und prototypische Realisierung eines Build-Verfahrens mit Docker	In der SDV IT werden bisher Realease-Builds auf einem zentralen Release- Server des Teams INPU gebaut. Aufgrund der verschiedenen Anforderungen der Anwendungen müssen an diesem direkt Änderungen vorgenommen werden. Diese Änderungen sollen durch die Integration von Docker in den Release-Prozess vermieden werden. Die benötigten Umgebungen für die Anwendungen sollen mittels Docker-Images abgebildet werden. Die Arbeit hat drei Ziele. Zum einen soll die nötige Struktur für den Einsatz von Docker zu erarbeiten werden. Docker in den Release-Prozess einer Anwendung prototypisch zu integrieren werden, und die Vor- und Nachteile der Lösung mit Docker zu dem bisherigen Verfahren sind herauszuarbeiten.
09.10.17	2018	extern	Bachelor	DE	Analyse, Konzeption und prototypische Umsetzung des DATEV eG Intranets (Publishing) für mobile Endgeräte	Das Intranet der DATEV eG ist hauptsächlich über den Desktop-Arbeitsplatz erreichbar. Der Zugriff auf das Intranet über mobile Endgeräte ist nur eingeschränkt möglich. Hierbei treten Probleme der Benutzbarkeit auf. Das Ziel der Arbeit ist es, eine passende Benutzeroberfläche für mobile Endgeräte, mittels Prototyp, bereitzustellen. Im Hinblick auf den Prototypen muss herausgefunden werden, wel-che funktionalen und nicht-funktionalen Anforderungen die Anwender für ein mobiles Intranet fordern. Die Anforderungen der Anwender werden mit Erhebungstechniken, wie z.B. mittels Fragebogen, ermittelt. Die Konzeption der Benutzeroberfläche wird mit der Webdesign-Strategie "Responsive De-sign" umgesetzt. Im Designkonzept werden die von der DATEV eG zur Verfügung gestellten DATEV-Farben verwendet.
09.10.17	2018	extern	Bachelor	DE	Vergleich der Empfehlungsqualität von Neuronalen Netzen mit dem bestehenden Recommender-Algorithmus eines großen deutschen Immobilienportals	Ziel der Arbeit ist der Vergleich der Empfehlungsqualität eines bestehenden Recommender-Algorithmus und eines Ansatzes der auf Neuronalen Netzen beruht. Im Rahmen einer Simulationsstudie sollen die Metriken AUC und Recall für einen bereitgestellten Trainings-/Testdatensatz bestimmt werden. Dabei soll auf eine in R implementierte Simulationsstudie, ein geeignetes Framework für Neuronale Netze und den in R implementierten Algorithmus für das bisherige bestehende Recommender-System zurückgegriffen werden. Um valide Testmetriken zu erzeugen, ist insbesondere auf die Vergleichbarkeit der Simulationsstudie auf Basis der Neuronalen Netze und der Simulationsstudie auf Basis des bestehenden Algorithmus zu achten. Ergebnis der Arbeit ist die Bewertung und Interpretation der Metriken der Simulationsstudie. Im Rahmen eines Ausblickes werden Handlungsempfehlungen für die Sicherstellung der Echtzeitfähigkeit einer Lösung, die auf Neuronalen Netzen beruht, gegeben.
09.10.17	2018	extern	Bachelor	DE	Untersuchung und Evaluierung der Einsatzgebiete von räumlichen Daten auf einem Immobilienportal	Im Rahmen dieser Bachelorarbeit werden die Einsatzmöglichkeiten von räumlichen Daten und Karten auf einem Immobilienportal aufgezeigt. Hierzu werden im Rahmen der Wettbewerbsanalyse die Produkte von europäischen und außereuropäischen Mitbewerbern ausgewertet. Ein firmeninternes Brainstorming nach der kreativen Methode 635 wird genutzt, um zusätzliche neue Einsatzgebiete zu identifizieren und neue Produktideen für die Verwendung von Geodaten zu generieren. Mit der Anwendung verschiedener Methoden der Ideenbewertung und Einbeziehung verfügbarer Informationen über Zielgruppen und deren Verhalten, werden diejenigen Produktideen identifiziert, deren Geschäftswert und Kundennutzen am höchsten ist. Dabei werden die Produktalternativen zuerst mit der Checkliste-Methode ausgewertet. Die verbleibenden Ideen werden mit der Portfolio- und Nutzwertanalyse bewertet. Als Ergebnis wird die erfolgsversprechende Produktidee ausgewählt. Anschließend wird diese Produktidee genauer beschrieben und dazu ein Mock-up erstellt.
09.10.17	2018	extern	Bachelor	DE	Identifikation von Verbesserungspotenzialen in der Planung und Steuerung eines skalierten Scrum-Ansatzes im IT-Systemhaus der Bundesagentur für Arbeit	Die Abteilung SEP51 des IT-Systemhauses der Bundesagentur für Arbeit hat sich vor rund fünf Jahren dafür entschieden, auf Scrum als Rahmenwerk für die Softwareentwicklung umzusteigen. Aufgrund der Größe und der Komplexität der Anwendung, die durch die Abteilung entwickelt wird, sind viele Scrum-Teams nötig, weshalb eine Skalierung von Scrum zum Einsatz kommt. Über die Jahre hat die Abteilung SEP51 unter dem Namen "Scrum@VAM" ihren eigenen skalierten Scrum-Ansatz entwickelt. Im Rahmen der Bachelorarbeit wurden die Probleme in der Planung und Steuerung dieses Ansatzes anhand von Interviews mit den verschiedenen Rollen analysiert. Zur Lösungsfindung wurden die skalierten Scrum-Frameworks Nexus, Large-Scale Scrum und Scaled Agile Framework untersucht. Die Hauptprobleme, welche sich herauskristallisiert haben, sind die fehlende objektive Priorisierung der Anforderungen, der starre Release Container, welcher die zu schaffenden Features fest definiert, sowie der fehlende Feedbackzyklus. Die verschiedenen skalierten Scrum-Frameworks boten unter anderem mit einem priorisierten Product Backlog, kurzen Releasezyklen, einem Sprint-Review und einer übergreifenden Planung durch die Teams viele Möglichkeiten der Verbesserung, jedoch können nur wenige innerhalb der Abteilung, ohne die Mitwirkung von außen, umgesetzt werden. Das Problem hierbei liegt in dem nicht agilen Denken des Fachbereichs und der Bundesagentur für Arbeit allgemein.
09.10.17	2018	extern	Bachelor	DE	Entwicklung einer App zur Anzeige von Verlegerstatistiken	Im Rahmen dieser Bachelorarbeit wird die Entwicklung einer App zur Anzeige von Verlegerstatistiken, über die Phasen Analyse, Konzeption bzw. Entwurf und Implementierung hinweg, durchgeführt. Die App soll den Verlegern eine unkomplizierte Einsicht in ihre Statistiken bieten. Darunter werden im Kontext dieser Arbeit beispielsweise Klicks, Views, Leads oder Sales verstanden. Derzeit ist die Anzeige lediglich über eine stark veraltete, fehlerhafte und nicht performante Webanwendung möglich. Die Verleger wünschen sich eine Möglichkeit, ihre Statistiken auf ihrem Smartphone einsehen zu können. Das Ziel dieser Arbeit ist die Konzeption und Entwicklung einer App, die den Verleger beim Einsehen seiner Daten unterstützt. Dafür sollen intuitive und einheitliche Darstellungsmöglichkeiten verwendet werden. Nach einer Einführung in die technischen Grundlagen zum Verständnis der Arbeit folgt die Erstellung eines Anforderungskataloges sowie die Ermittlung eines geeigneten Entwicklungsansatzes, gefolgt von der Wahl eines nützlichen Frameworks. Anschließend erfolgt die Konzeption der App. Diese ist in die Phasen Grobentwurf und Feinentwurf unterteilt. Nach abgeschlossener Entwurfsphase wird die Implementierung der App erläutert. Letztlich erfolgt ein Benutzer-Akzeptanztest und damit einhergehend eine Evaluation als Mixed-Methods-Ansatz, deren Motiv es ist, die Stärken und Schwächen des App-Prototypen aufzuzeigen. Abgerundet wird die Arbeit durch einen Anforderungsabgleich.
10.10.17	2018	intern	Master	DE	Haptic Exploration of Virtual Objects	In den letzten Jahren wurde die Darstellung einer virtuellen Realität, speziell für den Videospielemarkt, stets weiterentwickelt und ist so auf großes Interesse gestoßen. Neben dem hohen Spaßfaktor hat diese Technologie das Potenzial einen barrierefreien Zugang zu Informationen für im blind und taube Menschen zu ermöglichen. Diese Arbeit zeigt auf, welche Ansätze und Möglichkeiten es bereits gibt, virtuelle Objekte haptisch zu erkunden und wie diese eingesetzt werden. Darüber hinaus wird eine Anwendung entwickelt, die durch Verwendung von vibrotaktilen Aktuatoren sowie Audiosignalen, das Ertasten von virtuellen Objekten ermöglicht. Die Anwendbarkeit der Technologie dieser Arbeit wird im Rahmen einer Benutzerstudie evaluiert.
11.10.17	2018	extern	Bachelor	DE	Konzeption und prototypische Realisierung eines Systems zur automatisierten Durchführung und Auswertung von Lasttests 	Das Unternehmen führt Lasttests für angebotene Anwendungen durch, um zum Beispiel einen erhöhten Ressourcenverbrauch festzustellen. Um Änderungen an bestehenden Anwendungen vor dem Übergang in die Produktion zu testen, sollten Lasttests regelmäßig durchgeführt werden. Auch soll die Auswertung der Ergebnisse automatisch erfolgen und ein Report mit definierten Kennzahlen nach Abschluss der Lasttests bereitgestellt werden. Die Arbeit soll passende Werkzeuge auf deren Eignung einer Automatisierung prüfen. Hierbei gilt es ein Konzept zu erarbeiten, welches prototypisch an einer Anwendung umgesetzt wird. Das Vorgehen beinhaltet die Abstimmung relevanter Kennzahlen, sowie die Installation und Administration des Werkzeuges. Nach Abschluss der Arbeit sollen Lasttests regelmäßig und automatisiert ablaufen und anschließend Reports mit definierten Kennzahlen veröffentlicht werden.
11.10.17	2018	extern	Bachelor	DE	Konzeption sowie prototypische Realisierung der Einbindung eines Schedulingsystems in eine PaaS-Umgebung	Die vorliegende Bachelorarbeit betrachtet verschiedene Arten der Anbindung und Integration eines Job-Schedulers in eine Plattform as a Service Umgebung in der DATEV eG. Ziel war es, verschiedene Umsetzungsalternativen für den Betrieb eines Schedulers für die Batchverarbeitung als Soll-Konzept zu erarbeiten, daraus die vorteilhafteste Lösung abzuleiten und prototypisch umzusetzen. Hierzu wurden zunächst drei Umsetzungsalternativen erarbeitet und anschließend aufgezeigt. Dabei werden die Vor- und Nachteile beschrieben und Allein-stellungsmerkmale der jeweiligen Alternative hervorgehoben. Augenmerkliche Unterschiede fanden sich zwischen den Alternativen bei der Auswahl der Laufzeitplattform für den Betrieb der Software. Die verschiedenen Umsetzungsalternativen wurden hinsichtlich ausgewählter Kriterien quali-tativ mittels einer Nutzwertanalyse, welche mit Experten aus dem Entwicklerteam des Schedulers durchgeführt wurde, verglichen. Die Nutzwertanalyse ergab, dass die dritte Um-setzungsalternative umzusetzen ist. Bei dieser Alternative wurde die Auswahl der Laufzeit-plattform abhängig von der Stage ausgewählt, da auf Teststages andere Kriterien im Vorder-grund stehen als auf produktiven Stages. Mit der Wahl der Plattform steht die Art des Betriebs des Schedulers eng zusammen. So wird auf produktiven Stages eine zentrale Instanz des Schedulers auf dem IBM Mainframe bereit-gestellt und von einem Team verwaltet. Auf Teststages hingegen ist es möglich, sich in der Plattform as a
12.10.17	2018	extern	Bachelor	DE	Analyse und Einführung eines Versionskontrollsystems zur Verwaltung von SSIS-Paketen für das Data Warehouse Team der Immowelt AG 	Ziel dieser Arbeit ist es, den Änderungsprozess der SSIS-Pakete zu optimieren. Aus diesem Grund wurden zunächst ausgewählte Versionsverwaltungssysteme miteinander anhand einer Nutzerwertanalyse verglichen und dadurch das passende System für den beschriebenen Anwendungszweck evaluiert. Um dabei ein repräsentatives Ergebnis zu erhalten, ist die Durchführung einer ausführlichen Literaturrecherche und eines internen Meetings von Bedeutung gewesen. Die daraus gewonnenen Erkenntnisse führten zu einem Kriterienkatalog, anhand dessen jedes Kriterium für jedes der ausgewählten Systeme mit einer entsprechenden Punktzahl zu bewerten war. Das Ergebnis hat gezeigt, dass die Systeme in der Regel nahe beieinanderliegen. Letztendlich fiel die Auswahl für die Implementierung auf die Versionskontrolle "Team Foundation Server". Bei der Implementierung waren zuerst einmal die Grundlagen für ein erfolgreiches lauffähiges System zu schaffen und in Zusammenarbeit mit dem Projektteam einige Entscheidungen, wie die Versionskontrolle zukünftig zu nutzen sein soll, zu treffen. Nachdem schließlich alle Erwägungen in Betracht gezogen waren, erfolgte das Hinzufügen der SSIS-Pakete und der Strukturierung des Teamprojektes. Um das ganze Thema abzurunden, wurden abschließend praxisnahe Testszenarien erläutert und anschließend durchgeführt. Da alle Prüfungen des Systems erfolgreich verlaufen sind, steht einer zukünftigen Teamarbeit mit der Versionskontrolle "Team Foundation Server" nichts mehr im Wege.
12.10.17	2018	extern	Bachelor	DE	Bildklassifikation auf Basis von Firmenlogos zur Einordnung von Dokumenten mit DATEV.	Diese Bachelorarbeit adressiert die Einordnung von Dokumenten mit Methoden des Machine Learnings auf Basis von Firmenlogos. Es soll untersucht werden, ob eine Klassifikation von Dokumenten anhand ihrer Logos möglich ist. Ziel dieser Arbeit ist daher die Konzeption, Realisierung und Evaluierung eines überwachten Klassifikationssystems. Es werden aktuelle Verfahren zur Detektion und Klassifikation von Objekten in Bilddaten untersucht. Die verwendeten Technologien sind die Tensorflow Object Detection API und ein Faster R-CNN. Weiterhin wird die Erstellung und Verwendung von synthetischen Trainingsdaten untersucht. Die Ergebnisse zeigen, dass die Klassifikation von Dokumenten durch ihre Firmenlogos möglich ist. Allerdings fallen die Evaluierungs-Ergebnisse hinter den Anforderungen zurück. Dies kann darauf zurückgeführt werden, dass sich die verwendeten synthetischen Trainingsdaten zu stark von der Gesamtheit der Daten unterscheiden.
12.10.17	2018	extern	Bachelor	DE	Integration der Honorarordnung für Architekten und Ingenieure in das ERP-System Microsoft Dynamics NAV	Das ERP-System Microsoft Dynamics NAV stellt eine Basis für die Abbildung aller relevanten Geschäftsprozesse eines Unternehmens dar. Jedoch gibt es auch einige Branchen mit speziellen Anforderungen, die darin nicht abgebildet sind. Dazu zählen Architekten und Ingenieure, für welche in Deutschland eine gesetzliche Verordnung existiert, die sogenannte Honorarordnung für Architekten und Ingenieure. Diese definiert zu erbringende Leistungen sowie die Höhe der dafür anfallenden Honorare und die Form, in der diese Honorare abzurechnen sind. Da die Inhalte der Honorarordnung damit von erheblicher Bedeutung für Architekten und Ingenieure sind, wird für Microsoft Dynamics NAV eine Erweiterung benötigt, um diese Vorgaben abzudecken. Das Ziel dieser Arbeit besteht darin, eine solche Erweiterung zu entwickeln. Dafür wird das angewandte Vorgehen beschrieben, sowie die so erzielten Ergebnisse. Nach einer Schilderung der Ausgangssituation bildet hierbei eine Beschreibung der durchgeführten Anforderungsanalyse den Anfang, wobei auf das Vorgehen, die herangezogenen Quellen und die so ermittelten Anforderungen eingegangen wird. Aus den Anforderungen wird anschließend das Soll-Konzept der Erweiterung erarbeitet. Abschließend wird die Kodierung des ermittelten Konzepts näher beleuchtet, wobei insbesondere auf aufgetretene Schwierigkeiten und besondere Herausforderungen eingegangen wird.
12.10.17	2018	intern	Bachelor	DE	Analyse und Bewertung von Apps für das Wissensmanagement	Das Thema dieser Arbeit beschäftigt sich mit der Analyse und der Bewertung der aktuellen Apps, die es auf dem Markt für das Wissensmanagement gibt. Mittels der Analyse wurde indirekt die Frage untersucht, welche Apps in den Phasen des Bausteinmodells von Probst ihre Anwendung finden. Anschließend werden für die Bewertung funktionale und nicht-funktionale Kriterien einer App für das Wissensmanagement aufgedeckt. Daraufhin wird eine Alternative unter den Apps für das Knowledge-Management ermittelt, die für den Einsatz in ein Unternehmen in Frage kommen könnte.
12.10.17	2018	intern	Bachelor	DE	"Evaluation von Werkzeugen zur Testautomatisierung von mobilen Android-Applikationen"	Die Arbeit mit dem Titel "Evaluation von Werkzeugen zur Testautomatisierung von mobilen Android-Applikationen" wird sich letztendlich mit der Untersuchung und Bewertung von Tools zur Testautomatisierung von mobilen Anwendungen befassen. In Anbetracht dessen, dass der Markt für mobile Anwendungen sich in einem rasanten Wachstum befindet und zufriedene Nutzer unabdingbar für wirtschaftlich erfolgreiche Apps sind, sollte die Qualitätssicherung keineswegs vernachlässigt werden. Testautomatisierungs-Tools sollen dabei die Aufgabe erleichtern und beschleunigen. Im ersten Schritt der Arbeit sollen geeignete Tools ermittelt werden und diese dann anhand eines Anwendungsbeispiels getestet und bewertet werden. Hierfür wurden zunächst geeignete Tools ermittelt und miteinander verglichen. Daraufhin wurden, mithilfe einer Beispiel-App, Testfälle entworfen und implementiert. Schließlich wurde die Eignung der einzelnen Tools bewertet. Die Evaluation hat gezeigt, dass sich das offizielle Werkzeug Espresso für single-platform-Apps am besten eignet. Für cross-platform-Apps ist eine Kombination aus Espresso und Appium denkbar.
12.10.17	2018	extern	Bachelor	DE	Konzeption und prototypische Implementierung von digitalen Türbeschilderungen der DATEV eG mithilfe eines zentralen Digital Signage Systems	Die Arbeit befasst sich mit der Erarbeitung eines Medienkonzeptes für die effiziente Raumbuchung mithilfe von digitalen Türschildern aus dem Digital Signage Produktportfolio sowie deren prototypische Umsetzung. Durch die wachsende Nachfrage nach Besprechungs- und Konferenzräumen konnte der Bedarf der Mitarbeiter nicht optimal gedeckt werden. Durch den Einsatz digitaler Türschilder im Unternehmen wird eine Entlastung der IST-Situation erstrebt. Auf Basis von Recherchen, einer Marktanalyse und einem Produkttest wurde für das Unternehmen ein Türschild identifiziert. Anschließend wurde die Technik der Türschilder kritisch begutachtet. Unter Beachtung aller Faktoren wurde ein Konzept erarbeitet, das als Leitfaden für die Umsetzung auf das produktive Umfeld eines Nürnberger Softwarehauses angewandt werden kann.
13.10.17	2018	intern	Bachelor	DE	Erstellung eines IT-Grundschutz-Profils als Referenzmodell für kleine bis mittelständische Steuerberatungskanzleien 	Ziel meiner Bachelorarbeit ist es, ein IT-Grundschutz-Profil in Zusammenarbeit mit der DATEV eG zu erstellen. Dieses Profil richtet sich an Steuerberaterkanzleien, mit den hierfür typischen Geschäftsabläufen im Hinblick auf das Rechnungswesen, Jahresabschlüsse, Lohnverarbeitung, Steuerdeklaration und Wirtschaftsberatung sowie kanzleieigene Prozesse. Der Fokus liegt auf kleine und mittelständische Steuerkanzleien mit bis zu 15 Mitarbeitern, bei denen in der Regel davon auszugehen ist, dass Sie über keine professionelle IT-Kompetenz verfügen. Außerdem berücksichtigt es die besonderen Anforderungen dieses Berufsstands an die Verschwiegenheitspflicht und die damit einhergehende Vertrauensposition des Beraters gegenüber seiner Mandanten. Das Profil soll es den Steuerkanzleien ermöglichen einen Mindestschutz im Sinne des BSI Standards für seine Kanzlei zu erhalten. Dazu werden verschiedene Empfehlungen im Profil bereitgestellt. Das mit der Bachelorarbeit erarbeitete Profil soll später als Referenzmodell für ein BSI IT-Grundschutz-Profil für den Steuerberatenden Beruf dienen. Auf dessen Basis etwaige spätere Zertifizierungen wie beispielsweise nach ISO-27001 durchzuführen sind. Um die hierfür notwendige Wissensgrundlage zu erlangen, werden zahlreiche Interviews geführt sowie eine intensive Auseinandersetzung mit internen und externen Steuerberatern betrieben. Basis hierfür sind die vom BSI neu veröffentlichten Bausteine zur Erstellung eines Grundschutzprofils nach BSI Standard.
17.10.17	2018	extern	Bachelor	DE	Vergleich der Empfehlungsqualität von Fakturisierungsmaschinen mit dem bestehenden Recommender-Algorithmus eines großen deutschen Immobilienportals	Ziel dieser Bachelorarbeit ist der Vergleich der Empfehlungsqualität eines bestehenden Recommender-Algorithmus der Immowelt AG, mit einem auf Faktorisierungsmaschinen beruhenden Ansatz. Zu Beginn werden die theoretischen Grundlagen von Recommendersystemen im Allgemeinen, sowie die Funktion von Faktorisierungsmaschinen erläutert. Zudem sind Rahmenbedingungen, in Form einer in R implementierten Simulationsstudie, sowie eines Immobiliendatensatzes vorgegeben. Die Studie stellt die wissenschaftliche Vergleichbarkeit der Ansätze sicher und musste an die Faktorisierungsmaschine angepasst werden. Der von der Immowelt AG zur Verfügung gestellte Datensatz, beinhaltet verschiedene Arten von Immobilien und stellt die Grundlage für die Auswertungen dar. Die Änderungen, um mit diesen Daten Vorhersagen generieren zu können, werden im weiteren Verlauf beschrieben. Bei der Implementierung des neuen Ansatzes wurde sich für eine Faktorisierungsmaschine höherer Ordnung entschieden, da diese in der Lage ist, Ähnlichkeiten zwischen mehreren Variablen zu ermitteln. Parallel zu dieser Bachelorarbeit wird ein auf neuronalen Netzen beruhender Ansatz mit denselben Daten getestet. Der Vergleich erfolgt daher neben dem Recommendersystem der Immowelt AG auch mit diesem Ansatz. Die Empfehlungsqualität der Ansätze wurde mit den vorgegebenen Metriken Receiver Operating Characteristics Curve und Recall bestimmt.
18.10.17	2018	extern	Bachelor	DE	Konzepterstellung für eine Verbesserung des EB tresos-Konfigurationswerkzeuges basierend auf einem Vergleich mit anderen AUTOSAR-Werkzeugen	Die vorliegende Bachelorarbeit beschreibt die Optimierung der Gebrauchstauglichkeit der Software EB tresos Studio aus dem automobilen Bereich. Die Vorgehensweise der Arbeit basiert auf bestehenden theoretischen Grundlagen zur Gebrauchstauglichkeit von Produkten. Im praktischen Teil der Arbeit wird untersucht, ob sich Benutzerbefragungen und der Vergleich konkurrierender Produkte für die Optimierung der Gebrauchstauglichkeit eignen. Dies wird in einem Usability-Test mithilfe von abgeleiteten Anforderungen anhand eines Prototyps geprüft. Das Ziel dieser Bachelorarbeit ist es, einen effektiven Standardprozess zur systematischen Verbesserung der Gebrauchstauglichkeit von Software zu finden. Diese Arbeit ist interessant für alle, die sich mit der Optimierung der Gebrauchstauglichkeit von Produkten befassen. Außerdem richtet sie sich an Personen, die sich mit Methodiken zur Analyse von Software und mit benutzerorientierter Entwicklung von Software beschäftigen. Die Ergebnisse dieser Bachelorarbeit sind die Verknüpfung von zwei Methodiken zur Optimierung der Gebrauchstauglichkeit von Software sowie die Entwicklung eines Prototyps und die Testergebnisse aus dem Usability-Test.
18.10.17	2018	extern	Master	DE	Prognose von Absatzzahlen mithilfe eines neuronalen Netzes bei MediaMarktSaturn	Ziel dieser Arbeit war eine Machbarkeitsstudie über die Verwendung von neuronalen Netzen zur Prognose von Absatzzahlen zu erstellen. Dabei lag der Fokus auf Feed-Forward und Long Short-Term Memory Netzen. Diese wurden mit Absatzinformationen aus den vergangenen vier Jahren trainiert. Als Vergleichsmodell wurden Support Vector Machines trainiert. Der Test der trainierten Modelle zeigte, dass die Modelle zwar besser als eine naive Prognose funktionieren, aber die aktuell vorhandenen Trainingsdaten nicht ausreichend für das Training zuverlässiger Modelle sind. Ein Vergleich der Modelle zeigte, dass neuronale Netze in diesem Fall bessere Performance liefern als Support Vector Machines. Zwischen den neuronalen Netzen war kein eindeutig besseres Modell erkennbar. Um zukünftig präzisiere Modelle trainieren zu können, ist eine Erweiterung der Trainingsdaten nötig. Das betrifft zum einen den Zeitraum, der größer sein muss, um saisonale Effekte besser trainieren zu können. Zum anderen müssen die Input-Features erweitert werden, um bisher fehlende Einflussfaktoren abzubilden.
19.10.17	2018	extern	Bachelor	DE	Strategische und operative Aspekte der Performanceoptimierung bei Kundensystemen der DATEV eG	Ziel dieser Bachelorarbeit ist es, die Performance von Software als Faktor für Kundenzufriedenheit, aber auch für Servicebelastung im Softwarehaus einzuordnen. Vor diesem Hintergrund werden die strategischen und operativen Aspekte der Performanceoptimierung bei Kundensystemen betrachtet. Der operative Teil der Bachelorarbeit befasst sich mit der Optimierung eines konkreten Serviceprozesses zur Performanceanalyse von Kundensystemen der DATEV eG. Die strategischen Aspekte beleuchten, wie mittelfristig Performanceprobleme, aber auch Serviceanfragen zum Thema Performance präventiv vermieden werden können. Langfristig wird die Bedeutung von Performanceoptimierung im Hinblick auf die zunehmende Digitalisierung in sämtlichen Branchen und dem Trendwandel von On-Premises- zu Cloud-Lösungen betrachtet: Welchen Einfluss haben diese Entwicklungen auf den Serviceprozess der Performanceanalyse und wie muss der Prozess unter Berücksichtigung dieser Faktoren weiterentwickelt werden. Neben der Fallstudie im Unternehmen DATEV eG wird der Blick darauf ausgeweitet, welche Aspekte der Performanceoptimierung auf andere Unternehmen übertragen werden können und welche Voraussetzungen für die Übertragbarkeit der Erkenntnisse notwendig sind.
20.10.17	2018	extern	Bachelor	DE	Konzeption und Integration eines Sicherheitskonzeptes in einem Data Warehouse	Das Ziel dieser Bachelorarbeit besteht darin, gesetzliche Richtlinien des Datenschutzes in Bezug auf eine Business Intelligence Architektur zu betrachten. Insbesondere die europäische Datenschutzgrundverordnung gibt neue Anreize für alle datenverarbeitenden Unternehmen, die neuen Richtlinien bis zum Inkrafttreten der Verordnung umzusetzen. Vor diesem Hintergrund wird sich anfangs mit den neuen rechtlichen Bestimmungen und den daraus resultierenden Konsequenzen beschäftigt. In der Konzeptionsphase werden verschiedene Möglichkeiten betrachtet, die es erlauben den Zugriff auf Daten über unterschiedliche Benutzergruppen zu differenzieren. Insbesondere Daten mit Personenbezug gilt es nach dem Grundsatz der Datenvermeidung nur Anwendern zur Verfügung zu stellen, welche ein berechtigtes Interesse besitzen. Dabei werden die Vor- und Nachteile der Lösungsansätze betrachtet und Methoden zur Entscheidungsunterstützung angewendet. Schließlich wird die evaluierte Alternative im Rahmen einer prototypischen Umsetzung realisiert. Dabei werden die Voraussetzungen, welche in der BNP Paribas S.A. Niederlassung Deutschland für die Marke Consorsbank bestehen, berücksichtigt und die Einsatzfähigkeit der Lösung im Unternehmensumfeld kritisch betrachtet.
20.10.17	2018	extern	Bachelor	DE	Vergleich von SAP User Experience Techniken mit Hilfe der Implementierung von Beispieldialogen bei der Dematic GmbH	Die Firma Dematic ist einer der weltweit führenden Generalunternehmen im Bereich der Intralogistik, der Steuerung des Materialflusses und der Lagerautomatisierung. In einem Lagerkomplex werden viele verschiedene Techniken zur effizienten Bearbeitung von Aufträgen benutzt. Ein Großteil dieser Techniken wird durch einen oder mehreren Mitarbeitern durchgeführt. Dafür benötigt man eine Schnittstelle vom System zum Mitarbeiter, die in der Regel durch Dialoge realisiert wird. Dematic nutzt hierfür ein eigenes Framework, das die klassische Dynpro-Programmierung durch HTML und JavaScript Elemente erweitert, um somit den Kundenanforderungen besser gerecht zu werden. SAP hat jedoch mehrere Techniken entwickelt, um diese Dialoge einfach und benutzerfreundlich zu implementieren, die unter dem Begriff der SAP User Experience (UX) zusammengefasst sind. Im Rahmen dieser Arbeit werden mit Hilfe der von SAP publizierten Techniken Dialog- Prototypen entwickelt, um diese anhand mehrerer Kriterien vergleichen zu können. Dadurch kann abgewogen werden, ob die Kundenanforderungen mit diesen Techniken besser und effizienter erfüllt werden können und ob dadurch das Dematic-eigene Framework abgelöst werden kann.
20.10.17	2018	extern	Bachelor	DE	Erarbeiten einer Qualitätsmanagement Strategie im agilen Softwareentwicklungsumfeld bei DATEV eG	Zur Steigerung der Produktqualität der Abteilung EM3 des Entwicklungsbereichs der DATEV eG mit dem Produkt Kanzleimanagement muss der agile Entwicklungsprozess optimiert werden. Ziel dieser Bachelorarbeit ist das Erarbeiten einer Qualitätsmanagementstrategie im Rahmen des agilen Softwareentwicklungsprozesses für das Produkt Kanzleimanagement. Diese beschreibt ein ideales Endresultat, auf das hingearbeitet werden soll und repräsentiert damit zugleich die Antwort auf die Frage "Wo wollen wir hin?". Für die QM-Strategie wurden Ziele erarbeitet. Für diese Ziele wurden zur Konkretisierung Eckpfeiler erarbeitet, die das Erreichen des Ziels unterstützen sollen. Zudem wurde eine erste Maßnahme umgesetzt um dem Zielbild der Qualitätsmana-gementstrategie schrittweise näher zu kommen.
23.10.17	2018	extern	Bachelor	DE	Konzeption und Implementierung eines radiologischen Informationssystemsimulators als Teil einer Testumgebung für medizinische Bildsysteme	Radiologische Informationssysteme (RIS) dienen in klinischen Einrichtungen der zentralen Verwaltung und Dokumentation von Patienten- und Untersuchungsdaten. Das RIS liefert auf Anfrage eine sogenannte Modality Worklist. Also die für die nächste Zeit anstehenden Untersuchungen für verschiedene medizinische Geräte (auch Modalität, z.B. ein MRT oder CT). Des Weiteren findet vor einer radiologischen Untersuchung noch weitere Kommunikation mit anderen medizinischen Systemen, wie einem Bildarchiv, statt. Ziel dieser Bachelorarbeit, die in Kooperation mit der Siemens Healthcare GmbH angefertigt wurde, war es, einen Simulator für ein solches radiologisches Informationssystem zu entwickeln. Dieses sollte in ein internes Tool integriert werden, welches medizinische Testdaten verwaltet. Der RIS-Simulator soll einem zu testenden System eine Modality Worklist bereitstellen, und auf Wunsch des Nutzers eine komplette radiologische Untersuchung simulieren. Hierzu wurden bereits implementierte Features des Tools mit der neuen Implementierung des RIS-Simulators kombiniert, um den kompletten Arbeitsablauf einer radiologischen Untersuchung zu simulieren.
25.10.17	2018	intern	Bachelor	DE	Spielerische Anreizmechaniken in digitalen Anwendungen zur Förderung gesunder Ernährung und Bewegung	Diese Arbeit beschäftigt sich mit der Motivation von gesundem Ernährungs- und Sportverhalten unter der Zuhilfenahme von digitalen Anwendungen. Es wird der Frage nachgegangen wie der aktuelle Stand von spielerischen Anreizmechaniken in Ernährungs- und Sportanwendungen ist und wie diese gleichzeitig ethisch bewertet werden können. Diese Frage wird auf Grundlage der Auswertung aktueller Fachliteratur über Gamification und Verhaltensänderungstheorien diskutiert. Zur Beschreibung des aktuellen Stands wird repräsentativ für die digitalen Anwendungen der App-Markt von Google?s Playstore auf Anreizmechaniken untersucht und mit aktuellen Auswertungen ergänzt. Das Ergebnis der Untersuchungen zeigt eine schwache Präsenz spielerischer Anreizmechaniken in Ernährungs- und Sport-Apps. Die Apps enthalten zwar Motivationselemente, diese sind jedoch kaum spielerisch. Die Tendenz liegt in der vermehrten Nutzung sozialer Elemente und simpler Elemente, wie Punkte und Badges. Eine langfristige Verhaltensänderung wird nur bedingt gefördert. Aus ethischer Sicht sind mehrere Aspekte klargeworden. Einer Spielsucht sollte vorgebeugt werden. Die Anreizmechaniken dürfen nicht zum Kaschieren anderer Schwachstellen der Anwendung genutzt werden und die Effektivität der Anwendung sollte immer im Vordergrund stehen. Wichtige Funktionalität sollte nicht vorenthalten werden, um dann später mit teurem Premium-Content Geld zu erwirtschaften und alle Arten von Zwängen, wie sozialer Druck oder Geldstrafen, sollten
26.10.17	2018	extern	Master	DE	Analyse, Konzeption und Umsetzung einer prototypischen IoT-Architekturlösung unter Verwendung von Microsoft Azure im Anwendungsbereich der Industrie 4.0. 	Ziel dieser Masterarbeit war die Analyse, Konzeption und Umsetzung einer prototypischen IoT-Architekturlösung unter Verwendung von Microsoft-Azure im Anwendungsbereich der Industrie 4.0. Hierzu wurden im ersten Teil der Ausarbeitung die theoretischen Grundlagen in den Bereichen analytische Informationssysteme, Internet of Things und Industrie 4.0 dargelegt. Zur Synthese dieser Themengebiete wurde ein Modell von Industrie 4.0 eingeführt. Anschließend wurde ein Einsatzszenario für den zu entwickelten Prototyp beschrieben. Dazu wurde eine Ist-Analyse anhand einer beispielhaften Pharma Supply Chain durchgeführt und Geschäftsprozesse wurden bewertet. Auf Basis dieser Ergebnisse wurden konkrete Anwendungsfälle entwickelt und funktionale und nicht funktionale Anforderungen erhoben. Anschließend wurde ein für den Prototyp geeignetes Referenzmodell identifiziert und ein Architekturentwurf erstellt. Für die Umsetzung des Prototyps wurden die Komponenten Datenstreaming, Datenprozessierung, Daten-speicherung und Datenanalyse in der Cloud-Computing-Plattform Microsoft Azure realisiert. Anschließend wurde dargelegt, wie die gesammelten Informationen durch das Präsentationstool Power-BI Geschäftsprozessen verfügbar gemacht werden könnten. Im abschließenden Fazit wurden die Ergebnisse kritisch bewertet.
01.11.17	2018	intern	Master	DE	Gesichtsdetektion in Bildern mittels Region-based Convolutional Neural Networks	Das Ziel dieser Masterarbeit ist es, die Detektion von Gesichtern in Bilddateien mittels Region-based Convolutional Neural Networks (R-CNNs) zu untersuchen. Zunächst werden die theoretischen Grundlagen von R-CNNs vorgestellt und diese Methoden sowohl gegenübergestellt als auch verglichen. Anschließend werden aktuelle Methoden zur Detektion von Gesichtern in Bildern mit Gesichtsdetektoren auf Basis von neuronalen Netzen verglichen. Im praktischen Teil der Arbeit wird ein Region-based CNN für die Detektion und Lokalisierung von Gesichtern in Bildern erstellt und trainiert. Anhand einer oder mehrerer geeigneter Teststichproben wird die Erkennungsrate und der benötigte Rechenaufwand der Verfahren ermittelt und verglichen. Zusätzlich wird ein Vergleich mit einem klassischen Gesichtsdetektor wie dem Viola-Jones-Algorithmus durchgeführt.
02.11.17	2018	extern	Bachelor	DE	Proof of Possession - Zwei-Faktor-Authentifizierung zur Gewährleistung gesicherter Client-Server-Kommunikation	In der Bachelorarbeit geht es darum, das Proof-of-Possession-Verfahren auf einem Android-Client umzusetzen. Mit dem Proof-of-Possession-Verfahren können wir sicherstellen, dass die Person, zu der das Konto gehört, sich mit ihrem physischen Gerät anmeldet und nicht ein Hacker von einem anderen Gerät aus. Somit können die Daten von Personen vor Angriffen geschützt werden. Mit Hilfe von Kryptographie soll die Authentifizierung einer Person beim Anmelden in eine Banking-App, Versicherungs-App, Email-App, etc., noch sicherer gemacht werden.
06.11.17	2018	intern	Bachelor	DE	Wiedereinspielungsangriffe auf funkbasierte Autoschlösser mithilfe eines softwarebasierten Sendeempfängers	Das Ziel der vorliegenden Bachelorarbeit war es, mithilfe eines softwarebasierten Sendeempfängers, dem HackRF-One, Signale funkbasierter Autoschlüssel neuerer Fahrzeugmodelle abzufangen und wieder abzuspielen. Der Angriff erfolgt hierbei durch Wiedereinspielung abgefangener Signale. Funksignale neuere Fahrzeugmodelle verwenden zur Abwehr von Hack-Angriffen Rolling-Codes. Mithilfe des GNU-Radio-Companion und des YARD-Stick-Ones wurde jedoch gezeigt, dass diese dennoch angreifbar gemacht werden können. Hierzu wurde ein YARD-Stick-One mithilfe der RfCat-Framework als Störsender umfunktioniert und ein HackRF-One mithilfe des GNU-Radio-Companions als Empfänger und Sender der Autofunkschlüsselsignale verwendet. Die aufgezeichenten Signale wurden mittels eines Bandpass-Filters vom Störsignal des YARD-Stick-ones gefiltert, sodass diese beim Abspielen vom Auto ohne Probleme erkannt werden konnten. So konnte bewiesen werden, dass Autos mit Rolling-Code-Systemen angreifbar und damit unsicher sind.
06.11.17	2018	extern	Bachelor	DE	Konzeption und Implementierung eines integrierten Dienstleistungserfassungssystems	"Ziel dieser Bachelorarbeit war die Konzeption eines Dienstleistungserfassungssystems und dessen Implementierung in das Enterprise-Content-Management-System DOCUframe der Firma GSD-Software unter Verwendung der Programmiersprache DOCUcontrol.	 Dazu wurden die zugrunde liegenden Arbeitsschritte, vom Eingang eines Arbeitsauftrages bis hin zu dessen Abschluss, analysiert und anschließend in einer Anforderungsanalyse festgehalten. Grundlegende Bestandteile des geplanten Systems waren ein effizienter Erfassungsvorgang, eine Verwaltungsoberfläche für bestehende Tickets, eine Arbeitszeiterfassung für die Benutzer, sowie eine automatisierte Zeiterfassung Ticketeinträge.	 Am Ende der Arbeit steht ein funktionsfähiges System mit allen grundlegenden Funktionen der Anforderungsanalyse sowie der Vorgaben des Unternehmens . "
08.11.17	2018	extern	Bachelor	DE	Konzeption einer mobilen Projektzeiterfassung für das ERP-System Odoo	Um den Gesetzen zur Arbeitszeit gerecht zu werden und die betrieblichen Abläufe zu beschleunigen, stellen Firmen auf eine elektronische Zeiterfassung um. Zeitgleich werden auch ERP-Systeme (Enterprise-Resource-Planning) eingeführt. Eine Verknüpfung beider Bereiche mittels Smartphone-Apps führt zu einer weiter gesteigerten Effizienz. Deshalb wird im Rahmen dieser Arbeit zusammen mit der Firma LSK Engineering Services GmbH ein Prototyp für eine Projektzeiterfassungs-App entwickelt, der sich den Bedürfnissen des Betriebes nach die Mitarbeiter führenden und trotzdem flexiblen Zeiterfassung anpasst. Dieser Prototyp besteht aus einem Plugin für das ERP-System Odoo-10-Community-Edition und aus einer App für die Plattformen Android, iOS und Windows 10. Dazu wird der IST-Zustand der Zeiterfassung bei LSK untersucht und anschließend die Anforderungen an eine Projektzeiterfassung ermittelt. Diese werden mit anderen Zeiterfassungs-Apps verglichen. Anschließend wird eine eigene Zeiterfassungs-App erarbeitet. Diese App unterstützt sowohl die Erfassung nach dem Mindestlohngesetz, als auch die Erfassung der Projektzeiten. Bei Benutzung der App werden die Mitarbeiter auf die gültigen Gesetze zur Arbeitszeit hingewiesen.
09.11.17	2018	extern	Bachelor	DE	Analyse und Optimierung von Usability und Design einer plattformübergreifenden App für IT-Asset Management	Im Zuge der Migration von Cordova zu Xamarin.Forms einer mobilen App für IT-Asset Management der Firma Fair Computer Systems GmbH sind aufgrund von plattformübergreifendem Code einige Designschwierigkeiten aufgetreten. Um eine benutzerfreundliche App bereitzustellen, wurden Schwachstellen aufgedeckt und reduziert. Anhand von nativen Design-Vorlagen der Betriebssysteme Android, iOS und UWP konnten Trends identifiziert und umgesetzt werden. Um das Layout neu zu gestalten und die Akzeptanz der Benutzer zu steigern, wurden Konzepte mit Hilfe von Methoden aus dem User Centered Design erarbeitet. Des Weiteren konnte das Gesamterlebnis durch die Analyse von Usability-Zielen gesteigert und das neue User Interface auf Grundlage der Konzepte realisiert werden.
09.11.17	2018	extern	Bachelor	DE	Wirtschaftlichkeitsanalyse von Single-Source-Publishing-Lösungen am Beispiel eines mittelständischen Unternehmens	Single Source Publishing ist ein Verfahren bei dem Informationsprodukte an einer zentralen Stelle erstellt und verwaltet werden. Informationsprodukte werden von Technischen Redakteuren benötigt um z. B. Bedienungsanleitungen für technische Geräte oder Angebotsbeschreibungen für Onlineshops zu erstellen. Im Jahr 2014 wird die doctima GmbH von einem mittelständischen Unternehmen beauftragt, eine geeignete Single-Source-Publishing-Lösung für ihren neuen Webauftritt zu konzipieren. Neben der Evaluation geeigneter Software ist auch Eigenentwicklung von Komponenten nötig. Das Ziel dieser Arbeit ist die Analyse der Wirtschaftlichkeit einer Single-Source-Publishing-Lösung. Kennzahlen wie Zeitaufwand, Kosten, Qualität des Contents, Benutzerfreundlichkeit und Zugriffszahlen sollen mit geeigneten Methoden gewonnen und ausgewertet werden. Außerdem soll untersucht werden wie sich die Einführung einer Single-Source-Publishing-Lösung auf Bereiche außerhalb der Technischen Redaktion auswirkt. Zusätzlich soll ein Überblick über die eingesetzten Methoden und Technologien, zur Umsetzung der Projektziele, gegeben werden. Die Ergebnisse bestätigen, dass sich die Einführung einer Single-Source-Publishing-Lösung positiv auf die oben genannten Kennzahlen auswirkt. Bei der Gegenüberstellung von Kosten und Nutzen ist erkennbar dass eine Amortisierung der Kosten in wenigen Jahren möglich ist.
10.11.17	2018	extern	Bachelor	DE	Konzeption der Verwaltung von kundenspezifischen Anpassungen für standardisierte ERP-Systeme im Mittelstand	Im Rahmen dieser Bachelorarbeit wird anhand der Firma Vepos GmbH & Co. KG und deren ERP-Software v.Soft untersucht, wie kundenspezifische Anpassungen verwaltet werden können. Motivation ist der hohe Aufwand für die Verwaltung zahlreicher unterschiedlicher Versionen bei steigender Kundenanzahl. Nach der Systematisierung kundenspezifischer Adaptionen und der Problem- und Ursachenanalyse werden Lösungsansätze identifiziert, untersucht und bewertet, die es ermöglichen, kundenspezifische Anpassungen aufwandsarm zu verwalten. Das Ziel ist die Erarbeitung einer Lösungsstrategie, die mit den gewonnenen Erkenntnissen sinnvoll umgesetzt werden kann und die derzeitige Verwaltung ersetzt.
13.11.17	2018	extern	Bachelor	DE	Konzeption und Entwicklung eines lernenden Chatbots für die Unterstützung der digitalen Rechtsberatung	Ziel der Bachelorarbeit war es, ein Framework zur Erstellung von Chatbots für den Rechtsschutzmarkt zu entwickeln. Ein Chatbot, der mit dem prototypischen Framework erstellt wurde, soll durch Angaben des Kunden erkennen, welches Anliegen dieser hat. Die Herausforderung dabei besteht in der Fähigkeit des Bots, anhand von gesammelten Daten seinen Ablauf zu optimieren. Dazu zählt eine Situations-Analyse und das Erstellen eines Konzeptes aus den Resultaten der Analyse. Abschließend wurde ein Testfeld gesucht und durchgeführt. Damit wurde bewiesen, dass Chatbots zur Kundensteuerung am Rechtsschutzmarkt beitragen können.
13.11.17	2018	intern	Bachelor	DE	Lernende Organisationen im Spannungsfeld verschiedener organisationaler Gruppen und das dies-bezügliche spezifische Risikomanagement.	Durch die sich ändernden außerorganisationalen Gegebenheiten müssen Organisationen ggf. strukturelle Änderungen vornehmen und Vorgehensweisen anpassen. Dies führt zu unterschiedlichen Reaktionen der organisationalen Gruppen. Daher sollen Notwendigkeit und Perspektiven von spezifischem Risikomanagement bezüglich der organisationalen Gruppen herausgearbeitet werden. Für das Herausarbeiten wurde Literaturrecherche zu Definitionen der zentralen Begrifflichkeiten betrieben. Parallel dazu erfolgte eine empirische Untersuchung in Form eines Fragebogens und eine anschließende Auswertung der Ist-Situation. Ergebnis der Arbeit ist eine Dokumentation von Defiziten und Best Practices im Umgang mit organisationalen Gruppen.
17.11.17	2018	intern	Master	DE	Entwicklung eines Systems zur Erstellung und Benutzung von interaktiven taktilen Graphiken auf Basis eines Lasergravur-Verfahrens	Taktile Karten unterstützen blinde und sehbeeinträchtigte Menschen bei deren Orientierung und Mobilität. Durch die Verwendung von Touch Displays und Audio Feedback, konnte herkömmliches Schwellpapier bereits mit interaktiven Informationen angereichert werden. Des Weiteren wurde durch den 3D-Druck, eine weitere Herstellungsvariante von taktilen Karten ermöglicht. Nichtsdestotrotz birgt vor allem der 3D-Druck auch diverse Einschränkungen. Insbesondere die Erstellung von größeren 3D-gedruckten Karten, führt zu einem überproportional großen Zeitaufwand. Aus diesem Grunde wird in dieser schriftlichen Ausarbeitung, eine weitere Herstellungsalternative unter Zuhilfenahme eines Lasergravur-Verfahrens vorgeschlagen. Darüber hinaus wird ein geschlossenes und kostengünstiges System, bestehend aus Raspberry Pi, Touch Display und Laser, für den Unterricht an Blindenschulen vorgestellt. Mit dessen Hilfe kann das Lehrpersonal eigenes Unterrichtsmaterial erstellen und dieses mit digitalen Informationen anreichern. Im späteren Verlauf ermöglicht das System den Schülern, diese interaktiven taktilen Karten, für den Lernprozess zu verwenden. Diese Arbeit behandelt insbesondere die Anforderungen an das umgesetzte Lehrer- /Schülersystem, sowie die Erstellung und Analyse der neuen Herstellungsalternative. Eine durchgeführte Benutzerstudie mit Lehrern, unterschiedlichen Alters und technischer Erfahrung, bestätigte im Anschluss die grundsätzliche Funktionalität des umgesetzten Systems.
22.11.17	2018	intern	Bachelor	DE	Edition der mathematischen Textaufgaben aus dem Anhang von Anton Neudörffers Anweisung in die Arithmetic (1627)	Die Vermittlung mathematischen Wissens in Stadtschulen oblag vom 16. bis ins 18. Jh. sogenannten Rechenmeistern, die sich überdies als Autoren von Rechenbüchern auszeichnen konnten. Der Nürnberger Schreib- und Rechenmeister Anton Neudörffer (1571 ? 1628) ist durch seine mehrfach aufgelegte "Anweisung in der Arithmetic" bekannt. Durch die Wirren des 30jährigen Krieges wurde seine mit Vorabdrucken angekündigte "Grosse Arithmetic" weder gedruckt, noch ist ein Manuskript überliefert. Die Bayerische Staatsbibliothek München besitzt jedoch eine von Georg Wendler (1619 ? 1988) verfasste Handschrift, in der er unter anderem 390 Prosa- und Reim- Textaufgaben daraus behandelt. In dem Projekt soll auf der Basis dieser Handschrift eine Edition erstellt werden, die sowohl Aufgabentexte als auch Lösungen in heute verständlicher Form enthält. (vgl. https://www.th-nuernberg.de/forschung-innovation/die-zehn-leitthemen-der-technischen-hochschule-nuernberg/medien-und-kommunikation/forschungsprojekte/)
22.11.17	2018	intern	Bachelor	DE	Schwarmintelligenz	Die folgende Bachelorarbeit untersucht verschiedene ACO-Algorithmen im Bereich der Schwarmintelligenz im Bezug auf Optimierungsprobleme. Ziel ist es die effizientesten ACO-Algorithmen für dasselbe Optimierungsproblem zu finden um einen aktuellen Überblick zu erhalten. Es werden die effizientesten Parameter für bewährte ACO-Algorithmen anhand des Travelling-Salesman-Problems gesucht und miteinander verglichen.
24.11.17	2018	extern	Bachelor	DE	Feingranulare Datenbankzugriffe mit dokumentbasierten Datenbanken	Oftmals ist die Datenbank einer Webapplikation gegen unbefugte Zugriffe von autorisierte Benutzer nicht geschützt und Daten können von diesen extrahiert werden. Entweder werden tatsächliche Werte von Datenbankobjekten statt benutzerabhängiger Referenzwerte in der Applikation verwendet, oder die Applikation überprüft bei der Abfrage die Berechtigung des Benutzers für den Ressourcenzugriff nicht. Modifiziert ein Angreifer gezielt Parameter einer Anfrage und erhält Daten, welche sich auf den modifizierten Parameter beziehen, als Antwort, obwohl ihm dazu die Zugriffsberechtigung fehlt, spricht man von insecure direct object reference. Deshalb wird in dieser Arbeit ein Konzept vorgestellt, welches verhindert, dass aufgrund von Parametermanipulation einer Abfrage oder fehlender Zugriffsüberprüfung, ein unberechtigter Zugriff auf Ressourcen einer dokumentenbasierten Datenbank stattfinden kann. Als Grundlage der Konzeptentwicklung dient eine Fallstudie eines webbasierten Notenverwaltungssystems, welches die Daten in einer relationalen Datenbank sichert. Die Prozesse werden daraufhin analysiert, welche Faktoren bei der Entscheidung der Zugriffsberechtigung zu beachten sind. Um die Umsetzbarkeit des Konzepts zu verdeutlichen wurde dieses prototypisch implementiert. In diesem wurden das Anlegen, Lesen und Löschen von Ressourcen implementiert. Die Operation des Modifizierens wurde nicht implementiert, da erforderliche Prüfungen schon implementiert wurden.
27.11.17	2018	intern	Bachelor	DE	Integration dynamischer Objekte in die Carbot-Simulationsumgebung	Die Carbot-Simulationsumgebung erlaubt die Definition statischer Umgebungen, die aus einfachen Hindernissen (z.B. Wände, Säulen) bestehen. In diesen Umgebungen kann sich der simulierte Roboter bewegen und erhält entsprechende simulierte Sensoreingaben (beispielsweise ein Kamerabild, einen Laser-Entfernungs-Scan). Verfahren zur Kartographierung dieser statischen Umgebung stehen zur Verfügung. Rein statische Umgebungen liegen in der Realität aber sehr selten vor. Sehr häufig bewegen sich dynamische Hindernis, z.B. Menschen in Sensorreichweite. Diese sind von der Natur aus anders, dürfen beispielsweise nicht dauerhaft in eine Hinderniskarte eingetragen werden. Damit Algorithmen zur Handhabung dynamischer Hindernisse entwickelt und getestet werden können, wurde die Simulationsumgebung mit dieser Arbeit um dynamische Hindernisse erweitert. Es wurde ein Verfahren entwickelt, mit welchem die bewegten Hindernisse anhand einer Umgebungsdatei in die Simulationsumgebung eingelesen werden können und die gewünschte Bewegungsart (linear oder zufällig) von der CarbotSim umgesetzt und korrekt dargestellt wird. Die dynamischen Objekte besitzen zudem eine eigene Kollisionserkennung, damit sie sich nicht durch einander durch bewegen können. Es wurden zwei verschiedene Hindernistypen - Menschen und Carbots - integriert. Zur Umsetzung wurde an die bestehenden Technologien angeschlossen, die Grundstruktur der Anwendung bleibt unverändert.
27.11.17	2018	extern	Master	DE	Systematische Modernisierung von Legacy-Systemen	Bei der Modernisierung von Legacy-Systemen kommt es immer wieder zu Schwierigkeiten. Oft kommen diese aus den Systemen selbst. Im Rahmen der Masterarbeit wurden die Gründe für diese Schwierigkeiten untersucht. Das geschah zum einen durch Recherche von Literatur und zum anderen anhand von Experteninterviews. Diese wurden mit Personen geführt, die an Modernisierungsprojekten mit positiven Ausgang beteiligt waren. So sollte ermittelt werden, auf was besonders zu achten ist und wie ihr Erfolgsrezept lautet. Die Interviews wurden daraufhin ausgewertet, die Ergebnisse diskutiert und die Empfehlungen daraus vorgestellt. Am Ende ergeben sich daraus interessante Erkenntnisse, mit denen man teilweise so vielleicht nicht gerechnet hatte. Denkbar war, dass vor allem Abhängigkeiten, Komplexität und Vernetztheit der Systeme entscheidend sind. Sie führen zu individuellen Problemen, die sich nicht mit einer Musterlösung beseitigen lassen. Ein möglicherweise unerwarteter Punkt ist die Bedeutung des Stakeholder Managements. Das ist ein wichtiges Instrument. Außerdem scheint es als seien die Unterschiede zu Green Field Projekten nicht so groß.
30.11.17	2018	extern	Bachelor	DE	Konzeption und Realisierung eines universellen Dashboards für den Vertrieb im Autoteilegroßhandel auf Basis von Microsoft Dynamics NAV und Qlik Sense	Ziel der Bachelorarbeit ist es, ein Qlik Sense-Template für die Branche Automotive für den Bereich Vertrieb zu konzeptionieren sowie zu realisieren. Die Aufgaben belaufen sich dabei auf der Analyse der bestehenden Prozessabläufe zu Automotive im Bereich Vertrieb sowie die Erweiterung des bestehenden Datenmodells. Anforderungen müssen erhoben, dokumentiert und kategorisiert werden. Dadurch wird ein Mockup konzeptioniert, um das grobe Design darzustellen. Anschließend wird das Dashboards erstellt. Dabei müssen die richtigen Visualisierungsarten verwendet werden. Standards und Best Practices werden angewendet, um sinnvolle Oberflächen zu erstellen. Letztendlich entsteht eine Applikation, welche die Analyse verschiedener Perspektiven für eine Kennzahl ermöglicht.
01.12.17	2018	extern	Bachelor	DE	Design und prototypenhafte Umsetzung eines zentralen Archivierungssystems, zur Unterstützung der Aufnahmeplanung in der industriellen CT 	Die Durchführung einer Computertomographie unterliegt einer großen Fülle an Parametern. Je nach Bauteil und Prüfaufgabe ist eine entsprechende Parameterkombination sinnvoll. Daher ergibt sich eine sehr große Menge an Parameterkombinationen. Bisher ist die Wahl dieser Parameter an das Spezialwissen und die Erfahrung des Benutzers gebunden. Dauerhaft ist daher das Ziel, dieses Wissen, weg vom jeweiligen Benutzer hin zu einem intelligenten System zu führen. Grundlage dieses intelligenten Systems ist die Sammlung und Verwaltung der jeweiligen Parameterkombination mit der Verknüpfung zum Bauteil bzw. der Prüfaufgabe. Bestandteil dieser Arbeit ist daher die Konzeption und Erstellung eines digitalen Verwaltungssystems des oben beschriebenen Wissens. Die Einträge in das System sollen hierbei intelligent eingeordnet werden, damit hieraus Rückschlüsse auf den Zusammenhang der Parameter zu dem Bauteil und der Prüfaufgabe hergestellt werden können.
04.12.17	2018	extern	Bachelor	DE	Realisierung eines Werkzeugs zur Verwaltung von Konfigurationen für entwicklungsbegleitende Tests	Bei einer Vielzahl von Software-Produkten in einem Unternehmen, die in unterschiedlichen Beziehungen stehen, müssen die Kombinationen dieser Produkte erfasst und getestet werden. Wenn darüber hinaus noch Beziehungen zu fremder Software bestehen, ist es umso wichtiger, die gemeinsame Funktionalität der Produkte auf einem Rechnersystem sicherzustellen. Ein Ansatz dazu ist das Bereitstellen von Testumgebungen, welche die Kombinationen abbilden. Um dieses zu können, bedarf es an Informationen, welche die Testumgebungen beschreiben und zentral verwaltet werden. Im Rahmen dieser Bachelorarbeit wird ein Konzept für ein Werkzeug ausgearbeitet, das die Verwaltung von Testkonfigurationen in der DATEV eG zentralisiert und erleichtert. Zudem wird ein Prototyp im engeren Sinne entwickelt, welcher die Funktionen der Oberflächen beinhaltet. Anhand der Erkenntnisse, die durch die Umsetzung des Prototyps ausgehend vom Konzept gewonnen werden, wird eine Entscheidung zur Fertigstellung des Tools getroffen.
07.12.17	2018	extern	Master	DE	Evaluation und Implementierung geeigneter Verfahren zur Nutzbarmachung von nicht identischen Duplikaten und Synonymen im Umfeld archivierter Kassendaten	Eine hohe Datenqualität ist ein wichtiger Erfolgsfaktor für alle IT-Unternehmen. Daher müssen Datenfehler, welche die Qualität von Daten beeinträchtigen, gefunden und beseitigt werden. Zwei der am häufigsten auftretenden Datenfehler sind Duplikate und Synonyme. Die vorliegende Arbeit zeigte gängige Verfahren zur Duplikaterkennung auf und verglich diese hinsichtlich ihrer Effektivität und Effizienz. Außerdem wurde eine in vielen Unternehmen eingesetzte Methode zur Synonymerkennung vorgestellt. Die Verprobung und Implementierung der vorgestellten Verfahren wurde anschließend anhand der Datenbasis einer kleinen Lebensmittelkette vorgenommen. Das Ergebnis der Evaluation, welche mithilfe von Maßen des Information Retrieval durchgeführt wurde, zeigte auf, dass eine vorgelagerte Synonymerkennung die Qualität der anschließenden Duplikaterkennung erhöht und aufgrund der unterschiedlichen Ursachen der vorliegenden Duplikate (Rechtschreibfehler, Wortvertauschungen) eine Kombination aus mehreren Duplikaterkennungsverfahren das beste Mittel zur Erhöhung der Datenqualität ist. Außerdem wurde deutlich, dass sich deutliche Effizienzunterschiede nur durch den Einsatz unterschiedlicher Partitionierungsverfahren ergeben. Allerdings erkennen die implementierten Verfahren weitaus noch nicht alle vorhandenen Duplikate. Daher ist es notwendig, diese schrittweise zu verbessern, beispielsweise durch eine vorgelagerte Rechtschreibprüfung oder den Einsatz von Ontologien und künstlicher Intelligenz.
07.12.17	2018	extern	Bachelor	DE	Konzeption und Realisierung eines Software-defined networks und einer Mikro-Segmentierung im Netzwerk-Access-Bereich	Um das Management eines Firmennetzwerks zu vereinfachen und besser auf Ver- änderungen der Netzwerkstruktur reagieren zu können, ist es nötig, die Steuerung des Netzwerkverkehrs von der reinen Weiterleitung, die von der Hardware übernom- men wird, zu trennen. Dies wird durch Software-defined networking ermöglicht. Die Beschränkung des Zugriffs der Nutzer auf die jeweils benötigten Ressourcen (Clients, Drucker, Abteilungs-, Test- und Entwicklungsserver) ist eine der wichtigsten Anforderungen an ein Netzwerk. Diese Beschränkung soll erreicht werden, indem die Ressourcen, zu denen der Nutzer Zugang hat, in einem gesonderten Netzwerk- segment gekapselt werden. Ziel der Arbeit ist es, ein Konzept für ein Software-defined network und darauf aufbauend eine Mikro-Segmentierung im Firmennetzwerk der N-Ergie zu erstellen. Hierbei liegt der Fokus auf den benutzernahen Bereichen. Dafür wird eine Anfor- derungsanalyse durchgeführt und anhand des Ergebnisses eine passende Software ausgewählt. Dies macht es möglich, einen Laboraufbau zu entwickeln, mit dem das Konzept umgesetzt werden kann.
07.12.17	2018	extern	Bachelor	DE	Auswahl und Implementierung eines IT-Management-Tools für das interne Kontrollsystem eines IT-Dienstleisters im Bankensektor	Die Sparda-Datenverarbeitung eG (SDV-IT) ist ein mittelständischer IT-Dienstleister der Sparda-Banken. Das bestehende interne Kontrollsystem (IKS) begleitet die kontinuierliche Verbesserung der Prozesse und unterstützt ordnungsgemäße, nachvollziehbare und wirtschaftlich durchgeführte Unternehmensaktivitäten. Die Verantwortung für das IKS liegt im "Vorstandsstab" beim IKS-Beauftragten. Um einer effizienten Unternehmensorganisation gerecht zu werden und als Unterstützung zur Einhaltung gesetzlicher Anforderungen, ist die Einführung einer Software, mit der Zielsetzung eines integrierten Managementsystems geplant. Anhand des Tools sollen die im Vorstandsstab angesiedelten Disziplinen IKS, Prozess-, Datenschutz-, IT-Sicherheits- und Risikomanagement in der Verwaltung der jeweiligen Maßnahmen, Feststellungen und Anforderungen unterstützt werden und Schnittstellen effizient bedient werden. Infolge dessen bildet die prototypische Implementierung einer Risiko-Kontroll-Matrix anhand der Anwendung einen Bestandteil der Arbeit. Die Dokumentation der Second Level Controls (Beschreibung, Kontrolldurchführung, Maßnahmen) mit Hilfe der Software ist ein weiterer Baustein der Bachelorarbeit. Die Auswahl dieses Tools soll auf Basis eines zu definierenden Kriterienkatalogs erfolgen.
14.12.17	2018	intern	Master	DE	Bahnplanung für einen autonom fahrenden Roboter mit endlicher Lenkgeschwindigkeit, basierend auf Klothoiden	Im Rahmen des Carbot-Projekts wird analysiert, inwieweit Klothoiden sich eignen, um das Bahnplanungssystem des autonomen Roboters zu ergänzen und zu verbessern. Als wichtige Maßgabe gilt hier, dass Klothoidenbahnen sich berechnen lassen ohne dabei durch eingeschränkte Wertbereiche der Parameter für Fahrzeugposition, -ausrichtung und eingeschlagenem Lenkwinkel beeinträchtigt zu werden. Dafür werden verschiedene Ansätze zur Berechnung von Klothoidenbahnen analysiert und auf ihre Tauglichkeit geprüft. Die Ergebnisse zeigen dabei, dass sich die gängigen Rechenansätze nicht eindeutig analytisch durchdringen lassen und somit nur eingeschränkt für das System eignen. Es wurde allerdings ein vielversprechender Lösungsansatz gefunden, welcher noch weiter untersucht werden müsste.
14.12.17	2018	extern	Bachelor	DE	Realisierung eines sicheren Webportals zur formularbasierten Kundenkommunikation für individuelle Geschäftsprozesse	Ein wichtiger Bestandteil des Tagesgeschäfts der Voigtmann GmbH ist die Erfassung von Kundendaten für individuelle Geschäftsprozesse. Der dafür verwendete Prozess zeigt einige Problemstellen auf und soll optimiert werden. Hierfür wird ein Webportal implementiert, über welches zukünftig die Erstellung und Verteilung der Formulare sowie die Erfassung der Kundendaten geregelt werden soll. Insbesondere soll hierbei die Sicherheit der Anwendung gewährleistet sein, weshalb die Anwendung unter Beachtung der OWASP Top 10 Sicherheitsrisiken für Webanwendungen analysiert wird.
20.12.17	2018	intern	Master	DE	Konzeption und prototypische Realisierung eines Assistenzsystems bei der Stellensuche	Die Hochschul-Jobbörse der Technischen Hochschule Nürnberg bietet Studierenden die Möglichkeit deutschlandweit nach einer Vielzahl an Anstellungen zu suchen. Aktuell werden den Suchenden jedoch nur Stellenangebote angezeigt, die genau auf ihre Suchanfrage passen. Damit werden für Studierende potentiell attraktive Stellen nicht angezeigt, da sie nicht genau den eingegebenen Suchbegriffen entsprechen. Die Masterarbeit umfasst die Konzeption und prototypische Implementierung eines Assistenzsystems für die Stellensuche. Dabei soll eine Instanz geschaffen werden, die verschiedenen Szenarien betrachtet und anschließend den Suchenden bei der Einschränkung oder Erweiterung seiner Suchanfrage unterstützt. Der Assistent soll dabei ohne Zutun des Nutzers das Verhalten des Studierenden beobachten und autonom entscheiden, welche Option ein optimiertes Suchergebnis liefert.
20.12.17	2018	extern	Master	DE	Konzeption der Content Pool Benutzerschnittstelle eines webbasierten Unternehmens Interfaces 	Diese Arbeit steht eng in Zusammenhang mit dem neuartigen Unternehmens Interface der Axinom GmbH, das die derzeitige Website ersetzt. Durch ein Conversational Interface (CI) ? in Form eines persönlichen Chats ? als alleinige Schnittstelle nach außen, wird die direkte Kommunikation mit allen Interessenten erwirkt. Der Content Pool dient der multimedialen Bereitstellung aller Informationen bezüglich des Unternehmens (große Anzahl heterogener Inhalte) und präsentiert nach der ersten Kontaktaufnahme im Chats, den Benutzern das Unternehmen. In dieser Arbeit wurde zuerst eine Benutzergruppenanalyse durchgeführt, daraus entstanden sieben Personas. Aufgrund der hohen Anzahl an Personas, erlangte die Personalisierung der Benutzerschnittstelle besondere Bedeutung. Hierfür wurde ein Vektormodell-basiertes Konzept zur Ähnlichkeitsberechnung zwischen dem aktuellen Benutzer und den enthaltenen Inhalten erarbeitet. Die berechneten Ähnlichkeiten werden im UI visualisiert, dafür findet eine Kategorisierung der Inhalte statt. Die graphische Benutzerschnittstelle visualisiert die Inhalte als Graph. Alle Inhalte werden als Knoten und ihre Struktur durch Kanten dargestellt, der Kontext der Inhalte wird so visuell sichtbar. Aufgrund der hohen Anzahl an Inhalten können nicht alle gleichzeitig sichtbar sein, deshalb wurde ein schlankes Interaktionskonzept entwickelt. Die abschließenden Evaluationen der Personalisierung und der graphischen Benutzerschnittstelle zeigten vielversprechende Ergebnisse.
20.12.17	2018	extern	Bachelor	DE	Die Entwicklung moderner .NET Controls für HMI-Systeme	Die Bachelorarbeit handelte davon, für die Siemens AG herauszufinden, ob und wie es möglich ist .NET Controls in das HMI-System zu integrieren und wie viel Aufwand dies mit sich bringt. Die Integration der .NET Controls ist über den Global Assembly Cache von .NET möglich. Dort werden Anwendungen gespeichert, die unter .NET entwickelt und als DLL (Assemblies) gespeichert wurden. Es wurden zwei Diagramme zur Darstellung statischer Daten entwickelt, nämlich das Boxplot und das Histogramm. Die beiden Controls wurden im Visual Studio in C# unter .NET entwickelt und bei der Entwicklung der Benutzeroberfläche wurde auf den Werkzeugsatz von WinForms zurückgegriffen. Im Versuchsaufbau wurde eine Steuerung verwendet, an welcher ein Temperatursensor angeschlossen war. Die Steuerung war mit einem Algorithmus zur Aufnahme, Verarbeitung und Weitergabe dieser Sensordaten an das Visualisierungssystem ausgestattet. Die beiden Controls wurden in die Benutzerschnittstelle des Visualisierungssystems integriert. Der Datenaustausch zwischen dem Visualisierungssystem und der Steuerung geschieht über Polling. Die Daten werden über die HMI-Tags des Visualisierungssystems, welche mit den Variablen der Controls verknüpft wurden, an die Diagramme übergeben und angezeigt. Fazit: Die Entwicklung eines Anwendungsbeispiels, wie man .NET Controls entwickeln und in das HMI-System integrieren kann, bringt der Siemens AG einen größeren Mehrwert, als selbst .NET Controls zu entwickeln.
09.01.18	2018	extern	Master	DE	Evaluation von Einsatzszenarien der Blockchaintechnologie in der Logistik anhand eines Proof-of-Concepts	Effiziente Prozesse und hohe Transparenz in Supply Chains sind für Unternehmen entscheidende Faktoren, um erfolgreich zu sein und die steigenden Qualitätsansprüche erfüllen zu können. Mangelndes Vertrauen zwischen den Akteuren und Betrug durch Produktfälschungen stellen die Unternehmen vor zusätzliche Herausforderungen. Die Blockchain-Technologie bietet durch die unveränderbare Speicherung von Informationen und das Ausführen von Business-Logik mittels Smart Contracts trotz mangelndem Vertrauen eine mögliche Grundlage zur Zusammenarbeit aller Beteiligten. Im Siemens-Werk Erfurt werden Stanzteile aus Blech für Generatoren hergestellt und an Kunden weltweit versandt. In Kooperation mit der Siemens AG wurde im Rahmen dieser Arbeit ein Proof-of-Concept entwickelt, um den Prozess von der Stahlherstellung bis zur Übergabe an den Kunden durch die Blockchain zu unterstützen. Die Umsetzung hat gezeigt, dass sich Medienbrüche vermeiden und Prozessabläufe beschleunigen lassen, was zu Bestandsreduktionen und Kosteneinsparungen führen kann. Die Sicherstellung der Daten- und Prozessintegrität, der Verzicht von intermediären oder wechselnden Kooperationspartnern - die Blockchain-Technologie bietet ein breites Spektrum an Einsatzszenarien in der der Logistik. Der niedrige Reifegrad, mangelnde Standards und fehlende gesetzliche Rahmenbedingungen sind auf der anderen Seite aktuell die größten Hürden für eine schnelle Umsetzung von Projekten mit der Blockchain-Technologie.
15.01.18	2018	extern	Master	DE	I/O-Fuzzing im Linux-Kernel	Diese Arbeit entwickelt ein Konzept, wie das I/O-Subsystem des Linux-Kernels mittels Fuzzing getestet werden kann. Fuzzing ist eine Technik im Bereich des Software Testings, bei der ein zu testendes System mit semi-zufälligen Eingabedaten penetriert wird. Die Beobachtung des Systems und die Registrierung von unerwünschtem Verhalten hilft Entwicklern dabei, Softwarefehler zu identifizieren und zu beseitigen. Als Teil des I/O-Subsystems spielen Dateisysteme im Linux-Kernel eine wichtige Rolle. Es soll gezeigt werden, wie spezielle Bereiche von Dateisystemen innerhalb des Linux-Kernels penetriert werden können. Der Schwerpunkt liegt dabei auf der Identifizierung der entsprechenden Datenbereiche unterhalb der Dateisystemebene sowie deren Modifikation. Für die technische Umsetzung soll das Fuzzing-Framework syzkaller verwendet werden, das ursprünglich für das Testen von Systemaufrufen entwickelt wurde. Mithilfe eines Machbarkeitsnachweises soll gezeigt werden, welche Überlegungen und technischen Ansätze nötig sind um dies umzusetzen. Im Zuge dieser Arbeit ist ein Kernel-Modul entstanden, das eine Injektion von Daten in den Block-I/O-Layer des Linux-Kernels erlaubt. Durch eine Erweiterung des Fuzzing-Frameworks ist es gelungen, durch syzkaller generierte ext2-Inode- sowie Btrfs-Superblock-Strukturen in den Linux-Kernel zu injizieren. Während der Testdurchführung wurde ein Use-After-Free-Fehlverhalten in der Btrfs-Implementierung des Linux-Kernels entdeckt.
22.01.18	2018	extern	Master	DE	Anomaly Detection in der Buchführung in Kooperation mit der DATEV eG	Die Masterarbeit evaluiert den Einsatz der Anomalieerkennung als Methode für die Überprüfung der Buchführung von Unternehmen. Dazu wurden die Grundlagen der Wirtschaftsprüfung im Bezug auf die Buchführung dargestellt und Anforderungen an neue Methoden festgelegt. Die zwei wichtigsten sind die Verständlichkeit und die Darstellbarkeit der Ergebnisse der Algorithmen. Außerdem wurden die Grundlagen der Anomalieerkennung und die Techniken der unüberwachten Anomalieerkennung aufgearbeitet. Die Algorithmen HBOS, KNN und LOF wurden von einer Erweiterung des Data Mining Tools RapidMiner nach Python bzw. C++ portiert und deren Einsatz wurde in drei Buchführungen evaluiert. Bei der praktischen Evaluation hat sich herausgestellt, dass es Sinn macht, die Algorithmen auf ein Merkmal gleichzeitig anzuwenden und die sich daraus ergebenden Anomalie-Scores aufzusummieren. Dies ermöglicht die Visualisierung der Ergebnisse aus einem Merkmal und macht sie verständlich. Identisch dazu ermöglicht der Einsatz eines Merkmales in verschiedenen Kontexten, Objekte aus verschiedenen Blickwinkeln zu betrachten und darin Anomalien zu erkennen. Der HBOS ist für diese Methode nicht geeignet, da die Höhe seiner Anomalie-Scores sich nicht zwischen zwei Datensätzen vergleichen lassen. Der LOF und KNN sind geeignet. Wobei der Anomalie-Scores des KNN am verständlichsten ist. Er erfüllt die Anforderungen an die Methoden in den evaluierten Anwendungsfällen.
29.01.18	2018	intern	Master	DE	Generierung und Visualisierung interaktiver bildbasierter 3D-Szenen mittels merkmalsbasierten Morphings	Im Rahmen dieser Arbeit wird untersucht, inwieweit die Realisierung von frei navigierbaren bildbasierten Welten mit Hilfe des Image-Morphing-Verfahrens möglich ist. Hierbei wird eine Verarbeitungskette konzeptioniert und prototypisch realisiert, welche aus einer unsortierten Bildermenge eine interaktive bildbasierte 3D-Szene generiert. Während des Vorverarbeitungsprozesses wird ein Bildgraph erstellt. Hierzu werden mittels Matching von Merkmalen die Relationen der Bilder untereinander ermittelt. Anschließend werden mittels eines Structure-from-motion Verfahrens die relativen Kameraparameter berechnet. Im Visualisierungsprozess der Verarbeitungskette kann dann mit Hilfe des Graphen jede mögliche virtuelle Ansicht rekonstruiert werden. Dabei werden anhand der Pose der virtuellen Kamera die geeignetsten Nachbarknoten ausgewählt und eine entsprechende Gewichtung pro Knoten berechnet. Anschließend wird das Morphing-Verfahren dreiecksbasiert umgesetzt. Daher werden für die in den ausgewählten Knoten enthaltenen Bilder Dreiecksnetze anhand identischer Merkmale erzeugt. Hierzu wird die Delaunay-Triangulation eingesetzt. Durch das Morphing der entsprechenden texturierten Dreiecksflächen unter Berücksichtigung der zuvor berechneten Gewichtungen können dann neue Ansichten in Echtzeit erstellt werden. Mittels der prototypisch realisierten Verarbeitungskette werden im Rahmen dieser Arbeit erste Praxisbeispiele evaluiert. Des Weiteren wird ein Ansatz für zukünftige Projekte geschaffen.
30.01.18	2018	intern	Bachelor	DE	Echtzeit-Darstellung von Fahrzeugparametern mittels Arduino, OBD2 und CAN	In dieser Arbeit wird die Entwicklung und Umsetzung eines CAN-BUS-Kommunikationsgeräts dokumentiert. Als Basis dient ein Arduino UNO R3 und ein dazu passendes CAN-BUS-Shield. Dieses Shield verfügt über die nötigen Mikrokontroller um mit dem CAN zu kommunizieren. Die Auswahl der Komponenten wurde dokumentiert und eine Einführung in nötigen Themen wurde verfasst. Es wurden die Werte Motordrehzahl, Kühlwasser- und Ansaugtemperatur mithilfe des CAN ermittelt. Hierfür mussten Anpassungen an Bibliotheken gemacht werden und die Pinbelegung der OBD2-Schnitstelle ermittelt werden. Zusätzlich wurde, mithilfe einer Spannungsteilerschaltung und eines NTC-Ressistor, ein Öltemperaturfühler verbaut. Dieser ermittelt die aktuelle Öltemperatur des Motorrads. Mithilfe eines OLED-Displays werden die ermittelten Werte dem Fahrer zur Verfügung gestellt. Abschließend wird über die erfüllten Ziele diskutiert und mögliche Erweiterungen oder Themenfortführungen aufgezeigt.
01.02.18	2018	extern	Master	DE	Robustes Inside-Out Tracking für großflächige Mehrnutzer VR Systeme 	Die Verbreitung der virtuellen Realität (VR) in unserem Alltag nimmt immer noch zu. Früher waren VR-Systeme teuer und aufwändig zu installieren. Die Entwicklung moderner Head-Mountet-Displays (HMD) ermöglicht es jedoch kundenfreundliche Systeme zu entwickeln. Trotzdem sind diese VR-Systeme nur auf kleinen Flächen (ca. 20m2) einsatzbereit. und für wenige Nutzer geeignet oder erfordern teure Kamerasysteme, die aufwändig aufgebaut und eingemessen werden müssen. Die aktuelle Entwicklung von Inside-Out-Tracking (IO-Tracking) soll in Zukunft zwar allgegenwärtige VR ermöglichen, leidet jedoch noch an schlechter Zuverlässigkeit und niedriger Genauigkeit. In dieser Arbeit wird ein Verfahren vorgestellt, das durch die Fusion von Funk- und IO-Tracking ein System realisiert, das mehrere Nutzer auf einer Fläche von über ca. 30x30m zuverlässig und genau in der VR abbilden kann und die Wahrnehmung und das Wohlbefinden der Nutzer nicht negativ beeinflusst.
01.02.18	2018	extern	Master	DE	Robuste Posenschätzung durch Identifikation von Kalibriermomenten mittels Maschine Learning	Die Verbreitung der virtuellen Realität (VR) in unserem Alltag nimmt immer mehr zu. In diesem Kontext ist ein Tracking System entstanden, das die Kopforientierung und die Position von Benutzern zuverlässig erfasst. Um die Präsenz der Nutzer in der VR weiter zu steigern muss die Interaktionsfähigkeit der Nutzer ermöglicht werden und somit das zuverlässige und dauerhaft stabile Erfassen der Hand-Pose. Erste naive Versuche mit Inertial Measurement Units (IMUs) können aufgrund von relativen Positionsdaten und Orientierungsdrift keine langzeit-stabile Hand-Pose ermitteln. Magnetsensoren und Sensorfusionen können etwaige Fehler in Innenraumszenarien nicht auflösen. Im Rahmen dieser Arbeit wurde mit Ansätzen des Machine Learning (ML) versucht die Hand zu Körper Pose in der Bewegung wiederzufinden und mit Hilfe von vorhandenem Weltwissen die Fehler zu korrigieren. Eine Support Vector Machine löst mit einer Genauigkeit von über 30\% die Hand zu Körper Pose korrekt auf. Somit kann der vorgeschlagene Ansatz in 3 von 10 Fällen die absolute Orientierung korrekt bestimmen und etwaige Fehler auflösen. In den restlichen 7 Fällen passiert nichts, dass heisst es findet auch keine Verschlechterung der statt.
08.02.18	2018	extern	Master	DE	Tool zur Registrierung und Flächenrekonstruktion von Surfboards	In Kooperation mit der HNO-Klinik des Uni-Klinikums Erlangen (Prof. Michael Döllinger) wird ein Programm in MATLAB entwickelt, das die CT-Daten eingescannter Surfboards automatisiert in ein 3D-Modell umwandelt, mit welchem dann numerische Strömungsanalysen durchgeführt werden können. Die verschiedenen Datensätze eines mittels Computertomographie (CT) gescannten Surfboards werden rekonstruiert, indem sie einzeln segmentiert werden. Durch Translation und Rotation werden die Surfboard-Teile zueinander registriert und danach zu einem Objekt zusammengesetzt. Die zum Surfboard gehörenden Finnen und einteilige Surfboards werden in einem eigenen Programmablauf segmentiert. Diese Vorgänge sollen automatisiert ablaufen. Das Programm enthält mehrere grafische Benutzeroberflächen, in welchen die Funktionen zum Laden der CT-Daten für Surfboard und Finnen und das Speichern des fertigen 3D-Objekts eingebunden werden. Auch die Voreinstellungen für die Segmentierung und das Festlegen der manuellen Merkmalspunkte werden vom Anwender anhand der grafischen Benutzeroberflächen vorgenommen. Die Implementierung des Programms wird in MATLAB vorgenommen.
08.02.18	2018	extern	Bachelor	DE	Ein Konzept zur Einführung eines Customer Order Decoupling Points bei Schwan-Stabilo Cosmetics	Schwan-STABILO Cosmetics (SSC) ist einer der größten Produzenten von Kosmetikstiften. Durch den Wandel, welchen die Digitalisierung und soziale Plattformen mit sich gebracht haben, steigen die Anforderungen der Kunden. Das macht sich vor allem hinsichtlich der Lieferzeit bemerkbar. Um den Anspruch der Kunden gerecht zu werden, gilt es also die Durchlaufzeit zu reduzieren. In dieser Arbeit wurde also der Auftragsabwicklungsprozess analysiert, um Stellen zu identifizieren, die der Grund für die hohe Durchlaufzeit sind. Die Analyse ergab, dass vor allem die hohe Vorlaufzeit für die Beschaffung der Komponenten ins Gewicht fällt. Dazu muss man wissen, dass bei SSC auftragsbezogen gefertigt wird und die Komponenten des Kosmetikstiftes auftragsbezogen bestellt werden. Dadurch entstehen mehrere Wochen an Vorlaufzeit, die für die Auftragsabwicklung sehr kostbar sind. Als Lösungsansatz ergibt sich somit eine Entkopplung des Beschaffungsprozesses, indem man die Komponenten auftragsanonym beschafft. Kundenindividuelle Massenfertigung (Mass customization) und Variantenproduktion erschweren die Lagerhaltung, weil es wirtschaftlich nicht von Vorteil ist, alle möglichen Varianten von Komponenten zu lagern. Folglich macht nur eine Lagerhaltung von nicht kundenspezifischen Komponenten Sinn, weil diese variabel für mehrere Kunden verwendbar sind. Durch eine Lagerhaltung von Standardkomponenten kann somit die Durchlaufzeit reduziert werden. Der Beschaffungsprozess wird somit entkoppelt.
15.02.18	2018	extern	Master	DE	Konzeption und Entwicklung eines Machine Learning-Ansatzes zum dynamischen Frequency Capping von Online-Werbeanzeigen	Die vorliegende Master-Thesis erforscht die Fragestellung, auf welche Weise Machine Learning-Technologie im Online-Marketing der ING-DiBa AG eingesetzt werden kann, um eine personalisiertere Aussteuerung von Werbemitteln zu ermöglichen. Anhand ausgewählter Produktivdaten wird ein Datenmodell abgeleitet und ein fachliches Konzept entwickelt, das sowohl Anforderungen, als auch Verarbeitungsschritte eines technischen Lösungsansatzes definiert. Aufbauend darauf wird ein Machine Learning-Ansatz konzipiert und entwickelt, der die Möglichkeiten zur personalisierten Limitierung von Werbeausspielungen durch Frequency Capping erforscht. Zur Identifikation eines geeigneten ML-Ansatzes wird das Random Forest, XGBoost- und KNearestNeighbor-Verfahren in einem Multi-Label-Setting untersucht und anhand verschiedener Metriken vergleichend evaluiert. Die Untersuchungen zeigen, dass Machine Learning das Potential besitzt, die personalisierte Ausspielung von Anzeigen zu verbessern und den wirtschaftlichen Mehrwert von Werbung zu erhöhen. Entscheidungsbaumbasierte Ensemble Learning-Verfahren erweisen sich in den Untersuchungen als performante Methoden, da sie aufgrund ihrer Genauigkeit, Skalierbarkeit und Robustheit für die effiziente Verarbeitung strukturierter Daten geeignet sind. Die personalisierte Begrenzung von Werbung durch Frequency Capping erweist sich als ungeeigneter Ansatz, da eine individuelle Wirksamkeit von Anzeigen von einer Vielzahl individueller Faktoren abhängig ist.
19.02.18	2018	intern	Bachelor	DE	Analyse externer Manipulation von künstlichen neuronalen Netzen	Künstliche Neuronale Netze finden sich überall wieder. In modernen Haushalten zum Beispiel finden sie Einzug mit Apple Siri oder Amazon Alexa. Jedoch werden sie in verschiedenen anderen Bereichen verwendet, unter Anderem auch in sicherheitskritischen Bereichen. Aus diesem Grund ist es wichtige diese Technologie auf ihre Sicherheit gegen Manipulation und auf die Zuverlässigkeit im Ergebnis zu prüfen. Das Ziel der vorliegenden Bachelorarbeit war es, ein künstliches Neuronales Netz zu entwickeln sowie eine Manipulation, welche eine Fehlklassifizierung hervorruft. Hierbei sollte vor allem die besagte Sicherheit und Zuverlässigkeit künstlicher Neuronaler Netze erforscht werden. Zur Entwicklung des Neuronalen Netzes wurde TensorFlow verwendet, was eine Erweiterungsbibliothek für Python ist, dies ist eine der meist verwendeten Hilfsbibliotheken in diesem Bereich. Die Arbeit befasst sich mit der Erstellung des Netzes, sowie mit einer Manipulation dessen. Des Weiteren werden bekannte Manipulationen und verschiedene Schutzmechanismen angesprochen. Das künstliche Neuronale Netz, welches in dieser Arbeit entwickelt wurde, soll eine sechsstellige hexadezimale Zahl, welche einen Rot-Grün-Blau-Wert darstellt, als Farbe klassifizieren. Es wurde außerdem eine Manipulation konzipiert, die mit dem vorher entwickelten Netz verifiziert wurde. Im Vorfeld wurden verschiedene Manipulationen recherchiert, diese werden in dieser Arbeit vorgestellt.
21.02.18	2018	intern	Bachelor	DE	Analyse und Bewertung des Einsatzes von Apache Spark als zentrale Infrastruktur für die Vorverarbeitung und Analyse von Textdaten am Beispiel von Brettspielanleitungen	In der aktuellen Vorverarbeitung tauchen immer wieder Probleme im Ablauf auf. Diese treten aufgrund von heterogenen Daten auf und gehen mit anderen Problemen wie dasVerwenden von zwei Betriebssystemen einher, was eine automatischen Ablauf verhindert. Es wurde die Vermutung aufgestellt, dass die Probleme mit der Verwendung von Apche Spark als zentrale Infrastruktur für die Vorverarbeitung zu lösen sind, was im Laufe der Arbeit diskutiert wird. Anfangs werden die Probleme der aktuellen Vorverarbeitung diskutiert um einen Einblick zu geben weshalb die Arbeit nötig wurde. Weiter werden grundlegende Kenntnisse im Zusammenhang mit Apache Spark und anschließend das Prinzip der RDDs erklärt. Weiter wird ein Einblick über die Komponenten der Open- Source-Software und deren Funktionen dargestellt. Abschließend zum theoretischen Teil wird die Architektur einer Anwendung von Spark und dessen Komponenten erklärt. Zudem werden die möglichen Datenbanken erwähnt und auf Apache Cassandra, welche aktuell verwendet wird, mit dem HDFS in Kontrast gesetzt. Danach werden die Skripte für die Vorverarbeitung nach Python übersetzt, Optimierungen vorgenommen und zur Verwendung in Spark angepasst. Abschließend wird über die sich ergebenden Vor- und Nachteile durch die Verwendung von Spark diskutiert und eine Wertung über Spark als zentrale Infrastruktur abgegeben. Weiter werden die noch offenen Möglichkeiten, die Spark für das Projekt bietet angesprochen und Zum Schluss ein persönliches Resümee gezogen
01.03.18	2018	extern	Bachelor	DE	Analyse und Evaluierung aktueller MR Tracking Systeme am Beispiel ARKit	In dieser Arbeit werden MR-Trackingsysteme zur sogenannten Selbstlokalisierung mithilfe der auf dem freien Markt erhältlichen Plattformen Apple ARKit und Google ARCore realisiert. Mithilfe der Analyse von Schwachstellen dieser Systeme konnten Indikatoren für robuste und genaue Selbstlokalisierung gefunden werden. Die Indikatoren stehen in direktem Zusammenhang mit der Umgebungsbeschaffenheit (Anzahl der identifizierbaren Merkmale) und Bewegung (im Umfeld oder vom Anwender). Konkret konnten aus den Schwachstellen und Indikatoren eine Bewertungsvorlage zusammengestellt werden, welche Parameter für stabiles Tracking und den direkten Vergleich zwischen Systemen bereitstellt. Daraus wurden Messfälle konzipiert, die einerseits Laborbedingungen für Informationsgesamtheit, aber auch alltagsähnliche Szenarien beschreiben. Die Evaluation zeigte, dass die Umgebungsdynamik in merkmal-basierte Trackingsystemen starke Probleme auslöst, bei länger andauernder Verdeckung der Umfeld nicht zu korrigieren ist. Das System verliert in diesen Fällen jegliche, zur Verortung verwendete Merkmale. Ohne Merkmale fehlt die Korrelation aus optischem Fluss und der eigenen Bewegung und es kann keine Pose bestimmt werden. Aus den Messungen konnten Grenzwerte unterschiedlicher Szenarien für die Beschaffenheit der Umgebung und Bewegungszustände ermittelt werden, damit MR-Anwendungen ohne signifikanten Drift oder Systemausfälle verwendet werden können.
01.03.18	2018	extern	Master	DE	Entwicklung eines Verfahrens zur Qualitätssicherung mittels neuronaler Netze in der Elektronik-Fertigung	Die Prüfung von Leiterplatten auf eine korrekte Bestückung stellt eine komplexe Aufgabe für die industrielle Bildverarbeitung dar. Um diese Herausforderung zu bewältigen, werden aufwändige Bildverarbeitungssysteme und tiefgreifendes Expertenwissen benötigt. Die rasante Entwicklung im Bereich des maschinellen Lernens ermöglicht einerseits solche Systeme günstiger zu gestalten und andererseits deren Bedienung zu vereinfachen. Die vorliegende Abschlussarbeit demonstriert die Realisierung eines neu entwickelten Prüfverfahrens, dass dieses Potential ausschöpft. Da die Datenmenge ein zentraler Faktor für lernende Verfahren darstellt, wurde ein optisches Prüfsystem an der Bestückungslinie in der Fertigung der Firma IDS aufgebaut, um Prüfobjekte abzubilden. Diese Bilder wurden für das nicht überwachte Training diverser Autoencoder-Architekturen und deren anschließenden Evaluierung verwendet. Anhand einer Ähnlichkeitsanalyse der originalen und der vom Autoencoder generierten Bilder konnten fehlerbehaftete Platinen detektiert werden. Durch die Gegenüberstellung eines bisherigen Prüfverfahrens mit dem neu entwickelten, mit Fokus auf Autonomie und Bedienbarkeit, konnten konkrete Optimierungsmaßnahmen formuliert werden. Das neu entwickelte Verfahren kann durch Nutzung entsprechender Trainingsdaten auf ein breites Aufgabenspektrum aus dem Bereich der Qualitätssicherung erweitert werden.
06.03.18	2018	extern	Bachelor	DE	Visualisierung der weltweiten IT-Migrationen bei einer Prüfungs- und Beratungsgesellschaft mit Microsoft Power BI	Ein essenzieller Teil eines jeden Projektes ist das Reporting an das Management und weitere Stakeholder. In der Regel werden, mit hohem Aufwand, individuelle Inhalte, der aktuelle Projektstatus sowie KPIs (Key Performance Indicators) mit den bekannten Microsoft Office Produkten visualisiert und für die jeweilige Interessengruppe angepasst. Für die Umsetzung wird meist sehr viel Zeit aufgewendet, wodurch andere Aufgaben untergeordnet werden müssen und der Projektfortschritt stagniert. Ziel dieser Bachelorarbeit ist eine Verbesserung der täglichen Projektarbeit durch Automatisierung des Reportings und dem Einbau interaktiver graphischer Darstellungen. Zunächst sollen die gewünschten Erwartungen an das allgemeine Reporting innerhalb des Projektes Global Office bei Rödl & Partner durch eine Anforderungsanalyse erhoben werden. Anschließend werden mehrere Reporting-Möglichkeiten evaluiert und verglichen. Schlussendlich soll mit der Software Microsoft Power BI ein aktuelles und verständliches Berichtswesen mithilfe von Automatisierungen und interaktiven Elementen entwickelt werden, auf dessen Basis auch nachfolgende Projekte aufbauen können.
06.03.18	2018	intern	Bachelor	DE	Identifikation und Evaluation von Spielertypenmodellen hinsichtlich ihrer Eignung den Übertrag von Spiel-Design-Elementen in einen spielfremden Kontext zu unterstützen.	Der Evalautionsgegenstand dieser Arbeit sind vier Spielertypenmodelle, die unterschiedlichen Kontexten entstammen. Anhand von verschiedenen Evalationsszenarien und unter zur Zuhilfenahme von Patterns aus Gesellschaftsspielen wird geprüft, welches dieser Modelle sich am besten für den Einsatz in der Gamification eignet.
13.03.18	2018	extern	Bachelor	DE	Analyse und Umsetzung eines Deploymentprozesses von Anwendungen in Container	In der modernen Softwareentwicklung wird der Deploymentprozess von Anwendungen auf Server vermehrt optimiert. Mehrere Anwendungen sollen möglichst unabhängig voneinander auf einem Server lauffähig sein. Dies kann durch den Einsatz von virtuellen Containern realisiert werden. In dieser Bachelorarbeit wird in Kooperation mit der Firma endobit software solutions ein solcher Deploymentprozess entwickelt, der Anwendungen in Container auf einer Cloud- Plattform lauffähig macht. Für die Container-Technologien Docker und Turbo.net sowie den Cloud-Plattformen Microsoft Azure, Amazon Web Services (AWS) und Google Cloud Platform wird eine Analyse und anschließend eine Bewertung durchgeführt. Schließ- lich wird jeweils eine Technologie gewählt, um ein prototypisches Deployment einer Webanwendung durchzuführen. Es wird gezeigt, dass der Aufwand zur Durchführung dieses Deployment-Prozesses gering ist, aber dennoch Einschränkungen bei neueren Funktionen der verfügbaren Techno- logien vorhanden sind. Im Vergleich zu vorherigen Deployments auf einen einzelnen Anwendungsserver hat sich dieses Vorgehen als geeignete Alternative erwiesen.
15.03.18	2018	intern	Bachelor	DE	Konzeption und prototypische Realisierung einer Webapplikation für die individualisierte Online-Schlafberatung	Der Beratungsbedarf und das Beratungsangebot nehmen in allen Gesellschaftsbereichen durch das in den letzten zwei Jahrzehnten gestiegene Lebenstempo rasant zu. Der daraus entstehende Orientierungsverlust des Einzelnen führt zu einer extremen Nachfrage an Beratungsangeboten. Die Bachlorarbeit beschäftigte sich daher, am Beispiel der Online-Schlafberatung, mit der Entwicklung einer universal nutzbaren Beratungsplattform. Ausgangspunkt war dabei der erste Entwurf einer existieren Beratungsplattform. Diese wurde kritisch beleuchtet und durch den Einsatz moderner Webtechnologien, wie Angular 6, sukzessiv um weitere Funktionen erweitert. Die gestellten Anforderungen konnten vollständig umgesetzt und damit ein Mehrwert für die Beratung geschaffen werden. Schlussendlich wurde der bestehende Server betrachtet und eine Handlungsempfehlung auf Basis aktueller Frameworks, wie Loopback.js, erarbeitet. Der erste Entwurf eines neuen Servers, der die bestehenden Probleme behebt, wurde ebenfalls erfolgreich umgesetzt. Die Arbeit ordnet sich in die Schlafforschung des Instituts für E-Beratung der TH-Nürnberg ein und entstand in Zusammenarbeit mit diesem Institut.
15.03.18	2018	extern	Master	DE	Anwendungsfelder künstlicher Intelligenz zur Schaffung eines exzellenten Kundenservice	Ziel der vorliegenden Arbeit ist es, Anwendungsfelder künstlicher Intelligenz (kurz KI) für den Bereich des Privatkundenservice zu identifizieren, zu konzeptionieren und zu evaluieren. Anhand derer soll anschließend aufgezeigt werden, wie mithilfe von KI die dem Kundenservice zur Verfügung stehenden Ressourcen möglichst qualitätssteigernd und gewinnbringend eingesetzt werden können. Adressaten der Arbeit sind dabei strategische Mitarbeiter sowie Projektverantwortliche der IT und des Kundenservice. Zur Zielerreichung wird zunächst der theoretische Rahmen erarbeitet. Darauf aufbauend werden branchen- und unternehmensübergreifende Analyseerkenntnisse in einem Gesamtbild zusammengefasst, spezifische Kundenreisen der N-ERGIE evaluiert und kundenservicespezifische Anwendungsmöglichkeiten von KI definiert. Auf Basis dessen erfolgt anschließend die Formulierung einer Vision für den Kundenservice der Zukunft sowie die Ableitung von Transformationsprojekten zur Umsetzung dieser. Abschließend wird zur Verifizierung der ermittelten Erkenntnisse der Anwendungsfall der Auswertung von Kundenmails exemplarisch hinsichtlich Sprache, Kundenstimmung und Inhaltskategorie erprobt. Im Ergebnis wird deutlich, dass zur Etablierung eines zukunftsfähigen Kundenservice eine Entlastung von nicht wertschöpfenden Tätigkeiten durch KI unabdingbar ist.
15.03.18	2018	intern	Bachelor	DE	Vergleich von medizinischen Aktometern mit Smartwatches	Die Bachelorarbeit "Vergleich von medizinischen Aktometern mit Smartwatches" bei Herr Professor Gallwitz soll erarbeiten, ob ein Vergleich von medizinischen Geräten mit Fitnessarmbändern oder Smartwatches möglich ist. Dies soll im Rahmen einer Onlineschlafberatung des Instituts für E-Beratung geschehen. Bisher wird die Schlafqualität vom Probanden angegeben. Diese subjektiven Angaben können aber von der tatsächlichen Situation abweichen, wodurch eine optimale Beratung erschwert wird. Das Ziel ist es, die Schlafqualität objektiv zu ermitteln. Zusätzlich soll die Beratung der breiten Masse verfügbar gemacht werden, weshalb nach Möglichkeit auf die teuren medizinischen Geräte verzichtet werden soll. Dazu muss erarbeitet werden, welche Messwerte eines Aktometers für die Ermittlung der Schlafqualität herangezogen werden. Diese müssen aus geeigneten Smartwatches oder Fitnessarmbändern ausgelesen und mit denen, eines professionellen Geräts verglichen werden.
15.03.18	2018	extern	Bachelor	DE	Marktanalyse industriefähiger Single-Board Mikrocontroller und Programmierung dieser für den Einsatz im Globalen Datenraum der Firma ABC IT GmbH	Das Ziel dieser Arbeit ist es, zu zeigen, dass heutige Mikrocontroller in der Lage sind, größere Aufgaben zu erledigen und zwar auf industrieller Ebene. Hierbei werden drei Single-Board Mikrocontroller ausgesucht, die für die Industrie gedacht sind und bestimmte Kriterien erfüllen. Anschließend werden in alle drei Boards eine industrielle Kommunikationstechnik implementiert, in diesem Fall das GDX-Protokoll der Firma ABC IT GmbH. Abschließend werden Stabilitätstests und Datenverlustmessungen durchgeführt, die zeigen, dass Mikrocontroller die Leistung und Stabilität für den industriellen Einsatz bringen können.
19.03.18	2018	extern	Bachelor	DE	Konzeption von Workflows im Gefahren-Management-System 	Die DATEV eG ist ein Software- und IT-Dienstleister für Steuerberater, Wirtschaftsprüfer, Rechtsanwälte, mittelständische Unternehmen, Kommunen, Vereine und Institutionen. Das Unternehmen zählt zu den größten IT-Dienstleistern und Softwarehäusern in Deutschland. Aufgrund des besonderen Risikos der Datenkompromittierung, unterliegt das Unternehmen hohen Sicherheitsansprüchen. Die IT-Sicherheit hat die Aufgabe, auf technische Ereignisse, wie Angriffe durch Hacker, Viren, Troja-ner und Spyware zu achten. Die zweite Komponente des Sicherheitsanspruches wird durch die "Physische Sicherheit" wahrgenommen. Physische Sicherheit ist der Schutz von Mitarbeitern, Infrastruktur, Gebäuden, Anlagen, Hardware und Daten vor äußeren Gefahren und Ereignissen, die Schadensauswirkungen auf das Unternehmen haben könnten. Darin enthalten sind der Schutz vor elementaren Schäden, Einbruch, Diebstahl, Vandalismus, Terrorismus und Wirtschaftsspionage. Die "Physische Sicherheit" basiert auf den technischen, organisatorischen und personellen Komponenten "Sicherheitstechnik" und "Betriebsschutz". Anhand der Konzipierung von Workflows für das Gefahren-Management-System soll der Sicherheitsanspruch an die Physische Sicherheit effektiv und effizient gedeckt werden. Diese Konzeption bildet einen wesentlichen Bestandteil der nachfolgenden Arbeit.
19.03.18	2018	intern	Bachelor	DE	Exemplarische Realisierung einer Automotive Ethernet Anwendung zu Lehr- und Forschungszwecken	Ziel dieser Bachelorarbeit war die Entwicklung einer auf der Elektrobit Werkzeugkette basierenden AUTOSAR-Beispielanwendung zum Thema Automotive Ethernet für das Automotive Software Labor der Fakultät Informatik an der TH Nürnberg. Dazu wurden, neben der Vermittlung der notwendigen Grundlagen, eine geeignete Beispielanwendung ausgewählt, der Ablauf von der Planung bis zur Auswertung eines einfachen Automotive Software Engineering Projekts aufgezeigt, und die verwendeten Werkzeuge vorgestellt. Das gesetzte Ziel einer lauffähigen Software wurde allerdings verfehlt.
19.03.18	2018	intern	Bachelor	DE	Evaluierung von GitLab CI in Kombination mit docker für den Einsatz an einer Hochschule	Aktuell wird an der Technischen Hochschule Nürnberg eine GitLab Installation angeboten. Dort können Software-Projekte mit Quellcode, Aufgaben und Meilensteinen verwaltet werden. In der modernen Softwareentwicklung wird ein als Continuous Integration bezeichnete Verfahren genutzt, das von GitLab mit dem Produkt "GitLab CI" unterstützt wird. Im Rahmen dieser Bachelor-Arbeit wird evaluiert, ob "GitLab CI" für den Einsatz an der Technischen Hochschule Nürnberg geeignet ist. Hierbei ist auf Datenschutz, Sicherheit, die Vielfalt der Anwender und deren Anwendungsfälle zu achten. Um den Anforderungen gerecht zu werden ist zunächst angedacht die Integrationsmöglichkeit von "GitLab CI" und der Virtualisierungstechnologie docker zu nutzen um Flexibilität und Sicherheit zu gewährleisten.
20.03.18	2018	extern	Bachelor	DE	Out-of-the-Box IoT Connectivity Lösung	Im Rahmen dieser Bachelorarbeit wurde eine Software-Lösung entwickelt, die es ermöglicht, einen Bluetooth Low Energy Mikrocontroller als Co-Prozessor eines eingebetteten Systems zu verwenden. Dies ermöglicht eine Einbindung der drahtlosen Kommunikationstechnologie in bereits bestehende technische Anwendungen, welche standardmäßig keine Unterstützung hierfür mit sich bringen oder auf denen eine lokale Implementierung nicht in Frage kommt. Dabei wurde eine Firmware für einen ESP32 Mikrocontroller entwickelt, welcher als Bluetooth System on a Chip eingesetzt werden kann und grundlegende Bluetooth Low Energy Funktionalitäten über Datenbusse frei konfigurierbar zur Verfügung stellt. Ergänzend hierzu wurde eine passende Software Bibliothek entworfen, welche für eine einfache Integration der von der Bluetooth Hardware bereitgestellten Funktionalitäten auf einem Anwendungs-Controller eingesetzt werden kann. Die Bachelorarbeit gibt zu Beginn eine Einführung in den Bluetooth Standard sowie in die hierbei eingesetzten Technologien und gibt eine Analyse über bereits vorhandene Lösungsansätze. Anschließend wird auf die zur Umsetzung verwendeten Konzepte eingegangen, die unter Einbeziehung der zuvor durchgeführten Analyse daraus übernommen oder abgeändert wurden. Zuletzt wird beschrieben, wie das hierbei entstandene Produkt in ein konkretes Anwendungsszenario eingesetzt werden kann.?
23.03.18	2018	extern	Bachelor	DE	Intelligente Verknüpfung von Routenzügen und fahrerlosen Transportsystemen unter Nutzung von Digitalisierungsansätzen für die interne Materialversorgung des Gerätewerks Erlangen der Siemens AG	Diese Bachelorarbeit wurde in Zusammenarbeit mit der Siemens AG in Erlangen im Bereich der Inbound-Logistik erstellt. Ziel war es Optimierungspotentiale für die internen Transportsysteme zu ermitteln. Hierfür wurden zunächst, mit Hilfe der im Prozess erhobenen Daten, verschiedene Ursachen für die berechnete geringe Produktivität erarbeitet. Anhand einer Vision konnten diese dann in Kategorien und Maßnahmen übersetzt werden. Mit einer Expertenschätzung konnten einzelnen Maßnahmen Potentiale zugewiesen werden, die ihre Effektivität, hinsichtlich der Optimierungsmöglichkeiten, darstellen. Abschließend wurden ein Stufenkonzept entwickelt, mit dem die Maßnahmen einer sinnvollen Reihenfolge zugeordnet werden konnten.
26.03.18	2018	extern	Bachelor	DE	Konzeptionierung und Implementierung einer Benutzerschnittstelle für einen 3D-Bio-Drucker nach der Norm DIN EN 62366	Im Rahmen eines Forschungsprojektes arbeiten mehrere Partnerfirmen an der Erforschung und Evaluation des innovativen 3D-Druckers für die biologischen Zwecke, der entsprechenden Prozesse sowie an der Datenaufbereitung für das 3D-Bio-Printing und der Konzeption sowie Realisierung einer offenen, normkonformen und anpassbaren Software-Plattform zur Ansteuerung und Bedienung des Bio-Printers. Eine der wichtigen Ziele ist die Bereitstellung einer Software-Plattform, welche die Bedienung, Nutzung und Konfiguration eines 3D-Bio-Printer-Geräts ermöglicht und dabei eine vom Druckermodell unabhängige Kommunikationsschnittstelle evaluiert. Für den Benutzer soll es möglich sein, Materialien, Füllmuster und Druckmodelle hinzuzufügen, zu verändern und auszuwählen, Parameter für einen Fertigungsprozess einzustellen und, falls der Drucker angeschlossen ist, einen vorgespeicherten Druckauftrag ausführen lassen. Der Benutzer mit einer entsprechenden Berechtigung kann noch zusätzlich druckerspezifische Parameter einstellen. Diese Arbeit befasst sich mit der Konzeption und Entwicklung einer intuitiv und komfortabel bedienbaren Benutzerschnittstelle für die Ansteuerung des 3D-Bio-Printers. Dabei wird nach der Norm DIN EN 62366 vorgegangen um die Effektivität, Effizienz, Lernförderlichkeit und Zufriedenstellung des Benutzers zu erhöhen und die möglichen Risiken zu vermeiden.
01.04.18	2018	intern	Master	DE	Evaluierung eines virtuellen, sprachgesteuerten Assistenten zur Erweiterung eines Fuzzy-Optimierungssystems auf Basis von Open-Source-Technologien	Die vorliegende Masterarbeit zeigt durch die Evaluierung eines virtuellen, sprachgesteuerten Assistenten wesentliche Vorzüge und Schwachstellen einer rein sprachlichen Ein- und Ausgabe bei der Bedienung einer Software. Das betrachtete Fuzzy-Optimierungssystem steht dabei stellvertretend für komplexe Anwendungsbereiche, welche über einfache Tätigkeiten wie dem Setzten eines Weckers hinausgehen. Nach der Entwicklung eines Prototyps für den Open-Source-Sprachassistenten Mycroft AI erfolgt die Bewertung des Basismodells durch eine Nutzwertanalyse. Eine qualitative Bewertung der Erweiterung mit Einbezug externer Probanden im Zuge eines Usability-Tests trägt zu einer objektiven Einschätzung bei. Es wird gezeigt, dass Sprachassistenten im Bereich der Programmsteuerung einer konventionellen, oberflächengestützten Software überlegen sind, jedoch durch die rein sprachliche Wiedergabe komplexer Inhalte schnell an die Grenzen der menschlichen, auditiven Auffassungsgabe stoßen. Der Autor empfiehlt daher den Einsatz beider Technologien mit unterschiedlichen Schwerpunkten. Während die Programmsteuerung im Regelfall rein sprachlich erfolgen sollte, trägt eine visuelle Darstellung neben der sprachliche Ausgabe zu einem höheren Gesamtnutzen bei.
01.04.18	2018	extern	Bachelor	DE	Design und prototypische Implementierung eines Performance Profilers für SPS-Anwenderprogramme auf Basis von TIA Portal Openness	Automatisierungstechniker müssen Performance Tests für SPS-Anwenderprogramme heute händisch implementieren. Hierzu sind SPS-Code und entsprechende Protokollierungs- und Auswertungsmöglichkeiten zu implementieren. Die Tests werden dann meist manuell ausgeführt. Die Folge ist ein hoher manueller Aufwand, welcher zwangsläufig auch zu fehleranfällige Implementierung führen kann. Ziel der Bachelorarbeit ist es, ein Prototyp für automatisierte Performance Analysen von SPS-Anwenderprogrammen auf verschiedenen Zielsystemen (S7-1500, S7-1200, etc.) zu implementieren. Mit diesem soll es dem Anwender ermöglicht werden, ohne tiefe Kenntnisse von Hochsprachenprogrammierung automatisierte Performance Analysen auf dem Zielsystemen durchzuführen. Im Baukastenprinzip soll sich der Anwender seine gewünschten Analysen (Speicherbedarf, Laufzeit, etc.) auswählen können, daraufhin wird ihm automatisch der benötigte Code generiert und auf dem Zielsystem ausgeführt. Dies erfolgt über eine automatische Codegenerierung, welche mittels TIA Portal Openness angebunden ist. Die beispielhafte Umsetzung, die Teil dieser Bachelorarbeit sein wird, dient der Siemens AG als "Proof of Concept".
04.04.18	2018	extern	Bachelor	DE	Analyse von "Mobile Connect" als 2-Faktor-Authentisierung für Online-Services und Portal-Lösungen in Verbindung mit Open ID Connect	DATEV eG stellt als eingetragene Genossenschaft Software für seine Mitglieder aus den Berufsständen Steuerberater, Wirtschaftsprüfer und Rechtsanwälten bereit. Bei der Anbindung von neuen Zielgruppen und Märkten sollen marktkonforme, sichere Lösungen im Bereich der 2-Faktor-Authentisierung betrachtet und analysiert werden. Von den Netzbetreibern in Deutschland ist für das vierte Quartal 2018 der bereits in einigen Ländern verfügbare Dienst "Mobile Connect" angekündigt worden, durch den sich Kunden über ihr Smartphone mittels eines Kontos bei ihren Mobilfunkanbietern bei Online-Services anmelden können. Dadurch entfällt die Notwendigkeit, sich auf jeder Seite registrieren zu müssen, sofern die Seite Mobile Connect unterstützt. In der Abschlussarbeit wird Mobile Connect analysiert. Dabei werden zuerst die Eigenschaften des Dienstes und seine Funktionsweise dargestellt. Daraus werden fachliche, technische und rechtliche Vor- und Nachteile, die für eine Verwendung sprechen, behandelt, um anschließend mögliche Einsatzszenarien aufzuzeigen. Zusätzlich wird die Implementierung eines beispielhaften Prototypen ausgeführt. Anhand dieses Prototypen wird dargestellt, welche Schritte notwendig sind, um Mobile Connect in eine bestehende Webapplikation einzuführen. Anhand dieser Informationen wird ein Fazit gezogen und ein Ausblick auf die Einführung des Dienstes in Deutschland gemacht.
05.04.18	2018	intern	Master	DE	Analyse probabilistischer Bahnplanungsverfahren und Entwicklung eines Verfahrens für einen autonomen, mobilen Roboter	Die Arbeit befasst sich mit der Analyse probabilistischer Bahnplanungsverfahren der mobilen Robotik und der Entwicklung eines Prototyps für einen autonomen, mobilen Roboter, den Carbot. Der Carbot ist ein autonomer, nicht-holonomischer und radgetriebener Roboter, der von Prof. Dr. Jörg Roth an der Technischen Hochschule Nürnberg entwickelt wird. Dieser verfügt über deterministische Algorithmen zur Navigation (Pfad- bzw. Routenplanung) sowie anschließenden Bahnplanung (Fahrbahnbestimmung) im Zweidimensionalen und soll um ein zufallsbasiertes Bewegungs- bzw. Bahnplanungskonzept erweitert werden. In dieser Arbeit werden Verfahren zur probabilistischen Bewegungs- bzw. Bahnplanung untersucht und verglichen. Anschließend erfolgt die formale Konzeption und prototypische Implementierung einer zufallsbasierten Bewegungs- bzw. Bahnplanung für die Carbot-Umgebung. Abschließend wird ein Vergleich des Prototyps mit den bereits verfügbaren deterministischen Algorithmen zur Navigation und Bahnplanung durchgeführt.
06.04.18	2018	extern	Bachelor	DE	Evaluation of an existing color trend prediction model and investigation of potential effects on the result quality by means of sales data in a global sporting goods manufacturer	Das Ziel dieser Bachlorarbeit war es, eine Handlungsempfehlung zur Verwendung von Verkaufsdaten in zukünftigen Farbtrendprognosen in der Modebranche zu geben. Dazu wurde eine Literaturanalyse durchgeführt und bereits bestehende Farbtrendprognosen anhand von Verkaufszahlen ausgewertet. Variablen die nach Erkenntnissen dieser Arbeit großen Einfluss auf das Kaufverhalten und somit Verkaufsdaten haben, wurden dabei besonders berücksichtigt. Ergebnis dabei war es, dass die Verwendung von Verkaufsdaten, nur bedingt zur erstellung von Prognosen dieser Art geeignet ist.
09.04.18	2018	intern	Bachelor	DE	IT- Outsourcing: Aktuelle Trends, Chancen und Risiken durch die Digitalisierung in Unternehmen	Die Arbeit soll einen aktuellen Überblick über das Thema des IT-Outsourcings geben. Folgende Fragen stehen somit im Zentrum der Arbeit: 1) Welche Formen des IT-Outsourcings existieren aktuell, um dieses zügig und flexibel zu gestalten und entwickeln? 2) Welchen aktuellen Trends und Herausforderungen stehen Outsourcer und Provider gegenüber? 3) Handelt es sich bei einem IT-Outsourcing-Projekt um ein risikoreiches Vorhaben? 4) Gibt es gewisse Rahmenbedingungen, die beachtet werden sollen? 5) Was müssen Unternehmen beachten, die IT-Aktivitäten zu einem externen Partner auslagern wollen?
12.04.18	2018	intern	Bachelor	DE	Einsatz von Web 2.0 in Schwangerschaft, Geburt und Wochenbett- Entwicklung eines Konzepts für Online-Hebamme	Das Ziel dieser Arbeit ist eine Online-Plattform zu konzipieren, die den Eltern einen orts- und zeitunabhängigen Zugang zu Hebammenleistungen ermöglicht. Dazu wird die Forschungsfrage gestellt: Wie kann Web 2.0 als Instrument für die Digitalisierung des Hebammenangebots in Deutschland verwendet werden? Um diese Forschungsfrage zu beantworten, sind eine Analyse des Hebammenangebots in Deutschland und Interviews durchgeführt worden. Die Befragten wurden in zwei Gruppen unterteilt: Eltern eines oder mehrerer Kinder einerseits und Hebammen, die in Deutschland freiberuflich oder als Angestellte praktizieren andererseits. Die Analyse der Interviews zeigt, dass sich die meisten Eltern Online-Beratung oder Beratung per Chat wünschen und das Angebot einer Online-Hebamme in Anspruch nehmen würden. Die befragten Hebammen sehen solche Angebote als eine ergänzende Möglichkeit zu der herkömmlichen Beratung. Eine weitere Analyse zeigt wie das Angebot der Online-Hebamme dank der Web 2.0 Tools erweitert werden könnte, um einen breiteren Kundenkreis zu erreichen und eine Kundenbindung auf Dauer zu schaffen. Nach der Erstellung eines Online- Hebamme Konzepts für Online-Hebamme wurde eine abschließende Evaluation durch Eltern und Experten durchgeführt. Nach Auswertung aller Ergebnisse erfolgen Handlungsvorschläge seitens der befragten Eltern, Experten und der Autorin. Schlüsselwörter: Hebamme, Digitalisierung, Online-Beratung, Web 2.0, Soziale Netzwerke, Webblogs, YouTube, Experteninterview
17.04.18	2018	intern	Bachelor	DE	Untersuchung der Anforderungen und Entwicklung eines Konzeptes für die Einführung eines Dokumentenmanagementsystems an einer Hochschule	An der Technischen Hochschule Nürnberg soll ein neues Dokumentenmanagementsystem eingeführt werden, da das alte System den Ansprüchen nicht mehr genügt. Hierzu wurden zunächst die Stakeholder- und technischen Anforderungen an das System erhoben und analysiert. Daraus ergab sich eine Darstellung des bisherigen Systems und seiner Umgebung, inklusive anderer koexistierender Dateiablagen. Nachdem die anderen Ablagen und die Anforderungen bekannt waren, konnte ein Konzept für ein Dokumentenmanagementsystem erstellt werden. Bei der Erstellung des Konzeptes wurden die weiteren Ablagesysteme genau betrachtet und in die Überlegungen miteinbezogen. Damit genügt das Konzept den Anforderungen und ergänzt die restlichen Ablagen sinnvoll. Für diese Ergänzungen wurden ebenfalls zusätzliche Optimierungsmöglichkeiten aufgeführt, da auch nach Miteinbeziehung der gestellten Anforderungen weiteres Verbesserungspotenzial zu erkennen war. Nachdem sowohl der Ist- als auch der Soll-Zustand bekannt waren, wurde ein geeigneter Migrationsprozess gewählt, um die Ablösung des alten Systems zu bewerkstelligen. Die Arbeit ist damit besonders für die Mitarbeiter des Rechenzentrums von Interesse.
25.04.18	2018	extern	Master	DE	Entwicklung und prototypische Umsetzung eines Transformationskonzeptes einer Legacy-Infrastruktur zu Containern anhand eines konkreten Proof of Concepts im Applikationsserverumfeld	Die vorliegende Arbeit befasst sich mit der Ausarbeitung eines Konzepts zur Etablierung einer Container-Plattform in die bestehende Unternehmensinfrastruktur. Zur Themeneingrenzung wurde im Speziellen auf infrastrukturelle Fragestellungen eingegangen. Im Rahmen der Analyse wurde zunächst der Ist-Zustand dokumentiert und dargestellt. Zur Ausarbeitung des Konzeptes wurden neben Ist-Analyse auch Erkenntnisse der IT-Abteilung eines Bekleidungsherstellers sowie Referenzimplementierungen anderer Unternehmen herangezogen. Basierend darauf wurde ein Konzept zur Etablierung einer Container-Plattform ausgearbeitet. Abschließend wurde in einer prototypischen Implementierung einer Legacy-Anwendung gezeigt, dass das erstellte Konzept in der Praxis umsetzbar ist. Das Ergebnis der Arbeit besteht in einem Konzept zur Etablierung einer Container-Plattform innerhalb des Unternehmens. Es hat sich herauskristallisiert, dass eine Migration von Legacy-Anwendungen nicht immer sinnvoll ist, vielmehr muss geprüft werden, inwieweit Anwendungen in Containern betrieben werden können. Trotz alledem konnte gezeigt werden, dass eine Container-Plattform und implizit dadurch auch der Betrieb von Anwendungen in Containern einige Vorteile und Chancen mit sich bringt, wenngleich es technische, organisatorische und kulturelle Veränderungen im Unternehmen erfordert. Es wurde abschließend ein Prozess aufgezeigt, welcher zur schrittweisen Einführung der Technologie herangezogen werden kann.
01.05.18	2018	intern	Master	DE	Segmentierung von Gebäudefassaden mit Hilfe Neuronaler Netze	In der vorliegenden Arbeit wurde die Aufgabe der Segmentierung mit Hilfe neuronaler Netzwerke am Beispiel von Gebäudefassaden untersucht. Hierfür wurden die eingesetzten Techniken erläutert und verschiedene Verfahren zur Segmentierung mit Hilfe neuronaler Netzwerke untersucht und verglichen. Dabei wurden sowohl allgemeine, als auch speziell zur Segmentierung von Gebäudefassaden entworfene Verfahren untersucht. Im Anschluss wurde Deeplabv3+ eingesetzt, um damit drei unterschiedliche Datensets mit Fassadendaten zu segmentieren. In den Experimenten wurde die Auswirkung verschiedener Parameter auf die Ergebnisse untersucht. Ebenfalls wurde die Leistungsfähigkeit des trainierten Netzwerkes auf eigenen Aufnahmen des Autors getestet, um die Anwendbarkeit im Rahmen des Projektes Interaktive Gebäudevisualisierung des Energiecampus Nürnberg zu untersuchen. Die Ergebnisse zeigen bereits vielversprechende Segmentierungen, welche in Zukunft weiter untersucht werden können, um darauf aufbauend 3D-Modelle von Gebäuden zu erstellen.
01.05.18	2018	intern	Bachelor	DE	Monokulare Tiefenschätzung mit neuronalen Netzen	In dieser Arbeit gilt es eine Transferleistung von neuronalen Netze zu prüfen. Dafür soll einDatensatz aus monokular aufgenommenen RGB-Bildern und Tiefendaten angelegt werden. Der Trainingsgegenstand ist ein Modellgebäude aus Lego. Das neuronale Netz soll mit dem Datensatz trainiert werden. Anschließend soll getestet werden, ob das neuronale Netz eine akzeptable Tiefenschätzung mit monokular aufgenommenen Bildern von realen Gebäuden vornehmen kann. Zudem soll ermittelt werden, welche Leistung aktuelle neuronale Netze in Bezug auf monokulare Tiefenschätzungen erbringen können. Um die Daten aufzunehmen wurde eine Kinect for Windows v1 Kamera von Microsoft verwendet. Die Tiefendaten des Modells wurden um den Faktor vierzig erhöht, damit das neuronale Netz die Maße eines realen Gebäudes lernt. Als neuronales Netz wurde ein Residual Neural Net von Laina et al. gewählt. Aus einer Stichprobe an neuronalen Netzen konnte ermittelt werden, dass Residual Neural Nets die besten Ergebnisse bei monokularer Tiefenschätzung liefern. Das Experiment mit den hochskalierten Tiefendaten liefert Genauigkeitswerte mit denen die fragliche Transferleistung des neuronalen Netzes mit dem in dieser Arbeit generierten Datensatz nicht zweifelsfrei nachweisbar ist. Außerdem ist in der Arbeit ersichtlich geworden, dass die Kinect for Windows v1 nicht für den Außeneinsatz geeignet ist, da bei der Aufnahme der Tiefendatenim Außenbereich der Sensor durch die Sonneneinstrahlung gestört wird. Für weitere
01.05.18	2018	intern	Bachelor	DE	Konzeption und prototypische Umsetzung eines digitalen Magazins für die Fakultät Informatik	Diese Arbeit befasst sich mit der Konzeption eines digitalen Magazins für die Fakultät Infor-matik der Technischen Hochschule Nürnberg. Dieses wird mit dem Content Management System WordPress prototypisch umgesetzt. Im Rahmen der Konzeption werden aktuelle Websites analysiert, um ein modernes und für die Fakultät passendes Erscheinungsbild zu kreieren. Weiterhin thematisiert die Arbeit die Informationsarchitektur. Die Informationsar-chitektur beschreibt die Strukturierung einer Website und umfasst die Bereiche Organisati-onssystem, Navigationsstruktur und Suchsystem. Es werden jeweils mehrere Lösungsansätze vorgestellt und bewertet. Weiterhin erfolgt die Dokumentation der Umsetzung einiger aus-gewählter Strategien. Daraus ergibt sich der Prototyp eines digitalen Magazins, das den Jah-resbericht der Fakultät ablöst und um einige weitere Inhaltsbereiche erweitert.
01.05.18	2018	extern	Master	DE	Neukonzeption der digitalen Kundenansprache eines IT-Dienstleisters mit modernen Online Marketing Methoden	Die Arbeit zeigt, dass es fu?r Firmen nicht zwingend darum geht, grundlegend neue Wege zu gehen. Content Marketing ist beispielsweise schon 127 Jahre alt. Vielmehr geht es um die Flexibilita?t, die Methoden an neue Herausforderungen wie die Schnelllebigkeit der heutigen Zeit, die Bedu?rfnisse und Wu?nsche der Zielgruppe aber auch an die sich sta?ndig a?ndernden Algorithmen der Suchmaschine anzupassen. Webseiteninhalte sollten immer fu?r den Nutzer und fu?r die Suchmaschinen optimiert werden. Die ho?chste Pra?misse der Suchmaschine ist die Auslieferung von relevanten Suchergebnissen fu?r den Nutzer. Daher sollte der Nutzer mit seinen Bedu?rfnissen auch bei der Erstellung und Optimierung von Inhalten immer an erster Stelle stehen. Die angewandten Methoden eignen sich fu?r den sehr spezifischen Anwendungsfall eines B2B IT Beratungs- und Entwicklungsdienstleisters im neuen und wenig umka?mpften Bereich der digitalen Mobilita?t. Die Methoden sollten keinesfalls als fertige Lo?sungen fu?r andere Anwendungsbereiche betrachtet werden. Es ist erforderlich, jede Situation von Grund auf neu zu bewerten und zu analysieren. Zusa?tzlich beweist die Ausarbeitung in diesem Fall, dass wissenschaftliche Arbeit und die Schaffung von wirtschaftlichem Mehrwert gut zusammenpassen ko?nnen.
02.05.18	2018	intern	Bachelor	DE	Entwicklung eins gamifizierten Citizen-Science-Konzepts zur Mitwirkung unbeteiligter Dritter an datenbasierten Forschungsprojekten.	Zielsetzung der Bachelorarbeit ist es, ein gamifiziertes Citizen-Science-Konzept zu entwerfen, das es unbeteiligten Dritten ermöglicht, sich spielerischen an einem datenbasierten Forschungsprojekt zu beteiligen. Dies soll erreicht werden, indem auch an Forschung interessierte Laien mithilfe von Game-Design-Elementen dazu motiviert werden, an der Datenvorverarbeitung und -analyse mitzuwirken. Das Konzept fußt auf der Recherche und Analyse schon bestehender Ansätze zum Thema Motivation durch Gamification. Neben dem Konzept, das beschreibt, wie man Personen zur Mitwirkung an einem datenbasierten Forschungsprojekt motivieren kann, soll auch ein Mockup erstellt und getestet werden, um sich erste Eindrücke über eine mögliche Umsetzung in eine mobile Applikation zu verschaffen.
02.05.18	2018	intern	Bachelor	DE	Entwicklung eines DoS-Angriffs auf ein prototypisches CAN-Bus Netzwerk	Ziel der Arbeit ist es, einen Angriff auf ein prototypisches CAN-Bus Netzwerke zu implementieren, welcher die Funktionalität einzelner Netzwerkteilnehmer temporär, für die Dauer des Angriffs, komplett verhindert. Das anzugreifende Netzwerk soll aus mindestens zwei Arduinos, welche mit CAN-Shields bestückt sind, bestehen und leicht erweiterbar sein. Der Angriff wird durch die selbst zusammengestellte Angreifer-Hardware ausgeführt. Bei der Datenübertragung über den CAN Bus ist das 0-Bit dominant und das 1-Bit rezessiv. Daraus folgt, dass wenn zwei Teilnehmer gleichzeitig senden würden, die rezessiven 1-Bits von den dominanten 0-Bits überschrieben würden. In dem zu implementierenden Angriff wird das erste gesendete 1 Bit nach der Identifizierung des anzugreifenden Netzwerkteilnehmers durch den Angreifer mit einer dominanten 0 überschrieben. Da der aktuell sendende Teilnehmer seine gesendeten Daten mit dem logischen Wert auf dem Bus live vergleicht und feststellt, dass seine Nachricht verändert wurde, bricht dieser das senden ab, schickt eine Fehler-Nachricht auf dem Bus und erhöht seinen internen Zähler für Sende-Fehler. Falls dieser Zähler einen bestimmten Wert überschreitet wird die Sendefähigkeit dieses Teilnehmers für einen bestimmten Zeitraum oder bis zu einem Reset eingestellt. Des weiteren kann noch die Anbindung einer Bluetooth-Schnittstelle in das CAN-Bus Netzwerk sowie eine Möglichkeit den Angriff zu verhindern implementiert werden.
07.05.18	2018	intern	Bachelor	DE	Evaluierung, Auswahl und prototypische Umsetzung eines Datenschutzmanagementtools für eine Hochschule zur Umsetzung der Datenschutzgrundverordnung (EU-DSGVO)	Die EU erließ die Datenschutzgrundverordnung, die am 25. Mai 2018 in Kraft getreten ist. Aufgrund des Inkrafttretens der DSGVO fasste die Hochschule den Entschluss, für den Bereich des Datenschutzes ein IT-Tool einzusetzen, um die mit der DSGVO verbundenen erhöhten Dokumentations- und Nachweispflichten besser managen zu können. Da zudem auch in den Bereichen des Informationssicherheitsmanagements sowie des IT-Architekturmanagements aktuell noch keine Managementtools eingesetzt werden, soll mithilfe dieser Bachelorarbeit evaluiert werden, ob Tools existieren, die bedeutende Anforderungen aller Bereiche abdecken können. Damit könnte von Synergieeffekten zwischen den Bereichen profitiert werden, weshalb auch untersucht werden soll, ob Zusammenhänge zwischen den Bereichen existieren. Anforderungen an das einzuführende Tool wurden im Voraus mit Verantwortlichen der Hochschule im Rahmen von Interviews ausgearbeitet. Basierend darauf wurde ein Kriterienkatalog mit den Kategorien Datenschutz, ISMS, IT-Architekturmanagement, Usability erarbeitet. Die Evaluation der Tools wurde anhand einer prototypischen Umsetzung durchgeführt und die Tools mithilfe einer Nutzwertanalyse bewertet. Die Evaluation hat gezeigt, dass IT-Tools existieren, die Anforderungen aus allen drei Teilbereichen erfüllen können. Ein Tool konnte über alle vier Kategorien hinweg punkten und ist damit als das geeignetste aus der Evaluation herausgegangen und wird somit für einen Einsatz an der Hochschule empfohlen.
15.05.18	2018	extern	Bachelor	DE	Konzeption und Implementierung eines Event Stores mit Event-Versionierung	Für Softwareentwickler, die eine microservicebasierte Architektur als Ausgangspunkt haben, liefert diese Bachelorarbeit einen grundlegenden Überblick über die Funktionsweise und Konzepte im Zusammenhang mit Event Sourcing. Des weiteren wird eine alternatives Konzept zur konventionellen Speicherung nach dem Create-Read-Update-Delete (CRUD) Prinzip in Form von Command-Query-Responsibility-Segregation (CQRS) aufgezeigt. Die Pattern wurden ausführlich analysiert und der Umgang mit der Versionierung von Events untersucht. Auf Basis der umfangreichen Analyse wurde ein Event Store Microservice konzipiert, der alle Events eines Messaging Systems langfristig speichert und diese für Analysezwecke zur Verfügung stellt. Dabei galt es einige Anforderungen von Softwarearchitekten der Firma Schaeffler einzuhalten und die bestehende Architektur sinnvoll zu ergänzen. Die prototypische Umsetzung erfolgte mit Open-Source Technologien der Firma Elastic. Durch die Verwendung von Event Sourcing wurde eine Möglichkeit geschaffen, zusätzliche Daten für Analysezwecke bereitzustellen und eine unveränderbare Datenhistorie anzubieten, die als Basis für weitere Anwendungsfälle dient.
15.05.18	2018	intern	Bachelor	DE	Entwicklung eines Eclipse-Plugin zur Berechnung nicht explizit modellierter, linearer Qualitätsmerkmale, von zusammengesetzten EAST-ADL Systemkomponenten	Ziel der Arbeit ist es, eine Applikation für die Berechnung einer impliziten Qualität einer Systemkomponente aus den Qualitäten der in der Komponente enthaltenen Unterkomponente zu erstellen. Dazu ist zum einen erforderlich, alle zulässigen Konfigurationen der Unterkomponenten zu finden. Zum anderen muss herausgefunden werden, welche Unterkomponenten zu welchen Komponenten gehören. Aus den Konfigurationen soll die Qualitätseigenschaft der Komponente ermittelt werden. Zuletzt ist das Ergebnis dann in eine Zielfunktion zu überführen.
15.05.18	2018	extern	Master	DE	Konzeption einer Vorgehensweise zur Entwicklung digitaler Geschäftsmodelle für produzierende Unternehmen	Durch die Digitalisierung sind viele Veränderungen notwendig. In dieser spielen Begriffe wie Industrie 4.0, Internet der Dinge und die Transformation von Geschäftsmodellen eine wichtige Rolle. Die Transformation ist notwendig, damit sich Unternehmen auch in der Zukunft gegen Wettbewerber aufstellen können. Das Problem ist jedoch, dass Unternehmen die Relevanz dieses Themas nicht sehen und die Transformation nicht oder nur teilweise durchführen. Dies könnte auf fehlende Informationen, dem Wissen über dieses Thema oder auch Problemen innerhalb der Unternehmensarchitektur zurückzuführen sein. Das Ziel dieser Arbeit ist eine Konzeption für die Erstellung von digitalen Geschäftsmodellen. Es gilt zu klären, welches Wissen bzw. Fähigkeiten und Methoden für die Erstellung der Geschäftsmodelle benötigt werden sowie welcher Prozess durchlaufen werden muss. Es wurde daher zunächst Grundlagenwissen, wie Definitionen von Geschäftsmodellen, Digitalisierung und Strategie näher betrachtet. Auch bereits bestehende Ansätze für die Entwicklung von Geschäftsmodellen sind ein wichtiger Teil. Zusätzlich wurden verschiedene Methoden zur Findung und Erstellung von Geschäftsmodellen erläutert, welche mit einem erstellten Bewertungsraster validiert wurden. Neben diesem erfolgte die Konzeption einer Checkliste zur Validierung der Ist-Situation und dem Bereitschaftsgrad zur Digitalisierung. Als Abschluss wurde ein Prozess mit den Inhalten der Ansätze und des Bewertungsrasters erstellt.
15.05.18	2018	intern	Bachelor	DE	Prototypische Konzeption und Umsetzung eines Roboterhaustiers basierend auf dem Robotersystem "Cozmo"	Thema der Arbeit ist die software-technische Konzeption und Umsetzung eines Roboterhaustiers auf Basis des von der US-amerikanischen Firma Anki entwickelten Robotersystems Cozmo. Das von Anki für die Programmierung in Python bereitgestellte Open Source Cozmo SDK wird im Rahmen dieser Arbeit in eine C++-Umgebung eingebettet. Die Herausforderung besteht darin, unter Beachtung der vorhandenen Software-Architektur, ein neues C++-API für das Robotersystem zu konzipieren und zu implementieren. Die C++-Einbettung bildet damit die Grundlage für das eigentliche Umsetzungsziel: die Entwicklung eines prototypischen Roboterhaustiers. Diese Realisierung setzt sich aus folgenden Funktionalitäten zusammen. Eine selbstständige Standortermittlung der Ladestation bei niedrigem Batterie-Ladezustand inklusive Navigation und Parken. Die natürliche Mensch-Roboter-Interaktion in Form von Begrüßung und Verabschiedung bei der Erkennung eines menschlichen Gesichtes. Außerdem soll das Roboterhaustier in der Lage sein, einen neuen Gegenstand zu erkennen und darauf in Form einer Animation zu reagieren. Zudem werden die Kantendetektion, die Entfernungsmessung der gefahrenen Strecke mittels Odometrie und die Fortbewegung entlang eines Musters auch auf Basis des C++-API umgesetzt. Das Ergebnis ist eine Ansammlung von Funktionalitäten in Form von acht Anwendungsbeispielen, welche die Grundlage für die Implementierung eines Roboterhaustiers bildet.
16.05.18	2018	intern	Master	DE	Entwicklung und Analyse von Gamificationkonzepten als Beitrag zur Stadtentwicklung	Um die Ehre des Titels Kulturhauptstadt Europas 2025 bemüht sich zurzeit die Stadt Nürnberg. Da im Jahr 2025 eine deutsche Stadt den Titel erhält, nutzt Nürnberg die Chance und fokussiert in der Bewerbung verschiedene Themenbereiche. Ein Bereich umfasst die Themen "Arbeit, Lernen und Spiel". In diesem Zusammenhang ist Gamification ein passender Begriff. Dieses Wort tritt in der heutigen Zeit vermehrt auf und wird im Rahmen unterschiedlichster Kontexte verwendet, da die Einbindung spielerischer Elemente in spielfremden Prozessen vielseitig anwendbar ist. Somit stellt sich im Zusammenhang der Kulturhauptstadtbewerbung mit dem beinhalteten Themenbereich die Frage, inwieweit Gamification im Rahmen der Stadtentwicklung eingesetzt werden kann. Die Komplexität der Frage wurde in einzelnen Teilen beantwortet. Einleitend ist eine allgemeine Verständnisvermittlung des bestehenden Kontextes "Gamification innerhalb der Stadtentwicklung" gegeben. Auf Basis eines einheitlichen Verständnisses wurden aus einer Vielfalt von Gamificationkonzepten unterschiedliche Konzepte analysiert. Da innerhalb der analysierten Gamificationkonzepte das Potential für eine Übertragung auf die Stadt Nürnberg erkennbar war, wurden die Bedürfnisse verschiedener Ämter bzw. Einrichtungen Nürnbergs ermittelt. Diese Erkenntnisgewinnung diente der Erstellung individueller Konzepte für Einrichtungen und Ämter der Stadt Nürnberg, welche die Stadtentwicklung und zudem die Kulturhauptstadtbewerbung unterstützen können.
16.05.18	2018	intern	Master	DE	Autonome Navigation und Raumidentifikation in unbekannten Umgebungen am Beispiel des Robotersystems Pepper	Die Arbeit umfasst die Konzeption und Implementierung einer erweiterbaren C++ SLAM-Datenverarbeitungskette für den von SoftBank Robotics entwickelten Roboter Pepper. Der Fokus liegt hierbei auf dem Abspeichern von Informationen mit räumlichen Kontext. Bestandteil der Datenverarbeitungskette ist das Erkunden und Erstellen einer 2D-Karte der Umgebung mit Hilfe der drei Lasersensoren am Boden des Roboters. Hierbei werden die Odometrie-Informationen des Roboters und das Real-Time Correlative Scan Matching Verfahren verwendet. Dies dient dazu das inkrementell aufaddierende Rauschen der Odometrie- und Sensordaten zu bereinigen. Zusätzlich wird der in Computerspielen weit verbreitete A*-Algorithmus als Navigationskomponente in die Datenverarbeitungskette integriert. Des Weiteren wird in der Arbeit untersucht, ob mit Hilfe von Bildverarbeitungsverfahren wie zum Beispiel morphologischen Operationen und Region Growing aus der erstellten 2D-Karte Räume identifiziert werden können. Die identifizierten Räume sollen als selbst erlernte Navigationspunkte sowie als Kontext Information für weitere Aufgaben dienen. Ein Beispiel hierfür ist das Suchen eines Objektes in einem spezifischen Raum.
21.05.18	2018	extern	Master	DE	Neukonzeption der Datenhaltung im Bereich Netzwerk Services der DATEV eG	Die Speicherung und Verarbeitung von Daten ist ein grundlegender Bestandteil vieler IT-Systeme. Trotz dieser zentralen Rolle wird die Datenhaltung bei Veränderungen, wie wechselnden Anforderungen oder wachsenden Datenmengen nur selten angepasst. Daher wird in dieser Arbeit am Beispiel des Bereiches "Netzwerk Services" der DATEV eG ein Konzept zur Anpassung einer bestehenden Datenhaltung an neue sich verändernde Anforderungen in IT-Systemen erstellt. Hierbei wird besonders auf Systeme bestehend aus mehreren Anwendungen und gemeinsamer Datenhaltung eingegangen. Dabei werden einerseits die theoretischen Hintergründe dieser Probleme erläutert. Des Weiteren wird ein Vorgehensmodell erstellt, mit dem ein vorhandenes IT-System und dessen Datenhaltung analysiert und überarbeitet werden kann. Dieses Modell wird am Anwendungsfall "Netzwerk Services" der DATEV eG beispielhaft durchgeführt.
24.05.18	2018	intern	Bachelor	DE	Konzeption und Entwicklung eines eingebetteten Systems mit webbasierter Konfigurationsmöglichkeit zur Fernsteuerung von veranstaltungstechnischer Hard-und Software	Gegenstand der Bachelorarbeit ist eine Bedienoberfläche (Controller), bestehend aus den gängigsten Kontrollarten (Schiebe- und Drehregler, Taster, Display). Im Vordergrund steht dabei die Softwareentwicklung und Betrachtung einiger Kommunikationsprotokolle wie MIDI, OSC, OCA, TCP- und UDP Streams sowie REST Schnittstellen. Hintergrund des Themas ist die Digitalisierung in vielen Bereichen der Veranstaltungsindustrie. Dadurch werden immer mehr früherer Hardwaregeräte durch Software ersetzt, da dies mittlerweile zumindest gleichwertige Qualität, zudem aber mehr Möglichkeiten der Reproduzierbarkeit, Transportierbarkeit und Parametrierbarkeit bietet. Lediglich die Kontrollierbarkeit leidet hierunter, da Hersteller sich oft auf Funktionalität konzentrieren und die Bedienung bei Maus- und Tastatureingabe beschränkt bleibt. Ziel der Bachelorarbeit ist es, einen Prototyp zu entwickeln, der verschiedene Systeme fernsteuern kann. Dies soll über eine Weboberfläche konfiguriert werden können. Des Weiteren findet eine Analyse und Bewertung gängiger Kommunikationsprotokolle statt.
25.05.18	2018	extern	Bachelor	DE	Konzeption und Realisierung der Personalverwaltung für ein Webportal des pharmazeutischen Einzelhandels	Das Ziel dieser Arbeit ist die Konzeption und Realisierung einer Personalverwaltung in einem Webportal. Die Webanwendung der Firma Endobit Software Solutions stellt eine Plattform für den pharmazeutischen Einzelhandel zur Verfügung, die individuelle Konfigurationsmöglichkeiten für klein- und mittelständische Unternehmen bietet. Die Implementierung umfasst die Organisation und Erstellung eines Dienstplans auf Basis mitarbeiterspezifischer Dienstplanvorlagen. Für den Praxiseinsatz ist vorgesehen, dass Arbeits-, Urlaubs- und Fehlzeiten bearbeitet werden können und das deren Auswirkungen auf den Schichtplan berücksichtigt werden. Die Umsetzung erfolgt mithilfe von Microser- vices, um eine modulare Integration in das als Single-Page-Webanwendung existierende Webportal zu verwirklichen.
28.05.18	2018	extern	Bachelor	DE	Weiterentwicklung eines bestehenden Visualisierungstools im Bereich autonomes Fahren	Die Elektrobit Automotive GmbH ist in dem Projekt EB robinos mit der Entwicklung von Software für autonomes Fahren beschäftigt. Ein Teil dieses Projekts ist die Road Fusion. Die Road Fusion Komponente ist dabei zuständig für die Berechnung von Hypothesen, wo genau die Straßen- und Fahrstreifenenbegrenzungen liegen. Dazu bekommt sie verschiedene Eingangsdaten, zum Beispiel Fahrstreifen und Straßenmarkierungen von verschiedenen Quellen. Aus diesen berechnet sie dann die Hypothesen. Die Visualisierung hilft den Entwicklern genau zu sehen, was wo relativ zur eigenen Position berechnet wurde. Zu den Datenstrukturen der Road Fusion gibt es jeweils einen Layer, der diese graphisch darstellt, und ein Widget, in dem man alle Objekte der einzelnen Datenstrukturen ganz ausblenden kann oder sie einzeln auswählen kann und dort zusätzliche Informationen angezeigt bekommt. Gespeicherte Eingangsdaten können per JSON Stream an die Road Fusion übergeben werden. Aus deren Berechnungen kann die Visualisierung die Berechnungen eines ganzen Zeitfensters zur Laufzeit graphisch darstellen. Bei Testfahrten werden die Berechnungen ebenfalls in Echtzeit dargestellt. Die erste Aufgabe dieser Arbeit ist es den Ist-Zustand zu analysieren. Da die Aufgabe darin besteht die Visualisierung weiterzuentwickeln, soll dann zunächst mit Hilfe geeigneter Methoden die Anforderungen an die neue Visualisierung ermittelt werden. Diein einem Lastenheft zusammengetragenen Anforderungen sollen implementiert werden.
29.05.18	2018	extern	Bachelor	DE	Erfassung von Anlagenzuständen über XDK-Mikrocontroller	Es soll eine dezentrale, standardisierte Lösung geschaffen werden, um Fertigungssysteme zu überwachen. Hierbei ist das Ziel einen Mikrocontroller so einzurichten, dass dieser den Status einer angebrachten Ampel ausliest und per WLAN an ein Backend meldet. Hierfür wird das "XDK ? Cross Domain Development Kit" der Robert Bosch GmbH eingesetzt.
01.06.18	2018	extern	Bachelor	DE	Konzeption und Realisierung einer Crossplattform-Applikation für Neukundenbefragungen in Friseur- oder Kosmetikstudios	In dieser Arbeit wurde eine Crossplattform-Applikation für Neukundenbefragungen in Friseur- oder Kosmetikstudios für die Head-on Solutions GmbH konzipiert und erstellt. Zunächst erfolgt eine Analyse des Ausgangszustandes der Anwendung und der zu lösenden Problemstellung. Daraus abgeleitet erfolgt die Definition des Zielzustandes der Applikation. Zur Findung eines für die Applikation geeigneten Frameworks erfolgte eine Analyse von verschiedenen Frameworks hinsichtlich deren Anwendbarkeit, Funktionsumfang und Umsetzbarkeit der an die Applikation gestellten Anforderungen. Zur Findung des für die mobile Applikation zu verwendenden Frameworks wurde mit drei verbleibenden Frameworks eine Testapplikation umgesetzt. In einer eingehenden Anforderungsanalyse werden das Konzept für die Benutzeroberfläche und die Softwarearchitektur behandelt. Anschließend wird die Umsetzung der mobilen Anwendung behandelt und die hierbei angewandten Methoden und Technologien im Detail besprochen. Abschließend wird ein Fazit gezogen, bestehend aus Zielerreichung und Ausblick.
12.06.18	2018	intern	Bachelor	DE	Migration bestehender ABS-Software auf neues Steuergerät auf Grundlage von AUTOSAR	Diese Bachelorarbeit behandelt das Thema der Migration bestehender ABS-Software auf ein neues Steuergerät auf Grundlage von AUTOSAR. Ausgehend von der Systembeschreibung und der implementierten Applikationssoftware werden detailliert die notwendigen Arbeitsschritte erläutert, um die ABS-Software auf ein anderes Steuergerät zu übertragen. Beim neuen Steuergerät handelt es sich um KIT_AURIX_TC297_TFT von infineon. Zunächst wird mit dSpace SystemDesk 4.7 die Systembeschreibung aktualisiert. Anschließend wird mit EB Tresos Studio 22.0.1 TC29XT Multicore die Basissoftware konfiguriert. Zum Übertragen der kompilierten Konfiguration und Applikation auf das Steuergerät wird Lauterbach TRACE32 Software und Lauterbach Debugger Hardware verwendet.
14.06.18	2018	intern	Bachelor	DE	Konzeptionelle und anwendungsspezifische Unterschiede der Datenmodellierung für relationale und nicht-relationale Datenbanken, speziell für dokumentenorientierte und Key-Value-Datenbanken	Als nicht-relational bezeichnet man Datenbanken, die einen alternativen Ansatz zu den weit verbreiteten relationalen Datenbanken verfolgen. Nicht-relationale Datenbanken erfreuen sich immer größerer Beliebtheit. Doch die genauen Unterschiede zum relationalen Datenmodell sind oft nicht im Detail klar. Ziel dieser Arbeit ist es, diese Unklarheiten auszuräumen. Anhand einer Fallstudie werden verschiedene nicht-relationale Modellierungskonzepte erläutert. Dabei werden die Unterschiede zur Datenmodellierung relationaler Datenbanken aufgezeigt. Die in der Arbeit gewonnenen Erkenntnisse werden abschließend in verallgemeinerter Form zusammengefasst.
15.06.18	2018	intern	Master	DE	Interaktive und dynamische Visualisierung von Studentendaten in Bezug zum Studienerfolg und Identifikation möglicher Ursachen für den Studienmisserfolg an der TH Nürnberg	Auf unterschiedliche Weise kann ein Studium zu einem Misserfolg führen. Dabei wird das Studium beendet ohne den angestrebten akademischen Grad zu erhalten. Für alle Beteiligten wäre es von Vorteil bereits im Vorfeld Wissen über Faktoren zu haben welche den Erfolg des Studiums beeinflussen. So könnten zielgerichtet Maßnahmen durchgeführt werden welche dem Misserfolg im Studium entgegenwirken. Um diesem Ziel näher zu kommen wurde eine Anwendung geschaffen mit der vielfältige Analysen möglich sind. Die Daten wurden erstmals in dieser Form und Menge miteinander verknüpft. Auf anschauliche Weise werden die sie repräsentiert. Dafür wurde eine Visualisierungskonzept entworfen. Die Daten können durch viele Filter beeinflusst werden wobei sich diese Anpassungen auf die Darstellung auswirken. Das entwickelte Programm wird für erste Analysen, hauptsächlich hinsichtlich des Studienmisserfolgs, genutzt. Es werden selbst gewählte und von zwei Testpersonen entworfene Fragestellungen behandelt. Die Vorgehensweise und Ergebnisse werden protokolliert. Gefundene Zusammenhänge lassen sich über eine Exportfunktion aus der Anwendung heraus extrahieren. Die Exportfunktion wurde ebenfalls im Rahmen dieser Arbeit entwickelt. Durch die Analyse wurde unter anderem ermittelt, dass eine hohe Anzahl an Fachsemestern das Risiko auf einen Misserfolg nicht stark erhöht. Weiterhin hat sich gezeigt: eine Fünf in dem Fach welches im Studiengang am häufigsten nicht bestanden wird kann das Risiko erhöhen.
18.06.18	2018	intern	Bachelor	DE	Analyse und Vergleich von plattformunabhängigen Ansätzen für Webanwendungen am Beispiel der Nahrungs- und Genussmittelindustrie	Im Rahmen dieser Bachelorarbeit werden die plattformunabhängigen Konzepte des Graceful Degradation, Progressiv Enhancement und Mobile First analysiert und miteinander verglichen. Innerhalb der Analyse möchte ich auf die einzelnen entwicklungsspezifischen Aspekte der Vorgehensweisen eingehen. Mithilfe der drei Konzepte soll eine beispielhafte Webanwendung für die Nahrungs- und Genussmittelindustrie entwickelt werden. Am Ende soll der Leser ein Verständnis für die drei unterschiedlichen Konzepte besitzen und die jeweiligen Vor- und Nachteile kennen.
18.06.18	2018	extern	Bachelor	DE	Evaluierung der Front-End-Webframeworks Angular, Vue und React für den Einsatz in einem Feedback-Management-System	Die vorliegende Bachelorarbeit stellt die Front-End-Webframeworks Angular, React und Vue gegenüber. Dabei wurde eine Evaluierung anhand der Kriterien TypeScript, Lernkurve,Performance,Boilerplate-Code,InternationalisierungundUnit-Testingdurchgeführt.DieErgebnissederArbeitbringendieStärkenundSchwächen,sowiedieUnterschiedederFrameworkshervor.EbensowerdendieVorgehensweisenundLeitgedanken derFrameworksverglichen.DadurchkönnenAnwendungsfällede?niertwerden,fürwelche die einzelnen Frameworks eingesetzt werden können. Die Evaluierung wurde dabei an einer bereits bestehenden Webanwendung - einem Feedback-Management-System der MATHEMA Software GmbH - durchgeführt. Aus dem System wurde exemplarisch eine Webseite ausgewählt. Für diese sollte ein Entwurf konzipiert werden, welcher in allen drei Frameworks implementierbar ist. Im Rahmen der Arbeit wurde außerdem eine Umfrage, die sich besonders auf die Einschätzung und Erfahrung der FrameworkNutzer fokussiert, durchgeführt und analysiert. Insgesamt nahmen 127 Entwickler an der Umfrage teil. Die Zielgruppe der Bachelorarbeit sind Projektteams und Entwickler,diesichbereitsgrundlegendeKenntnisseimBereichderFront-End-Webentwicklung angeeignet haben.
22.06.18	2018	extern	Master	DE	Automatisierte Erstellung von User-Dokumentationen für ALM-Prozesstemplates in der Softwareentwicklung mittels Continuous Delivery im DevOps-Kontext	Die evosoft GmbH stellt für Siemens das Application Lifecycle Management (ALM) Tool "Team Foundation Server" (TFS) bereit, auf das täglich mehr als 10.000 Software-Entwickler zugreifen. Neue Features werden monatlich zur Verfügung gestellt und eine dazu passende User-Dokumentation parallel dazu erstellt. Zukünftig sollen Features viel häufiger, schneller und fehlerärmer bereitgestellt werden, indem auch die Generierung der User-Dokumentation mit in den bestehenden Build- und Release-Prozess integriert wird. Zu Beginn werden im Rahmen einer Analyse der bestehenden Vorgehensweise sinnvolle Ansätze für eine mögliche Prozessveränderung ermittelt. Zusätzlich werden mithilfe einer Stakeholderanalyse die Anwendungsszenarien, Nutzen und Risiken eines neuen Ansatzes aufgezeigt. Darauf basierend entsteht ein Konzept, welches vor der Überführung in den produktiven Einsatz einer kritischen Bewertung hinsichtlich realisierbarer Einspar- und Verbesserungspotenziale unterzogen wird.
11.07.18	2018	extern	Bachelor	DE	Vergleich der Distributed Ledger Technologien IOTA und Ethereum bei Anwendung in der Energiewirtschaft	Distributed Ledger werden als die disruptivste Technologie der letzten Jahre eingestuft. Sie sollen Prozesse vereinfachen und die Transparenz und Auditierbarkeit erhöhen. Von ihnen werden sich viele Effizienzgewinne, die mit Herkömmlichen Technologien nicht realisierbar sind, versprochen. Mit IOTA und Ethereum gibt es zwei Vertreter, die das Konzept der Distributed Ledger erweitern. Ethereum ermöglicht die Erstellung von Smart Contracts, mit deren Hilfe dezentrale Applikationen realisiert werden könne. IOTA auf der anderen Seite verspricht durch den Einsatz des Tangles die Probleme der Blockchain Technologie, wie begrenzte Skalierbarkeit und hohe Transaktionskosten, zu beheben. Das Ziel dieser Arbeit ist es, diese beiden Distributed Ledger Technologien miteinander zu vergleichen. Dies geschieht einerseits im Kontext eines Anwendungsbeispiels und andererseits auf Basis etablierter Messkriterien für Distributed Ledger. Als Anwendungsbeispiel wurde die Implementierung eines digitalen Marktplatzes zum Stromhandel, auf Basis eines Distributed Ledgers, gewählt. Die vielfältige Einbindung von Intermediären und die starke Zentralisierung des Energiesektors, sowie die Fähigkeit von Distributed Ledgern eben dieser Zentralisierung entgegenzuwirken, qualifizieren dieses Anwendungsbeispiel als Kontext für den Vergleich von IOTA und Ethereum.
12.07.18	2018	extern	Master	DE	Edge Computing - Potenziale, Grenzen und Auswirkungen dezentraler Datenstromverarbeitung 	Die vorliegende Arbeit beschäftigt sich mit einer technologischen Untersuchung im Kontext des Edge Computings. Neben einer allgemeinen technologischen Untersuchung in Bezug auf zur Verfügung stehende Soft- und Hardwarekomponenten findet eine Evaluierung drei aktueller Edge Computing Tools statt. Die für die Evaluierung notwendigen Bewertungskriterien werden anhand der Charakteristiken des Softwarequalitätsmodells nach ISO 25010 und auf Basis von typischen Edge Computing Anwendungsfällen identifiziert. Durch die Entwicklung und Implementierung eines prototypischen Edge Computing Szenarios werden die Tools in Form von Apache Edgent, Azure IoT Edge sowie AWS IoT Greengrass anschließend hinsichtlich der vorab identifizierten Anforderungen evaluiert. Im Zuge dessen wird ersichtlich, dass keines der drei Tools alle Anforderungen gleichermaßen erfüllt. Es ist vielmehr eine detaillierte Betrachtung des jeweiligen Einsatzzwecks sowie dessen konkreten Anforderungen notwendig, um eine valide Aussage über das zu präferierende Tool treffen zu können.
14.07.18	2018	intern	Master	DE	Entwicklung einer domänenspezifischen Sprache zur Realisierung von Sensornetzanwendungen	In dieser Masterarbeit wird eine domänenspezifische Sprache entwickelt, mit deren Hilfe sich Sensornetzanwendungen realisieren lassen. Zu diesem Zweck wird zunächst die Bereitstellung der Entwicklerwerkzeuge vereinheitlicht. Zusätzlich wird ein vermaschtes Netz mit Routingalgorithmus in TinyOS implementiert. Für die Entwicklung der Sprache wird dargelegt, dass YAML als Beschreibungssprache dafür geeignet ist. Weiterhin wird eine Beispielimplementierung der Sprache in C++ mit anschließendem Funktionstest durchgeführt.
16.07.18	2018	extern	Master	DE	Entwicklung von Strategien für die Paketierung und Lizenzierung von Software für große Unternehmenskunden	Das Ziel der vorliegenden Masterarbeit ist es, durch eine Analyse der eingesetzten Preismodelle in ausgewählten Industrien die Optimierungspotenziale im derzeitigen Preismodell für MRI-Software von Siemens Healthineers aufzuzeigen und basierend darauf ein neues Modell zu entwickeln. Die Grundlage der Arbeit bildet eine Literaturrecherche, mithilfe derer ein Überblick über die relevanten Gestaltungsparameter und Erfolgsfaktoren eines Software-Preismodells gegeben wird. Danach werden vom Autor die Produkte und das derzeitige Lizenzierungsmodell vorgestellt und ein Dashboard für die Visualisierung von Kennzahlen und Strukturen in den vergangenen Verkäufen der MRI-Software erstellt. Mithilfe der Analyse der Einkaufsdaten werden im Anschluss die Stärken und Schwächen des derzeitigen Preismodells ermittelt und aufgezeigt, welche Verbesserungspotenziale es für das Preismodell der Software-Optionen gibt. Die Analyse der Einkaufsdaten führte zu dem Ergebnis, dass die Etablierung eines neuen flexibleren Preismodells hohes wirtschaftliches Potenzial für das Unternehmen birgt. Die Literaturrecherche zeigte außerdem, dass in Bezug auf die Zahlungsform der Trend hin zu Preismodellen mit wiederkehrenden Gebühren geht. Zur Komplexitätsreduktion bei einer hohen Produktvielfalt werden Bündelungsstrategien empfohlen. Für das neue Preismodell werden daher eine Bündelung der Produkte und die Einführung einer auf dem Subscription-Modell basierenden, nutzungsunabhängigen Lizenzierung vorgeschlagen.
18.07.18	2018	intern	Bachelor	DE	Konzeption und Umsetzung einer Webanwendung für die Erstellung von Echtzeit-kollaborativen Mindmaps	Bestehende Lösungen um gemeinsam an Mindmaps arbeiten zu können sind oft kostenpflichtig, nur nach einer Registrierung nutzbar oder speichern die Daten auf ausländischen Servern. Die Kosten- sowie Registrierungspflicht sind insbesondere dann problematisch, wenn die Lösung zu Unterrichtszwecken eingesetzt werden soll. Um auch sensible Daten mit der Anwendung verarbeiten zu können, müsste in jedem Fall gewährleistet sein, dass die Daten in einem zweifelsfrei sicheren und vertrauenswürdigen Umfeld gespeichert werden. Das Ziel dieser Arbeit ist die Entwicklung einer Webanwendung, die es ermöglicht in Echtzeit, kollaborativ an Mindmaps zu arbeiten. Die hierbei entwickelte Lösung soll zu Lehrzwecken eingesetzt werden können und dabei ohne Registrierung, sowie unabhängig vom Endgerät nutzbar sein. Auch die Sicherheit der Daten, die mit der Anwendung erzeugt werden, muss gewährleistet sein, indem die Anwendung auch auf eigenen Servern betrieben werden kann. Zu Beginn der Arbeit wird analysiert, welche Technologien für die Umsetzung in Frage kommen. Daraufhin werden die einzelnen Komponenten der Anwendung entworfen. Dazu bedarf es einer funktionalen und gestalterischen Planung der Benutzeroberfläche, sowie einer strukturellen Planung des Datenbankmodells und des Backends. Nach Abschluss der Arbeit wird der entwickelte Quellcode als Open-Source veröffentlicht, um eine stetige Weiterentwicklung der Anwendung zu ermöglichen.
27.08.18	2018	extern	Bachelor	DE	Einsatzmöglichkeiten von Augmented Reality in modularen Fertigungsanlagen zur Unterstützung von Anlagenbedienern aus unterschiedlichen Fachbereichen	Das Ziel dieser Arbeit besteht in der Konzeptionierung und Entwicklung von Augmented Reality Anwendungen zur Lösung von Problemstellungen im Umfeld von modularen Fertigungsanlagen. Konkret werden zwei Problemstellungen untersucht. Zum einen werden zukünftig in modernen Fertigungsanlagen Roboter-Umhausungen durch ausgeklügelte dynamische Sicherheitskonzepte ersetzt. Die dabei zum Einsatz kommenden Sicherheitseinrichtungen wie beispielsweise Lichtgitter oder Laserscanner sind für das menschliche Auge nicht sichtbar. Zudem lässt sich die komplexe Dynamik solcher Systeme mit herkömmlichen Medien einem Nichtfachmann nur schwer erklären. Die Arbeit beschäftigt sich in diesem Zusammenhang mit der Fragestellung, wie durch die Visualisierung mit Augmented Reality die dynamischen Sicherheitskonzepte besser demonstriert und überprüft werden können. Zum anderen gibt es bei modularen Fertigungsanlagen eine hohe Anzahl an möglichen Anlagenrüstungsvarianten. Um die Anlagenrüstung für den bevorstehenden Produktionsauftrag optimieren zu können, wird ein Experte benötigt. Trotz umfassender Erfahrung kann dabei meist keine perfekte Lösung gefunden werden. Ein weiteres Ziel der Arbeit besteht deshalb darin, auch einem Anlagenbediener mit weniger Erfahrung die Optimierung einer modularen Fertigungsanlage zu ermöglichen. Die Bestimmung eines Optimums erfolgt dabei anhand von computergestützten Simulationen. Der Bediener wird beim Umkonfigurieren durch virtuelle Arbeitsanweisungen unterstützt.
01.09.18	2018	extern	Bachelor	DE	Auswirkung der EU-Verordnung 2017/746 auf die Weiterentwicklung einer Softwareplattform für In-vitro-Diagnostika	Die neue EU-Verordnung 2017/746 über In-Vitro-Diagnostika (IVD), die am 26. Mai 2017 in Kraft getreten ist, setzt Hersteller von IVDs unter Druck. Neue Produkte können nur noch unter Einhaltung der neuen Vorgaben in Verkehr gebracht werden. Bisher genehmigte Produkte müssen innerhalb von fünf Jahren erneut zertifiziert werden. Produkte, die bis zum 26. Mai 2022 nicht den neuen Anforderungen entsprechen, dürfen nicht mehr weiterentwickelt oder verändert werden. Die neue Verordnung verlangt grundlegende Veränderungen bei der Softwareentwicklung im Bereich IVD. Ein Beispiel dafür ist die überholte Sicherheitsklassifizierung, die Software in andere Sicherheitsklassen einteilt als bisher. Mit der neuen Sicherheitsklassifizierung gehen andere Verpflichtungen einher, die bei der Entwicklung einzuhalten sind. Die Arbeit zieht einen Vergleich zwischen der alten Richtlinie 98/79/EG und der neuen Verordnung 2017/746 der EU. Dabei wird die Auswirkung der Verordnung 2017/746 anhand der bei der infoteam Software AG entwickelten Softwareplattform untersucht. Dazu soll die Softwareplattform um eine neue Komponente erweitert werden, die konform zu den neuen und geänderten Anforderungen der Verordnung 2017/746 ist.
01.09.18	2018	extern	Bachelor	DE	Konzeption, Entwurf und Implementierung eines Transformators von EAST-ADL- zu AUTOSAR-Modellen	Diese Arbeit befasst sich mit der Transformation, oder auch Umwandlung, von Systemarchitekturmodellen, erstellt mit der Architekturbeschreibungssprache EAST-ADL, in Softwarearchitekturmodelle, erstellt mit AUTOSAR. Die Arbeit richtet sich somit an Softwareentwickler in der Automobildomäne mit Bezug zur System- und Softwarearchitektur von Fahrzeugsystemen. Die Umwandlung der Modelle geschieht manuell durch den Softwareentwickler und beansprucht dadurch dessen Zeit, birgt hohes Fehlerpotential und verursacht Kosten. Diese Missstände sollen durch eine automatisierte Transformation abgeschafft werden. Um dieses Ziel zu erreichen wird nach dem V-Modell und mittels Scrum eine Java Eclipse Applikation entwickelt, welche die Transformation automatisiert durchführen soll. Dazu werden die Anforderungen anhand von Anwendungsszenarien ausgearbeitet und in Form der IEEE-830 1998 dokumentiert. Zudem wird ein Zuordnungsschema zwischen EAST-ADL- und AUTOSAR-Elementen aufgestellt. Dabei wurde das Zuordnungsschema aus der Masterarbeit von Ahsan Shamim geprüft, aktualisiert und angepasst. Das resultierende Zuordnungsschema ist die Basis der Transformation der Modelle. Des Weiteren wird die Softwarearchitektur der Applikation aufgestellt und ein Entwurf der Software ausgearbeitet. Die Implementierung der Applikation erfolgt prototypisch. Es wird die grundlegende Konfiguration der Entwicklungsumgebung beschrieben und auf die Verwendung der Entwurfsmuster Strategy und Singleton eingegangen.
01.09.18	2018	extern	Bachelor	DE	Konzeption und prototypische Implementierung eines Moduls zur automatischen Erkennung und Verarbeitung von Nachrichten im internationalen Flugverkehr	Diese Bachelorarbeit wurde als Projekt der Firma ISO Software Systeme GmbH in Nürnberg im Zeitraum von 01.09.2018 bis 01.02.2019 erstellt. Ziel dieser Arbeit war die Konzeption und prototypische Implementierung eines Moduls, das in die SKYport Suite der ISO Software Systeme GmbH integriert werden kann. Dieses Modul soll automatisiert Nachrichten, die im internationalen Flugverkehr versendet werden, erkennen und verarbeiten. Dazu wurden mehrere Frameworks verglichen, die zum Parsen der Nachrichten geeignet sein könnten. Danach wurde auf die Anforderungen an das Modul und auf mögliche Designentwürfe und -entscheidungen, die diesen Anforderungen gerecht werden, eingegangen. Anschließend wurde der Prozess dargestellt, den die Nachricht im Modul durchläuft. Zuletzt wurden Performanz und Robustheit des Moduls geprüft. Daraus resultierte ein Prototyp, der Nachrichten, die nach dem AHM Standard definiert sind, erkennt und verarbeitet. Dieser Prototyp wurde in die SKYport Suite integriert.
01.09.18	2018	extern	Bachelor	DE	Entwicklung und ausgewählte prototypische Umsetzung einer Business-Intelligence-Strategie für den Zentraleinkauf der DATEV eG	Im Zuge der Digitalisierung werden auch Einkaufsabteilungen mit Big Data konfrontiert. Um diesbezüglich Wettbewerbsvorteile gegenüber der Konkurrenz zu realisieren, ist es entscheidend, die großen Datenmengen nicht einfach nur anzuhäufen, sondern sie auch zielgerichtet einzusetzen. Eine Möglichkeit hierfür bietet der Einsatz von Business Intelligence. Im Fokus dieser Arbeit steht die Entwicklung einer Business-Intelligence-Strategie für den Zentraleinkauf der DATEV eG. Hierfür werden nach Erläuterung der theoretischen und praxisbezogenen Grundlagen die Phasen Analyse, Bewertung, Konzeption und Maßnahmen des Strategieentwicklungsprozesses durchlaufen. In diesen Prozessphasen kommen verschiedene Methoden zum Einsatz, die jeweils konkrete Ergebnisse liefern. Sowohl die durchgeführte Bedarfserhebung als auch die SWOT-Aufstellung und Reifegradmodell-Einteilung zeigen Handlungspotential im Berichtswesen auf. Die Befragung ergab, dass insgesamt 60 Kennzahlen für den Zentraleinkauf der DATEV eG relevant sind. Jedoch werden diese aufgrund technischer oder organisatorischer Schwachstellen derzeit nicht vollständig ermittelt. Um diese Probleme zu beheben, wird der Einsatz einer Business-Intelligence-Lösung geplant. Im Rahmen der Konzeption werden beispielsweise Kennzahlen bewertet, Business-Intelligence-Produkte verglichen sowie das Einkaufsvolumen als Kennzahl prototypisch umgesetzt. Mithilfe der formulierten Business-Intelligence-Roadmap kann eine planvolle Realisierung erfolgen.
01.09.18	2018	intern	Bachelor	DE	Bildung und Bewertung von Standortindikatoren für Kundensegmentierung aus frei zugänglichen Datenquellen zur Verwendung in Machine Learning-Anwendungen	Das Ziel dieser Bachelorarbeit war es, Standortindikatoren für Kundensegmentierung mittels Relation zwischen den unternehmensexternen Marktdaten zu bilden und zu bewerten. Hierzu wurden drei Hypothesen erstellt: 1) Es gibt einen Zusammenhang zwischen soziodemographischen, ökonomischen und psychographischen Merkmalen 2) Das Zufriedenheitsniveau der Einwohner hängt von der Anzahl der verschiedenen Angebote in ihrem Wohnort, wie zum Beispiel Gastronomie, Sport- und Freizeitmöglichkeiten oder Naturobjekte ab 3) Auf Basis der Anzahl von verschiedenen Einrichtungen in einem Wohnort, kann man die Kaufkraft der Bewohner prognostizieren. Um diese Hypothesen zu prüfen, wurde eine riesige Datenbank in PostgreSQL mit statistischen, soziodemographischen, ökonomischen, psychografischen und OpenStreetMap-Daten erstellt und bearbeitet. Nach der durchgeführten statistischen Analysen wurde festgestellt, dass die Hypothese über den Zusammenhang zwischen soziodemographischen, ökonomischen und psychographischen Merkmalen bestätigt wurde. Zwei weitere Hypothesen zur Prognose der Kaufkraft und der Zufriedenheit auf Basis der Anzahl von verschiedenen OSM-Objekten wurden wegen unzureichendem Zusammenhang verneint. Die Ergebnisse der vorliegenden Arbeit können als ein Instrument angesehen werden, um eine Grundlage für eine weitere Standortanalyse, Geomarketing oder unternehmerische Entscheidungen zu schaffen.
01.09.18	2018	extern	Bachelor	DE	Machbarkeitsstudie und prototypische Entwicklung eines Time-Travel-Debuggers im Kontext eines konkreten Embedded Systems	In der Softwareentwicklung kostet die Analyse von Fehlern durch Softwareentwickler viel Zeit. Herkömmliche Debugger geben dabei keine Auskunft über den Fehlerhergang, sondern nur über den Programmzustand zum Fehlerzeitpunkt. Diese Lücke schließen Time-Travel Debugger, die durch Aufzeichnen des Programms den genauen zeitlichen Verlauf des Fehlers rekonstruieren können. Das Ziel dieser Arbeit ist es, in Kooperation mit der Firma e.solutions GmbH, eine Machbarkeitsstudie zum Einsatz eines Time-Travel Debuggers für das reaktive Embedded System "Virtual Cockpit" durchzuführen. Dabei war insbesondere relevant, wie hoch der Performance-Overhead bei der Aufnahme des Programms zur Ausführungszeit ausfällt und ob es möglich ist, das aufgenommene Programm in der PC-Simulation wiederzugeben. Dazu wurde, aufbauend auf bekannten Architekturen, ein Konzept erarbeitet und anhand eines prototypischen Time-Travel Debuggers umgesetzt. Dieser wurde erfolgreich auf seine Tauglichkeit im Embedded-Umfeld getestet. Um die Aufnahme zu einem beliebigen Zeitpunkt starten zu können, anstatt nur bei Programmstart, müsste der Prototyp um eine Snapshot-Funktionalität erweitert werden. Diese kann allerdings erst realisiert werden, wenn die Grundlagen vom Gesamtsystem geschaffen worden sind.
03.09.18	2018	extern	Bachelor	DE	Regelsätze und Werkzeugerweiterung für eine automatische Software-Analyse von C#-Projekten mit exemplarischer Visualisierung einer Auswertung	"Das Ziel der vorliegenden Bachelorarbeit war es eine automatische Software-Analyse für C# Anwendungen zu entwickeln. Um Verletzungen einer Softwarearchitektur zu entdecken, wurden Regelsätze definiert und entwickelt. Mithilfe des C# Scanners Architecture Analyzer werden Code Abhängigkeiten in Assemblies entdeckt und in Knoten und Kanten in eine Neo4j Graphdatenbank hochgeladen. Der Architecture Analyzer wurde für das Entwickeln der Regelsätze erweitert. Die entdeckten Verletzungen für Abhängigkeiten zwischen Assemblies, ungenutzte MEF Exports und öffentliche Klassen, welche nur in der eigenen Assembly verwendet werden, wurden in einem tabellarischen Report bzw. in einem Graphen visualisiert. Ein Jupyter Notebook diente als Ausführungskette und führte die folgenden Aktionen durch: ?	Identifikation der C# Assemblies ?	Ausführen des Architecture Analyzers ?	Ausführen der Regelsatz Abfragen ?	Aufbereitung und Überprüfung der Treffer ?	Visualisierung der Ergebnisse in einem Report und in einem Graphen "
10.09.18	2018	intern	Bachelor	DE	Rust und Go im Vergleich	Sowohl Rust als auch Go sind relativ junge und populäre Programmiersprachen, die als Alternativen für C und C++ entwickelt wurden und ihren Fokus auf systemnahe Entwicklung legen. Go zielt auf Einfachheit und hohe Effektivität ab, dagegen fokussiert sich Rust auf Schnelligkeit, Sicherheit und Nebenläufigkeit. In dieser Arbeit werden die Go und Rust miteinander verglichen. Hierfür werden die vergleichbaren Features der Programmiersprachen gegenübergestellt, um inhaltliche und konzeptionelle Unterschiede herauszuarbeiten. Anschließend werden einige Testfälle in beiden Programmiersprachen ausgewählt und weitestgehend äquivalent implementiert, um eine Performanceanalyse, die aus Laufzeitanalyse und Speichernutzungsanalyse bestehen, durchzuführen. Die hierdurch empirisch ermittelnden Daten werden dargestellt und Unterschiede zwischen den Sprachen erläutert. Die Ergebnisse zeigen, dass Rust mit der Compiler-Optimierung die effizienteste Sprache für die vorliegende Herausforderung ist.
12.09.18	2018	intern	Bachelor	DE	Graphische Netzwerkvisualisierung einer Game Design Pattern Language und quantitativer Vergleich mit der Pattern Language des EMPAMOS-Projektes	Ziel der Arbeit ist der vorwiegend quantitative Vergleich der bislang fremden Game Design Pattern Language (PL) von Staffan Björk mit der PL aus dem Forschungsprojekt EMPAMOS der TH Nürnberg. Auf diese Weise soll herausgearbeitet werden, wo strukturelle Gemeinsamkeiten oder Unterschiede bestehen und an welchen Stellen ein inhaltlicher Vergleich der Mustersprachen sinnvoll wäre. Dafür müssen die Daten von Björks PL extrahiert werden und eine Netzwerkvisualisierung soll deren Inhalte übersichtlicher darstellen. Der theoretische Teil der Arbeit befasst sich mit den Themengebieten der Game Design PL sowie der Netzwerkanalysen. Im praktischen Teil der Arbeit wurde mit Python und Scrapy ein Webcrawler entwickelt, der die Inhalte von Björks PL extrahiert. Anschließend wurde die Netzwerkvisualisierung mittels Cytoscape.js durchgeführt und die Daten aus beiden Pattern Languages wurden mit Gephi und Python-NetworkX analysiert und verglichen. Zentrale Erkenntnisse aus den Analyseergebnissen sind unter anderem, dass die PL aus dem EMPAMOS-Projekt trotz geringerer Größe auf eine höhere Evidenzbasis zurückgreifen kann und ihr Netzwerk sehr viel stärker vernetzt ist. Das Netzwerk der um einiges älteren PL von Björk ist stark zentralisiert, besitzt also wenige zentrale Patterns und viele Außenseiter. Eine Clusteranalyse von Björks PL zeigt abschließend, trotz unterschiedlicher Evidenzbasis, einige Patterns auf, die sich für einen inhaltlichen Vergleich mit den Patterns der EMPAMOS PL eignen.
13.09.18	2018	intern	Bachelor	DE	Implementierung einer plattformunabhängigen Pipeline zwischen den Robotern "Pepper" sowie "NAO" und Software zur Objekterkennung.	Im Rahmen dieser Bachelorarbeit wird dem Roboter Pepper die Fähigkeit gegeben, durch rein mündliche Bedienung Objekte und deren Position zu erkennen und zu erlernen. Durch manuellen Einsatz von zusätzlicher Software ist es Pepper bereits möglich konkrete Objekte zu erlernen und anschließend wiederzuerkennen. Allerdings kann dabei immer nur das konkrete Objekt wiedererkannt werden. Das Hauptziel dieser Arbeit ist es, den Lernprozess vollständig zu automatisieren, sodass Pepper durch mündliche Interaktion Objekte erlernen und erkennen kann. Dabei können Objekte derselben Art zusammengefasst werden. Hierzu wird ein, auf dem Deep Learning-Ansatz [2] basierendes Objekterkennungs-system eingesetzt; Faster RCNN [3], ein tiefes neuronales Netzwerk, welches eine robuste Objekterkennung ermöglicht. Da Pepper nicht leistungsstark genug ist, um dieses System in hoher Geschwindigkeit auszuführen, wird dieses als eigenständiges Programm implementiert, welches durch eine REST-Schnittstelle angesprochen werden kann. Als Ergebnis soll eine plattformunabhängige Softwarelösung entstehen. Dadurch wird Pepper ermöglicht hunderte verschiedene Objekte zu erlernen und zu erkennen.
13.09.18	2018	extern	Bachelor	DE	Implementierung eines Management-Dashboards bei einer Direktbank zur Visualisierung von Unternehmenskennzahlen in Echtzeit	Um dem Top-Management der Consorsbank einen aktuellen Einblick in die operativen Systeme und die wichtigsten Bereiche des Geschäfts zu ermöglichen, ist die Anforderung des Chief Data Officer, ein Kennzahlendashboard für die neue Management Area bereitzustellen. Mittels der Software TIBCO Spotfire sollen verschiedene Metriken der Produkteröffnungsprozesse, der Besucheranzahl auf den Plattformen, der Auslastung des Kundendialogs sowie des Tradings in diversen Diagrammen dargestellt und mit historischen Werten verglichen werden. Hierfür ist es notwendig, Daten aus verschiedenen Quellen wie dem Data Warehouse und den operativen Systemen mithilfe des ETL-Prozesses anzubinden. Die einzelnen Phasen dieses Prozesses gestalten sich je nach Integrationsweise unterschiedlich und erfordern verschiedene Softwarelösungen. Zusätzlich wird das Projekt einer kaufmännischen Betrachtung unterzogen. Es wird im Nachgang eine Total-Cost-of-Ownership-Analyse durchgeführt, um die angefallenen und noch anfallenden Kosten des Vorhabens zu beziffern.
14.09.18	2018	intern	Bachelor	DE	Automatisierte Bestimmung einer Zuordnung von Benutzerkennungen zu SQL-Queries in Webanwendungen	Ein weit verbreiteter Typ von Sicherheitslücken in Webanwendungen sind Broken Access Controls (OWASP Top10: A5-20017): Zugriffsbeschränkungen für authentisierte Benutzer werden nicht richtig durchgesetzt. Eine externe Security-Appliance nach [PrGrTr2013], die einen Reverse-HTTP-Proxy zwischen Browser und Webanwendung sowie einen SQL-Proxy zwischen Webanwendung und Datenbank einsetzt, könnte eine bestehende, fehlerhafte Webanwendung gegen solche Angriffe absichern, ohne dass Änderungen am Quelltext vorgenommen werden müssen. Ziel dieser Arbeit ist dazu die Entwicklung einer sogenannten "Mapping Engine" zur automatisierten Zuordnung der Benutzerkennung desjenigen Benutzers, der ursprünglich einen HTTP-Request an die Webanwendung gestellt hatte, zu der in Folge durch die Webanwendung ausgelösten SQL-Query. Es soll keine manuelle Konfiguration der Mapping-Engine erforderlich sein.
20.09.18	2018	extern	Bachelor	DE	Evaluierung der Möglichkeiten und Herausforderungen von automatisierten Performancetests auf Kundensystemen der DATEV eG	Performance-Kennzahlen, die die Programmdurchlaufzeiten darstellen, sind für einen Softwarehersteller wie der DATEV eG entwicklungsseitig relevant, da sie ein Gradmesser für die potentielle Kundenzufriedenheit sind. Das zentrale Performancemesstool ?GKPer-fTool?, das im Sinne einer Testautomatisierung einen Use-Case simuliert, wird derzeit bei der DATEV eG intern für entwicklungsbegleitende Qualitätssicherungsmaßnahmen ge-nutzt. Im Rahmen dieser Arbeit werden die Möglichkeiten einer automatisierten Performance-messung auf Kundensystemen der DATEV eG genauer untersucht. Außerdem werden Herausforderungen, die bei einer Umsetzung entstehen, geprüft und Lösungsmöglichkeiten evaluiert. Abschließend wird, aufgrund der Gegenüberstellung von Herausforderungen und Möglichkeiten, eine Handlungsempfehlung aufgezeigt. Für die Untersuchung gelten die Rahmenbedingungen des bestehenden Performancemesstools ?GKPerfTool?.
01.10.18	2019	extern	Bachelor	DE	Testautomatisierung für Workflows am Beispiel des Workflow-Management-Systems JobRouter	Diese Arbeit befasst sich mit der Testautomatisierung von Workflows und richtet sich an Workflow-Designer und Workflow-Tester, die mit webbasierten Work-flow-Management-Systemen arbeiten. Anhand der Perspektiven eines Workflows werden die Anforderungen an das automatisierte Testen von Workflows herausgearbeitet und in einem praktischen Beispiel angewendet. Es wird ein Weg gezeigt, wie ein automatisierter Workflow-Test für ein webbasiertes Workflow-Management-System programmiert werden kann. Für den Test wird ein Workflow gewählt, der ein Rollenkonzept, Parallelisierun-gen, Benutzer-, wie auch Systemaktivitäten enthält. Das genutzte Workflow-Management-System für dieses Beispiel ist JobRouter. Für die Testimplementie-rung werden neben Selenium WebDriver in der Programmiersprache C# die Frameworks NUnit für das Testmanagement und Extent Reporting für die graphi-sche Aufbereitung der Testergebnisse genutzt. Das entstandene prototypische Testkonzept mit Open Source Mitteln kann auf andere webbasierte Workflow-Management-Systeme übertragen werden, solange diese einen clientseitigen Zugriff auf Workflow-Variablen und -Informationen erlauben. Das entwickelte Testkonzept ermöglicht ein vollständiges Testen des Kontrollflusses und Rollenkonzepts des Workflows. Die Integration des Daten-flusses, die Beurteilung kostenpflichtiger Testwerkzeuge und deren Vergleich mit Selenium WebDriver können Themen für weitere Arbeiten darstellen.
01.10.18	2019	extern	Bachelor	DE	Konzeption und Ausarbeitung eines Prototyps zum Austausch betrieblicher Regelungen in der N-ERGIE AG.	Diese Arbeit behandelt eine Problemstellung im Auftrag der N-ERGIE AG Personalabteilung. Betrachtet wird der Informationstransfer betrieblicher Regelungen, welcher durch die Personalabteilung verantwortet wird. Ziel ist ein schneller, einfacher und auf den Mitarbeiter positiv wirkender Informationstransfer. Erzielt wird dies, indem die betrieblichen Regelungen nach Zielgruppen unterteilt und in eine klare Struktur aufgearbeitet sind. Dabei wird die Ansammlung von Betriebsvereinbarungen und der hohe personelle Aufwand zur Kommunikation gelöst. Der Personalabteilung ist es wichtig, dass die Mitarbeiter Kenntnis über die Regelungen haben, diese schnell verstehen und anwenden können. Im Rahmen leitfadengestützter Interviews, wird Aufschluss darüber gegeben, welche Potenziale in der Kommunikation erreicht werden können. Zudem wird die Ist Situation festgehalten. Befragt werden zwei konträre Zielgruppen, wobei die Unterschiede in den jeweils zu vermittelnden betrieblichen Regelungen liegen. Aus den Ergebnissen der Interviews, erschließt sich, dass die Ausgangssituation nicht zielführend ist. Zur Problemlösung wird ein Konzept ausgearbeitet. Dieses wird zur visuellen Darstellung in Form eines interaktiven Prototyps realisiert. Aus einer qualitativen Inhaltsanalyse gehen die Anforderungen hervor. Sie werden in User Stories abgeleitet und dienen als Input für die Erstellung des Konzepts.
01.10.18	2019	extern	Bachelor	DE	Geolocation im Transformator-Werk der Siemens AG: Kosten-Nutzen-Analyse zur Verbesserung des Materialflusses	Bei der Produktion der Großtransformatoren besteht das Problem darin, dass durch unzureichende Kennzeichnung von einzelnen Teilen das Material häufig nicht aufgefunden werden kann oder gar verloren geht. Der Materialfluss im Werk erfolgt, je nach Materialgruppe (Fremd, Eigen, Isolierteile, Stahlteile, etc.) und verantwortlicher Organisation, in unterschiedlicher Form und dementsprechend variierender Ausprägung der Systemunterstützung. Eine durchgängige Steuerung und Lokalisierung von Einzelteilen über alle Materialgruppen hinweg entlang der Prozesskette ist nicht gegeben. Es entstehen lange und nicht-wertschöpfende Suchzeiten der Materialien. Dies kann wiederum zur Verzögerungen in der Produktion, Kapazitätsverschwendung, Non-Conformance-Costs und Kundenunzufriedenheit bei möglicher verspäteter Lieferung führen. Die Identifizierung und Reduzierung von diesen Verlusten ist somit eine Priorität für die Produktion, um Beeinträchtigungen zum Nachteil des Unternehmenserfolgs zu vermeiden. Das Kernergebnis dieser Arbeit ist es eine Basis für eine Geolocation-Technologie zu schaffen, damit alle Materialien und wesentlichen Fertigungshilfsmittel aufwandsarm identifizierbar und jederzeit auffindbar sind. Dadurch sollen die Suchaufwände verringert und ein reibungslosen Produktionsablauf sichergestellt werden.
01.10.18	2019	extern	Bachelor	DE	Prototypische Anbindung von Power BI an die DATEVconnect-Schnittstelle von Kanzlei-Rechnungswesen	Im Rahmen vorliegender Arbeit wird untersucht, inwieweit sich gesetzliche Auswertungen wie Bilanzen sowie Gewinn- und Verlustrechnungen in einem Business-Intelligence-Werkzeug (BI-Werkzeug) betriebswirtschaftlich korrekt gemäß der Gliederungsstruktur abbilden lassen. Dazu werden zunächst die wesentlichen Anforderungen an die korrekte Darstellung und Aufberei-tung gesetzlicher Auswertungen spezifiziert. Anschließend wird unter Berücksichtigung der zuvor beschriebenen Herausforderung ein ETL-Prozess (Extract, Transfer, Load) implementiert. Dieser basiert auf einem Python-Skript, welches die durch eine DATEV-interne Anwendung (DATEV Referenzsystem) bereits vorverarbeiteten Daten aus DATEV Kanzlei-Rechnungswesen, von einer normierten REST-Schnittstelle (DATEVconnect) abfragt und in eine Form überführt, die sich mit einem BI-Werkzeug verarbeiten lässt. Am Ende wird auf Ba-sis der durch den ETL-Prozess aufbereiteten Daten ein prototypischer Bericht mit dem BI-Werkzeug Microsoft Power BI erstellt, welcher der gesetzlichen Gliederungsstruktur von Bilanz sowie Gewinn- und Verlustrechnung entspricht und so die Grundlage für standardisierte Be-richte, interaktive Apps, Dashboards usw. bildet.
01.10.18	2019	intern	Bachelor	DE	Fusion und interaktive Visualisierung von Terraindaten am Beispiel Bayern	In dieser Arbeit werden Terraindaten des Bayerischen Landesamts für Digitalisierung, Breitband und Vermessung, des Advanced Spaceborne Thermal Emission and Reflection Radiometer sowie der Shuttle Radar Topography Mission im Gebiet von Bayern untersucht und auf Qualität, Verschiebungen und Höhendifferenzen relativ zueinander geprüft und bewertet. Mit den dadurch gewonnenen Erkenntnissen werden die Daten zu einem kombinierten Höhenmodell mit einer Auflösung von 1 m fusioniert, wobei fehlende Höhenwerte durch Interpolation berechnet werden. Anhand dieses Höhenmodells wird beschrieben, wie ein interaktiver Terrain Viewer erstellt werden kann. Darin wird das Terrain des Höhenmodells als dreidimensionale Karte visualisiert und kann frei und stufenlos vom Benutzer durch Überfliegen erkundet werden.
01.10.18	2019	extern	Bachelor	DE	Konzeption und Umsetzung einer multimodalen Mensch-Maschine-Schnittstelle für den Service von Produktionsmaschinen	Für den Service von Produktionsmaschinen stellt die Benutzerschnittstelle einen wesentlichen Bestandteil dar. Diese ist jedoch hauptsächlich auf den Produktionsbetrieb ausgerichtet und unterstützt den Menschen, bei der Instandhaltung, nur eingeschränkt. Abhilfe kann der Einsatz von natürlichen Interaktionskanälen schaffen und führt somit zu dem Einsatz einer multimodalen Mensch-Maschine-Schnittstelle. Das Ziel der Bachelorarbeit war die Untersuchung einer multimodalen Mensch-Maschine-Schnittstelle für den Service von Produktionsmaschinen. Hierzu sollte ein Konzept aufgestellt und anschließend ein Softwaredemonstrator umgesetzt werden. Anhand des Softwaredemonstrators sollte der Mehrwert sowie die Begeisterungs- und Akzeptanzkriterien evaluiert werden. Für die Untersuchung wurde die Ist-Situation eines charakteristischen Wartungsszenarios analysiert. Anschließend wurden auf Basis von identifizierten Optimierungspotenzialen die Anforderungen abgeleitet. Bezüglich der ermittelten Anforderungen wurde ein multimodales Konzept aufgestellt, das eine taktile, visuelle und auditive Modalität unterstützt. Dieser Entwurf diente als Grundlage für die Realisierung des Softwaredemonstrators. Der Softwaredemonstrator wurde im Rahmen einer Nutzerstudie mit 11 Probanden aus dem industriellen Umfeld evaluiert. Dabei konnte gezeigt werden, dass durch den Einsatz natürlicher Interaktionskanäle, ein Mehrwert geschaffen werden kann und dies eine hohe Akzeptanz bei den Probanden aufweist.
01.10.18	2019	intern	Bachelor	DE	Grafische Bedienoberfläche und funktionelle Erweiterung eines Programms zur Berechnung spieltheoretischer Funktionen	Die Arbeit beschäftigt sich mit der Weiterentwicklung eines Terminalprogramms zur Berechnung spieltheoretischer Funktionen. Hauptaufgabe dabei war es eine grafische Bedienoberfläche und somit eine neue Menüführung zu entwickeln. Dabei wurde besonders darauf geachtet, dass die zuvor implementierten Funktionen weiterhin funktionieren, sich die Benutzerfreundlichkeit erhöht und es für die Zukunft gute Änderungsmöglichkeiten gibt. Zudem wurde das Programm um die Berechnung des Holler-Packel-Index erweitert. Des Weiteren wurde eine Laufzeitabschätzung mit in die Anwendung implementiert, diese war zwar schon vorhanden, aber nur in Form eines eigenständigen Programms.
01.10.18	2019	extern	Bachelor	DE	Analyse von Produkten zur Qualitätssicherung - Klassifizierung und Lokalisierung von Produktteilen mittels bildverarbeitender Neuronaler Netzwerke im industriellen Umfeld 	In den letzten Jahren gewann das Forschungsgebiet der künstlichen neuronalen Netzwerke und der Bedarf an dynamischen und modularen Fertigungsanlagen im industriellen Umfeld eine immer größer werdende Bedeutung. Im Speziellen wurde in dieser Arbeit ein Prozess entwickelt, der den Einsatz von bildverarbeitenden neuronalen Netzwerken im Kontext einer modernen Forschungsanlage ermöglicht. Hierzu liefert diese Arbeit eine fundamentale Wissensbasis zum Umgang mit künstlichen neuronalen Netzwerken, deren Training und dem Transferieren von Wissen. Im speziellen wurde hierbei auf die CNN eingegangen und deren Möglichkeiten zur Objekterkennung. Um ein solches Netzwerk im industriellen Umfeld, speziell zur Qualitätskontrolle, einsetzen zu können wurden u. a. beschreibende Kriterien der bildverarbeitendes Qualitätssicherungssysten erläutert. Es erfolgte die Auswahl von Mask R-CNN unter mehreren state-of-the-art Netzwerken. Der entwickelte Prozess ermöglicht den Einsatz von CNNs in modernen Fertigungsanlagen. Mit den Kernpunkten AR zur Umgebungserfassung und des on-the-?y Datensatzgenerierung wurde die Daten Generierung gestaltet. Die Ergebnisse des eingesetzten Mask R-CNN waren äußerst zufriedenstellend.
01.10.18	2019	extern	Bachelor	DE	Agile Softwareoptionen im Outsourcing-Kontext beim IT-Systemhaus der Bundesagentur für Arbeit	Die vorliegende Bachelorarbeit, die in Kooperation mit dem IT-Systemhaus der Bundesagentur für Arbeit geschrieben wurde, beschreibt Konzepte für die Softwareentwicklung, den Betrieb sowie für die Zusammenarbeit der beiden Teams. Die Konzepte vereinen die Themen Agilität, externe Dienstleister wie auch verteilte Teams und versuchen, Lösungsansätze für all die Herausforderungen aufzuzeigen, die durch die unterschiedlichen und teils gegensätzlichen Themengebiete entstehen. Zu beachten ist, dass die Konzepte speziell für den Servicebereich BAS2 des IT-Systemhauses entworfen und die verwendeten agilen Methoden, konkret Scrum und Kanban, individuell auf die vorhandenen Gegebenheiten angepasst wurden. Die Übertragbarkeit dieser Konzepte auf andere Unternehmen ist somit ohne eine Anpassung wohl kaum möglich, jedoch können die Konzepte als Beispiel für die Verwendung von agilen Methoden unter den Geschichtspunkten des Einsatzes von externen Dienstleistern im Unternehmen und verteilten Teams im Sinne von verteilten Teammitgliedern dienen.
01.10.18	2019	intern	Bachelor	DE	Deep Learning im Browser	Der Fokus dieser Arbeit liegt auf der Evaluation von JavaScript Bibliotheken, deren Mechanismen auf Deep Learning, einer untergeordneten Art des Machine Learning, basieren und im Browser verwendet werden. Zu Beginn der Bachelorarbeit werden die Grundlagen zu Deep Learning, WebGL und den Bibliotheken TensorFlow.js, ConvNetJS und Brain.js vermittelt. Der Primärteil befasst sich mit der Umsetzung und Auswertung der genannten Bibliotheken in einer Anwendung, die durch die Verarbeitung von gezeichneten Ziffern die konkrete Ziffer ermitteln kann. In der anschließenden Evaluation werden die Trainingsgeschwindigkeit und -qualität der Modelle, die Auswirkungen der Verarbeitung auf die User Experience im Browser sowie die Ressourcenauslastung mit und ohne WebGL ausführlich gemessen und die Ergebnisse entsprechend erläutert. Durch die Evaluationsergebnisse ist das Trainieren der Modelle im Browser aufgrund einer hohen Auslastung und der daraus resultierenden Auswirkungen auf die User Experience nicht zu empfehlen. Trainierte Modelle sollten für die Nutzung im Browser über bereitgestellte Importfunktionen geladen werden. Grundsätzlich bietet TensorFlow.js - zusammen mit aktiver WebGL-Unterstützung - die besten Performanceergebnisse. Unabhängig von den Performanceauswirkungen entkoppelt Deep Learning im Browser jegliche Verarbeitung auf einem Server und kann, durch den Zugriff auf Web APIs, schnell und einfach vorhandene Eingabemedien auf jedem Endgerät mit einem Browser nutzen.
01.10.18	2019	extern	Bachelor	DE	Konzeption und Ausarbeitung der Prototyping-Phase im Innovationsprozess	Innerhalb der N-ERGIE IT GmbH erfolgt aktuell eine Umstrukturierung vom internen Dienstleister, welcher sich hauptsächlich um den Systembetrieb kümmert, hin zum Innovationstreiber, welcher die Geschäftsbereiche mit neuen digitalen Lösungen unterstützt. Ziel dieser Arbeit ist es, die allgemeinen Vorgaben zum Innovationsprozess in der N-ERGIE AG darzustellen und einen angepassten Innovationsprozess für die N-ERGIE IT GmbH zu entwickeln. Weiterhin soll eine Prototyping-Software, welche innerhalb der N-ERGIE IT GmbH für die Erstellung digitaler Prototypen als Standardsoftware verwendet wird, ausgewählt und in einer Beispielanwendung getestet werden. Die vorliegende Arbeit gibt zunächst einen Überblick über die theoretischen Grundlagen des Innovationsprozesses und spezifiziert nachfolgend die Konzernvorgabe bezüglich des Prozesses der N-ERGIE AG. Basierend auf dieser Rahmenvorgabe wird ein Innovationsprozess entwickelt, welcher speziell an die Anforderungen der N-ERGIE IT GmbH angepasst ist. Anschließend wird die Prototyping-Software für die N-ERGIE IT GmbH ausgewählt. Hierfür werden zuerst die Anforderungen an die Anwendung definiert. Mit dieser Software ist im Anschluss ein konkreter Prototyp umzusetzen. Das Ergebnis dieser Arbeit ist die Lean Spiral Methode als angepasster Innovationsprozess für die N-ERGIE IT GmbH. Im Auswahlprozess der Prototyping-Software wird mit Hilfe einer Nutzwertanalyse das Produkt "Axure RP" als Empfehlung festgelegt. Mit dieser Anwendung wird im Ans
01.10.18	2019	extern	Bachelor	DE	Analyse und graphische Aufbereitung von Logdaten und Server-Metriken mittels des Elastic Stacks zur Unterstützung von Managemententscheidungen	Durch die steigende Komplexität und Größe von Softwareapplikationen steigt gleichfalls die Menge an erzeugten Logdaten. Um einen Überblick über diese zu behalten, ist es häufig notwendig eine detaillierte Loganalyse durchzuführen. Daher wurden in dieser Arbeit Logdaten und Server-Metriken aus dem AnalyzeIT-Umfeld analysiert und graphisch aufbereitet, um die Entscheidungen des Managements zu unterstützen. Dazu wurden die Logdaten und Server-Metriken mit Hilfe des Elastic Stack gesammelt, aufbereitet und entsprechend visualisiert. Das bestehende Setup wurde durch Installation neuer Komponenten wie einem Metricbeat erweitert bzw. durch Modifikation der Konfigurationsdateien von Logstash angepasst. Nach der Aufbereitung wurden die gewonnenen Informationen in Elasticsearch gespeichert und konnten mit dem Visualisierungswerkzeug Kibana graphisch aufbereitet werden. Ergebnis dieses Prozesses ist ein Dashboard, bestehend aus speziell für die Bedürfnisse der Stakeholder angefertigten Visualisierungen. Dabei wurde auf die Auswahl geeigneter Visualisierungsformen geachtet. Das Dashboard ermöglicht dem Management einen schnellen Einblick in die Vorgänge und den Zustand der Applikation AnalyzeIT. Es ist fester Bestandteil des Entscheidungsprozesses. Zudem ist eine Erweiterung der Nutzung durch andere Applikationen geplant.
01.10.18	2019	extern	Bachelor	DE	Analyse, Konzeption und Implementierung einer Wissensmanagement-Lösung zur Sicherung und Weitergabe des Wissens 	Die Bachelorarbeit beschäftigt sich mit dem Thema Wissensmanagement bei WITRON Informatik & Logistik GmbH. Im genauen handelt es sich um die Analyse, Konzeption und Implementierung einer Wissensmanagement-Lösung zur Wissenssicherung und Wissensweitergabe. Der Handlungsbedarf ist dadurch gegeben, dass Projekterfahrungen mangelhaft erfasst und nicht zielgerichtet ausgetauscht werden. Diesbezüglich ist das Ziel die Auswahl, Gestaltung und Einführung einer Wissensmanagement-Lösung, mit deren Hilfe Projekterfahrungen effizienter erfasst, organisiert und zugänglich gemacht werden. Um das Ziel zu erreichen wurde zunächst eine Ist-Analyse durchgeführt. Hierbei haben sich bestimmte Optimierungspotentiale und deren Ursachen herausgestellt. Nach der anschließenden Ermittlung der Anforderungen an die Soll-Situation, konnten Optimierungsansätze zur Behebung der Schwachstellen ausgearbeitet werden. Für die Lösungsansätze, bestehend aus "Mikroschulungen", "Wissensbewahrung durch Dokumentation" und "Wissensbewahrung durch Unterstützung IuK-Technologie" erfolgte, soweit möglich, die Ausarbeitung eines Konzepts und die Einführung dieses im Unternehmen.
01.10.18	2019	extern	Master	DE	Entwicklung eines Vorhersagemodells für den Maintenance-Prozess mit Hilfe eines künstlichen neuronalen Netzes.	Künstliche Intelligenz hat in den letzten Jahren große Fortschritte gemacht. Mit Hilfe von Deep Learning können heute beispielsweise komplexe Muster in Daten erkannt werden. Dies kann unter anderem dazu verwendet werden Vorhersagen zu machen. Die Maintenance-Abteilung der \suse ist für die Instandhaltung der Produkte zuständig. Durch das Veröffentlichen von Updates für Softwarepakete werden Sicherheit und Stabilität der Produkte gewährleistet. Wie lange ein Update zur Veröffentlichung benötigt hängt dabei von vielen Faktoren ab wie beispielsweise dem Testaufwand. Durch die Vorhersage der Update-Dauer sollen wichtige sicherheitskritische Updates künftig schneller veröffentlicht werden können. Zu diesem Zweck wurden zwei künstliche neuronale Netze implementiert. Mit einem neuronalen Netz wird die Zeit in Tagen vorhergesagt. Ein zweites Netzwerk sagt die Zeit mittels Klassifikation vorher. Beide neuronalen Netzwerke erzielten keine exakten Vorhersagen und bieten somit keine Rechtfertigung für den Einsatz in der Maintenance-Abteilung. Die Ursache der Ungenauigkeiten der Vorhersage ist in den Daten zu finden. Dennoch konnte während der Trainingsphase ein Lernfortschritt erzielt werden. Diese Erkenntnis legt nahe, dass durch die Verwendung besserer Daten auch die Vorhersage verbessert werden kann.
01.10.18	2019	extern	Master	DE	Digitale Assistenten und Sprachdialogsysteme im Unternehmen - eine Analyse am Beispiel Amazon Echo mit Schwerpunkt Nutzung in der Qualitätssicherung	Im Rahmen der Arbeit wurde ein Prototyp für einen Alexa-Skill konzipiert und implementiert. Schwerpunkt bei der Entwicklung war es, möglichst kurze und einfache Dialoge mit Alexa zu bieten, um Informationen aus einer Datenbank zu Schadensfällen zu finden. Die Ergebnisse können dem Nutzer sowohl vorgelsesen werden, als auch in Textform auf ein kompatibles Gerät gesendet werden. Im Zuge dessen ist Alexa mit Konkurrenzprodukten verglichen worden, auf seine Tauglichkeit in verschiedenen Umgebungen getestet worden und es wurden verschiedene Möglichkeiten zu einer Implementierung betrachtet. Aus den gebotenen Alternativen wurden die am passendsten wirkenden gewählt und ein Skill entwickelt, der auf den Diensten von AWS aufbaut und in NodeJS geschrieben ist. Potentielle Schwierigkeiten bei der Erstellung eines Interaktionsschemas und beim Datenschutz wurden identifiziert und Lösungsmöglichkeiten vorgestellt. Für die Konzeption und Implementierung wurde ein empirisches Vorgehen gewählt, um eine möglichst zufriedenstellende Lösung zu erreichen. Die Qualität des Prototyps konnte nicht in einer Nutzerstudie getestet werden. Gründe dafür waren technische Probleme, die außerhalb des Einflusses des Projektteams lagen, sowie zeitliche Gründe um alternative Lösungen für eine Studie zu finden. Insgesamt konnten die meisten der Anforderungen zufriedenstellend erfüllt werden, besonders für Datenschutz und Zugriffskontrolle müsste Alexa for Business verwendet werden (in D noch nicht verfügbar).
02.10.18	2019	intern	Bachelor	DE	Interaktive Visualisierung des Netzwerkgraphen einer Pattern Language für Spiel-Design-Elemente	Das Forschungsprojekt EMPAMOS setzt sich mit motivierenden Spielelementen in Gesellschaftsspielen auseinander, die immer wieder in bestimmten Zusammenhängen und Kombinationen zum Einsatz kommen. Meine Arbeit beschäftigt sich mit der graphischen Aufbereitung dieser Spielelemente. Dabei wird die Frage verfolgt, welche Art der Darstellung und Interaktion dem Nutzer den effektivsten Einblick in die Spielelemente gibt. So stand im Mittelpunkt, den Zusammenhang zwischen den wissenschaftlichen Forschungsergebnissen und dem theoretischen Bereich der Gesellschaftsspiele zu verdeutlichen. Dazu wurde zunächst eine Stakeholder- und Zielgruppenanalyse durchgeführt und unter anderem das Spielearchiv befragt. Im Rahmen der Anforderungsermittlung konnten dann aus Personas und daraus resultierenden User-Stories Erwartungen an die Anwendung generiert werden. In der Phase der Anwendungskonzeption wurden dann die Anforderungen aller Stakeholder zusammengetragen und daraus eine graphische Benutzeroberfläche konzipiert. Die Forschungsergebnisse des EMPAMOS-Projektes wurden anschließend mit Hilfe von verschiedenen Frameworks in Form einer Netzwerkstruktur visualisiert und in die Anwendung integriert. Daraufhin konnte ein Prototype entwickelt werden, der per REST-Schnittstelle auf die Daten des Forschungsprojektes zugreift. Abschließend wurde die Anwendung per Usability-Test validiert, um Optimierungen für die nächste Iteration festzuhalten und im letzten Schritt auf einem Tablet installiert.
04.10.18	2019	extern	Bachelor	DE	Untersuchung und Bewertung von Anwendungsfällen im Bereich Augmented Reality zur Unterstützung der Fahrzeugdiagnose und beispielhafte prototypische Implementierung 	Bei der Fahrzeugdiagnose werden mithilfe von Softwarewerkzeugen u.a. Prüfabläufe erstellt, validiert und schließlich ausgeführt. Diese unterstützen den Werker bei der Ausführung verschiedener Arbeitsschritte z. B. durch An-zeige von relevanten Informationen. Geeignete Augmented Reality Brillen könnten den Arbeitsprozess des Werkers unterstützen, indem sie die Mensch-Maschinen-Interaktion erleichtern. Durch die integrierten Kameras und inno-vativen Projektionsmöglichkeiten ist ein Zugriff auf benötigte Informationen möglich, ohne den aktuellen Arbeitsfluss zu unterbrechen. Als Beispiel für ein Fahrzeugdiagnose-Werkzeug wird das SIEMENS Produkt SIDIS Pro verwendet. Im Kontext von SIDIS Pro werden sinnvolle Unterstüt-zungsmöglichkeiten für die Werker ermittelt, ausführlich betrachtet und bewer-tet. Für eine industrietaugliche Augmented Reality Brille wird das relevanteste Anwendungsszenario prototypisch umgesetzt.
09.10.18	2019	extern	Bachelor	DE	Konzeption und Realisierung eines Dashboards für Reiseveranstalter	"Das Ziel der vorliegenden Bachelorarbeit ist es, ein Dashboard auf Basis des Reservierungssystems eines Reiseveranstalters zu konzipieren und realisieren. Die Problemstellung besteht darin, dass die Vorgangsdatensätze für das Controlling über eine Schnittstelle exportiert und die Daten dabei komprimiert werden, sodass das Controlling auf der Ebene einer Reise mit allen Reisedetails nicht mehr möglich ist. Das Ziel des Dashboards ist es, eine kaufmännische Auswertung der operativen Daten unter Einbezug aller Details möglich zu machen. Dabei standen die drei zentralen Fragen im Vordergrund: ?	Welche kaufmännischen Kennzahlen gibt es bei Reiseveranstaltern und welche sind relevant? ?	Wie können diese Kennzahlen technisch in ein Dashboard eingebunden werden? ?	Wie erstellt man konzeptionell und visuell ein praktikables Dashboard? Die Kennzahlen wurden in der Konzeptionsphase gefunden und betrachtet. Es wurde die Frage bezüglich der Umsetzung in der Realisationsphase beantwortet. Die Grundstruktur des Dashboards wurde im Konzeptionskapitel dargelegt und die visuelle Gestaltung im Realisationskapitel abgehandelt. Es wurde ein praktikables Dashboard erstellt, das ein Vertriebsprototyp ist und kein fertiges Produkt repräsentiert. "
10.10.18	2019	extern	Bachelor	DE	Konzeption und Implementierung eines Prozessablaufes für die Einführung und Migration einer ERP-Software bei kleinen und mittelständischen Unternehmen	Die Vepos GmbH \& Co. KG ist ein ERP-Anbieter für den Handel, das Projektmanagement und den Service. Bei der Einführung eines ERP-Systems in kleinen und mittleren Unternehmen wird im Vorfeld ein Analyse-Workshop durchgeführt, in dem die Soll-Prozesse des Kunden und eventuell nötige Anpassungen an der Software aufgenommen werden. Ziel dieser Arbeit ist es, Software-Referenzmodelle zu entwickeln, anhand derer Abweichungen vom Standard dokumentiert werden können. Eine Prozessaufnahme soll durch die Veranschaulichung mittels BPMN-Modellen und eine Darstellung in Excel erleichtert werden. Abweichungen vom Standard werden festgehalten und dem Kunden zur Verfügung gestellt. Diese Dokumentation dient im weiteren Verlauf als Grundlage für kundenspezifische Tests bei Updates und dazu passende Schulungen. Hierzu wurden die Standardprozesse der Software ermittelt und als Referenzmodelle mit begleitender Excel-Tabelle erfasst. Im Rahmen eines prototypischen Workshops bei einem Bestandskunden wurde das neue Konzept getestet und anschließend die Ergebnisse evaluiert.
10.10.18	2019	intern	Bachelor	DE	Durchführung von und Schutz vor Angriffen auf das YOLO Objekterkennungssystem mit einem Trojan Trigger	Diese Bachelorarbeit befasst sich mit dem Thema der Durchführung eines Angriffs auf ein Objekterkennungssystem und des Erstellens eines Schutzes gegen derartige Angriffe. Nach der Schilderung der Problemstellung, der Vorstellung der Motivation und der Zielsetzung sowie der Präsentation der Vorgehensweise und der Ergebnisse wird ein kurzer Überblick über die Grundlagen der neuronalen Netze vorgestellt. Anschließend werden das YOLO Objekterkennungssystem sowie der Trojan Trigger vorgestellt und ausführlich beschrieben. Nach der Präsentation Anforderungen wird eine Einführung in die Entwicklung eines Entwurfs des Angriffs sowie in die Analyse der möglichen Schutzvorkehrungen gegeben. Zudem wird auf die Analyse der Entwicklungsrisiken, die Inbetriebnahme des YOLO Objekterkennungssystem, die Beschreibung der Anforderungen und der Bestandteile des Angriffs sowie die Erarbeitung der Abwehrmethoden näher eingegangen. Danach werden die Phasen der Angriffsdurchführung und die Implementierung des Schutzprogramms ausführlich erklärt. Anschließend werden die Implementierung eines entsprechenden Schutzes und die Anwendung der Abwehrmethode beschrieben. Hiernach wird die Durchführung der Tests geschildert und analysiert. Abschließend wird aus der Analyse der Ergebnisse ein Fazit gezogen, wobei eine persönliche Bewertung abgegeben und ein Ausblick präsentiert werden.
10.10.18	2019	extern	Bachelor	DE	Analyse und Weiterentwicklung von Metriken der Softwarequalität bei der Schema Gruppe	In dieser Arbeit werden nach der Identifikation und Analyse vorhandener Metriken der Schema Gruppe zur Softwarequalität, weitere Metriken hinsichtlich der bekannten Problemfelder ermittelt. Da zum Zeitpunkt der Bearbeitung eine Auswertung der Codemetriken nicht möglich war und an erster Stelle Produktmetriken ermittelt werden sollen, wurde der Fokus auf Fehler- sowie Testmetriken gesetzt. Die Ermittlung der Metriken erfolgt anhand der Top-down und Bottom-Up Ansätze. Beim Top-Down Ansatz wird die Literatur als Hilfestellung hergenommen. Anfangs werden hierzu Ziele in Bezug zur Softwarequalität formuliert. Da nicht alle Ziele analysiert werden können, und die vorhandenen Metriken sich weitestgehend auf die Zuverlässigkeit beziehen wurde der Fokus auf das Ziel der Verbesserung der Zuverlässigkeit gesetzt. Ausgesehen von diesem Ziel werden Fragestellungen abgeleitet und mit Metriken in Verbindung gesetzt. Da für die ermittelten Metriken kein Datenbestand vorliegt, wird das weitere Vorgehen mit dem Bottom-Up Ansatz ergänzt. Dazu werden anhand des vorliegenden Datenbestandes Annahmen getroffen und eine Datenauswertung durchgeführt. Die Auswertung des Datenbestandes ermöglicht es neue Metriken zu ermitteln, die zuvor durch die Top-Down Methode nicht in Betracht gezogen bzw. abgeleitet wurden. Insgesamt konnten durch beide Ansätze neue Erkenntnisse und Metriken generiert werden.
10.10.18	2019	intern	Bachelor	DE	Entwicklung und Bewertung von automatisierten Unit-Tests im SAP-Umfeld der Dematic GmbH	Das Ziel dieser Arbeit ist es zu ermitteln, ob sich eine Einführung von Testautomatisierung im Bereich der Unit-Tests in der SAP-Abteilung der Dematic GmbH effizienter und zugleich effektiver auf den Testprozess auswirken könnte. Dabei stellen sich Fragen wie, welchen Anforderungen müssen die zu testenden Objekte entsprechen um mithilfe der Unit-Tests prüfbar zu sein, was für Kosten treten durch den aufkommenden Aufwand in der Testerstellung und -durchführung auf sowie ob ein Mehrwert durch eine Testautomatisierung erreichbar ist. Um auf all diese Fragen eine entsprechende Antwort zu bekommen, wurde eine Kosten-Nutzen-Analyse durchgeführt, die durch das Gegenüberstellen des IST-Zustands zum gewünschten SOLL-Zustand eine repräsentative Rückmeldung wiedergibt. Dabei konnte das Ergebnis ermittelt werden, dass eine Testautomatisierung von Unit-Tests einige Vorteile mit sich bringt. Außerdem ist aufgrund der Bewertung erkennbar, dass ab einer geringen Anzahl von Testdurchführungen die Kosten bei den Unit-Tests geringer ausfallen, als bei der manuellen Testdurchführung. Beachtet werden muss nur, dass dies nicht für alle zu testenden Objekte gilt und bestimmte Gegebenheiten herrschen müssen, um Unit-Tests realisieren und automatisieren zu können. Zusammenfassend ergab sich das Ergebnis, dass eine Testdurchführung mittels der Test-Tools und den Frameworks empfehlenswert ist. Dies lässt sich durch die gewonnenen Erkenntnisse, Vorteile sowie der möglichen Kosteneinsparung begründen.
11.10.18	2019	extern	Bachelor	DE	Zukunft des Berechtigungsmanagements der DATEV eG mit Fokus auf der Ermöglichung von agilem Arbeiten	Zukünftig plant die DATEV eG verstärkt auf agile Methoden zu setzen. Für die Zentrale Rechteverwaltung im Unternehmen stellt diese sukzessive Umstellung vor allem für die Elemente des Berechtigungsmanagement, Rechteprüfung und Rechteverwaltung eine Herausforderung dar. Die Anwendung von agilen Methoden, hat Auswirkungen auf bestehende Organisationsstrukturen und somit auf die damit verbundenen Verantwortlichkeiten. Nach aktuell praktizierten Verfahrensweisen müssen die Mitarbeiter ihre Berechtigungen über den, von der Zentralen Rechteverwaltung angebotenen Selfservice des Rechtestammblatts bestätigen. Abschließend muss die Führungskraft die bestätigten Rechte für seine Mitarbeiter zertifizieren. Diese Führungskraft kann ebenfalls die bestehenden Berechtigungen seiner Mitarbeiter verwalten. Ursprünglich lag die fachliche und disziplinarische Verantwortung bei der Führungskraft, die die Rechte zertifizieren und verwalten konnte. Bei der Anwendung von agilen Methoden verliert die Führungskraft die inhaltliche und fachliche Führung. Diese Führung steht im engen Zusammenhang zu Berechtigungen. Die Beurteilung von Berechtigungen durch die Führungskraft, wird daher erschwert. In dieser Arbeit werden Lösungsansätze vorgestellt, welche eine sinnvolle Rechteprüfung und -verwaltung beim agilen Arbeiten ermöglichen sollen. Die Lösungsansätze werden anhand einer Nutzwertanalyse gegenübergestellt und die daraus erlangten Erkenntnisse zu einem Soll-Konzept zusammengefasst.
11.10.18	2019	extern	Bachelor	DE	Konzeption und prototypische Realisierung eines Kennzahlensystems für das Prozessmanagement eines IT-Dienstleisters in der Bankenbranche	Partnerunternehmen ist der zentrale IT-Dienstleister der Sparda-Banken, die Sparda-Datenverarbeitung eG (SDV-IT). Das Thema der Arbeit ist unternehmensintern im Vorstandsstab angesiedelt. Zu den Hauptschwerpunkten dieser Stabstelle gehört unteranderem das unternehmensweite Prozessmanagement. Um die darin verankerte Steuerung und Kontrolle der Prozesse vorzunehmen, bedarf es funktionierender Reporting-Mechanismen. Jedoch sind in der SDV-IT verwendeten Verfahren des Prozesscontrollings sehr schwerfällig, da lediglich individuell von Fachbereichen sporadisch Auswertungen vorgenommen werden. Zielsetzung der Arbeit ist es, ein zentrales Kennzahlensystem einzuführen, welches möglichst standardisierte und automatisierte Reporting-Verfahren nutzt, um aussagekräftige Prozesskennzahlen zu erheben.
12.10.18	2019	intern	Bachelor	DE	Agile Transformation - Outsourcing agiler Projektarbeit und dessen Einfluss auf das klassische Projektmanagement	Agile Transformation - Outsourcing agiler Projektarbeit und dessen Einfluss auf das klassische Projektmanagement In dieser Abschlussarbeit wird sich mit dem Vergleich zwischen klassischem und agilem Vorgehen in einem Outsourcing auseinandergesetzt. Eine neue Zeit mit neuen Anforderungen und Herausforderungen erfordert neue Herangehensweisen an bekannte Systeme. Daher werden zunächst die die Ausgangssituation erläutert sowie die agilen und die klassischen Modelle vorgestellt. Im Folgenden werden agile und klassische Ansätze verglichen, wobei Unterschiede sowie Vor- und Nachteile herausgearbeitet werden. Im Kern der Arbeit geht es darum zu identifizieren, ob ein agiles Vorgehen bei Outsourcing, Vorteile gegenüber einem klassischen Vorgehen bietet. Hierbei wird geklärt welche Outsourcingarten bei einem agilen Vorgehen praktikabel sind, inwiefern die agilen Werte Einfluss auf das Projekt haben und wie solche Projekte organisiert werden. Ebenfalls wird erläutert, welche Motive für ein agiles Outsourcing sprechen können und wie bei größeren Projekten vorzugehen ist. Des Weiteren werden Empfehlungen für eine Strategiegestaltung, Providermanagement, Changemanagement und andere wichtige Faktoren besprochen. Zuletzt wird auf die Auswirkungen von Agilität und Outsourcing auf das klassische Projektmanagement eingegangen.
15.10.18	2019	intern	Master	DE	Unauffällige Anonymisierung von Gesichtern in Bildern mit "Generative Adversarial Networks"	Die stetig voranschreitende Speicherung und Auswertung digitaler Bilder stellt für die Privatsphäre jedes Einzelnen eine immer größere Bedrohung da. Bisherige Technologien zur Anonymisierung von Gesichtern sind entweder nicht mehr effektiv oder führen zu starken Veränderungen der ursprünglichen Aufnahmen. Durch den Einsatz von "Generative Adversarial Networks" zur Anonymisierung von Gesichtern sind hingegen Techniken umsetzbar, die eine unauffällige Anonymisierung erlauben. Es werden zwei Konzepte zur Umsetzung dieser erarbeitet. Ein bestehendes Gesicht wird dabei entweder in eine anonymisierte Fassung transformiert oder durch ein künstliches Gesicht ersetzt. Bei der Anwendung dieser beiden Konzepte auf ausgewählte Stichproben wird die Identifizierung einer Person merklich erschwert und meist unmöglich gemacht. Die erfolgte Manipulation der Gesichter bleibt im Vergleich zu bisherigen Techniken weitgehend verborgen. Dabei noch bestehende Herausforderungen und zukünftige Lösungsmöglichkeiten werden abschließend diskutiert.
15.10.18	2019	intern	Bachelor	DE	Evaluierung der Microsoft Azure Cloud Services im Kontext von Lehre, Forschung und Hochschulmanagement an der Technischen Hochschule Nürnberg	Ziel der vorliegenden Bachelorarbeit war es zu untersuchen, welche datenschutzrechtlichen Herausforderungen der Einsatz von Cloud Services in den Bereichen Lehre, Forschung und Hochschulmanagement mit sich bringt, welche Maßnahmen notwendig sind, um Azure Cloud Services an einer Hochschule einzuführen und welche Cloud Services das IT-Serviceportfolio der Technischen Hochschule Nürnberg sinnvoll ergänzen können und sich gut für ein Pilotprojekt eignen. Das Ergebnis der Arbeit ist eine Verfahrensbeschreibung über den Bezug von Azure Cloud Services über den Deutschen Forschungsnetz-Verein. Darüber hinaus wird beschrieben, welche kontextabhängigen Maßnahmen für den Einsatz von Cloud Services im Bereich Lehre, Forschung und Hochschulmanagement durchgeführt werden müssen. Im Rahmen von Interviews und Workshops mit Professoren der Technischen Hochschule Nürnberg wurden mehrere User Stories für mögliche Einsatzgebiete der Cloud Services erarbeitet, aus welchen zwei für die Umsetzung in einem Pilotprojekt ausgewählt wurden. Abschließend werden die vorbereitenden Schritte zur Umsetzung der Services innerhalb des Pilotprojekts skizziert. Die Arbeit ist für alle diejenigen interessant, die Cloud Services in Hochschulen oder Universitäten etablieren möchten.
15.10.18	2019	intern	Bachelor	DE	Requirement Engineering für den Einsatz eines CRM Systems für die Hochschulbeziehungen zu kooperierenden Unternehmen und Alumni an der Fakultät Informatik und prototypische Umsetzung anhand einer geeigneten Software.	Das Ziel dieser Arbeit ist die Identifizierung und Optimierung von Customer- Relationship-Management-Aktivitäten zur Beziehungspflege mit Unternehmenskooperationen und Alumni an der Fakultät Informatik. Dazu erfolgen eine Ermittlung und Analyse der Anforderungen für ein mögliches Customer-Relationship-Management-System, welches hierfür zum Einsatz kommen soll. Im Rahmen eines Requirements Engineerings werden die bestehenden CRM-Tätigkeiten analysiert und zusammen mit den Stakeholdern bewertet, um daraus Produktanforderungen für das geplante System abzuleiten. Die Ermittelten und dokumentierten Anforderungen werden im Anschluss in einem CRM-System prototypisch umgesetzt.
15.10.18	2019	extern	Master	DE	CNN-basierte Objekterkennung in Echzeit mit einem Smartphone	Inhalt der Arbeit ist die Analyse von CNN-basierten Applikationen sowie die Implementierung eines Prototyps zur Objekterkennung in Echtzeit. Der Prototyp wird umfassend hinsichtlich notwendiger Komponenten, Funktionsweise und Umsetzung beschrieben. Er wird für die Plattform Android entwickelt und verwendet das Framework TensorFlow Lite, sowie ein vortrainiertes Modell basierend auf dem Single Shot MultiBox Detector (SSD) Algorithmus. Ziel ist eine Anwendung, die Objekte in Echtzeit erkennt und entsprechend mit einem Label und einem Rahmen markiert. Darüber hinaus werden bestehende kommerzielle Anwendungen untersucht und mit den Ergebnissen des Prototyps verglichen. In Kapitel 2 wird die Geschichte der Objekterkennung beschrieben und Herausforderungen, sowie wichtige Zusammenhänge der CNN-basierten Objekterkennung erläutert. Kapitel 3 beschäftigt sich mit der umfassenden Beschreibung der Funktionsweise neuronaler Netze und zeigt die wichtigsten Algorithmen zur Objektlokalisierung im Überblick. Kapitel 4 befasst sich mit Anforderungen an Smartphones, Herausforderungen der Applikationen und gibt einen Überblick über geeignete CNN-basierte Modelle für Smartphones. In Kapitel 5 werden bestehende Applikationen für die Plattformen Android und iOS getestet und mit dem in Kapitel 6 entwickelten Prototyp verglichen. Ein abschließendes Fazit gibt einen Überblick über die erzielten Ergebnisse und gibt einen Ausblick auf weitere Implementierungsmöglichkeiten.
16.10.18	2019	intern	Bachelor	DE	Identifikation und Evaluation von relevanten Parametern bei der Fortbewegung in einer virtuellen Umgebung	In einer Benutzerstudie soll eine realistische und angenehme Fortbewegung in VR untersucht werden und welchen Einfluss zuvor definierte Parameter wie z. B. Schrittlänge, Laufge-schwindigkeit oder Winkeltreue zwischen Blick- und Laufrichtung darauf haben. Das Ziel dieser Arbeit ist die Identifikation und Evaluation von relevanten Parametern bei der Fortbewegung in einer virtuellen Umgebung. Hierbei wird sich auf die gewohnte Fortbewegungsart des Menschen ? das Laufen ? als auch auf die Verwendung von Hilfsmitteln wie Controller beschränkt. Die gewonnenen Ergebnisse aus der Benutzerstudie sollen unterstützend eine Aussage darüber treffen, welche Fortbewegungsmethode den besten Kompromiss aus geistiger, körperlicher und zeitlicher Anforderung für den Benutzer bietet. Die Messergebnisse zeigen, dass die Fortbewegungsart ausschließlich mittels Controller effizienter als der Einsatz einer Tretmühle ist. Hingegen liefert die Kombination von einem Controller und einer Tretmühle sowohl bei der Testlaufzeit, der Laufgeschwindigkeit als auch bei den Bewertungen durch die Probanden die besten Ergebnisse. Somit stellt diese nicht-natürliche Fortbewegungsart den besten Kompromiss aus den gewählten Anforderungen gegenüber der semi-natürlichen Fortbewegungsart mit der Tretmühle dar.
19.10.18	2019	extern	Bachelor	DE	Konzeption und Entwicklung einer generischen Leerbehälterverwaltung für SAP-EWM-Systeme	In den meisten Softwareprojekten, die mit SAP-EWM realisiert werden, spielt der automatische Materialfluss (MFS) innerhalb eines Lagers eine zentrale Rolle. Ein Teilbereich des MFS behandelt die Verwaltung von leeren Transporteinheiten. Da leere Transporteinheiten über das Lager verteilt benötigt werden, ist Aufwand an Zeit und Ressourcen notwendig, um auftretende Bedarfe optimiert auszugleichen. Derzeit werden diese Anforderungen in projektspezifischen Lösungen umgesetzt. Das Ziel dieser Abschlussarbeit ist es, eine Leerbehälterverwaltung zu entwickeln, die generische Schnittstellen aufweist und sich so als eigenes SAP-Modul für verschiedene Lagerkonstellationen verwenden lässt. Über die implementierten Schnittstellen soll die Möglichkeit bestehen, benutzerdefinierte Algorithmen zur Laufzeit der Anwendung einzubinden. Die Ermittlung der Leerbehälter soll dabei auf Basis unterschiedlicher Auswahlstrategien erfolgen. Die Anforderungen an die zu entwickelnde Software ergaben sich durch Analyse eines Referenzsystems. Die einzelnen Komponenten der Leerbehälterverwaltung sind unabhängig voneinander einsetzbar. Konfigurationsmöglichkeiten sind an zentraler Stelle durch eigens dafür angelegte Datenbanktabellen gegeben. Die derzeitige Ausführung der Software bietet bereits Algorithmen zur Bedarfsermittlung, Depotauswahl, Leerbehälter-Ermittlung und für den Transport der Behälter. Die entwickelte Software wurde im Rahmen eines Kundenprojektes getestet und die Ergebnisse evaluiert.
23.10.18	2019	intern	Bachelor	DE	Evaluation von GraphQL als Alternative zum RESTful-API-Design	Das Ziel dieser Bachelorarbeit ist die Evaluation von GraphQL als Alternative zum RESTful-API-Design. GraphQL ist eine 2012 von Facebook entwickelte Abfragesprache, Spezifikation und Sammlung von Werkzeugen, welche den Betrieb eines einzelnen HTTP-Endpunkts ermöglicht, um Leistung und Flexibilität von Client-Server-Anwendungen zu optimieren. Zuerst soll ein Überblick über GraphQL-Werkzeuge und das Umfeld geboten werden. Wichtige Aspekte für Entwicklung von Web-APIs wie Dokumentation, Sicherheit und Caching sollen für GraphQL betrachtet, mit bestehenden Lösungen im RESTful-API-Design verglichen und bewertet werden. Anschließend soll an einer beispielhaften RESTful-API-Implementierung aufgezeigt werden, wie die Stärken von GraphQL genutzt werden können. Dabei kommt zum einen die Durchführung einer Migration in Betracht, zum anderen, wie man eine hybride Lösung finden kann, bei der REST und GraphQL nebeneinander verwendet werden können.
24.10.18	2019	extern	Bachelor	DE	Analyse, Konzeption und Realisierung einer unternehmensweiten Application-Performance-Monitoring-Lösung am Beispiel des Produkts Ratenkauf der TeamBank AG	Die zunehmende Digitalisierung unserer Zeit spiegelt sich in Unternehmen wie der TeamBank AG vor allem im organischen Wachstum heterogener IT-Landschaften wider. Abhängig ihrer Kritikalität für eine Organisation, müssen die Systeme der IT-Landschaften höchste Sicherheits-, Stabilitäts- und Verfügbarkeitsanforderungen erfüllen. Um diesen Anforderungen gerecht zu werden, ist das traditionelle Monitoring als Vorkehrungsmaßnahme um ein Werkzeug zur Einbeziehung des Nutzererlebnisses für Endanwender zu ergänzen. Kernaufgabe dieser Bachelorarbeit ist demnach die Analyse und Konzeption einer unternehmensweiten Application-Performance-Monitoring-Lösung, die am Beispiel der Anwendung für das Produkt Ratenkauf der TeamBank realisiert werden soll. Der Fokus soll dabei primär auf der Überwachung von Performance auf Basis der Entwicklung von technischen und fachlichen Metriken im Zeitverlauf liegen. Im Rahmen dieser Arbeit wird aufgezeigt, welche Infrastrukturkomponenten für das Application-Performance-Monitoring (APM) benötigt werden und wie die Architektur für den Betrieb der APM-Lösung aussieht. Außerdem erfolgt ein Vergleich und die anschließende Auswahl der für das APM einzusetzenden Technologien. Im Kontext des Produkts Ratenkauf werden zudem die technischen und fachlichen Metriken herausgestellt und deren Visualisierung in Dashboards dargestellt.
29.10.18	2019	intern	Bachelor	DE	Anwendung einer Gamification-Mustersprache auf gamifizierte mobile Foodtracking-Applikationen zur Verbesserung der motivationalen Wirkung	Das Ziel der Bachelorarbeit ist es, motivationale Probleme, welche bei bereits gamifizierten Anwendungen bestehen, zu identifizieren und die Anwendbarkeit der Gamification-Mustersprache aus dem Forschungsprojekt "Empirische Analyse motivierender Spielelemente zur Entwicklung einer Gamification-Mustersprache" auf die Analyse und Lösung von konkreten Problemstellungen in der Praxis zu überprüfen. Hierzu sollen gamifizierte Foodtracking-Applikationen hinsichtlich ihrer motivationaler Probleme analysiert werden, indem der bisherige motivationale Erfolg anhand Sekundärquellen und nach Kriterien zur Einschätzung der motivationalen Wirkung von Anwendungen aus der Fachliteratur bewertet wird. Im Anschluss sollen spezifische Spiel-Design-Elemente basierend auf der Mustersprache des EMPAMOS-Projekts zu Lösung der Probleme ausgewählt und die Eignung des aktuellen Entwicklungsstands der Mustersprache für diese Art von Aufgaben bewertet werden.
31.10.18	2019	extern	Bachelor	DE	Konzeption und Implementierung eines Ranking-Algorithmus für die Suche mit einem Case-Based-Reasoning-Ansatz und Kreuzvalidierung unterschiedlicher Ergebnismengen 	Ziel der Arbeit ist die Konzeption und Implementierung eines Ranking-Algorithmus für die Suche mit einem Case-Based-Reasoning-Ansatz sowie die Konzeption und Implementierung einer geeigneten Teststrecke. Die Ergebnisse eines Testlaufs ermöglichen Aussagen über die Qualität der Case-Based-Reasoning-Suche und den Erfolg der Migration auf eine neue Suchmaschinentechnologie. In der Ist-Analyse wird sowohl der technologische Aufbau der Suchmaschine, als auch die einzelnen Verarbeitungsschritte einer Suchanfrage näher untersucht. Bei der Konzeption des Ranking-Algorithmus ist der Aufbau der zweiten Suchanfrage und die Berechnung des Relevanzwertes eines Dokuments hervorzuheben. Für die Verwendung der Teststrecke hat sich die Leave-One-Out-Kreuzvalidierung als bestes Verfahren herausge-stellt. Als Kennzahl zur Bewertung werden der Mean-Average-Precision und der Normalized-Discounted-Cumulative-Gain verwendet. Die Implementierung orientiert sich ebenfalls an der Zweiteilung zwischen Ranking-Algorithmus und Umsetzung der Teststrecke. Dabei wird auf gängige Design-Patterns in der objektorientierten Softwareentwicklung eingegangen und die Besonderheiten des Systems beschrieben. Zentrale Erkenntnisse aus der Analyse sind die Notwendigkeit eines zweistufigen Suchprozes-ses aufgrund der Beschaffenheit der Fallbasis. Auch die Wichtigkeit eines möglichst präzisen Relevanzwertes bei der Ermittlung ähnlicher Problembeschreibungen, hat sich als kritischer Faktor herausgestellt.
01.11.18	2019	extern	Bachelor	DE	Konzeption, Entwicklung und Integration eines Animations-Tools für die grafische Annotation von Videos in einem Grafikzeichenprogramm	Diese Arbeit zielt darauf ab, ein Animations-Tool in das bestehende Grafikzeichenprogramm der SCHEMA Gruppe zu integrieren. Dieses Tool soll Technischen Redakteuren bei der Erstellung von Videos mit grafischen Annotationen unterstützen. Im Laufe der Arbeit werden zunächst die Potentiale von Videos in der Technischen Dokumentation erläutert. So sind vor allem Videos ohne Tonspur eine geeignete Erweiterung zur klassischen textuellen Dokumentation. Eine Analyse von verschiedenen Video- und Animations-Tools dient einer ersten Übersicht, welchen Anforderungen das Animations-Tool gerecht werden muss. Für die Integration wird weiter das Grafikzeichenprogramm hinsichtlich seiner Technologie untersucht. Neben zusätzlich definierten Benutzeranforderungen bilden diese Ergebnisse die Kriterien für die anschließende Konzeptentwicklung. Ferner werden zwei Integrationskonzepte ausgearbeitet und durch eine prototypische Umsetzung vorgestellt. Auch ein möglicher Export des Videos mit den animierten Annotationen wird untersucht. Den Ergebnissen zufolge lässt sich die Integration eines Animations-Tools in das bestehende Grafikzeichenprogramm durchführen. Die Einbettung eines Chromium-Webbrowsers ist hierfür ein vielversprechendes Konzept. Die Ausgabestrecke erfolgt mittels SVG und CSS-Animationen innerhalb einer HTML-Datei. Mit Hilfe der Ergebnisse dieser Arbeit kann eine Weiterentwicklung des Animations-Tools im Grafikzeichenprogramm für ein zukünftiges Produkt Release erfolgen.
01.11.18	2019	extern	Bachelor	DE	Erarbeitung und Bewertung von Vorgehensweisen zur Integration der vollständigen Jobrolle Test Engineer in ein agiles Team	Zur Steigerung der Qualität von Softwareprodukten, wurde in der DATEV eG die neue Jobrolle Test Engineer definiert. Ziel dieser Arbeit ist es für die DATEV eG eine Empfehlung zu erarbeiten, die aussagt, welche Vorgehensweise zur Integration der vollständigen Jobrolle Test Engineer in ein agiles Team verwendet werden sollte. Integration ist dabei mit dem Erwerb und Ausbau von Skills, die ein Mitarbeiter benötigt, um die Jobrolle Test Engineer in seinem Team übernehmen zu können, gleichzusetzen. Denn damit diese vollständig in ein Team integriert werden kann, muss sich mindestens ein Mitarbeiter dieses Teams, die dazu notwendigen Skills aneignen bzw. seine vorhandenen Skills ausbauen. Die vorliegende Bachelorarbeit betrachtet die folgenden vier Vorgehensweisen zum Erwerb und Ausbau von Skills: Gamification, Schulung, Pairing und Rapid Skill Acquisition. Die Empfehlung sollte unter Beachtung der Rahmenbedingungen und des Arbeitsumfeldes erfolgen. Hierzu wurden die vier Vorgehensweisen analysiert und das Meinungsbild bezüglich dieser von den Mitarbeitern ermittelt. Als Basis für die Evaluation wurde jeweils eine sechsstufige Likert-Skala gewählt, um die persönliche Meinung der Mitarbeiter gegenüber den Untersuchungsobjekten einordnen zu können. Zusätzlich wird die Pilotierung einer Vorgehensweise durchgeführt.
01.11.18	2019	intern	Master	DE	Die Umsetzung und Evaluierung einer kollaborativen VR-Anwendung für blinde Menschen	Blinde Menschen sind im Alltag mit vielen Hürden konfrontiert, die für sehende Menschen nicht relevant sind. Neue Wege zur Arbeit oder tägliche Besorgungen können zu unüberwindbaren Aufgaben werden. Deshalb werden diese Wege und der Umgang mit Hilfsmittel für die Orientierung mit sogenannten Rehabilitationstrainern trainiert, deren Verfügbarkeit leider sehr gering ist. Aufgrund von neuen technologischen Möglichkeiten, soll in dieser Masterarbeit ein kollaboratives, virtuelles Training für blinde Menschen entwickelt und evaluiert werden. Ein Hauptaugenmerk liegt dabei auf dem kollaborativen Anteil, der durch die Hilfestellung zwischen Trainer und Lernenden repräsentiert wird. Daraufhin ist eine Unity-Anwendung entstanden, in der das Begehen einer virtuellen Welt mit bidirektionaler Kommunikation nach außen möglich ist. Somit kann sich der Trainer über seinen PC oder mobil über das Smartphone einwählen und kollaborative Hilfestellung leisten. Diese Anwendung ist anschließend im Rahmen einer Vorstudie mit sehenden Menschen, unter dem Gesichtspunkt des positiven Effektes von Kollaboration, evaluiert worden. Für eine Kohärenz zu blinden Menschen wird den sehenden Probanden, virtuell die Augen verbunden. Anhand von Kriterien zu Zeit, Wegstrecke, mentale Belastung und Usability ist die Anwendung mit zehn Probanden untersucht worden. Die erhaltenen Testergebnisse zeigten einen signifikanten Unterschied für die Bedingung mit kollaborativer Hilfestellung zur Bedingung ohne Hilfe.
05.11.18	2019	intern	Bachelor	DE	DNA als Speichermedium für textuelle Informationen Codierungsmethoden und experimentelle Ansätze 	Aufgrund des exponentiellen Wachstums aller weltweit erzeugten Daten, steigt der Bedarf an einem Speichermedium mit hoher Speicherkapazität, hoher Speicherdichte und langer Lebensdauer. Die DNA erweist sich als ein potenzielles Medium zur Datenspeicherung. Das Ziel dieser Bachelorarbeit ist, die bereits angewandten Codierungsmethoden für textuelle Informationen auf DNA (Desoxyribonucleinsäure) genauer darzustellen und zu analysieren, ob die DNA als Medium zur Datenspeicherung geeignet ist. Außerdem soll ein Überblick über die experimentellen Ansätze gegeben werden. Bevor die Codierungsmethoden erläutert werden, werden die theoretischen Grundlagen aufgeführt, um eine angemessene Einführung in das Thema zu erhalten
09.11.18	2019	intern	Bachelor	DE	Inhaltsanalyse von sozialen Beratungsforen mit maschinellen Lernverfahren	Durch soziale Beratungsangebote werden jährlich Tausenden von Menschen bei der Bewältigung persönlicher oder familiärer Probleme geholfen. Neben der traditionellen Beratung stellt hierbei die Online-Beratung eine gute Alternative dar. Diese Arbeit befasst sich mit der Auswertung von Beratungsgesprächen des Online-Beratungsforums der Bundeskonferenz für Erziehungsberatung. Hierbei galt es Methodiken zur Auswertung der unstrukturierten Beratungstexte zu erforschen mit dem Ziel, Ansatzpunkte für Verbesserungen der Beratungsqualität zu ermitteln. Um dies zu erreichen wurden Verfahren aus dem Bereich der maschinellen Textanalyse eingesetzt. Diese Verfahren werden, neben inhaltsanalytischen Grundlagen, zunächst erläutert und anschließend anhand exemplarischer Fragestellungen durchgeführt und ausgewertet. Die Fragestellungen wurden hierbei auf Basis des Beratungsforums der BKE-Elternberatung sowie bestehender Forschungsarbeiten abgeleitet. Die Mehrheit der untersuchten Fragestellungen konnten, unter Einsatz von computergestützten Wörterbuchsuchen, Lesbarkeitsformeln und Vektorraummodellen, erfolgreich beantwortet und die eingesetzten Methodiken evaluiert werden. Ein besonderes Augenmerk lag bei dieser Arbeit auf der Feststellung von Konversationsphasen in den Forenbeiträgen. Hierbei wurde ein Konversationsphasenmodell anhand des Forums abgeleitet und der Versuch unternommen dieses in den, durch ein unüberwachtes Lernverfahren, bestimmten Konversationsphasen festzustellen.
13.11.18	2019	intern	Bachelor	DE	Prototypische Entwicklung eines Logistik-Sprachassistenten für ein Luftfahrtunternehmen	This bachelor thesis describes the design and a prototypical implementation of a speech assistant for Lufthansa Technik. The implementation of the interface between in-house logistics and the company's cross-company customers is examined using a system for processing natural language called Dialogflow as an example. After considering the basics of "Natural Language Processing?, a general introduction to speech dialogue systems as well as the design of language assistants, I discuss the requirements of the considered assistant in detail. The scenarios relevant to Lufthansa Technik are analyzed in detail both functionally and non-functionally. The implemented prototype of the speech assistant was created using Dialogflow, a Google deep learning platform for conversational communication and Natural Language Processing. In addition to describing the design and implementation of the assistant, I also explain key features of the software architecture of Dialogflow and the related frameworks Firebase and Node.js. An evaluation was undertaken at Lufthansa Technik to show the strengths and weaknesses of the realization. I finish my thesis with some considerations about possible technical alternatives according to the present realization.
14.11.18	2019	intern	Master	DE	Drohnenbasierter Stereo-SLAM	Visual Simultaneous Localization and Mapping (VSLAM) behandelt das Problem, eine räumliche Karte einer unbekannten Umgebung aus Kameraaufnahmen zu erstellen und gleichzeitig die Position der Kamera in dieser Karte zu bestimmen. Ziel der Masterthesis ist es, bestmögliche Gebäuderekonstruktionen mit Hilfe von VSLAM zu generieren, um Wärmeaustritte an Gebäuden lokalisieren und visualisieren zu können. Hierfür wird eine mit einer Stereokamera ausgestattete Drohne verwendet. Neben einer Analyse zum aktuellen Stand der Technik des VSLAM-Problems in Verbindung mit Drohnen, Stereokameras und merkmalsarmen Umgebungen werden ausgewählte VSLAM-Verfahren getestet und evaluiert. Dies geschieht anhand der durch die Stereokamera erzeugten Gebäudeaufnahmen und der resultierenden dreidimensionalen Rekonstruktionen der VSLAM-Methoden mittels Punktwolken. Es erfolgt eine Gegenüberstellung der Ergebnisse dieser VSLAM-Algorithmen. Hierzu werden die Aufnahmen der Stereokamera, die als Eingabe für die VSLAM-Algorithmen dienen, mittels der von der Drohne bereitgestellten Schnittstelle abgegriffen. Die Evaluation der VSLAM-Verfahren hat gezeigt, dass keine brauchbaren Gebäuderekonstruktionen mit den verwendeten Bilddaten generiert werden können. Die Rotationen in den unstabilisierten Aufnahmen der Stereokamera führen zu Problemen bei der Rekonstruktion.
15.11.18	2019	extern	Master	DE	Konzeption und prototypische Implementierung einer Testkette für automatische Abnahmetests innerhalb einer verteilten Anwendungsumgebung	Das Ziel der vorliegenden Masterarbeit war die Erörterung der Frage, wie Abnahmetests eines komplexen verteilten Systems beschaffen sein müssen, um maximale Ausfallsicherheit und Fehlerfreiheit zu gewährleisten. Ein wesentlicher Fokus lag insbesondere auf der Automatisierung von Testvorgängen bzw. auf der bestmöglichen Einbindung manueller Teilprozesse in automatisierte toolgestützte Workflows. Am Ende der Arbeit ist eine Testkette entstanden, die alle typischen und relevanten Testarten abdeckt und passende Auswertungen für die unterschiedlichen Rollen innerhalb der Projektteams bereithält. Für die Klärung, aus welchen konkreten einzelnen Testschritten die final festzulegende Testkette zusammengesetzt sein musste, wurde zuallererst der Begriff des Softwaretests näher beleuchtet und eine geeignete Klassifikation für diesen Terminus vorgestellt. Dabei wurden neben der allgemeinen Klassifikation der Testarten insbesondere auch manuelle und automatisierbare Testarten voneinander abgegrenzt. Da der Testprozess von außen betrachtet jedoch kein losgelöstes, singuläres Ereignis darstellt, sondern Glied einer Softwareproduktionskette ist, war es unabdingbar, auch die vor- und nachgelagerten Prozesse der verschiedenen Testarten zu betrachten. Dabei hat sich das Prinzip des "DevOps" als besonders relevant herausgestellt und wurde mit Bezug auf das Thema "Testen" im Detail untersucht. [...]
19.11.18	2019	extern	Master	DE	Konzeption und Entwicklung einer automatisierten Lagerreorganisation im SAP EWM	Die vorliegende Arbeit beschäftigt sich mit der Konzeption und Entwicklung einer automatisierten Lagerreorganisation in SAP EWM. Hierzu wird vorab das Problem der Lagerplatzzuordnung erläutert, um ein einheitliches Verständnis für die anschließende kritische Ist-Analyse zu schaffen. Angesichts der vorhandenen Datenmengen und Datenvielfalt ist die standardmäßige Lagerreorganisation des SAP EWM zu statisch ausgerichtet, um die steigenden Kundenanforderungen an ein Lagerverwaltungssystem zu erfüllen. Es folgt ein Einblick zum aktuellen Stand der Forschung über das Thema Lagerreorganisation und darauf aufbauend eine Konzeption für einen neuen Ansatz im SAP EWM. Dieser beruht auf einer regelmäßigen Produktklassifizierung, womit die Umlagerungsmaßnahmen auf Basis der aktuellen Nachfragehäufigkeit stattfinden. Für die Identifikation der umzulagernden Handling-Units kommt eine mehrdimensionale Bewertungsgrundlage zum Einsatz, die statische und dynamische Parameter, sowie die Profitabilität einer Umlagerung berücksichtigt. Dadurch können eindeutige Empfehlungen zur Umlagerung ausgesprochen werden. Mithilfe eines zweistufigen Optimierungsverfahrens erfolgt die Berechnung der optimalen Umlagerungsroute für die entsprechenden Handling-Units. Zum Abschluss wird die neue Lösung innerhalb einer Simulationsumgebung validiert. Die Ergebnisse zeigen, dass die Lagerreorganisation im Vergleich gegenüber eines normalen Lagerbetriebs eine Reduzierung der Pick-Distanz von bis zu 16% erzielen kann.
23.11.18	2019	intern	Bachelor	DE	Einsatz von Empamos-Spiel-Design-Entwurfsmustern zur Motivationssteigerung im Kontext des agilen Projektmanagements	Abstract Motivation ist ein wichtiger Antrieb für Handlungen. Gamification versucht Motivation gezielt zu erzeugen und zu steuern, um somit Personen gezielt zu Handlungen zu bewegen. In dem Empamos-Projekt der TH Nürnberg wird eine Pattern-Language entwickelt, welche eine Hilfestellung geben möchte, um ein Gamification Konzept zu erstellen. Das Ziel dieser Arbeit ist es, den Arbeitsstand der Pattern-Language im Kontext zu den agilen Projektmanagementmethoden Kanban und Scrum anzuwenden. Die beiden agilen Projektmanagementmethoden besitzen bereits Gamification- Elemente sowie motivationale Defizite. Ich habe Die Pattern durch eine Analyse erarbeitet. Eine Auswahl an Defiziten habe ich mittels Interviews identifiziert. Anhand der Patterns wurden Ansätze erarbeitet, um die Defizite durch geeignete Erweiterung mit neuen Pattern abzubauen. Ich habe in Kanban 27 und in Scrum 31 Pattern identifiziert. Aus den Interviews habe ich neun Defizite extrahiert. Zu sieben dieser neun Defizite kann der Arbeitsstand der Pattern-Language Ansätze geben, um sie abzubauen.
27.11.18	2019	intern	Bachelor	DE	Analyse von Stellenanzeigen für Informatik-Absolventen mit Machine Learning	Die Stellenanzeigensuche in Onlinejobbörsen ist oftmals sehr zeitintensiv. Einen Filter für Absolventen gibt es nur bei einigen wenigen Jobbörsen und diese sind unzureichend umgesetzt. Die Schwierigkeiten bei der Stellenanzeigentextanalyse und -verarbeitung sind beispielsweise Mehrdeutigkeit, unterschiedliche Formatierung und Strukturierung. In dieser Arbeit werden die Klassifikation und die Cluster-Analyse aus Machine Learning auf die Stellenanzeigentexte angewendet. Der Klassifikator soll anhand der Stellenanzeigentexte eines typischen Jobs für Informatiker die Stellenanzeigen für Einsteiger und für Berufserfahrene klassifizieren. Aus drei Klassifikatoren hat der beste Klassifikator eine Korrektklassifizierungsrate von 91%. Zusätzlich werden eine Reihe von Datenanalysen durchgeführt und die Ergebnisse visualisiert dargestellt.
27.11.18	2019	extern	Bachelor	DE	Entwicklung eines Textanalysealgorithmus zur systematischen Sammlung von Bedrohungsmeldungen über Third-Party-Software im Internet	Im Bereich der Softwareentwicklung stellen Sicherheitslücken ein großes Risiko dar. Um dieses Risiko zu minimieren werden in sogenannten Software-Schwachstellen-Datenbanken offiziell anerkannte Sicherheitslücken gespeichert. Oft kursieren allerdings im Vorfeld schon Meldungen von Schwachstellen im Internet. So werden auch Personen auf diese aufmerksam, welche durch Ausnutzung der Sicherheitslücke nicht autorisierten Zugriff auf Daten erhalten können. Mit dem Problem der frühzeitigen Veröffentlichung von Software-Sicherheitslücken, beschäftigt sich die vorliegende Arbeit. Es wurde ein Textanalysealgorithmus entwickelt, welcher die wesentlichen Informationen aus offiziellen und inoffiziellen Software-Schwachstellen-Quellen kombiniert. Dabei wurden zunächst unterschiedliche Software-Sicherheitslücken-Quellen analysiert. Als repräsentativste Datenquellen haben sich dabei die NVD von NIST, das Online-Magazine heise und der Software Hersteller Microsoft herausgestellt. Darüber hinaus wurde ermittelt, welche Metadaten für die Erfassung von Sicherheitslücken relevant sind. Für die Unterscheidung zwischen Software-Schwachstellen-Meldungen und sonstigen Bekanntmachungen wurde der Textanalyseanalysealgorithmus um einen Klassifikator erweitert. Neben dem Naive Bayes Klassifikator wurde auch der Support Vector Machine Klassifikator umgesetzt. Für die Trennung der Meldungen erwieß sich der SVM als effektiver.
27.11.18	2019	extern	Bachelor	DE	Identifizierung und Analyse von verwendeter Third-Party-Software eines Unternehmens und Entwicklung eines Tools zur automatisierten Benachrichtigung beim Bekanntwerden von Sicherheitslücken	Software besteht zu einem großen Teil aus Komponenten, die von Drittanbietern stammen. Dies führt zwar zu einer Kosten- und Zeitersparnis, birgt aber auch viele Risiken. So ist durch eine Sicherheitslücke in einer Komponente die komplette Software gefährdet. Um dieses Risiko zu mindern, wird für ein IT-Unternehmen ein Tool entwickelt, welches im Internet nach Sicherheitslücken von Softwarekomponenten sucht und Mitarbeiter benachrichtigen kann. Dabei soll gezielt nur externe Software untersucht werden. Dazu wird die folgende Forschungsfrage gestellt: Wie kann man Third-Party-Software in Projekten identifizieren? Um diese Forschungsfrage zu beantworten, ist eine Befragung durchgeführt worden, die sich an die Projektleiter von Kundenprojekten richtete. Die Antworten sollten Aufschluss darüber geben, welche Vorgehensweise sich am besten für die Identifizierung von Fremdsoftware eignet. Die Ergebnisse zeigten, dass in jedem Projekt die Dokumentation und Speicherung von Fremdsoftware unterschiedlich erfolgt. So mussten verschiedene Wege erarbeitet werden, wie Fremdsoftware aus Repositories herausgelesen werden kann. Anschließend konnte ein Algorithmus entwickelt werden, welcher für jede Fremdsoftware im Internet nach Sicherheitslücken sucht. Ist eine Sicherheitslücke vorhanden, wird der Projektleiter des betroffenen Projekts per E-Mail benachrichtigt. Dazu wurden weitere Algorithmen entwickelt, die sich mit der Beschaffung von Mitarbeiter- und Projektinformationen beschäftigen.
28.11.18	2019	intern	Bachelor	DE	Konzeption und prototypische Implementierung eines OpenID Connect Identity Provider unter Verwendung der W3C WebAuthn API zur passwortlosen Authentifizierung	Das Ziel der vorliegenden Arbeit war der Entwurf eines OpenID Connect Identity Providers mit einer passwortlosen Authentifizierung auf Basis der W3C WebAuthn API und dessen anschließende Validierung durch eine prototypische Implementierung. Hierfür wurde zunächst die Entwicklung eines Konzepts zur Komposition der Technologien, dem OAuth 2.0 Protokoll mit der Authentifizierungsschicht OpenID Connect und der W3C WebAuthn API, benötigt. Des Weiteren mussten Konzepte für die Realisierung der funktionalen Bestandteile des Identity Providers entwickelt werden. Hierzu wurden nach Vorüberlegungen und der Beschreibung von Anwendungsszenarien die Definition der funktionalen und nicht-funktionalen Anforderungen an den zu konzeptionierenden Identity Provider durchgeführt. Im Anschluss wurde die Konzeption der Komposition der Technologien sowie der weiteren funktionalen Bestandteile des Identity Providers durchgeführt und somit deren theoretische Realisierbarkeit gezeigt. Im Rahmen der folgenden prototypischen Implementierung wurde nach der Evaluation von bestehenden PHP-Bibliotheken der Entwurf des Identity Providers durchgeführt und durch die anschließende Implementierung die praktische Realisierbarkeit des konzeptionierten Identity Providers belegt. Durch die abschließende Evaluation des Prototyps wurde die vollständige Erfüllung der initial definierten Anforderungen und im Rahmen der Validierung die Erfüllung der Erwartungen an die Sicherheit und Effizienz festgestellt.
28.11.18	2019	intern	Bachelor	DE	Der Chatbot als Assistent für den Konsumenten im stationären Einzelhandel: Konzeption und prototypische Implementierung 	Viele Kunden nutzen während des Einkaufs in einem Laden ihr Smartphone, um sich über die dort angebotenen Produkte zu informieren und bessere Kaufentscheidungen treffen zu können. Im Hinblick darauf ist das Ziel dieser Arbeit, einen prototypischen Einkaufsassistent-Chatbot zu entwickeln, der die selbstständige Informationsbeschaffung der Kunden erleichtern und sie beim Einkauf unterstützen kann. Hierfür wird zunächst ein Konzept des Chatbots erstellt und anhand dessen ein Prototyp implementiert. Mithilfe eines Nutzertests und einer Umfrage wird schließlich die Nutzerfreundlichkeit und das Interesse an dieser Technologie ermittelt. Die Evaluation der Ergebnisse zeigt, dass ein Großteil der Probanden diesen Chatbot zur Hilfe beim Einkauf nutzen würde. Weiterhin konnten Verbesserungspotenziale identifiziert werden, die bei einer Weiterentwicklung des Chatbots zu berücksichtigen sind.
29.11.18	2019	extern	Bachelor	DE	Design und Implementierung eines Continuous Integration Prozesses für die Business-Intelligence-Software "QlikView"	In modernen Unternehmen zählen Kennzahlen als wichtiges Steuerungsinstrument. Bei DATEV kommt hier unter anderem die Software QlikView zum Einsatz. In verschiedenen Abteilungen entstehen Statistiken über CPU-Verbräuche, Auslastungen und weitere wichtige Zahlen. Dabei läuft das Testen, Sichern alter Softwarestände der QlikView-Applikationen und das Bereitstellen auf der zentralen Serverplattform noch weitgehend von Hand. Mit Hilfe eines Continuous Integration Prozesses soll die Arbeit der QlikView-Entwickler zukünftig gestützt werden. Durch die Verwaltung der Sourcen in einer zentralen Verwaltung, sowie nachgelagerten, automatisierten Build-Abläufen werden die verschiedensten Auswertungen in einem zu definierenden CI-Prozess erzeugt und auf die entsprechenden Server geschoben. Die für den vollständigen Ablauf erforderlichen Skripte werden erstellt, getestet und auf ein geeignetes System übertragen. Mit diesem Konzept wird die Grundlage für einen automatisierten und erweiterbaren Prozess geschaffen, die die Zeit bis zur Veröffentlichung einer neuen Version verkürzt und dynamische Anpassungen auf Basis des Source Code ermöglicht.
29.11.18	2019	extern	Master	DE	Modellierung und Implementierung eines Event-Mechanismus in einem verteilten Software-Framework zur Testautomatisierung	Ziel dieser Arbeit war es, einen Event-Mechanismus zu entwerfen und prototypisch zu implementieren, der die Verarbeitung von Ereignissen durchgehend in allen Teilen der vorhandenen Testautomatisierungsoftware eines PROFINET-Stacks ermöglicht. Diese Software wird verwendet, um einen PROFINET-Stack auf einer verteilten Testanlage, bestehend aus mehreren Test-PCs und PROFINET Hardware, zu verifizieren. Die Testautomatisierung besteht aus mehreren Servern und einem Client, welcher sich auf die Test-PCs der Testanlage verbindet. Aktuell initiiert immer der Client die Kommunikation mit den Servern, was dazu führt, dass die Informationen, welche der Client hält, nicht immer die aktuellen Ereignisse auf den Servern widerspiegeln, weswegen die Eventverabeitung implementiert werden soll. Diese Arbeit entwickelt ein Konzept zur Verarbeitung von Ereignissen in einem verteilten System und setzt diese anschließend prototypisch um. Dieser Prototyp bildet die Grundlage für weitere Entwicklungen. Durch Einführung dieses Event-Mechanismus können nun relevante Informationen an interessierte Teilnehmer verteilt werden, ohne diese Information abfragen zu müssen. Da sich die Anforderungen an Tests des PROFINET-Stacks kontinuierlich ändern, wurde darauf geachtet, dass es einfach ist, auch neue unbekannte Eigenschaften zu überwachen.
30.11.18	2019	intern	Bachelor	DE	Untersuchung maschineller Lernverfahren für Frage-Antwort-Systeme	Frage-Antwort-Systeme sind eine spezialisierte Form von Information Retrieval-Systemen, deren Aufgabe es ist, in natürlicher Sprache gestellte Fragen zu beantworten. In dieser Arbeit wird aufgezeigt, wie diese Systeme aufgebaut sind, klassifiziert werden können und welche Ansätze für die Erstellung eines solchen Systems existieren. Insbesondere der Ansatz des maschinellen Lernens hat in den letzten Jahren deutlich an Bedeutung gewonnen, sodass diese Verfahren genauer untersucht wurden. Dafür wurden das Dynamic Memory Network und die Bidirectional Encoder Representations From Transformers analysiert und auf Basis dieser Modelle eigene Frage-Antwort-Systeme erstellt und evaluiert. Die untersuchte Implementierung des Dynamic Memory Networks erreichte in diesem Versuch lediglich eine Genauigkeit von etwa 45-55% Prozent bezüglich des bAbI-Datensatzes und erwies sich damit als nicht praktikabel. Das System mit Bidirectional Encoder Representations From Transformers hingegen erreicht SQuAD-Werte von bis zu 90%. Durch das multilinguale Modell ist dieses System auch in der Lage, die meisten deutschen Fragen zu beantworten. Aufgrund der Architektur und des Fine-Tunings anhand des SQuAD-Datensatzes funktioniert dieses Modell allerdings nur zuverlässig für Fließtexte und Fragen, deren Antworten sich im Text befinden.
01.12.18	2019	extern	Bachelor	DE	Analyse und Integration des iiRDS Standards zum Austausch intelligenter Informationen in der Technischen Dokumentation	Zur kontextbezogenen Verteilung von Informationen wird ein für Maschinen lesbarer Kontext benötigt. Für die Beantwortung der Frage wie ein solcher Kontext beschrieben und mit der zugehörigen Information verknüpft werden kann, gibt es verschiedene Lösungsansätze. Im Teilbereich "Content Delivery" aus der Technischen Dokumentation wurde zu diesem Zweck der intelligent information Request and Delivery Standard (iiRDS) konzipiert. In dieser Arbeit soll geklärt werden, wie der iiRDS in bereits bestehende Software aus dem Bereich "Content Delivery" integriert werden kann. Zunächst definiert der iiRDS ein Vokabular zur Kennzeichnung von Inhalten mit Metadaten. Außerdem wird im iiRDS ein Paketformat definiert, das es erlaubt Inhalte mit den zugehörigen Metadaten zusammen zu verteilen. Um die Verwendung des iiRDS evaluieren zu können, wurde der SCHEMA ContentDeliveryServer (CDS) um einen Import für iiRDS-Datensätze erweitert. Diese Erweiterung ermöglicht es die Daten aus dem Paketformat des iiRDS in das Format des CDS zu überführen und den resultierenden CDS-Datensatz hochzuladen. Anschließend wurden einige Testdatensätze importiert und das Ergebnis des Imports analysiert. So konnten im Test alle Metadaten aus den iiRDS-Datensätzen ohne Verlust in den CDS übertragen werden. Diese Übertragung erfolgt anhand einer vom Nutzer des CDS vorher festgelegten Zuordnung. Der iiRDS konnte dabei allen Anforderungen aus der Technischen Dokumentation gerecht werden.
01.12.18	2019	extern	Bachelor	DE	Design eines Benutzer-Lifecycle-Prozesses mit Microsoft Identity Manager für Verzeichnisdienste	In der IT-Infrastruktur des Unternehmens DATEV eG existieren mehrere, voneinander unabhängige Verzeichnisdienste. Diese stehen administrierten Ressourcen, wie beispielsweise Computern und Benutzern, als Identitäts- und Authentifizierungsdienst zur Verfügung. Die Ressourcen werden in Gruppen verwaltet. Um den manuellen Aufwand der Synchronisation der Verzeichnisdienste zu reduzieren sowie einen durchgängigen Ressourcen-Lebenszyklus zu gewähren, wird ein Prozess konzipiert, welcher eine automatisierte Übertragung von Ressourcen und Gruppen ermöglicht. Dieser Ablauf wird anhand des Benutzermanagements und einer prototypischen Umsetzung evaluiert. Die Verwaltung von Benutzerobjekten umfasst neben der Übertragung von Attributen auch die Anlage, Aktualisierung sowie Löschung oder Deaktivierung. Bei der prototypischen Implementierung wird das Tool Microsoft Identity Manager analysiert und bewertet.
03.12.18	2019	extern	Bachelor	DE	Implementierungsanalyse ausgewählter Augmented-Reality Smart Glasses (ARSG) mit anschließender Konzeption und Realisierung einer Anbindung zu bereits vorhandenen, individuellen Webanwendungen über einen REST-Service	Die vorliegende Bachelorarbeit beinhaltet die Implementierungsanalyse ausgewählter Augmented Reality Smart Glasses (ARSG) mit anschließender Konzeption und Realisierung einer Anbindung zu bereits vorhandenen, individuellen Webanwendungen über einen REST-Service. Bei dieser Arbeit wird die Automotive-Branche in den Fokus genommen. Dementsprechend werden Erklärungen und Beispiele innerhalb eines Produktionswerkes stattfinden. In diesen Stätten werden alle laufenden, wie auch fehlerhaften Prozesse auf wenigen Monitoren dargestellt. Um als Mitarbeiter den aktuellen Stand der Prozesse einsehen zu können, muss dieser in regelmäßigen, zeitlichen Abständen den momentanen Arbeitsplatz verlassen, um auf einen der Monitore blicken zu können. Der Einsatz von ARSG soll den Aufwand verringern und einen zeitlichen Vorteil verschaffen. Dies schafft eine Möglichkeit mobil und mit möglichst geringer Ablenkung die fehlerhaften Prozesse unverzüglich angezeigt zu bekommen. Dadurch können ohne Umwege Gegenmaßnahmen eingeleitet werden. Das Ergebnis der Bachelorarbeit wird mit ausgewählten Mitarbeitern der Produktionsstätte eines namhaften Automotive-Unternehmens getestet. Es wird anschließend eine Evaluation stattfinden.
03.12.18	2019	intern	Bachelor	DE	Beschreibung und strukturierte Darstellung aktueller Trends im Bereich Lernende Organisationen	Lernende Organisation beziehungsweise organisationales Lernen sind Teil der erweiterten verhaltenswissenschaftlichen Entscheidungstheorie, die zu den Organisationstheorien zählt. Organisationales Lernen beschäftigt sich damit, wie der Wissenserwerb in Unternehmen umgesetzt werden kann. Als Möglichkeiten hierfür kommen unter anderem das Change- und Wissensmanagement in Frage. Als unterstützende Lernmethoden können Storytelling und Gamification genutzt werden. Ein möglicher Lerngegenstand, der mit den genannten Lernmethoden vermittelt werden könnte, ist Corporate Social Responsibility (CSR), die derzeit kulturellen Wandel in den Unternehmen nötig macht. CSR ist deshalb ein zentrales Thema in Organisationen, weil für Verbraucher wie auch Mitarbeiter Nachhaltigkeit in sozialer, ökonomischer und ökologischer Form ein zentrales Anliegen bildet.
06.12.18	2019	intern	Bachelor	DE	Analyse und Auswertung von Stellenausschreibungen durch Methoden des maschinellen Lernens	Mit der Hochschul-Jobbörse stellen mittlerweile 15 Partnerhochschulen in Bayern eine Online-Plattform für Stellenanzeigen zur Verfügung, um Studierende, Absolventinnen, Absolventen sowie Alumni mit erster Berufserfahrung und Unternehmen für beide Seiten gewinnbringend zusammen zu führen. Das Archiv der Hochschuljobbörse, beinhaltet eine Sammlung der ausgeschriebenen Stellenanzeigen jeder teilnehmenden Hochschule, der letzten Jahre. Ziel dieser Bachelorarbeit ist es herauszufinden welche Informationen sich durch Anwendung von maschinellen Lernalgorithmen und regelbasierten Analyseverfahren aus den Stellenanzeigen der Hochschuljobbörse gewinnen lassen. Dafür wird zunächst durch statistische Analyse der Jobtitel geprüft, welche Berufsklassen in den Datensätzen vorkommen. Anschließend werden die Stellenausschreibungen durch überwachte Lernverfahren den jeweiligen Berufsklassen zugeteilt. Aus den klassifizierten Stellenanzeigen werden dann die Qualifikationsanforderungen extrahiert und zum Schluss in Kategorien eingeteilt. Das Ergebnis der durchgeführten Analyse der IT-Stellenanzeigen sind Kompetenzprofile der jeweiligen Berufsklassen, die eine Übersicht über die am häufigsten genannten Anforderungen in den untersuchten Stellenanzeigen geben.
11.12.18	2019	intern	Bachelor	DE	Benutzerschnittstelle zur Visualisierung von Gesichtserkennungsverfahren	Im Rahmen dieser Bachelorarbeit soll eine Benutzerschnittstelle zur Visualisierung von Gesichtserkennungsverfahren entwickelt werden. Diese soll beispielsweise in Lehrveranstaltungen zum Einsatz kommen, um die Funktionsweise der Verfahren zu veranschaulichen. Das zu entwickelnde Tool soll bereits trainierte künstliche neuronale Netze einbinden können. Es soll darüber hinaus möglich sein, Bilder von Gesichtern einzulesen, zu verwalten, mit Labeln (Namen bzw. Farben) zu versehen sowie den Abstand der Gesichter im Merkmalsraum zu visualisieren. Hierfür soll das Verfahren T-distributed Stochastic Neighbor Embedding (t-SNE) zum Einsatz kommen. Bei dem Verfahren werden hochdimensionale Daten in zwei- oder mehrdimensionalen Räumen abgebildet ohne dabei die Struktur der Daten zu verändern, was eine hohe Nachvollziehbarkeit für das menschliche Auge ermöglicht. Auf diese Weise kann man Ähnlichkeiten zwischen Gesichtern optisch demonstrieren. Innerhalb der Fakultät Informatik werden verschiedene Betriebssysteme eingesetzt, daher sollte die Anwendung möglichst plattformunabhängig sein.
13.12.18	2019	extern	Bachelor	DE	Extraktion, Aufbereitung und Darstellung immobilienwertrelevanter Informationen aus Baugenehmigungen. Teil 2: Konzeption und Entwicklung einer Applikation zur Visualisierung auf einer digitalen Karte	Das Ziel der Arbeit ist es, Personen, welche an Immobilien oder Grundstücken interessiert sind, eine Möglichkeit zu bieten, eventuelle - durch Umgestaltungen im Umfeld bedingte - Wertänderungen von Immobilien bzw. Grundstücken leichter zugänglich zu machen. Hierfür werden als Beispieldaten Amtsblätter von fünf ausgewählten Städten betrachtet und die darin befindlichen Baugenehmigungen genutzt. In einer parallel entstehenden Bachelorarbeit werden die Inhalte der Baugenehmigungen mithilfe von Text-Mining-Methoden aufbereitet und immobilienwertrelevante Informationen extrahiert. Diese immobilienwertrelevanten Informationen werden im Rahmen dieser Arbeit in einer für den Endbenutzer gut zugänglichen, strukturierten Form auf einer digitalen Karte visualisiert. Dafür wird zunächst ein Darstellungskonzept entworfen, mithilfe dessen der Prototyp entwickelt werden kann. Zur Qualitätssicherung und Planung der Weiterentwicklung wird neben internen Komponenten- und Integrationstests auch ein externer Benutzertest unter einer Zahl von Mitarbeitern der Immowelt AG durchgeführt.
21.12.18	2019	extern	Bachelor	DE	Optimale Lagerplatzvergabe: Generierung von endlichen Automaten zur Unterstützung der performanten Suche bei der Dematic GmbH	Die Suche nach dem optimalen Lagerplatz ist eine elementare Aufgabe bei der Ein- und Auslagerung von Gütern in einem Warenlager. Damit der Zugriff auf die Güter eines Lagers möglichst effizient ist, werden endliche Automaten verwendet. Im eigenentwickelten Lagerverwaltungssystem der Dematic GmbH werden die endlichen Automaten manuell erstellt. Ziel der Arbeit ist die Ablösung der bisherigen manuellen Vorgehensweise zur Erstellung von endlichen Automaten durch einen Algorithmus. Die Phasen zur Entwicklung der Anwendung umfassen die Analyse, Konzeption, Umsetzung und die anschließende Bewertung der Ergebnisse. Der Algorithmus für die Erstellung von endlichen Automaten wird sukzessiv in Form von Prototypen implementiert. Nach jedem Prototyp ergibt sich eine ablauffähige Anwendung, die einen Teil der Funktionalitäten wiederspiegeln. Im Rahmen der Konzeption werden für jeden der entworfenen Prototypen bestimmte Funktionen geplant. Die Phase Umsetzung umfasst die Implementierung des entsprechenden Programmcodes sowie die erforderliche Testaktivitäten. Nach jedem Prototyp werden die Ergebnisse des Algorithmus bewertet. Der in dieser Arbeit realisierte Generator kann verschiedene endliche Automaten mit unterschiedlich großen Ladeeinheiten erstellen.
15.01.19	2019	extern	Bachelor	DE	Konzeption und Implementierung einer Schnittstelle zur automatischen Erkennung von Fehlermustern und deren Bereinigung bei der Siemens AG	Diese Arbeit behandelt ein Innovationsprojekt zur Erstellung von MIMIR im Auftrag der Siemens AG. Das Ziel dieser Arbeit ist es, eine Schnittstelle von THOR zu Splunk herzustellen, die es Support Mitarbeitern und weiteren interessierten Nutzern erlaubt Suchpattern zu erstellen. Mit den Suchpattern sollen Support Mitarbeiter durch automatisierte Behebung bestimmter Fehler entlastet werden. Außerdem sollen für diese Suchpattern Analysen bereitge- stellt werden, die die Fehlerhäufigkeit pro Zeiteinheit zeigen. Um die Wünsche der Nutzer einzufangen, sind moderierte Interviews mit Key Usern aus verschiedenen Bereichen veranstaltet worden. In diesen Interviews konnten die Nutzer in einem gewissen, durch den Moderator gegebenen Rahmen, User Stories erstellen. Auf Basis dieser User Stories wurde eine Benutzerschnittstelle in Form einer Webanwendung, sowie Prozesse erstellt, die das Programm mit den gewünschten Funktionen ausstatten. Bei der Entwicklung der Schnittstelle zeigten sich Beschränkungen bei der Abfrage in Splunk. Dem wurde in großen Teilen durch Umstrukturierung der Architektur entgegengewirkt, jedoch war dies in einzelnen Punkten im zeitli- chen Rahmen nicht möglich, wodurch die Produktivstellung der Anwendung nicht erfolgt ist. Im Rahmen dieser Bachelorarbeit wurde ein solides Grundgerüst erstellt, das den Wünschen der Nutzer entspricht und nach Beseitigung der Beschränkun- gen in der Siemens AG verwendet werden kann.
17.01.19	2019	intern	Master	DE	Gestaltungsoptionen für die IT-Governance und IT-Portfoliomanagement an Hochschulen	Die IT-Governance ist heutzutage ein zentraler Bestandteil der Corporate Governance, welche der Sicherstellung des effektiven Gebrauchs von IT zur Unterstützung der Unternehmensstrategie dient. Da die IT in den letzten Jahren auch an Bedeutung an Hochschulen gewonnen hat, werden große Anstrengungen unternommen, auch hierfür effektivere Entscheidungsstrukturen zu entwickeln. Ziel der Arbeit ist es, Möglichkeiten zur Modellierung geeigneter IT-Governance-Strukturen aufzuzeigen und unter Beachtung ihrer Eignung für Hochschulen zu analysieren. Um diese Zielsetzung zu erfüllen, wurden bezüglich der Gestaltungsoptionen die IT-Governance-Literatur und -Studien ausgewertet sowie aktuelle Praktiken an Hochschulen untersucht, um auf diese Weise best practices ableiten zu können. Als zentrale Ergebnisse der Arbeit zeigten sich, dass eine stärkere Einbindung des CIOs in die Entscheidungsstrukturen, sowie dessen Etablierung als zentraler Ansprechpartner für IT-Belange an der Hochschule empfehlenswert sind. Auch sind best practices aus IT-Governance-Frameworks wie ITIL hilfreich für effektivere Prozesse zur Entscheidungsfindung.
28.01.19	2019	extern	Bachelor	DE	Evaluation und Technologievergleich der Container-Orchestrierungstools Docker-Swarm, Kubernetes und Pivotal-Container-Services zur Skalierung des zentralen Buildsystems Jenkins	In der Abschlussarbeit gilt es zu untersuchen, welches Container-Orchestrierungstool sich für das horizontale Skalieren des Open-Source Buildsystems Jenkins am besten eignet. Die zur Auswahl stehenden Tools sind Docker-Swarm, Kubernetes und Pivotal Container Services. Um zu evaluieren, welche Technologie sich für die Datev eG am Besten eignet, wird ein Technologievergleich zwischen Docker-Swarm, Kubernetes und Pivotal Container Service durchgeführt. Hauptmerk wird dabei auf die Wartbarkeit und Administrierbarkeit gelegt. Zur Evaluation wird der Betrieb des Jenkins-Masters innerhalb eines Docker-Swarm Cluster und Kubernetes Cluster prototypisch umgesetzt.
31.01.19	2019	intern	Bachelor	DE	Konzeption und prototypische Implementierung eines Chatbots für die Themen W-LAN und VPN an einer Hochschule	Zu Beginn eines jeden Semesters treffen bei der IT-Support-Organisation mehrere Anfragen bezüglich Schwierigkeiten bei der Einrichtung einer Hochschulnetzwerkverbindung ein. Dabei handelt es sich überwiegend um wiederkehrende Fragen, die mithilfe eines digitalen Assistenten unterstützend sowie vollautomatisiert beantwortet werden können. Die Herausforderungen liegen in der dynamischen Vermittlung von explizitem Wissen sowie in der autonomen Erfassung von relevanten Systeminformationen des Nutzers bzw. der Nutzerin. Im Rahmen der vorliegenden Arbeit wurde eine mögliche Dialogstruktur für den Bereich WLAN und VPN realisiert. Ein mündliches Experteninterview diente der Analyse und der Konzeption. Das resultierende Konversationsmodell wurde prototypisch umgesetzt. Anschließend wurde zur Verifizierung eine quantitative Online-Befragung mit den Mitarbeitern des Support-Teams durchgeführt. Das Resultat der Beobachtung gibt Auskunft darüber, ob der Einsatz von Chatbots an der Hochschule tendenziell erfolgen kann.
31.01.19	2019	intern	Bachelor	DE	Entwicklung eines kontextbezogenen Wortvorschlagssystems unter Einsatz von Machine Learning	Das Ziel der Arbeit ist die Entwicklung eines kontextbezogenen Wortvorschlagssys-tems. Dieses soll anders als herkömmliche Tastaturen Informationen, wie den derzeitigen Gesprächspartner, die Uhrzeit sowie den Standort in die Wortvorschläge mit einbezie-hen. Für die Entwicklung werden zunächst vier bestehende Wortvorschlagssysteme ver-glichen und das geeignetste für den Anwendungsfall ausgewählt. Das ausgewählte Ver-fahren wird anschließend um kontextbezogene Informationen erweitert. Späterer Ein-satzzweck des Systems ist eine App, die Menschen mit einer Sprachbehinderung die Kommunikation erleichtern soll.
11.02.19	2019	intern	Bachelor	DE	Verarbeitung von Projektaktivitätsdaten aus SW-Entwicklungsprozessen	Die Aufgabenstellung dieser Arbeit besteht darin, ein Auswertungssystem zu entwickeln, welches in der Lage ist, Projektaktivitätsdaten eines Projektmanagementsystem zu exportieren und diese in einer eigenen Datenhaltung zu speichern. Diese Daten werden anschließend ausgewertet und für den Benutzer visualisiert. Grundsätzlich soll die betriebswirtschaftliche Problematik der fehlenden Transparenz untersucht und die daraus resultierenden Anforderungen in einer Anforderungsanalyse dokumentiert werden. Die Datengrundlage der Projektaktivitätsdaten wird zudem auf ihre Aussagekraft überprüft wobei zu den Eingabedaten kritisch Stellung genommen wird. Da die Auswertung personenbezogene Daten beinhalten könnte, bedarf es ebenfalls einer Datenschutzprüfung. Nach dieser Prüfung wird das Auswertungssystem zunächst in einem Fachkonzept festgehalten und im Anschluss erfolgt eine ausführliche Abhandlung über die Bereitstellung der Datenhistorie des Team Foundation Servers. Nach einer detaillierten Beschreibung des Fachkonzeptes, soll die konkrete Umsetzung in ein IT-Konzept aufgezeigt werden. In einem letzten Schritt folgt die Evaluation des Auswertungssystems durch Mitarbeiter, um Nutzen, Umsetzbarkeit und Transparenz zu überprüfen.
11.02.19	2019	intern	Master	DE	Kompetenzentwicklung in MINT-Berufen - Ermittlung zukünftig notwendiger Kompetenzen mittels Machine Learning	Bei Bewerbungen auf verschiedene MINT-Berufe ist oft unklar, welche Kompetenzen für die Ausübung des jeweiligen Berufs erforderlich sind. Des Weiteren werden bei auf sich ähnelnden Positionen teilweise unterschiedliche Kompetenzen erwartet. Auch im Laufe der Zeit ändern sich die Erwartungshaltungen an einen Beruf. Daher stellt sich die Frage, welche Kompetenzen in Zukunft an MINT-Berufe gestellt werden könnten. In Stellenbeschreibungen von Jobbörsen werden Kompetenzen beschrieben, die von Bewerbern erwartet werden. Aus alten Datensätzen von Stellenbeschreibungen lassen sich darüber hinaus Erwartungen extrahieren, die in bereits abgelaufenen Stellenanzeigen an die Bewerber gestellt wurden. Diese Forschungsarbeit beschäftigt sich daher zunächst mit der Identifizierung von Kompetenzen aus aktuellen und vergangenen Stellenbeschreibungen, um auf deren Basis mögliche zukünftige Kompetenzen ermitteln zu können. Dafür wird zunächst ein gemeinsames Begriffsverständnis zwischen Leser und Autor geschaffen. Es werden die Begriffe Data Mining, Machine Learning und Kompetenz geklärt. Anschließend werden die notwendigen Arbeitsschritte erläutert, die für die Prognose der zukünftig notwendigen Kompetenzen nötig waren. Dazu gehören die Vorverarbeitung des vorliegenden Datensatzes sowie die Datenverarbeitung. Um eine möglichst genaue Prognose liefern zu können wird aus einem von zwei vorgestellten Machine Learning Modellen gewählt, auf dessen Basis dann die Vorhersage erfolgt.
14.02.19	2019	intern	Master	DE	Modellierung einer Customer-Journey-Map für die Informatik Fakultät der Technischen Hochschule Nürnberg Georg Simon Ohm	Die Laufbahn eines Studierenden hat viele unterschiedliche Abschnitte. Schon in der Phase der Suche nach einem Studienplatz hat ein künftiger Studierender Berührungspunkte mit einer Hochschule oder Universität. Ziel dieser Masterarbeit ist die Modellierung einer Customer-Journey-Map für die Informatik Fakultät der TH Nürnberg. Hierzu wird zunächst der Student Lifecycle der Studierenden ausgearbeitet. Anschließend werden die Aktivitäten, Erwartungen und Berührungspunkte der Studierenden mit der TH Nürnberg identifiziert und abgebildet. Die jeweiligen Aktivitäten und Erwartungen sind stets aus der Sicht des Studierenden zu betrachten. Mithilfe der Customer Journey werden diese Berührungspunkte analysiert. Schwachstellen in den sogenannten Touchpoints werden dokumentiert und mögliche Verbesserungsvorschläge ausgearbeitet.
25.02.19	2019	intern	Master	DE	Entwicklung und prototypische Umsetzung von Konzepten für digitale Bildungsmaßnahmen zur Unterstützung benachteiligter Studierender	Ziel der Masterarbeit war es, Konzepte für digitale Bildungsmaßnahmen zur Unterstützung benachteiligter Studierender zu entwickeln und prototypisch umzusetzen. Hierfür wurden zunächst die Personengruppen der benachteiligten Studierenden ermittelt. Für die Personengruppen wurden die Benachteiligungen ausgearbeitet. Aus den Benachteiligungen wurden die spezifischen Förderbedarfe abgeleitet. Anschließend wurden für die spezifischen Förderbedarfe digitale Bildungsmaßnahmen aufgezeigt, um die benachteiligten Studierenden in der digitalen Hochschulbildung zu unterstützen. Abschließend erfolgte eine prototypische Umsetzung der entwickelten Konzepte zur Unterstützung der benachteiligten Studierenden in der digitalen Hochschulbildung.
27.02.19	2019	extern	Bachelor	DE	Konzeption und Evaluierung eines agilen Vorgehensmodells und Realisierung im Bereich Intralogistik bei der Dematic GmbH	Agile Methoden sind in der Regel wirtschaftlicher und für Kunden transparenter als lineare Vorgehensmodelle. Deren Hauptproblem besteht darin, dass aufgrund logisch abgegrenzter Abläufe flexible Änderungen an der Software in späteren Phasen nicht umsetzbar sind. Die Dematic GmbH liefert intelligente Intralogistik-Lösungen für unterschiedliche Branchen und beschäftigt weltweit über 6000 Mitarbeiter. Die Bachelorarbeit befasst sich mit der Untersuchung des bestehenden Vorgehensmodells der Softwareentwicklung im Java-Bereich. Um den Ist-Zustand zu ermitteln und Schwachstellen zu identifizieren, werden unterschiedliche Verfahren angewendet. Anschließend wird ein Konzept auf Basis der agilen Methode Scrum erstellt. Mit Hilfe einer Machbarkeitsstudie sowie anschließender Realisierung im Bereich Intralogistik wird evaluiert, ob zukünftig ein agiles Vorgehen angewendet werden soll.
01.03.19	2019	extern	Bachelor	DE	Konzeption und Implementierung eines Codegenerators zur Exportierung eines in EB-GUIDE erstellten Modells nach HTML5	Die vorliegende wissenschaftliche Arbeit behandelt die Erstellung sowie anschließende Implementierung eines Konzeptes das es ermöglicht, ein in EB GUIDE Studio - ein Tool zur Modellierung von Human-Machine-Interfaces - erstelltes Modell nach HTML5 zu exportieren, ohne dabei die bereits bestehenden Konzepte und Features von EB GUIDE aufzubrechen. Hierbei wurde ein JSON-Exporter sowie ein Codegenerator erstellt, der es ermöglicht JavaScript-Module aus dem exportierten Modell zu erstellen. Des weiteren wurde zur Exportierung der eigens entwickelten Skriptsprache EB GUIDE Script ein JavaScript Transpiler entwickelt welcher den bestehenden Skriptcode in JavaScript-Code umwandelt. Zur Ausführung des exportierten Modells im Browser, wurde eine eigene Laufzeitumgebung in JavaScript entwickelt welche die existierenden Features und Konzepte in EB GUIDE beachtet.
04.03.19	2019	extern	Bachelor	DE	Entwerfen einer Referenzarchitektur für die Entwicklung und den Betrieb von Microservices	Gegenstand der hier vorgestellten Arbeit ist der Entwurf einer Referenzarchitektur für die Entwicklung und den Betrieb von Microservices. Diese, in Form eines Schaubilds, festgehaltene Referenzarchitektur entstand durch die Analyse der für Microservices relevanten Bereiche. Gegenüber einem Monolithen bieten Microservices zwar einige Vorteile, bringen jedoch auch neue Herausforderungen und Komplexität mit sich. Ziel der aufgezeigten Architektur ist es, den Umgang mit Microservices zu vereinfachen. Im Rahmen eines Beispiels aus der Praxis wird die Realisierbarkeit der entstandenen Referenzarchitektur sichergestellt.
15.03.19	2019	extern	Bachelor	DE	Konzeption und Kodierung einer unkonventionellen optoelektronisch lesbaren Schrift	Das Ziel der vorliegenden Arbeit war es ein Konzept für eine eigenen maschinenlesbare optische Code zu erstellen. Dieser Code soll sich insbesondere durch eine ästhetische und unauffällige Erscheinung auszeichnen und auf Papier oder Folie gedruckt werden können. Zu Beginn wurden die Anforderungen und die möglichen Anwendungsszenarien dokumentiert. Anschließend wurden verschiedene bestehende Codes, wie zum Beispiel der EAN-13 Strichcode und der QR Code, analysiert. Basierend auf verschiedenen Skizzen wurde eine Darstellungsmöglichkeit erarbeitet und die Kodierung von Daten konzipiert. Die Lösung hat eine Wellenform, trägt den Namen TimCode und kann bis zu 8 Byte an Daten abbilden. Es gibt mehrere Parameter um die genaue Darstellung zu beeinflussen und an die eigenen Wünsche anzupassen. Außerdem wurde eine ein Python Skript geschrieben um den Code zu generieren. Um das Einlesen des Codes zu demonstrieren, wurde eine Android Anwendung erstellt. Die Bildverarbeitungsbibliothek OpenCV wird verwendet um das Kamerabild zu verarbeiten und auszuwerten. Im Rahmen der Arbeit wurden auch die Lesegeschwindigkeit, Datenmenge und Ästhetik evaluiert. Zum Abschluss wurde noch ein Ausblick mit möglichen Verbesserungen und Erweiterungen gegeben.
15.03.19	2019	extern	Bachelor	DE	Entwicklung eines WebRTC-Dienstes mit dynamischer Netzwerktopologie	Ein Videokonferenzdienst kann nach verschiedenen Topologien aufgebaut sein. Weit verbreitet sind die direkte Peer-to-Peer Topologie Mesh, sowie die Sterntopologien Selective Forwarding Unit und Multipoint Conferencing Unit. Für unterschiedliche Anwendungszwecke kann jeweils eine andere Topologie sinnvoll sein. Deshalb wird im Rahmen dieser Arbeit untersucht, wie ein WebRTC Dienst entwickelt werden kann, der abhängig von der individuellen Videokonferenz die Topologie wechselt, um die bestmögliche Qualität zu erreichen. Die durchgeführten Wechsel der Topologie dürfen hierbei zu keiner Unterbrechung der Videokonferenz führen. Um diese Frage zu beantworten wird ein solcher WebRTC Dienst mit dynamischer Netzwerktopologie implementiert. Es werden die technischen Hürden der Entwicklung erläutert wie die automatische Wahl der Topologie und der unterbrechungsfreie Topologiewechsel. Abschließend werden Tests mit der entwickelten Software durchgeführt, die zeigen, dass die automatisch durchgeführten Topologiewechsel die Videoqualität verbessern. Auch dass der Wechsel zwischen den Topologien ohne Unterbrechung der Videoübertragung verläuft, wird durch Tests bestätigt.
18.03.19	2019	intern	Bachelor	DE	Konzeptionierung und Evaluation der Einbindung eines Force Feedback Geräts in eine VR Umgebung	Haptische Wahrnehmung ist ein Teil der Mensch-Computer-Interaktion in einer virtuellen Realität. Es existieren Geräte, welche ein haptisches Feedback durch eine einfache Vibration ausgeben. Komplexere Geräte benutzen Mechanismen, die eine Gegenkraft als haptisches Feedback ausgeben. In der vorliegenden Arbeit beschäftigt sich damit das kraft-reflektierende, haptische Gerät Phantom Premium 1.5 in die VR-Entwicklungsumgebung ''Unity'' einzubinden. Dazu wird ein System zum Austausch der Daten nach dem Client-Server Modell entwickelt, welches das haptische Gerät in Unity ansteuern soll. In einem Prototyp wird mithilfe der Virtual Reality Modeling Language haptische Objekte erzeugt, die in das mitgelieferten Software Toolkit importiert werden. In einem weiteren Versuch wird mit der Penalty Based Method und dem Hookschen Gesetz ein haptischer Render Algorithmus entwickelt, um ein haptisches Feedback zu erzeugen. Eine Evaluation wird im Rahmen dieser Arbeit nicht durchgeführt.
19.03.19	2019	extern	Master	DE	Performance-Analyse populärer Web-Frontend Frameworks	Ziel der Masterarbeit ist die Herausarbeitung eines gültigen Vergleichs dreier Frontend-Frameworks im Hinblick auf deren Performance. Diese werden am Beispiel einer exemplarischen Anwendung gegenübergestellt. Es wird hinterfragt warum Performance in moderner Webanwendungen essentiell ist und ein Überblick über bekannte und allgemeingültige Ansätze der Performance-Optimierung für Entwickler gegeben und deren Auswirkungen erfasst. Daraufhin werden passende Performance-Metriken und hilfreiche Tools gelistet. Anhand von Statistiken werden drei Frontend Frameworks ausgewählt, die im nachfolgenden für die Implementierung herangezogen werden. Die bestehende Anwendung wird dabei in Angular 7, React und Vue implementiert. Es werden die Besonderheiten des jeweiligen Frameworks herausgearbeitet, die Reimplementierung nachvollzogen, Gründe für deren performantes Verhalten untersucht und mögliche Optimierungen ans Licht gebracht. Im Nachfolgenden wird in einem Vergleich gegenübergestellt, welches Framework am besten bei der Performance abschneidet. Dies erfolgt über Synthetic Tests. Die zuvor erfassten Performance-Metriken dienen dabei als Maßstab und zum Nachweis der Optimierung. Ein letzter allgemeiner Vergleich der Front-End-Frameworks gibt Aufschluss darüber wann welches Framework am besten zum Einsatz kommen sollte und wie dessen Beliebtheit am Markt ist. Die Arbeit endet mit einer Zusammenfassung der Ergebnisse, Ausblick und Diskussion.
20.03.19	2019	intern	Bachelor	DE	Anwendung einer Gamification-Mustersprache zur Verbesserung der motivationalen Wirkung von Lehrveranstaltungen an Hochschulen	Das Ziel der Bachelorarbeit ist es, motivationale Probleme von Lehrveranstaltungen an Hochschulen zu identifizieren und die Anwendbarkeit der Gamification-Mustersprache aus dem Forschungsprojekt "Empirische Analyse motivierender Spielelemente zur Entwicklung einer Gamification-Mustersprache" zur Lösung von konkreten Problemstellungen in der Praxis zu überprüfen. Hierzu werden die motivationalen Probleme der Lehrveranstaltungen analysiert und diese durch Kombination spezifischer Spiel-Design-Elemente aus der Mustersprache des EMPAMOS-Projektes zu bestimmten Spielelementkombinationen gelöst. Dabei wird bewertet, wie sich der aktuelle Enwicklungsstand der Mustersprache für diese Problemlösung eignet. Zusätzlich wird ermittelt und beschrieben, wie sich die Spielelementkombinationen realisieren lassen.
21.03.19	2019	extern	Bachelor	DE	Entwicklung eines KI-basierten Answer Bots zur Lösung von Low-Touch-Tickets für ein Helpdesk-System	Diese Bachelorarbeit befasst sich mit der Entwicklung des KI-basierten Answer-Bots. Dieser soll zu häufig auftretenden Supporttickets, geeignete Einträge aus der Wissensdatenbank finden, wobei für diesen Zweck Maschinelles Lernen eingesetzt wird. Hierfür werden zunächst die notwendigen Grundlagen erläutert, bevor für diesen Anwendungsfall ein Konzept entwickelt wird. Bei der Konzeption des Answer-Bots wird ein weiteres Programm vorgestellt, dass mithilfe der Kosinus-Ähnlichkeit aus den gespeicherten Tickets und Einträgen der Wissensdatenbank einen markierten Datensatz erstellt. Bei der Implementierung werden verschiedene Methoden zur Erstellung der Merkmalsvektoren sowie zwei Lernalgorithmen zum Trainieren eines Modells miteinander verglichen. Dabei erzielt eine Support Vector Machine mit Tf-Idf Gewichten als Merkmalsvektoren die besten Ergebnisse, für den verwendeten Datensatz. Abschließend werden kurz mögliche Verbesserungen des Answer-Bots aufgezählt.
21.03.19	2019	intern	Master	DE	Räumliche Sonifikation für sehbeeinträchtigte Menschen in Form eines Augmented Reality Zeilenscanners	Das Wissenschaftsfeld der Sonifikation bietet vielversprechende Ansätze, um die physiologischen und pathologischen Einschränkungen des menschlichen Körpers im Hinblick auf die audiovisuelle Wahrnehmung zu verbessern. Dabei werden räumliche Informationen von, sowohl physikalischen als auch virtuellen Objekten, im unmittelbaren Kontext des Nutzers als non-verbaler Sound wiedergegeben. Bei der konkreten Implementierung und akustischen Modellierung gibt es jedoch noch viele unterschiedliche Ansätze. Diese wissenschaftliche Arbeit widmet sich der Evaluierung eines sequentiellen Scanverfahrens in einer gemeinsamen Benutzerstudie unter Beteiligung von sehbehinderten und blinden Personen. Ziel ist es zu bestimmen, ob ein räumliches Verständnis besser durch die akustische Dimension der Frequenz, oder der Amplitude gefördert werden kann. Das Scanverfahren wurde durch die Verwendung einer "Microsoft HoloLens" und eines "RPLIDAR A2" Laserscanners umgesetzt. Dieser Forschung gelang es herauszufinden, dass ein genaueres räumliches Verständnis durch Sonifikation anhand Frequenzänderung in signifikant kürzerer Zeit geschieht als durch eine Änderung der Amplitude. Die Benutzerfreundlichkeit des, mit der HoloLens umgesetzten, Zeilenscanners wurde höher eingestuft als die des LIDAR-Prototyps. Der Autor erhofft sich durch diese Antworten Erkenntnisgewinn, welcher insbesondere sehbehinderten Menschen zu Nutze kommen soll.
22.03.19	2019	intern	Master	DE	Analyse von E-Learning im Studium und empirischer Vergleich zu traditionellen Lehreinheiten zur Ableitung von Empfehlungen bezüglich des Einsatzes von E-Learning-Elementen	Während digitale Angebote an Hochschulen als Ergänzung zum traditionellen Unterricht bereits breiten Einsatz finden, sind E-Learning-Kurse als Alternative zum traditionellen Unterricht an Präsenzhochschulen seltener vertreten. In diesem Zusammenhang stellt sich die Frage, ob die Vorteile der Digitalisierung in diesem Bereich weniger ausschlaggebend sind und traditionelle Lehrmethoden im Vergleich zu einem besseren Lernergebnis führen, oder ob E-Learning-Kurse ein zumindest gleichwertiger Ersatz sein können. Zur Ermittlung für die Fragestellung relevanter Parameter ist ein möglicher Ansatz die Durchführung eines empirischen Vergleichs von zwei Studierendengruppen, die inhaltlich identische Lehreinheiten mit jeweils der anderen Lehrform erhalten. Durch eine Prüfung können die jeweiligen Lernerfolge quantitativ gemessen und unterschiedliche E-Learning-Elemente evaluiert werden. Um damit zusammenhängenden Faktoren berücksichtigen zu können, kann eine empirische Befragung zur Akzeptanz oder Erfahrung mit E-Learning erfolgen. Zudem können zur Erweiterung des Betrachtungsumfelds auch andere Studien einbezogen werden, die beide Lehrformen gegenüberstellen. Ziel ist es Potentiale und Hindernisse von E-Learning als alternative Lehrmethode im Hochschuleinsatz zu erfassen, um Rückschlüsse für die Entwicklung, Weiterentwicklung, Optimierung und Einsatzform neuer oder bestehender E-Learning-Angebote zu ziehen.
22.03.19	2019	extern	Master	DE	Einsatz maschineller Lernverfahren zur Genre-Klassifizierung von Brettspielen	Neben anderen Bereichen hat der Digitalisierungsprozess auch in der Brettspielindustrie begonnen. Dabei können maschinelle Lernverfahren helfen, effizient mit den großen Datenmengen umzugehen. Eine potentielle Aufgabe von maschinellen Lernverfahren besteht in der Erstellung und Zuweisung von Klassen. Hierfür findet sich im Genre eine mögliche Klassifizierungsart. Diese Arbeit hat das Ziel, Genre-Kandidaten aus den Spielen zu ermitteln und diese anschließend zuzuweisen. Dafür werden Verfahren aus dem Bereich Topic Modeling als Grundlage verwendet, wobei ausschließlich die Algorithmen LDA, HDP und LSA getestet wurden. Eine theoretische Auseinandersetzung mit pLSA wird jedoch zusätzlich beschrieben. Außerdem werden mehrere Modelle eines Algorithmus zusammen in einem Ensemble-Learning-Ansatz verwendet. Beim Topic Modeling entstehen gewichtete Wortlisten, die für verschiedene Themen stehen. Aus diesen Wortlisten können mit weiteren Verfahren Genres interpretiert und anstelle der Themen an die Spiele vergeben werden. In dieser Arbeit wird für die Themeninterpretation das Word-Embedding-Verfahren Word2Vec genutzt. Die entwickelten Methoden wurden für zwei Datensätze getestet. Zur Beurteilung der Ergebnisse daraus fanden in verschiedenen Phasen Evaluierungen beim Deutschen Spielearchiv Nürnberg statt. Bei der abschließenden Evaluierung erhielten die Ergebnisse eine durchschnittliche Bewertung zwischen "Beschreibt das Spiel zum Großteil" und "Beschreibt das Spiel vollständig".
25.03.19	2019	intern	Bachelor	DE	Erstellung einer Webanwendung zur Visualisierung sozialwissenschaftlicher Texte	In dieser Bachelorthesis wird das Thema Textanalyse, -aufbereitung und -visualisierung wissenschaftlich betrachtet. Es werden verschiedene Modelle und Methoden betrachtet und gezeigt, welche Visualisierungsmöglichkeiten für die Daten existieren und anhand welcher Variablen diese bestimmt werden. Außerdem lernt man Tools und Frameworks der Textvisualisierung zum selber ausprobieren kennen und sieht, welche davon für diesen Sachverhalt passend ausgewählt wurden. Des Weiteren wird das Forschungsprojekt "Computerunterstützte Analyse Sozialwissenschaftlicher Texte" (Casotex) erläutert und näher auf das Teilprojekt "Visuelle Analyse sozialwissenschaftlicher Texte" (Casovis) eingegangen. Dieses wurde von der Fakultät Sozialwissenschaft, Fakultät Informatik und dem Institut für E-Beratung ins Leben gerufen. In dieser Bachelorarbeit erfährt man die Ziele, die Hintergründe und das Vorgehen dieses Projektes. Es wird die Webanwendung Casovis beschrieben und alle dazugehörigen Anforderungen aufgeführt. Man sieht wie der aktuelle Stand der Anwendung ist und welche Funktionen vorhanden sind. Die Benutzung dieser wird auch erklärt. Außerdem wird darauf eingegangen welche Funktionen es in Zukunft noch geben wird.
28.03.19	2019	extern	Bachelor	DE	HR-Cloud-Transformation - Analyse zur Auswahl einer Digital Adoption Platform für SAP SuccessFactors in der Schaeffler Gruppe 	Für die Einführung von SAP SuccessFactors werden im Rahmen eines Harmonisierungsprojektes die Prozesse global an die Lösung angepasst. Folglich muss weltweit den Systemanwendern neues Prozesswissen und der Umgang mit der Software SAP SuccessFactors vermittelt werden. Die zukünftigen Nutzer der Software sollen durch den Einsatz einer geeigneten Digital Adoption Platform (DAP), die dem Benutzer interaktive Schritt für Schritt Touren durch die Prozesse zur Verfügung stellt, dabei unterstützt werden, sich das neue Prozesswissen und den Umgang mit einer neuen Software anzueignen. Außerdem soll der Anwender bei auftretenden Schwierigkeiten in einem Prozessschritt durch eine kontextbezogene Hilfe Unterstützung erhalten. Dabei wurden im Rahmen der Bachelorarbeit die Anbieter Userlane und WalkMe im Hinblick auf ihre Eignung analysiert. Dargestellt wurde dabei der Ist- und Soll-Zustand, wie explizites HR-Prozesswissen im Unternehmen aktuell und zukünftig durch den Einsatz einer DAP bereitgestellt werden könnte. Zudem zeigten Experteninterviews, welche Potentiale interne Mitarbeiter bei einem Einsatz sehen. Außerdem wurden im Rahmen der Befragungen Anforderungen aufgenommen, die an eine DAP und den zugehörigen Anbieter bestehen. Durch den anschließenden Einsatz einer Nutzwertanalyse konnte die DAP identifiziert werden, die in Hinsicht auf den Leistungsumfang die Bedürfnisse des Unternehmens am besten erfüllen kann und eine Handlungsempfehlung für die Anbieterauswahl abgeleitet werden.
01.04.19	2019	extern	Bachelor	DE	Prototypische Implementierung eines interaktiven Analyse-Dashboards auf Basis des referenzierten DATEV-Jahresabschlusses 	Externe Adressaten wie z.B Steuerberater benötigen aussagekräftige Berichte und Dashboards, um sich einen schnellen Überblick über die wirtschaftliche Lage ihrer Mandanten zu verschaffen und so eine tiefergehende betriebswirtschaftliche Beratung leisten zu können. Zielsetzung der Bachelorarbeit liegt darin, ein Dashboard auf Basis des referenzierten DATEV-Jahresabschlusses als Prototyp zu realisieren.
01.04.19	2019	extern	Bachelor	DE	Entwicklung und Implementierung eines Konzepts für die Automatisierung von administrativen Prozessen des User-Managements für Unix-Systeme	Unternehmen der freien Marktwirtschaft sind stehts angehalten sich weiterzuentwickeln und auf neue Technologien und Innovationen zu reagieren. Dabei ist dies nicht ohne genaue Analyse ihrer internen Prozesse und zur Verfügung stehenden Möglichkeiten umsetzbar. Es gibt viele Technologien die Großes versprechen, dies aber auch nur unter speziellen Gegebenheiten liefern. Das Ziel dieser Forschung ist es zu bestimmen, welche Möglichkeiten der Modernisierung einem Prozess der Administration zur Verfügung stehen und wie diese abhängig der Systemstruktur genutzt werden können. Dabei steht im Vordergrund den bisherigen Zustand der Systeme zu beachten und so nur wirklich sinnvolle Modernisierungen im Rahmen dieser Arbeit in Betracht zu ziehen. Dazu wurde ein solcher Prozess in der Form der Rechtevergabe von UNIX-Systemen innerhalb der DATEV eG genauer untersucht. Mit einer Analyse des bisherigen Zustands und verbreiteten Umsetzungen konnte so entschieden werden, dass eine Automatisierung mit Hilfe der bereits eingesetzten Technologien als vielversprechendes Konzept gilt. Eine anschließende Umsetzung zeigte auf, dass zwar viele Hürden durch verwachsene und veraltete Systeme in großen Systemlandschaft genommen werden müssen, diese sich aber durch klare Effizienz- und Effektivitätssteigerungen auszahlen. Neuere Technologien wurden als weitere Möglichkeiten angesehen, auf die Prozesse angewandt zu werden, benötigen aber zusätzliche, vertiefte Forschungen.
01.04.19	2019	extern	Bachelor	DE	Konzeption und Implementierung effizienter, paralleler Datenzugriffe für einen C#-basierten Webdienst	Die DATEV eG bietet eine Desktopanwendung zur Erstellung der Finanzbuchführung von Unternehmen an. Analog dazu wird eine Webanwendung entwickelt, die die gleiche Funktionalität zur Verfügung stellt. Um die Wartung sowie die Weiterentwicklung der Komponente zu erleichtern, sollen die Datenzugriffe beider Anwendungen vereinheitlicht werden. Das Ziel dieser Arbeit ist die Erarbeitung eines einheitlichen Konzepts für die Datenverwaltung sowie die Datenzugriffe, bei dem die Anforderungen beider Anwendungen zu berück-sichtigen und aufeinander abzustimmen sind. Angestrebt wird außerdem, durch das neue Konzept die Dauer der Datenermittlung zu reduzieren. Dazu wurden zunächst die Systemarchitekturen sowie die aktuell umgesetzten Lösungen der Anwendungen analysiert. Auf Basis der Ergebnisse wurde ein Konzept für eine anwendungsübergreifende Datenverwaltung entwickelt und implementiert, die sowohl auf hochgradig parallelisierte als auch auf sequentielle Datenzugriffe ausgelegt ist. Die nach der Umsetzung des neuen Konzepts durchgeführten Tests zeigen, dass die Ermittlungsdauer der Daten im Vergleich zur heutigen Umsetzung teilweise erheblich reduziert werden konnte. Bei keinem der Tests wurden eine erhöhte Vorgangsdauer festgestellt. Die durch die Konzeption und Implementierung gewonnen Erkenntnisse werden bei Neu- und Weiterentwicklungen von Anwendungen der DATEV eG berücksichtigt und sofern sinnvoll, wiederverwendet.
01.04.19	2019	extern	Bachelor	DE	Konzeption und Implementierung eines Tools zum Auslesen von Energiezählern über das Modbus-Protokoll bei der ProleiT AG 	Es wurde ein Tool entwickelt mit dem es möglich ist, Energiezähler über ein bestehendes Netzwerk, mithilfe des Modbus-Protokolls auszulesen. Sowohl die Konzeptionierung als die Implementierung wurde behandelt. Dies geschah in Zusammenarbeit mit der Firma ProLeiT AG.
03.04.19	2019	intern	Bachelor	DE	Einsatz maschineller Lernverfahren zur Entitätserkennung in der Trendanalyse	Ziel der Arbeit ist die Konzeptionierung eines lernfähigen Prototyps, der aus Texten Entitäten erkennt. Diese Entitäten sollen in einem Wissensgraphen geschrieben werden. Anhand der Veränderung des Wissensgraphen lassen sich Trends ablesen. Erkannte Entitäten müssen disambiguiert, vereinheitlicht und verlinkt, sein, um möglichst viele Informationen aus bestehenden Wissensgraphen einzubeziehen. Der Prototyp soll als eigener Service betrieben werden können und aus frei verfügbaren Tools sowie Frameworks bestehen. Kern des Projektes ist die Arbeitsgruppe Future Engineering. Teil dieser Gruppe ist die TH-Nürnberg, vorrangig mit der Fakultät BW. Ein weiterer Projektbeteiligter ist das Fraunhofer Institut SCS aus Nürnberg. Abschließend gehört Trivadis zur Arbeitsgruppe. Trivadis ist ein Beratungsunternehmen mit Hauptsitz in der Schweiz. Der Prototyp misst sich mit dem Tool TextRazor. Dieses bietet NLP als kostenpflichtigen Service für größere Datenmengen an. TextRazor ist dem Prototyp in Quantität wie auch Qualität überlegen. Im Rahmen der Evaluation sind die folgenden Verbesserungsmöglichkeiten ableitbar. Um die Quantität zu verbessern, empfiehlt sich eine Aufteilung mehrgliedriger Entitäten in deren Bestandteile. In der Disambiguierung ist der Prototyp 5 % besser als TextRazor. Die Zielstellungen, nur aus freien Tools und Frameworks zu, ist ebenfalls erreicht. Eine LernfähiLernfähigkeit ist durch die Trainierbarkeit der eingesetzten Tools Spacy und Flair gegeben.
03.04.19	2019	intern	Bachelor	DE	Big Data Log-File Analytics - Vom Batch zum Stream Konzeption und prototypische Implementierung eines REST-Webservice zum Streaming von Messwerten der DATEV Programmstatistik 	Um Auswertungen über die Nutzung der DATEV-Software tätigen zu können, existiert die sogenannte Programmstatistik. Hierbei werden mit der Einwilligung des Kunden (Anwenders) die Nutzerdaten erfasst und im Rechenzentrum der DATEV gespeichert. Die Daten werden als LogFiles über eine HTTPS-Verbindung an den Trackingserver von Mindlab, einem externen Anbieter, gesendet und anschließend durch ein Batch-Verfahren in einem Datenbank-Cluster abgespeichert. Das Ziel der Arbeit besteht darin, die Abhängigkeit vom Fremdanbieter abzuschaffen, indem der Tracker von Mindlab durch eine eigene Lösung, in Form eines Prototypen, ersetzt wird. Zusätzlich wird eine Streaming-Architektur konzeptioniert, die als Alternative zum bisherigen Batch-Verfahren dient. Im Rahmen einer Anforderungsanalyse wird zunächst evaluiert, welche Funktionalitäten der Prototyp abbilden soll. Weiterhin wird untersucht, welche Voraussetzungen zum Streamen von Daten bestehen. Die gesammelten An-forderungen werden durch ein Architekturkonzept abgebildet und anschließend die ver-wendeten Entwicklungswerkzeuge in der Implementierungsphase dargestellt. Das Ergebnis ist ein Springboot-Webservice, der als Prototyp konzeptioniert und entwickelt wurde und die Entgegennahme von Nutzerdaten im JSON-Format sowie das Abspeichern der Nutzerdaten in einer Dokumentendatenbank ermöglicht. Weiterhin wurde eine Architektur konzeptioniert, die den Einsatz einer Kafka-Pipeline berücksichtigt, um die Messwerte bereitzustellen.
05.04.19	2019	intern	Bachelor	DE	Objekterkennung mittels neuronaler Netze zur Anwendung in der Robotik	Das in dieser Arbeit behandelte Kernthema, das Erkennen von Objekten in Bilddaten, stellt ein komplexes Problem dar, weil geometrische Körper durch ihre Lage im Raum, deren Beleuchtung und der Abbildung von drei auf zwei Dimensionen viele unterschiedliche visuelle Darstellungen einnehmen können. Das Ziel dieser Arbeit ist es, eine Software zu entwerfen und zu implementieren, die in der Lage ist Bilddaten mithilfe neuronaler Netze so auszuwerten, dass alle vorher trainierten Objekte mit einer für den praktischen Einsatz signifikanten Genauigkeit erkannt werden können. Nach einer Einarbeitung in "Convolutional Neural Networks", ist geplant, diese zur oben beschriebenen Auswertung einzusetzen. Nach der Einarbeitung in "Convolutional Neural Networks", wird eine noch zu findende konkrete Referenzarchitektur gewählt. Nach dem Training des Modells mit offen zugänglichen Bilddatenbanken, wie zum Beispiel dem Open Image Dataset, soll der Roboter dazu in der Lage sein, zweidimensionale Bilddaten an eine Schnittstelle, welche das Modell anspricht, zu senden und als Resultat die zugehörigen Objekt-Klassifizierungen zurückgeliefert zu bekommen. Abschließend soll ein interaktives, inkrementelles Lernen implementiert werden. Dafür werden dem Roboter zu erlernende Objekte präsentiert, die dem Modell dann über "Incremental Learning" beziehungsweise "Online Learning" zugeführt werden.
08.04.19	2019	extern	Bachelor	DE	Konzeptionierung und Implementierung einer prototypischen, webbasierten Oberfläche zur elektronischen Prüfung von Eingangsrechnungen in Kooperation mit der DATEV eG	Durch die Digitalisierung der Arbeitswelt und ihrer Prozesse beschleunigen sich Arbeitsabläufe in Unternehmen zunehmend. Im Zuge dessen steht eine fehlerfreie Verarbeitung betrieblicher Dokumente im Fokus eines jeden einzelnen Unternehmens. Unter verschiedenen Dokumentenarten sind es vor allem Rechnungsdokumente, die für Firmen monetäre Verbindlichkeiten mit sich bringen. Damit ausschließlich syntaktisch und semantisch korrekte Rechnungen intern weiterverarbeitet werden, bedarf es einer softwarebasierten Lösung, welche die erforderlichen Arbeitsschritte für den Benutzer angenehm gestaltet und wenn möglich sogar automatisiert. Im Rahmen dieser Arbeit wird deshalb eine webbasierende, prototypische Oberflächenanwendung für die DATEV eG konzipiert und anschließend implementiert, die sowohl die manuelle Prüfung, als auch exemplarisch die automatisierte Prüfung von Rechnungsdokumenten abbildet. Durch die hinzugewonnenen Automatisierungsroutinen in der neu konzeptionierten Anwendung gewinnt die Lösung an Attraktivität für Unternehmen, deren Effizienz im Prüfungsworkflow durch diese Lösung gesteigert werden kann. Zusätzlich bietet eine webbasierende Lösung für Mitarbeiter in Unternehmen und Kanzleien neue Möglichkeiten, da der Rechnungsprüfungsprozess mobil verfügbar gemacht wird. Eine intuitiv gestaltete Oberfläche des Prototypen nach zeitgemäßen Usability Anforderungen trägt ebenfalls zu einem professionellen und zugleich effizienten Einsatz eines neu
09.04.19	2019	extern	Bachelor	DE	Migration einer nativen Desktopanwendung in eine Webanwendung: Konzeptionierung und prototypische Implementierung für das ERP-System v.Soft der Firma Vepos GmbH & Co. KG	Die vorliegende Arbeit wird in Kooperation mit der Firma Vepos GmbH & Co. KG verfasst, wobei deren eigene ERP Software v.Soft als Referenz dient. Die bisherige Version der Software besitzt einige signifikante Schwachstellen. Aus diesem Grund wird in der Arbeit die Migration von v.Soft in eine Webanwendung betrachtet. Zunächst wird die bereits vorhandene Software untersucht, wobei grundlegende Nachteile und daraus resultierende Problem kritisch betrachtet werden. Aus der Analyse der vorhandenen Schwachstellen wird die Notwendigkeit von neuer Technologie diskutiert. Während der Konzeptionsphase werden Anforderungen definiert, der Einsatz der verwendeten Designsprache vorgestellt und anwendbare Technologien verglichen. Die darauffolgende Implementierung besteht aus der Vorstellung der eingesetzten Technologie sowie der Umsetzung des Prototyps. Die Umsetzung der Anwendung besteht aus den beiden Komponenten Frontend und Backend. Für das Frontend wird zunächst eine grundlegende Anwendung entwickelt. Die entstehende Anwendung wird durch die Umsetzung von verschiedenen Masken erweitert. Das Backend stellt eine RESTful-API dar und verwaltet die Kommunikation zwischen Client und Datenbank. Als Resultat der Arbeit entsteht eine plattformunabhängige Webanwendung, die sowohl als Desktopanwendung als auch als Android-App vorliegt. Dadurch soll die theoretische Durchführbarkeit der Migration in eine Webanwendung bestätigt werden.
11.04.19	2019	intern	Master	DE	Konzeption eines Assistenzsystems zur Unterstützung von Studieninteressierten bei der Entscheidung für ein MINT-Studium	Damit es im nachgelagerten Studienverlauf nicht zum Studienabbruch kommt, wird auf Basis einer Anforderungserhebung und einer Analyse des aktuellen Beratungsangebotes der TH Nürnberg ein Assistenzsystem für Studieninteressierte konzipiert und prototypisch umgesetzt. Anschließend erfolgt eine Untersuchung der Prototypen in einem Testpanel, gefolgt von der Analyse der Versuchsergebnisse und einem Ausblick auf die weitere Umsetzung. Ziel bei der Konzeption dieses Assistenzsystems war die Unterstützung von Studieninteressierten von in MINT-Studiengängen unterrepräsentierten Gruppen (z.B. Studierende aus nicht-akademischen Haushalten, Studierende mit Migrationshintergrund, ?), indem diesen bereits im Vorfeld des Studiums eine Einschätzung ermöglicht wird, ob bzw. unter welchen Voraussetzungen ein Studium im MINT-Bereich wahrscheinlich erfolgreich abgeschlossen werden kann. Dazu wurden auf Basis wissenschaftlicher Studien sowie von Studierendendaten und Forschungsarbeiten der TH Nürnberg die Gründe für einen Studienabbruch und die Zusammenhänge zwischen einer Zugehörigkeit zu im Studienumfeld unterrepräsentierten Gruppen und dem Abbruch des Studiums untersucht. Unter Einbezug des vorhandenen Beratungsangebotes der TH Nürnberg erfolgte dann die Konzeption eines Assistenzsystems, das die bereits vorhandenen Angebote der Hochschule sinnvoll ergänzt und dadurch die Zielgruppe bereits in der Orientierungsphase vor einem Studium unterstützt.
11.04.19	2019	intern	Master	DE	Konzeption eines Frühwarn- und Assistenzsystems zur Bewahrung von MINT-Studierenden vor einem Studienabbruch	Um gefährdete Studierende vor einem Studienabbruch zu bewahren, sollen diese frühzeitig erkannt und durch geeignete Maßnahmen und Leistungen aktiv unterstützt werden. Der Fokus liegt auf Studierende in MINT-Studiengängen, die einer minderpräsentierten Studierendengruppe (z.B. Studierende aus nicht-akademischen Haushalten, mit Migrationshintergrund, ?) angehören. Hierfür soll ein Frühwarn- und Assistenzsystem konzipiert und prototypisch als webbasiertes Portal implementiert werden, indem sich Studierende über digitale Bildungsmaßnahmen, wie Beratungsangebote und Hilfeleistungen, informieren und bei Bedarf in Anspruch nehmen können.
11.04.19	2019	intern	Bachelor	DE	Nutzen und Grenzen von sozialen Netzwerkanalysen im Unternehmen	Die vorliegende Arbeit behandelt die Fragestellung, wie Unternehmen von sozialen Netzwerkanalysen profitieren können. Es werden die Grundlagen der sozialen Netzwerkanalyse und ihre Einsatzmöglichkeiten in einem Unternehmen erläutert. Dabei erfolgt eine Vorstellung zentraler Konzepte dieser Methode sowie die Erklärung wichtiger Grundbegriffe. Das Potenzial der sozialen Netzwerkanalysen wird anhand einiger Anwendungsszenarien erörtert und ihr Nutzen für ein Unternehmen wird dargestellt. Die Phasen einer organisationalen Netzwerkanalyse werden anhand zweier Verfahren aus der Fachliteratur beschrieben. Anschließend werden die Datenerfassung, die Datenaufbereitung und die Analyse informeller Netzwerke behandelt und die Herausforderungen, die damit verbunden sind, dargelegt. Abschließend wird eine exemplarische Analyse anhand einer fiktiven Fallstudie beschrieben, bei der die Zusammenarbeit innerhalb eines Thinktanks mithilfe der organisationalen Netzwerkanalyse untersucht wird. Die Auswertung von Fachliteratur bildet die Grundlage für die Beantwortung der Fragestellung.
25.04.19	2019	extern	Bachelor	DE	Konzeption, prototypische Entwicklung und Implementierung eines Scrumpoker-Plugins für die Portal-Software Liferay	Im Rahmen dieser Bachelorarbeit wird ein Scrumpoker Plugin in Zusammenarbeit mit der Ancud IT-Beratung GmbH entwickelt. Dafür werden zwei verschiedene Tools untersucht, welche zum Schätzen von Anforderungen in der agilen Methode Scrum verwendet werden. Durch die Ist- und Schwachstellenanalyse haben sich Defizite herausgestellt, wodurch diese Tools in Projekten bei der Ancud nicht weiter genutzt werden konnten. Besonders die räumliche Trennung der einzelnen Teammitglieder stellt eine große Herausforderung dar. Anhand der gewonnenen Erkenntnisse werden Anforderungen definiert, die in dem eigens entwickelten Tool umgesetzt werden. Die Entwicklung des Tools basiert auf einem der Kernprodukte der Ancud IT, dem Liferay Portal. Die Version, die für die Umsetzung verwendet wird, ist die Liferay Portal CE 7.1 Version, welche zu Beginn der Bachelorarbeit die aktuelle Version ist. Für die Umsetzung wird auf das dynamische Komponentenmodell OSGi zurückgegriffen, welches eines der Kernbestandteile in der Entwicklung in Liferay darstellt. Verwendet wird in der Entwicklung ein Liferay Portlet sowie der Liferay Service Builder. Anhand eines geeigneten Datenbankschemas wird das Backend entwickelt. Das Frontend basiert auf Java Server Pages in Zusammenhang mit dem AUI und JQuery Framework. Der Austausch der Daten zwischen dem Frontend sowie dem Backend basiert auf dem Liferay Portlet Lifecycle.
25.04.19	2019	extern	Bachelor	DE	Entwurf und Realisierung eines Konzepts zur sicheren und zuverlässigen Integration einer Software-as-a-Service	Das Ziel der vorliegenden Bachelorarbeit war es, ein Konzept zur Integration einer Software-as-a-Service in die bestehende Infrastruktur der DATEV eG zu entwickeln. Dabei stand die Konzeption eines sicheren und zuverlässigen Integrationssystems im Zentrum dieser Arbeit. Hierfür wurden zunächst allgemeine Gefährdungen, die bei der Integration einer Software-as-a-Service zu berücksichtigen sind, identifiziert. Anschließend wurden die Anforderungen analysiert, die für ein sicheres und zuverlässiges Integrationskonzept erforderlich sind. Auf dieser Basis konnte ein Integrationssystem konzipiert werden, das den Gefährdungen entgegenwirkt. Zum Schluss wurde dieses Konzept anhand der vorher ermittelten Anforderungen evaluiert und eine Realisierungsmöglichkeit aufgezeigt. Es hat sich gezeigt, dass die identifizierten Anforderungen größtenteils im Rahmen des Konzepts erfolgreich berücksichtigt werden konnten, jedoch einzelne Maßnahmen in Form einer Softwarelösung realisiert werden müssen. Diese Realisierung wurde anhand eines Beispiels erläutert.
25.04.19	2019	extern	Bachelor	DE	Prototypische Entwicklung einer Webanwendung zur Administration projektspezifischer Hardware bei der e.solutions GmbH	Die e.solutions GmbH entwickelt Infotainment-Systeme für den Volkswagen-Konzern. Um die Systeme entwickeln und testen zu können, arbeiten die Mitarbeiter an ihrem Arbeitsplatz mit sogenannter projektspezifischer Hardware. Hierzu zählen jegliche Komponenten, die später in den Fahrzeugen verbaut werden. In der Vergangenheit ist es bei der Administration und Nachverfolgung dieser Hardware oft zu Schwierigkeiten gekommen. Im Rahmen dieser Arbeit wurden die Prozesse zur Administration der Hardware erfasst, analysiert und optimiert. Zur Unterstützung der Prozessabläufe wurde prototypisch eine Webanwendung entwickelt. Die Prozesse wurden dabei mithilfe der Business Process Model and Notation (BPMN) Spezifikationssprache dokumentiert. Zusätzlich sollte überprüft werden, ob die aktuelle Inventarsoftware zur unternehmensweiten Inventarisierung der Projekthardware durch eine geeignete Standardsoftware ersetzt werden kann. Diese Evaluation ist während der Arbeit relativiert worden, weil ein Team des Unternehmens bereits eine Standardsoftware namens Insight eingeführt hat. Die Standorte sind bezüglich des Einsatzes der Standardsoftware geteilter Meinung, weshalb für eine Einhaltung des zeitlichen Rahmens der Arbeit die Annahme getroffen werden musste, dass die Standardsoftware eingesetzt wird. Der resultierende Prototyp basiert auf dieser Annahme.
29.04.19	2019	extern	Master	DE	Klassifikation und Informationsgewinnung bei bankrelevanten Texten durch den Einsatz von maschinellen Lern- und Textanalyse-Verfahren	Banken und Finanzinstitute sind zahlreichen Regularien der deutschen und internationalen Behörden ausgesetzt. Damit diese nicht selbst nach neuen Regularien suchen müssen, wurde im Vorfeld dieser Arbeit bereits ein Webcrawler von Blue Reply erstellt. Diese Arbeit widmet sich der Weiterverarbeitung der gewonnen Daten und untersucht die Forschungsfragen, welche Informationen automatisch aus den Texten generiert werden können und wie gut sich die Texte klassifizieren lassen. Die Arbeit folgt in ihrem Ablauf dem CRISP-DM Model und legt besonderen Wert auf die Betrachtung unterschiedlicher Vorverarbeitungen und einer Vielzahl von Modellen. Die Ergebnisse werfen dabei vor allem die Frage auf, wie viel Vorverarbeitung wirklich nötig ist um die besten Ergebnisse erzielen zu können. Es konnte dabei nachgewiesen werden, dass jeder zusätzliche Vorverarbeitungsschritt bei bankrelevanten Texten die Ergebnisse der Verfahren und Klassifikatoren verschlechtert.
30.04.19	2019	intern	Bachelor	DE	Konzeption und prototypische Realisierung einer mobilen Webapplikation für Obdachlose	Die steigende Anzahl an Obdachlosen in Nürnberg und fehlende digitale Angebote, die einen Mehrwert für die Obdachlosen schaffen, waren Ausgangspunkt eines IT-Projektes. Dieses wurde zusammen mit der Fakultät Informatik und dem Institut für E-Beratung durchgeführt, mit dem Ziel, eine Hilfe-App für Wohnungslose in Nürnberg zu entwickeln. Das daraus entstandene Konzept bildet die Grundlage der Bachelorarbeit. Dieses Konzept wurde mithilfe der nutzerorientierten Entwicklung weiterentwickelt und kritisch betrachtet. Auf Basis der daraus entstandenen Anforderungen wurde ein technisches Konzept entwickelt, das eine Grundlage für weitere Entwicklungen bietet. Zusätzlich wurde ein technischer Prototyp angefertigt, der eine modulare Software-Architektur anstrebt und eine Basis für eine weitere Entwicklung und Usability-Tests bietet. Die Arbeit ordnet sich in das Projekt "Smart Inklusion für Wohnungslose" (SIWo) des Instituts für E-Beratung der TH-Nürnberg ein und entstand in Zusammenarbeit mit diesem Institut.
30.04.19	2019	extern	Bachelor	DE	Geruchsprädiktion aus Molekülstrukturen mittels Deep Learning	In unserem Alltag sind wir ständig von Gerüchen umgeben. Gerüche sind hochkomplex und sogar durch den technologischen Fortschritt fällt es uns schwer vorherzusagen, wie ein Molekül riechen wird. Bereits kleine Änderungen der Molekülstruktur können den Geruch verändern, welchen wir wahrnehmen. In vielen Bereichen wird Deep Learning bereits erfolgreich eingesetzt und bietet auch hier Potenzial. In den vergangenen Jahren wurde ein neuer Deep Learning Ansatz veröffentlicht, welcher Transformer genannt wird. Dieser unterscheidet sich von Recurrent Neural Networks und basiert auf die sogenannte Attention. In dieser Bachelorarbeit wird der Transformeransatz verwendet, um Gerüche anhand von Molekülstrukturen zu prädizieren. Diese Herangehensweise führt zu ähnlichen Ergebnissen, die durch andere Ansätzen erzielt wurden und bietet weiterhin Potenzial.
30.04.19	2019	extern	Bachelor	DE	Digitalisierung in der Landwirtschaft: Entwicklung einer App für die optimale Bearbeitung von Feldern	Die Zahl der Lohnunternehmer in Deutschland steigt immer weiter und in der Landwirtschaft ist kein standardisiertes Verfahren für die Aufgabenverteilung der Flächenbearbeitung vorhanden. Für die Felderidentifikation und -kommunikation soll eine App konzipiert und umgesetzt werden. Um die Anwendung zu realisieren wurden verschiedene Programmiersprachen bezüglich der Erfüllung funktionaler Anforderungen verglichen und beurteilt. Anschließend wurden die Datenbank durch ein logisches Datenbankmodell, Userinterfaces durch Mockups und Programmlogiken und Userinteraktionen durch verschiedene UML-Diagramme konzeptioniert. Auf Basis der Planung wurden die gestellten Anforderungen realisiert und abschließend die Qualität der Anwendung durch diverse Tests gesichert. Das Ergebnis ist eine plattformunabhängige Anwendung, mit rufnummernbasierter Authentifizierung für Landwirte und Lohnunternehmer. Der Landwirt ist nun in der Lage, seine Felder und Äcker zu verwalten sowie Maßnahmen zu erstellen. Jene Maßnahmen kann er an Lohnunternehmer senden, sodass diese die Aufgaben erledigen.
30.04.19	2019	intern	Bachelor	DE	Automatische Bewertung von Programmieraufgaben aus der Web-Entwicklung	Automatische Bewertung von Programmieraufgaben aus der Web-Entwicklung Softwaretests und Testautomatisierung sind wichtige Bausteine moderner Softwareentwicklung. Gerade im Bereich der Web-Entwicklung gibt es zahlreiche Frameworks und Tools, die den Entwickler bei der Aufgabe, Softwaretests durchzuführen, unterstützen. Im Rahmen der Ausbildung von Informatikern kommen häufig Programmieraufgaben zum Einsatz, die von den Studierenden zu lösen sind. Bei der anschließenden Bewertung der Aufgaben durch den Dozenten ergibt sich eine ganz ähnliche Situation. Die von den Studierenden entwickelte Lösung muss bestimmte Kriterien erfüllen, um positiv bewertet zu werden. Im Gegensatz zu den durchzuführenden Softwaretests außerhalb der Ausbildungssituation bestehen bei der Bewertung solcher Aufgaben jedoch gewisse Freiräume, die von automatisierten Test-Frameworks häufig nicht auf einfache Art und Weise abgedeckt werden können. Daher wird in dieser Bachelorarbeit untersucht, inwiefern existierende Test-Frameworks, die für den automatisierten Test von Webanwendungen entwickelt wurden, dazu geeignet sind, die Bewertung von Programmieraufgaben im Rahmen der Lehre zu unterstützen. Dabei werden gewisse Test-Frameworks verglichen, Konzepte zur Umsetzung der Testfälle erarbeitet und anhand einer Aufgabenstellung implementiert, angewandt und die daraus resultierenden Ergebnisse ausgewertet und diskutiert.
01.05.19	2019	extern	Bachelor	DE	Analyse einer rechtskonformen Erhebung von personenbezogenen Nutzungsdaten auf mobilen Endgeräten und prototypische Implementierung am Beispiel der DATEV Programmstatistik	Die rechtlichen Aspekte sind ein wichtiger Punkt bei der Erhebung von personenbezogenen Nutzungsdaten in Softwareanwendungen. Welche Auswirkungen durch die gesetzlichen Rahmenbedingungen sowie technischen Einschränkungen im Umfeld mobiler Endgeräten für den Entwickler zu erwarten sind, klärt diese Arbeit. Zum einen werden die möglichen Datenquellen mobiler Endgeräte kategorisiert und zum anderen die Chancen sowie Risiken der Datenanalyse ermittelt. Die vorgeschlagenen Präventionsmaßnahmen sollen die bestehenden Risiken, wie beispielsweise den Datenmissbrauch, minimieren. Die Ergebnisse wurden gebündelt bei der Entwicklung einer prototypischen Implementierung angewendet. Zum Schluss folgt die Beschreibung der Umsetzung, wie die Erfassung der Einwilligung des Anwenders und die Datenerfassung sowie Datenübermittlung auf mobilen Endgeräten implementiert wurden. Der Prototyp wird künftig weiterentwickelt und soll letztendlich in den produktiven Apps der DATEV Verwendung finden.
01.05.19	2019	extern	Bachelor	DE	Konzeption und Entwicklung einer prototypischen Cross-Plattform-App zur Störungskommunikation im RZ-Umfeld	Bereits Xamarin ermöglicht, eine breite Basis geteilten C# und Codes auf den Zielplattformen iOS, Android und Windows 10 wiederzuverwenden, um Wartungsaufwand zu reduzieren. Xamarin.Forms, eine Weiterentwicklung des Cross-Platform-Frameworks von Microsoft, ermöglicht darüber hinaus die Auslagerung gemeinsamer UI-Logik. Während mittels nativer Entwicklung mit Xamarin - eine wohlüberlegte Softwarearchitektur vorausgesetzt - maximal 80% des Codes (Geschäftslogik und Datenzugriffsschicht), plattformübergreifend verwendet werden kann, da für jede Zielplattform ein eigenes User Interface programmiert werden muss, verspricht Xamarin.Forms, über diesen Anteil geteilter Logik hinauswachsen zu können, was anhand eines Prototyps demonstriert wird. Inwiefern Xamarin.Forms inzwischen geeignet ist, UI-Elemente auf den verschiedenen Zielplattformen Android, iOS und Windows 10 anzusprechen, um einen höheren Anteil geteilten Codes erreichen zu können, soll eruiert und im konzeptionellen Teil dieser Arbeit eingebracht werden. Ziel des Praxisteils dieser Arbeit ist die Konzeption einer Cross-Platform-App zur Kommunikation von Störungsmeldungen innerhalb von Rechenzentren inklusive eines lauffähigen Prototyps, der als Proof-of-Concept der Möglichkeit herangezogen wird, Code für ein User Interface zielsystemübergreifend wiederzuverwenden. Geschildert wird ein Szenario, in dem der Einsatz von Xamarin.Forms gegenüber einer nativen Entwicklung für drei verschiedene Systeme vorzuziehen ist.
02.05.19	2019	intern	Bachelor	DE	Entwicklung einer Bluetooth-gestützten Applikation zur Organisation und Kommunikation im Veranstaltungssegment	Diese Arbeit zeigt die prototypische Entwicklung einer Bluetooth-gestützten Applikation zur Kommunikation und Organisation im Veranstaltungssegment auf. Dabei werden zunächst die Grundlagen erörtert, anschließend Anforderungen erhoben, konzipiert, implementiert und evaluiert.
02.05.19	2019	intern	Bachelor	DE	Evaluation von Multi-Modell-Datenbankkonzepten zur Verwaltung polystrukturierter Daten	Das Ziel dieser Bachelorarbeit ist es, ein Evaluationsschema zu entwickeln, mit dem sich Multimodelldatenbanksysteme anhand von konkreten Anwendungsszenarien be-werten lassen. Hierzu wurde sich zunächst ein Anwendungsszenario überlegt, welches zum Speichern der Daten, mehrere Datenmodelle benötigt. Die verschiedenen Daten-modelle wurden dann auf ihre Vor- und Nachteile, sowie auf ihre möglichen Anwen-dungsgebiete untersucht. Es wurde sich daraufhin ein Marktüberblick über die ver-schiedenen Multimodelldatenbanken verschafft. Die Multimodelldatenbanksysteme ArangoDB, OrientDB, MarkLogic und MySQL wurden genauer im Hinblick auf Daten-modell, Transaktionen und Abfragesprachen untersucht. Schließlich wurde ein Bewer-tungsschema entwickelt. Anhand von dem überlegten Anwendungsszenario wurde das Bewertungsschema mit den untersuchten Multimodelldatenbanksystemen durchge-führt. Dabei hat sich herausgestellt, dass für den Anwendungsfall OrientDB die am bes-ten geeignete Multimodelldatenbank ist. Im Hinblick auf Performance, beim Laden und Abfragen von Dokumenten, sind die untersuchten Multimodelldatenbanken bei kleinen Datenmengen genauso schnell wie die Dokumentendatenbank MongoDB. Bei großen Datenmengen bricht die Performance allerdings stark ein.
02.05.19	2019	extern	Bachelor	DE	Konzeption und prototypische Implementierung eines HA-Clusters als Infrastruktur eines mittelständischen Unternehmens.	Ziel dieser Arbeit ist es, ein vollständiges Konzept für eine hochverfügbare Clusterlösung zu entwerfen und mögliche Lösungen zu evaluieren. Dabei sind folgende schon bekannte Anforderungen zu berücksichtigen: - Horizontale Skalierbarkeit - Live Migration - kein Single-Point-of-Failure - Backup und Desaster Recovery Ein weiteres Ziel ist die prototypische Umsetzung des Konzepts auf eigens dafür ausgesuchter Hardware.
07.05.19	2019	extern	Bachelor	DE	Analyse, Klassifizierung und Visualisierung von Daten zur Ermittlung von Optimierungspotenzialen bei der Sparda-Bank Nürnberg eG	Ausgangssituation Mit der voranschreitenden Digitalisierung werden stetig mehr Daten generiert und gespeichert. Das Bankwesen ist davon ebenfalls betroffen. Um zu prüfen, ob und welche Daten über Optimierungspotenziale verfügen und wie es um die jeweilige Datenqualität steht, wird im Rahmen dieser Arbeit eine Datenanalyse bei der Sparda-Bank Nürnberg eG durchgeführt. Problemstellung Eine konkrete Datenanalyse zur Prüfung der Datenqualität sowie möglicher Optimierungspotenziale hat bisher nicht stattgefunden. Zielsetzung Das Ziel dieser Arbeit ist es, anhand von zwei Use-Cases zu prüfen, welche Daten für eine Analyse dieser Use-Cases in Frage kommen, wie es um die Datenqualität steht und welche Optimierungspotenziale daraus resultieren können. Vorgehen Für die Datenanalyse werden die Use-Cases definiert. Anschließend wird geprüft, welche Daten für die jeweiligen Use-Cases in Frage kommen, bzw. für Analysen verwertbar sind. Die ermittelten Datensätze werden bereinigt, transformiert und anschließend in Microsoft Power BI für Visualisierungen geladen. Die Bereinigung und Transformation erfolgt mit dem Tool Jupyter Notebook. Anhand der Resultate der Transformation und Visualisierung der Daten, werden mögliche Optimierungspotenziale sowie Handlungsempfehlungen vorgeschlagen. Ergebnisse Optimierungspotenziale und Handlungsempfehlungen werden u. a. für die Verbesserung der Datenqualität vorgeschlagen. Die Einführung eines Dashboards gehört auch zu einer der Empfehlungen.
07.05.19	2019	extern	Bachelor	DE	Konzeption und Entwicklung eines E-Mailverificationsmicroservices für ein Data Providing System	Gegenstand dieser Arbeit ist die Konzipierung und Entwicklung einer Anwendung, wel-che E-Mail-Adresse verifiziert. Die Anforderungserhebung beschreibt die Anforderun-gen, die an das Gesamtsystem gestellt werden. Unter dem Einsatz der analysierten Techniken und unter Berücksichtigung der Anforderungen wird ein Konzept der An-wendung entwickelt. Dieses wird in der Programmiersprache Java mit den entspre-chenden Techniken implementiert. Es wird ein geeigneter Algorithmus der Prüfung der E-Mail-Adressen umgesetzt. Eine Validierung der Implementierung erfolgt mit Hilfe von verschiedenen Tests.
13.05.19	2019	extern	Bachelor	DE	Konzeption einer zentral verwalteten Linux-Server-Infrastruktur für ein hochskalierbares Umfeld	Eine Bedarfsanalyse hat die Notwendigkeit der Bereitstellung des Betriebssystems Linux ergeben. Der Betrieb des Betriebssystems erfordert eine zentrale Verwaltung. Mithilfe dieser Arbeit soll das Vorgehen zur Auswahl einer passenden Verwaltungssoftware dargestellt werden. Die Verwaltungssoftware soll verschiedene Aufgaben wie das Life-Cycle-Management, die Provisionierung, die Konfiguration und das Patch-Management von physischen und virtuellen Servern übernehmen. Mit der Arbeit soll geprüft werden, ob für den vorgesehenen Einsatzzweck eine passende Software zur Verfügung steht und ob diese auch in die vorliegende Infrastruktur integriert werden kann. Auch ist Bestandteil der Prüfung, wie das Verwaltungstool zur Skalierbarkeit der Umgebung beitragen kann und ob die Technik des Tools die gestellten Anforderungen auch in größeren Umgebungen erfüllen kann. Es konnte für den relevanten Einsatzzweck ein geeignetes Verwaltungstool gefunden werden, das alle Anforderungen erfüllen kann. Es handelt sich dabei um ein Open-Source-Produkt, das kostenlos genutzt werden kann und durch seine vielfältige Einsetzbarkeit die Integration in die vorliegende Infrastruktur ermöglicht. Die Bereitstellung von automatisierten Verfahren sorgt für die Beherrschung eines wachsenden Umfelds, jedoch erfordert die konzipierte Lösung eine wiederkehrende Anpassung der Infrastruktur des Verwaltungstools, um auf die Zunahme von verwaltenden Servern entsprechend reagieren zu können.
16.05.19	2019	extern	Bachelor	DE	Effiziente Überprüfung von Auftragsverarbeitern unter Zuhilfenahme von Prüfkatalogen	Effiziente Überprüfung von Auftragsverarbeitern unter Zuhilfenahme von Prüfkatalogen Motivation der Arbeit: Die neue Datenschutz-Grundverordnung (DSGVO) trat zum 25. Mai 2018 in Kraft. Mit der neuen Verordnung werden die Regeln zur Verarbeitung personenbezogener Daten durch private Unternehmen und öffentliche Stellen EU-weit vereinheitlicht werden. Dadurch soll einerseits der Schutz personenbezogener Daten innerhalb der Europäischen Union sichergestellt, andererseits der freie Datenverkehr innerhalb des Europäischen Binnenmarktes gewährleistet werden. Die Ziele der DSGVO sind der Schutz der Grundrechte und Grundfreiheiten natürlicher Personen und insbesondere deren Recht auf Schutz personenbezogener Daten (Art. 1 Abs. 2 DSGVO) und der freie Verkehr personenbezogener Daten (Art. 1 Abs. 3 DSGVO). Die vorangestellten Ziele sollen durch die in Art. 5 DSGVO festgelegten Grundsätze der Verarbeitung personenbezogener Daten erreicht werden: Rechtmäßigkeit, Treu und Glauben, Transparenz, Zweckbindung, Datenminimierung, Richtigkeit, Speicherbegrenzung, Integrität und Vertraulichkeit, Rechenschaftspflicht. Die Datenschutz-Grundverordnung wird das europäische Datenschutzrecht nicht völlig umwälzen, weist aber eine Reihe von in der Praxis erheblichen Änderungen auf. Eine der wesentlichen Änderung ist die stärker Fokussierung auf den technischen Datenschutz. Dieser ist sehr viel konkreter zu beschreiben und eine korrekte Umsetzung nachzuweisen. Neu im Datenschutz ist auch der risikobasiert
16.05.19	2019	intern	Bachelor	DE	Kursberechnungen und Steuerung eines autonomen Segelbootes	Diese Arbeit beschäftigt sich mit den Herausforderungen der Routenberechnung eines autonom fahrenden Segelbootes. Die Verwendung von Wind als einziges Antriebsmittel hat zur Folge, dass Aufgrund von Veränderungen der Windrichtung der Kurs immer wieder neu berechnet und angepasst werden muss. Dies macht Die Wegfindung beim Segeln prinzipell komplexer als bei anderen Fortbewegungsmitteln. Der Fokus dieser Arbeit liegt darin passende Algorithmen für die Routenberechnung zu finden und zu vergleichen, diese dann zu programmieren und zu implementieren und anschließend durch Testfahrten auf ihre Effizienz zu testen. Das autonom fahrende Segelboot soll in der Lage sein, entweder die schnellste oder die energieeffizienteste Route zu fahren. Die energieeffizienteste Route ist die Route, bei der das Segel und das Ruder möglichst wenig bewegt werden. Das Boot soll ebenfalls statischen Hindernissen ausweichen können. Zur Routenberechnung gehört der richtige Umgang mit Abdriften, Winddrehern und Böen, die Berechnung der Windrichtung unter Berücksichtigung des Fahrtwindes, sowie die Bestimmung des idealen Winkels des Segels zum Wind für die best mögliche Geschwindigkeit.
20.05.19	2019	intern	Bachelor	DE	Agiles Testen auf Weboberflächen - eine Guideline für Studenten	Die vorliegende Arbeit soll Studenten oder Quereinsteigern als Guideline dienen und das agile Testen auf Weboberflächen als standardisierten Prozess festhalten. Neben den grundlegenden Begriffen und Methoden des Softwaretests werden auch praktische Beispiele anhand einer selbsterstellten Weboberfläche verdeutlicht. Der Fokus dieser Arbeit liegt auf der Spezifikation und Ausführung von manuellen Testfällen.
20.05.19	2019	intern	Bachelor	DE	Ideenmanagement: State of the Art	Ziel der vorliegenden Forschungsarbeit war, zwei zentrale General-Fragen zum Ideenma nagement zu beantworten. Zum einen wie sich das heutige Ideenmanagement mit den sich ständig wechselnden Anforderungen der digitalen und innovativen Marktdynamik in deut schen Organisationen bewährt. Zum anderen Trends aufzuspüren, die in Zukunft für das Ideenmanagement von Bedeutung sein können.
20.05.19	2019	intern	Master	DE	Anonymisierung von natürlichsprachigen Texten	Ziel dieser Arbeit war die Erstellung eines Konzepts, das beschreibt, wie natürlich- sprachige Texte sprach- und kontextunabhängig anonymisiert werden können. Um das Konzept anschließend in der Praxis validieren zu können, sollte dieses ebenfalls implementiert werden. Das erstellte Konzept beschreibt dabei, welche Informationen in einem Text eine Identifikation erlauben. Weiterhin besteht es aus zwei verschiedenen Phasen: zum Ersten die Erkennung von sensiblen Informationen. Hierbei wird eine Kombination aus regulären Ausdrücken, Wörterbüchern und Named Entity Recognition (NER) genutzt. Zum Zweiten wird beschrieben, wie erkannte Informationen aus dem Text entfernt werden können. Ferner definiert das Konzept drei verschiedene Stufen der Anonymisierung, die je nach gewünschter Vertraulichkeit, verwendet werden können. Abschließend wurde das Konzept in der Programmiersprache Python implemen- tiert. Die Evaluierung der Ergebnisse hat gezeigt, dass das Konzept dazu befähigt, natürlichsprachige Texte weitestgehend zu anonymisieren. Weiterhin hat die Bewer- tung ergeben, dass nicht alle Fälle von sensiblen Informationen automatisch erkannt werden können. In diesen Fällen ist ein manueller Eingriff des Nutzers notwendig.
23.05.19	2019	extern	Bachelor	DE	Business Process Optimization - Digitalisierung der Auftragsabwicklung innerhalb des Datenübergabeprozesses im Rahmen der Kündigung von DATEV-SmartIT / DATEVasp	Im Rahmen dieser Arbeit wurde ein Geschäftsprozess der DATEV eG neugestaltet. Nachdem der Kunde sein DATEV-Cloud-Sourcing-Produkt gekündigt hat, ist es ihm unter anderem wichtig, die Daten aus der Cloud übergeben zu bekommen. Der Datenübergabeprozess geht diesem Kundenwunsch nach. Das konkrete Ziel dieser Arbeit war es, den manuellen Aufwand bei der im Datenübergabeprozess vorgesehenen Auftragsabwicklung durch Digitalisierungsmaßnahmen zu reduzieren. Im ersten Abschnitt wurden die theoretischen Grundlagen zum Thema Geschäftsprozessmanagement dargestellt. Der Prozess wurde auf Basis der vorgestellten Modellierungssprache modelliert, um Verbesserungspotential aufzuzeigen. Daraufhin wurde eine optimierte Auftragsabwicklung konzeptioniert, die die ermittelten Optimierungspotenziale umsetzt und frei von den zuvor erfassten Schwachstellen ist. Dabei wurde auch diskutiert, ob es sinnvoll ist für die Digitalisierung des Prozesses eine eigene Software zu entwickeln oder der Einsatz von Standardsoftware genügt. Nach der Realisierung erfolgte eine Evaluierung des Systems. Die Wirksamkeit der Optimierung wurde durch den Vergleich zum "analogen Telefonprozess" verdeutlicht. Abschließend wurde ein Ausblick in die Zukunft gewährt. Hierbei wurden weitere mögliche Digitalisierungsansätze für den Datenübergabeprozess vorgestellt.
28.05.19	2019	extern	Bachelor	DE	Konzeption und Entwicklung einer Nachrichtenzentrale für ein plattformübergreifendes Mediaberatersystem mit Xamarin	Gegenstand dieser Arbeit ist die Konzeption und Entwicklung einer Nachrichtenzentrale für ein plattformübergreifendes Mediaberatersystem mit Xamarin. Zunächst wird die Entwicklung als native Anwendung der Verwendung des hybriden Frameworks Xamarin gegenübergestellt. Außerdem beinhaltet die Arbeit die Analyse des bestehenden Systems, aber auch von Techniken und Entwurfsmustern. Es wird auf die unterschiedlichen Funktionalitäten des Prism Frameworks und deren Verwendung eingegangen. Zusätzlich wird der Einsatz des Microsoft AppCenters zum Versenden von Benachrichtigungen untersucht und die Implementierung beschrieben. Abschließend werden die Komponenten- und Integrationstests mit dazugehörigem Mocking Framework erläutert.
28.05.19	2019	extern	Bachelor	DE	Untersuchung und Konzeptionierung des Einsatzes von IoT-Komponenten im ERP-System NAV	Die KUMAVISION versteht sich nicht nur als Anbieter von ERP-Systemen, sondern möchte ihren Kunden eine umfassende Plattform zur Optimierung ihrer Geschäftstätigkeiten bieten. Die Technologien aus dem Bereich IoT nehmen stetig zu. Wie sich die ERP-Lösung mit den Smart Devices verzahnen kann wurde analysiert. Vorgehensweise: - Untersuchung der Rahmenbedingungen - Sammlung konkreter Möglichkeiten - Betrachtung von Sicherheitsaspekten - Erstellung einer Nutzwertanalyse - Prototypische Umsetzung Ergebnisse: - Nutzung von Bilderkennung in dem Bereich der Produktion - Konzeption eines maschinengestützten Handlagers
17.06.19	2019	extern	Master	DE	Einfluss verschiedener Inertial- und Funksensordaten auf die Posenschätzung von Menschen mittels Rekurrenter Neuronaler Netze	In localization, tracking, and navigation applications, it is important to precisely determine human movements and predict their path to prevent accidents, avoid collisions, and to accomplish effective human-computer interaction. In such scenarios, position and orientation (pose) error of a few decimeters or degrees or a (temporary) failure of the entire localization system leads to the respective traffic participants being in an apparently offset pose. Especially in difficult situations, complementary sensor system, consisting of radio and inertial measurement unit (IMU) sensors, help to get information about the current pose over time. Recent research has shown that data-driven end-to-end learning methods such as Recurrent Neural Networks (RNNs) are much easier to model than Kalman filters, learn complex, non-linear motion patterns of humans, and successfully map even variable changes of the measurement?s environment in their architecture. Based on the DeepIO architecture, LSTM- and GRU-RNNs model the individual movement behavior of 14 training- and 1 test- subjects, despite a small amount of data (405 min). LSTM- and GRU-RNNs process the input sequences such that they generalize from known, elliptical trajectories to unknown, random trajectories. They simultaneously successfully predict, i.e., extrapolate, future motion data, internally smooth inertial sensors data affected by sensor noise, and interpolate subsampled radio signals.
18.06.19	2019	extern	Master	DE	Erkennung und Klassifikation von Mustern sowie Ähnlichkeiten innerhalb der UI-Texte bei einem ERP-System	Das Ziel dieser Arbeit ist es Muster und Ähnlichkeiten in den UI-Texten eines ERP-Systems zu finden, um einheitliche Texte zu gewährleisten. Der Fokus liegt hierbei jedoch nicht auf der Ähnlichkeit des Inhaltes, sondern auf der Struktur dieser Texte. Dazu wurde die Struktur der Sätze anhand der Ähnlichkeiten von Parse-Bäumen sowie einer TF-IDF Matrix, auf Basis syntaktischer N-Gramme von Wortarten, abgebildet. Aufgrund fehlender Klassenzuordnung wurde das unüberwachte Verfahren der Cluster-Analyse zur Mustererkennung ausgewählt. Zum Clustering wurden unterschiedliche Verfahren verwendet und die erhaltenen Clusterzuordnungen wurden abschließend mit internen Validitätsmetriken bewertet und verglichen. Dabei fand eine bewusste Auswahl der Algorithmen K-Means, DBSCAN und HDBSCAN* statt. Da vorher keine Information zum Unterschied in den Mustern der Satzstruktur bekannt ist, beinhaltet die Selektion Verfahren zur potenziellen Ermittlung unterschiedlicher Cluster-Formen. Durch die eingesetzten Verfahren, allen voran DBSCAN, konnten teilweise sinnvolle Clusterzuordnungen gefunden werden. Diese können in Zukunft zur Ermittlung von Texten mit Verbesserungspotenzial verwendet werden, um die Arbeit mit dem ERP-System für Anwender zu erleichtern.
20.06.19	2019	extern	Master	DE	Change-Controlling im IT Projektmanagement: Qualitätssteigerung mithilfe von Data-Mining 	In dieser Masterarbeit wird die Fragestellung behandelt, wie Change-Management in ein IT-Projekt eingebunden werden kann. Dafür wird erforscht, welche Methoden, Techniken und Vorgehensmodelle es bereits in diesem Bereich gibt. Interessant ist auch, wie diese tatsächlich die bisher schlechte Erfolgsrate von Projektabschlüssen erhöhen können. Das Ziel dieser Arbeit ist es deshalb Gründe für ein Scheitern von Change-Management zu identifizieren und anschließend anhand dessen herauszuarbeiten, wie ein solches Scheitern mittels Controlling und Data-Mining verhindert werden kann, sodass ein Mehrwert für das Unternehmen entsteht. Ein besonderes Augenmerk liegt hierbei auf dem Data-Mining und wie dieses im Change-Management sinnvoll eingesetzt werden kann.
28.06.19	2019	intern	Bachelor	DE	Analyse und Bewertung einer Mustersprache zur Beschreibung suchterzeugender Mechanismen in sozio-technischen Informationssystemen 	2. Fragestellung & Zielsetzung Die Bachelorarbeit möchte drei, für diese wissenschaftliche Arbeit zentrale, Fragen beantworten: 1. Weshalb sind gewisse Mechanismen suchterzeugend? 2. Kommen suchterzeugende Mechanismen in sozio-technischen Systemen vor? 3. Kann man die identifizierten Mechanismen mit den Patterns (dt. Muster) der Mustersprache Empamos beschreiben? Im Detail, verfügt die Mustersprache genug Ausdrucksfähigkeit, um die erarbeiteten Mechanismen zu charakterisieren? Ziel der Arbeit ist es aufzuzeigen, weshalb bestimmte Mechanismen eine suchterzeugende Wirkung besitzen. Nach der Ausarbeitung wird betrachtet, ob die Mechanismen in soziotechnischen Systemen vorkommen. Im selben Zuge wird die Zulänglichkeit der Mustersprache Empamos daraufhin untersucht, inwiefern sie in der Lage ist, die suchterzeugenden Mechanismen mithilfe der identifizierten Patterns zu beschreiben.
12.07.19	2019	intern	Master	DE	Deep-Learning Verfahren zur semantischen Segmentierung von Gebäudefassaden im sichtbaren und infraroten Bereich	In der vorliegenden Masterarbeit werden verschiedene Deep-Learning-Verfahren zur Semantischen Segmentierung von Gebäudefassaden betrachtet. Um neben den RGB-Aufnahmen der Fassaden zusätzlich deren Infrarot-Daten zu verarbeiten, werden zwei Convolutional Neural Networks entwickelt, die mit verschiedenen Fusionierungsvarianten arbeiten. Die Netzarchitekturen basieren auf der Encoder-Decoder-Struktur des State of the Art Frameworks DeepLab. Die Architektur, die die Bildkanäle in zwei Netz-Strömen separat verarbeitet, kann dabei bessere Ergebnisse erzielen als die Architektur, die die Kanäle der RGB- und Infrarot-Daten gemeinsam verwendet. Als Erweiterung wird zudem Deep Generalized Max Pooling integriert und eine Variante untersucht, die dem Klassenungleichgewicht des Datensatzes entgegenwirkt. Zur Schärfung der Kanten wird eine Methode betrachtet, die auf dem Bilden von Edge Maps mithilfe des Sobel-Operators basiert. Die Evaluierung erfolgt über einen projektspezifischen RGB-Infrarot-Fassadendatensatz, der im Rahmen der Arbeit annotiert wird. Insbesondere die Ergebnisse der Experimente ohne Erweiterungen bestätigen den Mehrwert der Infrarot-Daten. Allen Versuchen werden Trainingsvorgänge auf der Basis eines vortrainierten Modells gegenübergestellt, die durch die Feinabstimmung des Modells auf den Datensatz eine deutlich höhere Performance erreichen können.
15.07.19	2019	intern	Master	DE	Zeitliche Synchronisation von Video-Streams aus unterschiedlichen Spektralbereichen	Das Ziel der vorliegenden Masterarbeit war es, die zeitliche Differenz von zwei Videos aus unterschiedlichen Spektralbereichen mit Hilfe von Machine Learning zu berechnen. Die Datenbasis bestand aus Videoaufnahmen des infraroten und des für den Menschen sichtbaren Spektrums, die von einer Drohne aufgenommen wurden. Für die Beantwortung der Forschungsfrage, ob Machine Learning eingesetzt werden kann, um die zeitliche Differenz von Videos aus unterschiedlichen Spektralbereichen zu berechnen, wurde ein Prototyp konzipiert, implementiert und schließlich evaluiert. Im Rahmen der Konzeption wurde sich für ein Siamese Network mit Convolutional Neural Networks zur Berechnung der zeitlichen Differenz entschieden. Die Ergebnisse bestätigen, dass es möglich ist mit Ansätzen des Machine Learnings die zeitliche Differenz von Videos aus unterschiedlichen Spektralbereichen zu berechnen. Die zeitliche Differenz konnte mit einer Präzision von 0,5 Sekunden kalkuliert werden. Im Gegensatz zur ursprünglichen Annahme führte die zusätzliche Berechnung des optischen Flusses nicht zu einer Verbesserung der Ergebnisse. Hierbei war die Idee, durch die Berechnung des optischen Flusses die Unterschiede der Spektralbereiche zu minimieren und die Ergebnisse dadurch zu verbessern.
18.07.19	2019	intern	Master	DE	Anonymisierung von Drohnen-Videoaufnahmen	Die im Mai 2018 in Kraft getretene Datenschutz-Grundverordnung stuft Videoaufnahmen in ein "Verarbeitungsvorgang mit hohem Risiko" ein. Betroffene Personen müssen bei fehlender Zustimmung durch eine Form des "eingebauten Schutzes" unkenntlich gemacht werden. Demzufolge wird ein System aufgebaut, das Gesichter automatisch detektiert und anhand von einfachen und Pseudo-Anonymisierungstechniken unkenntlich macht. Die Arbeit orientiert sich an Drohnen-Videoaufnahmen im infraroten und sichtbaren Spektrum. Zu diesem Zweck werden verschiedene State-of-the-Art-Detektoren betrachtet. Während traditionelle Ansätze meist die Technik des gleitenden Fensters oder Pyramidenabbildungen anwenden, greifen moderne Methoden oft auf Deep-Learning-Algorithmen mit Convolutional Neural Networks zurück. Neben dem Einsatz von einfachen Filtern, werden bei der komplexeren Pseudo-Anonymisierung häufig Generative-Adversarial-Network-basierende neuronale Netze genutzt. Die höchsten Average-Precision-Werte konnte in beiden Spektren der Dual Shot Face Detector vorweisen. Zur Wahrung der Privatsphäre muss die Kombination aus einfachen Techniken angewandt oder auf die Pseudo-Anonymisierung zurückgegriffen werden. Aufgrund nicht überzeugender Ergebnisse einer Heatmap in Kombination mit einem Segmentierungs Generative Adversarial Network, wird die Delaunay-Triangulierung genutzt. Das Flickern in den resultierenden Videos wird am besten durch die Glättung der Merkmalspunkte durch den Kalman-Filter reduziert.
24.07.19	2019	intern	Bachelor	DE	Unterstützung von Führungsaufgaben im Informationsmanagement durch ausgewählte Aspekte der Unternehmensmodellierung Anforderungen im Allgemeinen und Umsetzung speziell bei ARIS, MEMO und SOM	Wesentliches Ziel dieser Bachelorarbeit ist es, Potentiale der Unternehmensmodellierung zur Unterstützung der Anforderungen an die Führungsaufgaben im Informationsmanagement aufzuzeigen. Zu diesem Zweck wird anhand von Fachliteratur bestimmt, was unter Informationsmanagement und Unternehmensmodellierung zu verstehen ist. Dabei erfolgen eine wissenschaftliche Einordnung und Erklärung theoretischer Grundlagen. Aus dieser Begriffsbestimmung werden Anforderungen an die Führungsaufgaben des Informationsmanagements abgeleitet, die dafür genutzt werden, aufzuzeigen, welche Unterstützungsmöglichkeiten ausgewählte Aspekte der Unternehmensmodellierung im Allgemeinen und speziell bei den Konzepten Architektur integrierter Informationssysteme (ARIS), Multi Perspective Enterprise Modeling (MEMO) und Semantisches Objektmodell (SOM) bieten. Hierfür wird bei den Konzepten eine Evaluation durchgeführt, um darzustellen, wie mit diesen Konzepten die Anforderungen an die Führungsaufgaben unterstützt werden können.
20.08.19	2019	intern	Bachelor	DE	Einführung von SAP Enable Now als unternehmensinterne e-Learning-Lösung: Kritische Betrachtung und Gestaltungsvorschläge	Ziel dieser Arbeit ist es, die Einführung einer e-Learning-Lösung (SAP Enable Now) kritisch zu betrachten und die Chancen herauszuarbeiten, die sich für die verschiedenen Bereiche eines Unternehmens ergeben. Die Einführung von SAP Enable Now ist in mehreren Bereichen denkbar. Die bisher verwendete unternehmensinterne e-Learning-Software kann dadurch abgelöst werden, die Erstellung von SAP-Dokumentationen wird durch die zusätzlichen Funktionen erleichtert und eine Entlastung für Routineanfragen im IT-Support werden erwartet. Das Tool soll eine einheitliche Plattform für e-Learning und Wissenstransfer realisieren. Die Arbeit analysiert den Nutzen des Systems, in welchen Bereichen ein Einsatz sinnvoll ist und in welchen Arbeitsbereichen dadurch verbesserte Prozesse erzielt werden können. Im Zuge dessen wurden verschiedene Methoden des Change Managements, eine Prozessanalyse und eine Kosten-Nutzen-Analyse zur Bewertung eingesetzt. Zusätzlich wurde an einer Lösung zur Audio-Erstellung gearbeitet und eine Reporting-Lösung entwickelt.
01.09.19	2019	intern	Bachelor	DE	Kontextbezogene Informationsbereitstellung für Studierende in den Räumlichkeiten einer Hochschule	Die vorliegende Bachelorarbeit befasst sich mit der kontextbezogenen Informationsbereitstellung an einer Hochschule. Dabei wurden Use-Cases mit Hilfe von Rechercheergebnissen entwickelt und durch eine Studierendenbefragung evaluiert. Auf Basis der Umfrageergebnisse wurden anschließend drei Use-Cases auf Basis des Content-Management-Systems umgesetzt. Zusätzlich wurde eine auf das CMS zugeschnittene DSGVO-konforme Erklärung erstellt.
04.09.19	2019	extern	Master	DE	Erstellung von Softwaremetriken in der Automatisierungstechnik (Arbeitstitel) 	Ziel dieser Masterarbeit ist es, eine statische Code-Analyse als Verfahren und Prototyp zu entwickeln, die Entscheidern einen tiefergehenden Einblick in die Software ihrer Automatisierungsprojekte gibt. Dafür bietet das sogenannte TIA Portal, das Engineering-Framework in der Fertigungs- und Prozessautomatisierung der Siemens AG, eine Programmierschnittstelle, mit deren Hilfe die Softwarebestandteile eines Projekts automatisiert analysiert werden können. Die Entwicklung der statischen Code-Analyse bedient sich dabei Konzepten des Compilerbaus, der Softwaremessung und der Informationsextraktion aus Quellcode. Der Entwurf des Prototypen basiert auf Mitteln des User Experience Engineering und Konzepten der objektorientierten Programmierung.
16.09.19	2019	extern	Bachelor	DE	Wandel der Anforderungen an die Informatik im Zeitalter von Industrie 4.0 am Beispiel eines "Custom Visuals" in Microsoft Power BI	Diese Arbeit untersucht den Wandel und die Anforderungen an die Informatik im Verlauf der Zeit vor dem Hintergrund von Industrie 4.0. Die Veränderungen werden aus verschiedenen Blickwinkeln detailliert untersucht. Der Wandel erfolgte nicht nur in der Zuliefererindustrie, sondern auch im Schulunterricht und in der IT-Organisation. Der Fokus des Wandels in der Informatikgeschichte wird auf die klassischen Anwendungen und den Berufen bzw. Tätigkeiten des Wirtschaftsinformatikers gelegt. Der klassische Informatiker hat früher programmiert und heutzutage übernehmen viele Informatiker oder die sogenannten "Citizen Developer" schon vorhandene Entwicklungsumgebungen und erstellen damit Systeme und Anwendungen. Office 365 bietet viele Anwendungen, die auch ohne Programmierkenntnisse genutzt werden können. Citizen Developer sind Endnutzer, die an neuen Programmen arbeiten und ohne professionelle Unterstützung von Programmierern nicht arbeiten können. Um den Wandel im Digitalisierungszeitalter zu erfragen wird folgende wissenschaftliche Frage formuliert: "Wie haben sich die Anforderungen an die Informatik im Zeitalter von Industrie 4.0 gewandelt?" Diese wissenschaftliche Frage wird durch zwei Forschungsfragen detailliert beantwortet. Das Praxisbeispiel umfasst eine Erstellung eines Custom Visuals in Microsoft Power BI. Es wurde eine benutzerdefinierte Visualisierung auf Basis des Maturity Indexes erstellt.
17.09.19	2019	extern	Bachelor	DE	Maschinelle Identifikation von Verhaltensmodellen automatisierter Produktionsanlagen	Die Montage- und Prüfanlage Rollenhülse des Praxispartners Schaeffler besteht aus 23 Stationen, die alternierend diverse Montage- und Prüfaufgaben beinhalten. Erfassbar sind stationsbezogene, diskrete Steuerungssignale, die dem Zustand eines Sensors bzw. Aktors entsprechen. Die Automatisierung dieses Systems wird durch die Variation der Werte der Steuerungssignale erreicht Beispielsweise kann der Näherungssensor 10A A73.0 (Station 10 Ausgang + individuelle Bezeichnung) einen Gegenstand detektieren oder auch nicht (true /false). Die Modellbildung und Überwachung des Systems gestaltet sich sehr komplex und die Überwachungslogik ist durch menschliche Experten manuell implementiert. Die Lösung des Problems ist hierbei die Realisierung einer selbstlernenden, modellbasierten Zustands- und Prozessüberwachung.
01.10.19	2020	intern	Bachelor	DE	Plastikmüll in unseren Ozeanen - Untersuchung verschiedener technologischer Ansätze zur Eindämmung der Meeresverschmutzung	Um das in den letzten Jahrzehnten entstandene Problem der Meeresverschmutzung einzudämmen, werden in dieser Arbeit technologische Entwicklungen nach ihrer Technik und ihrem Nutzen untersucht, die vorhandenen Meeresmüll aufsammeln, filtern und entfernen können. Darüber hinaus wird eine Online-Umfrage zum Ausmaß der Meeresverschmutzung durchgeführt. Zielgruppe für diese Befragung sind professionelle Tauchschulen, die qualitative Fragen zur aktuellen Lage der Verschmutzung sowie zur zukünftigen Hilfe durch Technik beantworten. Abschließend wurden ausgewählte Technologien mit Hilfe einer Nutzwertanalyse evaluiert. Es wurde ein Fazit aus den Ergebnissen gezogen und gezeigt, dass Technologien zwar helfen können, aber letztendlich noch mehr Aufklärung nötig ist und die Politik in der Pflicht ist.
01.10.19	2020	extern	Bachelor	DE	Konzeption und Entwicklung von Eingabemöglichkeiten für die flexible Abfrage von Informationen aus workflowgestützten Prozessen in einem Content-Management-System	In dieser Arbeit sollte ein Konzept gefunden und entwickelt werden, mit dem man Abfrage-Eingaben in einem Content-Management-System (CMS) für Anwender erleichtern kann. Als Software-Grundlage für das Konzept wurde das CMS SCHEMA ST4 (ST4) verwendet. Innerhalb von ST4 gibt es einen Workflow Designer, mithilfe dessen Workflows erstellt werden können, für die Informationen aus ST4 über STPath abgefragt werden können. STPath ist eine Obermenge von XPath und damit ebenfalls eine Abfragesprache für XML-Dokumente. Zur Unterstützung für die Konzeptentwicklung eines Editors wurden verschiedene Editoren auf Hilfestellungen für Nutzer untersucht. Ein Ergebnis der Recherche war, dass bei den Hilfestellungen der Editoren, für die kein XML-Dokument gebraucht wird, am häufigsten eine Syntaxhervorhebung implementiert wurde. Für den STPath-Editor im Workflow Designer wurde im Rahmen dieser Arbeit eine farbige Syntaxhervorhebung der Editoreingabe umgesetzt. Die Analyse für die eingegebenen Ausdrücke wurde so implementiert, dass man sie sowohl für XPath als auch für Obermengen von XPath verwenden kann. Zusätzlich wurde die Hervorhebung von Klammerpaaren implementiert. Anhand von Testdurchläufen wurde unter anderem festgestellt, dass durch die Hervorhebung der Syntaxelemente das Finden eines Fehlers im getesteten Ausdruck im Durchschnitt rund neun Sekunden weniger dauert. Durch den Zeitgewinn wird das Erstellen eines Ausdruckes effizienter und verringert die Frustration bei Anwendern.
01.10.19	2020	extern	Bachelor	DE	Automatisierte Provisionierungsmechanismen für Laufzeitumgebungen von Legacy z/OS Anwendungen mit IBM Cloud Provisioning and Management for z/OS am Beispiel der Rechnungsschreibung bei DATEV eG	Ziel dieser Arbeit ist es, zu bestimmen, ob die Bereitstellung von Laufzeitumgebungen für legacy z/OS Anwendungen über einen cloud nativen, Platform-as-a-Service Ansatz bei DA- TEV e.G. möglich ist. Es werden folgende Forschungsfragen gestellt: ? Ist es möglich, den Bereitstellungsprozess für z/OS Anwendung bei DATEV e.G. mit Hilfe des "IBM Cloud Provisioning and Management for z/OS"-Tools an cloud native Prozesse anzunähern? ? Erzeugt die Nutzung von "IBM Cloud Provisioning and Management for z/OS" einen Mehrwert bei den Stakeholdern, also den Entwicklerteams und den Administratoren- teams? Dafür wurde anhand einer Beispielanwendung von der DATEV e.G. das Tool "IBM Cloud Provi- sioning and Management for z/OS" untersucht. Es wurden zwei vorhandene Möglichkeiten aufgezeigt, eine davon implementiert. Für ein Meinungsbild bezüglich Mehrwertes und Ak- zeptanz des Tools, wurden Interviews mit Stakeholdern durchgeführt. Diese Bild zeigt, dass in dem Tool eine Chance auf Verbesserung der aktuellen Prozesse gesehen wird. Ergebnis war auch, dass die implementierte Variante nicht optimal für den Praxiseinsatz bei DATEV e.G. ist, aber eine wichtige Basis für die automatisierte Bereitstellung von Lauf- zeitumgebungen für z/OS Anwendungen darstellt. Weiterführende Forschung könnte darauf aufbauend Variante zwei untersuchen und Möglichkeiten einer weiteren, praxisgeeigneteren Optimierung des z/OS Bereitstellungsprozesses aufzeigen.
01.10.19	2020	extern	Bachelor	DE	Kann ein datengetriebenes Word Embedding-Modell einen redaktionellen Thesaurus für Query Expansion ersetzen?	Zwecks der Verbesserung von Suchergebnissen wird im Kontext des Information-Retrievals bei DATEV Query Expansion eingesetzt. Als domänenspezifische Datenquelle steht dafür ein redaktioneller Thesaurus zur Verfügung, in dem unterschiedliche semantische Konzepte hinterlegt sind. Die Pflege des Thesaurus und dessen kontinuierliche Aktualisierung erfolgt manuell und erweist sich als ressourcenaufwendiger Prozess. Daher ist das Ziel der vorliegenden Arbeit zu evaluieren, wie gut sich semantische Konzepte aus dem Thesaurus mit Word-Embeddings-Techniken automatisch konstruieren und unterscheiden lassen. Dafür sind vier Word-Embeddings-Modelle mit fastText auf Basis von Daten aus dem Servicebereich trainiert worden. Nach Art der semantischen Relation, wie z.B. Synonymie oder Hyponymie, ist die Güte der Embeddings dieser Modelle anhand von Word Similarity, Mean Absolute Error und Thesaurusabdeckung ermittelt worden. Das Wikipedia-Korpus-basierte Modell, das mit Service-Daten nachtrainiert wurde, hat beste Ergebnisse bei der Thesaurusabdeckung über alle semantischen Relationen demonstriert. Die Evaluationsergebnisse haben gezeigt, dass unter Beachtung von Auswirkungen auf Performance sich nur ein kleiner Teil des Thesaurus konstruieren lässt. Die Unterscheidung nach der Anzahl an relevanten semantischen Konzepten lässt sich mit Hilfe von topn-Parameter und Similarity-Score bedingt beeinflussen. Die Güte des Modells kann im weiteren Downstream Task evaluiert werden.
01.10.19	2020	extern	Bachelor	DE	Entwicklung eines Backup-/Restore-Werkzeuges für Multiserver-Installationen von Steuerungssoftware verfahrenstechnischer Anlagen	Diese Bachelorarbeit widmet sich der Entwicklung eines Werkzeugs zur Sicherung und Wiederherstellung von Datenbanken im Umfeld des Plant iT Prozessleitsystems der Firma ProLeiT. Problem: Das Sicherungs- und Wiederherstellungswerkzeug Project Saver existiert es bisher nur für den Produktbereich Prozessleitsystem (PCS, Process Control System), nicht aber für andere Produktbereiche. Ferner ist die Benutzeroberäche nach heutigen Maÿstäben unästhetisch und wurde ohne Berücksichtigung von Aspekten der Usability entwickelt. Ziel ist es daher, die Anwendbarkeit des Project Savers zu erweitern und die Benutzeroberäche zu modernisieren. Zudem sollen die Architekturvorlagen Volere und arc42 analysiert und bewertet werden. Für die Anforderungsanalyse und den Architekturentwurf der geplanten Software sollen die Architekturvorlagen Volere bzw. arc42 verwendet werden. Diese werden anhand der Entwicklung analysiert und bewertet. Im Anschluss an die Implementierung wird die Usability der Anwendung geprüft. Hierfür wird das Usability Engineering Team der Firma ProLeiT zu Rate gezogen. Des Weiteren werden ein Funktionstest und ein Performance-Test durchgeführt. Resultat der Entwicklung ist die fertige Anwendung. Diese kann sowohl durch einfaches Kopieren als auch per Setup bereitgestellt werden. Vor der Auslieferung wird die Anwendung jedoch noch von dem Quality Assurance Team der Firma ProLeiT ausführlich getestet. Die Architekturvorlagen Volere und arc42 wurden überwiegend positiv (cont.)
01.10.19	2020	extern	Bachelor	DE	Konzeption und prototypische Realisierung von automatisierten Tests für hybride Anwendungen	Im Unternehmen bestehen Infrastrukturen, um in den jeweiligen Bereichen (On-Premises und Webanwendungen) isoliert Unit-Tests bzw. Integrationstests durchzuführen. Allerdings sind diese Tests stets homogen, d. h. es besteht keine Möglichkeit hybride Schnittstellentests durchzuführen, die sowohl On-Premises- als auch Webanwendungsteile zugleich abdecken. Es soll ein Konzept entwickelt werden, das es ermöglicht, Schnittstellen zwischen OnPremises- und Webanwendungen im Rahmen des Entwicklungsprozesses kontinuierlich zu testen. Das Konzept beinhaltet Informationen zu der Vorgehensweise der Testausführung und der einheitlichen Ablage der Testergebnisse. Idealerweise können bestehende Technologien/Tests ohne große Anpassungen in die Lösung eingebunden werden. Es soll ein Prototyp realisiert werden, der erste Durchläufe mit bestehenden Technologien ermöglicht. Anhand eines Beispiels wird die Verwendung der erarbeiteten Lösung veranschaulicht.
01.10.19	2020	extern	Bachelor	DE	Aufbau einer Integrationsarchitektur für ein Auslastungsanalysetool in Grafana	Im Rahmen der Digitalisierung steigt bei vielen Organisationen die Anzahl der Komponenten ihrer IT-Infrastruktur stark an. Dies geht mit einer erhöhten Komplexität der IT-Landschaft einher, was eine ganzheitliche Überwachung dieser mit traditionellen Überwachungstools erschwert. Im Rahmen der vorliegenden Arbeit soll eine Anwendung mit einer neuartigen 3D-Visualisierung, die das oben geschilderte Problem zu lösen versucht, in das Auslastungsanalysetool Grafana integriert werden. Das Ziel dieser Arbeit ist es zu untersuchen, inwiefern sich eine Integrationsarchitektur für Grafana konstruieren lässt, welche einerseits einen adäquaten Grad der Integration in Grafana ermöglicht, aber gleichzeitig eine angemessene Performanz und die Erweiterbarkeit der Architektur für ähnlich gelagerte Anwendungsfälle sicherstellt. Im Anschluss an die Umsetzung wird die fertige Architektur auf die geforderten Eigenschaften hin untersucht.
01.10.19	2020	extern	Bachelor	DE	KPIs eines Zertfikatsmanagement-Systems	Für das automatisierte Zertifikatsmanagement im Unternehmen wurde der Certificate Proxy (CertProxy) entwickelt. Mit Hilfe eines Administrationsprogramms wird automatisiert ein Client-Skript auf zahlreichen Servern ausgeführt. Durch dieses Skript wird ein Zertifikatsantrag erstellt und an den Certificate Proxy weitergeleitet. Der Proxy validiert die Anfrage und durchläuft verschiedene Security-Constraints. Bei erfolgreichem Durchlauf sendet der Proxy die Anfrage zur Zertifizierungsstelle. Diese händigt das Zertifikat über den Proxy an den Client aus.\Damit mehr Transparenz im System entsteht, sollen die relevanten Prozesse analysiert und ausgewertet werden. Anhand der Auswertungen sollen Key Performance Indicators (KPIs) definiert und anschließend auf einem Dashboard veranschaulicht werden.
01.10.19	2020	extern	Bachelor	DE	Konzeption und Entwicklung einer Web-Applikation zur Visualisierung medizinischer Bilddaten auf HTML5 Clients durch server-seitiges Rendering	Microsoft stellt mit dem plattformübergreifenden Open Source Framework ASP.NET Core eine Technologie bereit, um Web-Applikationen zu entwickeln, welche durch Cloud Computing verfügbar gemacht werden können. Es erlaubt auch den Aufruf von Funktionen aus Software-Bibliotheken, die mit den Programmiersprachen C und C++ entwickelt wurden. Dadurch sollte es möglich sein, parallelisierbare Berechnungen durch die von NVIDIA bereitgestellte CUDA-Plattform, welche die Entwicklung von GPU-beschleunigten Anwendungen erlaubt, zu realisieren. Zudem bietet die Open Source-Bibliothek SignalR die Unterstützung der WebSocket-Technologie für ASP.NET Core-Anwendungen, um performante Datenverbindungen und Streaming-Szenarien zu ermöglichen. Um die Realisierung einer Web-Applikation mit hinreichender Leistungsfähigkeit durch den Einsatz der oben genannten Technologien zu zeigen, wurde im Rahmen dieser Bachelorarbeit ein System zur dreidimensionalen Visualisierung medizinischer Bilddaten konzipiert und entwickelt. Auf dem Server werden mit Hilfe von CUDA Volumendaten von DICOM-Dateien, welche von einem PACS abgerufen werden, auf ein zweidimensionales Bild durch Volume Rendering abgebildet. Das erstellte Bild wird anschließend durch Einsatz einer ASP.NET Core-Applikation über eine SignalR-Verbindung für Clients verfügbar gemacht. Für die Darstellung und Interaktion mit dem berechneten Modell auf der Client-Seite wird eine Angular-Applikation als grafische Benutzeroberfläche eingesetzt.
02.10.19	2020	intern	Bachelor	DE	Voll ausgearbeiteten Business Model Canvas, mit einer abschließenden Go/No-Go Analyse für einen Demonstrator.	Die vorliegende Bachelorarbeit beschäftigt sich mit der Entwicklung eines Ge-schäftsmodells für die Stottertherapie im Kontext des DVG. Als Ausgangslage dient ein bereits in der Entwicklung befindlicher Algorithmus, der nach gestotterten Silben in einer Sprachaufnahme auswerten kann. Ziel dieser Arbeit ist es zu konzipieren, in welcher Form dieser Algorithmus in eine digitale Gesundheitsanwendung integriert werden kann, um so einen Mehrwehrt für potenzielle Kunden zu liefern und für gesetzlich Krankenversicherte eine Deckung der Kosten durch die Krankenkasse zu erhalten. Anhand der Methode der Customer Discovery werden verschiedene potenzielle Geschäftsmodelle erarbeitet. Die folgende Bachelorarbeit beginnt mit Grundlagen zum Thema Stottern. Anschlie-ßend wird das Ecosystem rund ums Thema Stottern aufgezeigt. Im Anschluss wird die Erarbeitung des Geschäftsmodells und das finale Geschäftsmodell aufgezeigt. Abschließend wird noch ein Produktentwurf inklusive möglicher Preisgestaltung vor-gestellt.
02.10.19	2020	extern	Bachelor	DE	Adaptive EB GUIDE Studio 6 mit Machine Learning: Prototypische Implementierung eines Plugins zur Datensammlung und Vorhersage der nächsten Modellierungsschritte	Die vorliegende wissenschaftliche Arbeit behandelt die prototypische Implementierung eines Plugins zur Datensammlung und Vorhersage der nächsten Modellierungsschritte in EB GUIDE Studio 6.8. Hierbei wurde zunächst ein Plugin entwickelt, welches die Datensammlung der aktuellen Aktionen des Modellierers ermöglicht. Anschließend wurde mithilfe des Plugins ein Datensatz erstellt, welcher für das Training eines rekurrenten neuronalen Netzwerks verwendet wurde, welches Sequenzen lernen und auch Vorhersagen treffen kann. Dieses in Python selbst erstellte neuronale Netz wurde schließlich in den Quellcode von EB GUIDE Studio 6.8 in C# integriert und in das vorher implementierte Plugin zur Sammlung der Daten eingebunden, wo letztendlich eine erfolgreiche Vorhersage der nächsten Benutzeraktionen gelungen ist.
02.10.19	2020	extern	Bachelor	DE	Analyse und Überarbeitung des Graphical User Interfaces von EB GUIDE Studio 6 zur Steigerung der Usability	Die vorliegende wissenschaftliche Arbeit behandelt die Analyse und anschließende, teilweise Überarbeitung des User Interfaces von EB GUIDE Studio 6, mit der Zielsetzung dessen Usability zu verbessern. Um dies zu erreichen, wird sich an den einzelnen Iterationsschritten des Human-Centered Design Process orientiert. Für die Identifizierung der Schwächen im Interface werden Modellierer innerhalb der Zielgruppe bei ihrer täglichen Arbeit beobachtet und befragt. Für drei dieser Schwächen werden, nach allgemein gültigen Gestaltprinzipien, Verbesserungen erarbeitet, welche teilweise mithilfe eines Prototyping Tools und teilweise, im bestehenden Projekt, mit C# und WPF umgesetzt werden. Die zu bearbeitende Testaufgabe wird so ausgelegt, dass die Nutzer, während des Tests, mit allen eingearbeiteten Verbesserungen interagieren. Um vergleichbare Werte zu erhalten, wird die Aufgabe von je fünf Nutzern mit dem bestehenden und dem überarbeiteten Interface durchgeführt. Bei der Messung der Usability, wird bei der Auswertung der Tests auf die Effizienz und Fehlerrate der Nutzer geachtet. Nach einer Iteration des Design Process wird deutlich, dass die Anpassungen die Usability teilweise erhöht haben, die Verbesserungen jedoch noch Schwächen enthalten, die Nachbesserung verlangen. Hierfür können, aufbauend auf der, durch diese Arbeit bereit gestellten Grundlage, weitere Iterationen des Design Process durchgeführt werden, bis die Verbesserungen die Benutzeranforderungen hinreichend erfüllen.
04.10.19	2020	intern	Bachelor	DE	Auswirkungen der Digitalen Transformation auf den operativen Beschaffungsprozess bei einem Industrieunternehmen	Durch die vierte industrielle Revolution haben viele Unternehmen eine klare Vision für das zukünftige Geschäft mit Blick auf den Einsatz von IT. Industrie 4.0 bedeutet vor allem: neuartige Produktionsverfahren (z. B. 3D-Druck) und Arbeitswelten. Neue Techniken, wie beispielsweise das Internet der Dinge (IoT) sollen dabei mit zentralisierten und virtuellen Speicher den Benutzer bei seiner Tätigkeit unterstützen. Um die Veränderungen darzulegen wird in dieser Bachelorarbeit näher auf den operativen Beschaffungsprozess eingegangen. Beginnend wird die Siemens AG, speziell die Gas-und-Power-Division, näher beschrieben. Anschließend folgen eine Begriffsabgrenzung sowie die Beschreibung des Beschaffungsprozesses, damit der Leser einen Einblick in das Thema bekommt. Nach dem Beschaffungsprozess werden die vorhandenen Tools analysiert und in einer Matrix die Vor- und Nachteile visualisiert. Im dritten Kapitel wird durch Durchführung einer Literaturrecherche ein neues Gestaltungspotenzial näher beschrieben. Dies wird durch die Vorstellung von SAP Ariba für die operative Beschaffung geschehen. Außerdem werden dem Leser Trends, die in Beschaffungsabteilungen zum Einsatz kommen können mit Hilfe eines Beispiels erklärt. Im vierten Kapitel werden die Herausforderungen und Auswirkungen der Digitalen Transformation hervorgehoben.
07.10.19	2020	extern	Bachelor	DE	Konzeption und Entwicklung eines Systems zur automatisierten Installation und Konfiguration von z/Linux Systemen	Auch in der heutigen Zeit werden Mainframes von vielen Unternehmen als zentrales System verwendet. Durch den Hypervisor z/VM und der Portierung des Linux-Kernels auf die Architektur des Mainframes, kann auf diesem eine große Anzahl an Linuxsystemen konsolidiert werden. Um diese effizient zu verwalten, werden häufig Konfigurationsmanagementtools eingesetzt. Der Support des bisher eingesetzten Tools Puppet wurde vom Hersteller der auf dem Mainframe betriebenen Linux-Distribution eingestellt. Deshalb wurde im Rahmen dieser Bachelorarbeit in Kooperation mit der Firma T-Systems Client Services ein neues Tool, für die Verwaltung der z/Linux Umgebung, eingeführt. Hierfür wurden die Tool Ansible und SaltStack nach einer Analyse miteinander und mit Puppet verglichen. Anschließend wurde das am besten geeignete Tool ausgewählt, um in einer Proof-of-Concept Umgebung ein Konzept zu entwickeln und einige grundlegende Konfigurationen für die Systeme dieser Umgebung implementiert.
07.10.19	2020	extern	Bachelor	DE	Verbesserung der Prognosegenauigkeit für die Ressourceneinsatzplanung als Erweiterung einer ERP-Branchenlösung 	Die relevanten Geschäftsprozesse eines Unternehmens können mit dem ERP System Microsoft Dynamics NAV abgebildet werden. Für Projekte wurde von der KUMAVISION AG eine Branchenlösung entwickelt, um diese um die Anforderungen von Projektdienstleistern zu erweitern. Innerhalb dieser Lösung gibt es einen Projektstrukturplan, in dem die anfallenden Arbeiten anhand von Arbeitspaketen strukturiert dargestellt werden. Zusätzlich gibt es einen Projekt Forecast, der eine rollierende Planung darstellt, und eine Ressourcenplanung. Der Aufwand der in einzelnen Arbeitspaketen anfällt wird aktuell entweder gleichmäßig über den Zeitraum verteilt oder gar nicht. Für eine bessere und effizientere Ressourcenplanung ist es aber notwendig so genau wie möglich zu wissen, wann wieviel Arbeit anfällt. Deswegen ist es wichtig zu wissen, wie sich der Aufwand auf die Monate/Wochen/Tage verteilt. Das Ziel dieser Arbeit wird folglich darin bestehen, die bisherige Projektlösung um die für die Integration eines zeitlich auswertbaren Aufwandes benötigten Funktionen zu erweitern. Hierzu müssen zunächst die relevanten, im ERP-System abzubildenden Anforderungen ermittelt werden. Danach wird aus diesen Anforderungen ein SOLL Konzept erstellt. Zum Schluss wird auf die Umsetzung des vorher erarbeitenden Konzeptes näher eingegangen mit dem Schwerpunkt auf den Herausforderungen und Besonderheiten bei der Kodierung.
11.10.19	2020	intern	Bachelor	DE	Virtueller Assistent für Studierende - eine Möglichkeit zur Hilfestellung für Studierende der TH Nürnberg 	Diese Arbeit beschäftigt sich mit der Möglichkeit und der Frage nach dem Bedarf Studenten der Fakultät Informatik bei der Informationssuche von studienbezogenen Daten mit einem virtuellen Assistenten zu unterstützen. Im Zuge dieser Arbeit wurde ein Chatbot mit dem Framework von Rasa entworfen, der Anfragen von Studierenden annehmen kann und die gesuchten Informationen als Link ausgibt. Es stellte sich heraus, dass von Seiten der Studierenden ein großer Bedarf besteht die Informationssuche zu erleichtern. Es konnte festgestellt werden, dass ein virtueller Assistent sich als zentraler Einstiegspunkt zur Informationssuche eignet und den Suchaufwand stark reduzieren kann.
11.10.19	2020	extern	Bachelor	DE	Adaption einer Kommentarfunktion für eine Multi-User-Webanwendung	Ziel der Arbeit ist es, das Feature der SCHEMA-ST4-Kommentarfunktion in eine moderne Webanwendung zu überführen. Im XML-Redaktionssystem lassen sich textuelle Anmerkungen zu Inhalten erstellen. In dessen neuer Fassung sollen die Funktionalitäten nun mithilfe von neuen Bedienmetaphern umgesetzt werden. In der momentanen Version sind die Nutzer stark entkoppelt. Es gibt keine Möglichkeit zu sehen, ob ein weiterer Nutzer zeitgleich einen Kommentar erstellt oder ändert. Erst beim Auftreten eines Konflikts wird darauf hingewiesen und der Nutzer aufgefordert, die Seite neu zu laden. In Zukunft soll für die Redakteure und Reviewer ersichtlich sein, ob gerade an Kommentaren gearbeitet wird. Hierfür soll der Applikation eine Echtzeitkomponente hinzugefügt werden. Möglichkeiten hierfür bietet beispielsweise das WebSocket-Protokoll, das Long-Polling und Server-Sent Events. Die Vor- und Nachteile werden erarbeitet und anschließend wird die passende Alternative ausgewählt. Desweiteren soll das User Interface optimiert werden. Hierfür werden Regeln des UI Designs zur Hilfe genommen. Anschließend werden verschiedene Komponenten auf Webseiten untersucht die im Annotations-Tool Verwendung finden. Mithilfe dieser Ergebnisse wird dann das User Interface gestaltet. Anschließend wird der Prototyp unter Berücksichtigung der Ergebnisse dieser Arbeit implementiert. Abschließend werden die gesammelten Anforderungen überprüft und ein Ausblick auf die Weiterverwendung des Prototypen gegeben.
13.10.19	2020	intern	Bachelor	DE	Merkmalsbasierte Wiedererkennung von Objekten mit Anwendung für die Robotik	Im Rahmen dieser Arbeit werden merkmalsbasierte Verfahren des maschinellen Sehens zur Objektwiedererkennung auf Robotersystemen untersucht. Die Herausforderung besteht dabei, Objekte auch aus verschiedenen Blickwinkeln und Perspektiven, sowie unter verschiedenen Lichtverhältnissen zu erkennen. Ziel ist es durch Vorverarbeitung durch Gaußfilter, merkmalbasierte sowie histogrammbasierte Verfahren mithilfe von OpenCV eine wiederverwendbare C++-Bibliothek zur Objektwiedererkennung zu implementieren. Die Grundfunktionalität soll anschließend auf einer Testanwendung auf dem Robotersystem Pepper demonstriert werden. Damit sollen Objekte gelernt und wiedererkannt werden. Zum Erlernen eines Objektes wird dieses in der Kameramitte platziert und durch ein Sprechkommando mit einem Textlabel versehen. Zur Wiedererkennung werden Objekte zunächst zweidimensional betrachtet. Aus der zweidimensionalen Darstellung der Objekte werden durch SIFT- bzw. SURF-Verfahren Merkmale ermittelt und anschließend Merkmalskorrespondenzen zu den abgespeicherten Objekten gebildet. Das Textlabel des Objektes mit den meisten Korrespondenzen wird als Ergebnis ausgegeben. Um Objekte auch aus verschiedenen Blickwinkeln zu erkennen, werden außerdem histogrammbasierte Verfahren angewendet. Als Ergebnis soll eine echtzeitfähige Lösung entstehen, die als Softwarebasis für zukünftige Forschungsprojekte, wie z.B. die visuelle Selbstlokalisierung von Robotern, dienen könnte.
14.10.19	2020	extern	Bachelor	DE	Nutzung von Low-Code-Plattformen für die effiziente Entwicklung betriebswirtschaftlicher Anwendungen bei DATEV	Die vorliegende Bachelorarbeit wurde in Zusammenarbeit mit DATEV eG durchgeführt. Ziel der Arbeit ist die Untersuchung, welche marktrelevanten Low-Code-Plattformen für einen potentiellen Einsatz bei DATEV geeignet sind. Hierfür wird anhand einer konkreten Plattform analysiert, wie mit der Low-Code-Technologie entwickelt wird. Zudem erfolgt eine Bewertung verschiedener Plattformen hinsichtlich eines möglichen Einsatzes bei DATEV. Voraussetzung für die Nutzung dieser Plattformen ist die Erstellung moderner serviceorientierter Anwendungen, die plattformunabhängig sind und auf verschiedenen Zielsystemen gehostet werden können. Diese Voraussetzung liegt bei der Bewertung im Fokus.
14.10.19	2020	extern	Bachelor	DE	Untersuchung unterschiedlicher Machine-Learning-Modelle in der Risikoanalyse zur Gewichtung von Vorabanmeldungen in der Bundeszollverwaltung.	Die Bachelorarbeit behandelt die Untersuchung von unterschiedlichen Machine-Learning-Modellen im Bereich der Risikoanalyse in der Bundeszollverwaltung. Dabei wird untersucht, ob mittels des maschinellen Lernens die Gewichtung der Vorabanmeldungen (für die Einfuhr von Waren) realisierbar ist. Ein mit Risikoregeln hinterlegtes System erzeugt für die eingehenden Vorabanmeldungen Hinweise für die weitere Bearbeitung durch das Zollkriminalamt. Die für die Erarbeitung der Bachelorarbeit relevanten Daten werden vom ITZBund bereitgestellt. Hierbei werden Informationen aus bereits durchgeführten Kontrollen repräsentiert, die Hinweise dazu geben, welche Risikoregeln zu einem tatsächlichen Fund geführt haben und welche nicht. Mit Hilfe dieser Daten werden Modelle entwickelt und Vorhersagen über die Trefferwahrscheinlichkeiten unterschiedlicher Regelmuster getroffen. Mittels der Forschungsergebnisse konnten die aufgestellten Thesen, die die Grundlage dieser Arbeit bildeten, beantwortet werden.
14.10.19	2020	extern	Bachelor	DE	Ortsbezogene Visualisierung ausgewählter Datensätze zum Visual Data Mining in der virtuellen Realität	Die weltweiten Datenbestände nehmen Jahr für Jahr stetig zu. Mit dem rasanten Wachstum werden die Strukturen innerhalb der Daten stets komplexer und unübersichtlicher. So gibt es schon viele Ansätze zur Datenvisualisierung, um eine bessere Interpretation der Daten bieten zu können. Dabei wird jedoch hauptsächlich auf zweidimensionale Visualisierungsmöglichkeiten, wie beispielsweise Balken- oder Liniendiagramme, zurückgegriffen. Daher werden in dieser Arbeit die Möglichkeiten und Vorteile von Visualisierungen mit zusätzlicher räumlicher Dimension untersucht. Können komplexere Daten durch eine dreidimensionale Visualisierung einfacher dargestellt werden? Ebenfalls wird aufgezeigt, welchen grundsätzlichen Mehrwert grafische Datenaufbereitungen besitzen. Anhand bestimmter Anforderungen wurden angebotene Visualisierungstools getestet. Durch die Analyse und der Bewertung konnte festgestellt werden, dass keines der Tools alle benötigten Anforderungen erfüllt. Deshalb wurde eine eigene Anwendung programmiert, die alle Anforderungen umsetzt.
14.10.19	2020	extern	Bachelor	DE	Die Analyse und Optimierung von Human Computer Interaction in einem komplexen Autokonfigurator für Neufahrzeuge.	Diese Bachelorarbeit beschäftigt sich mit der Analyse und Optimierung der Mensch-Computer-Interaktion in einem komplexen Autokonfigurator (e:c:car) für Neufahrzeuge. Das Ziel dieser Bachelorarbeit ist es, das Benutzerverhalten der Autokonfigurator-Webanwendung genauer zu untersuchen und dabei Problemfelder zu finden, die in der Zukunft mithilfe von Optimierungsmaßnahmen behoben werden können. Um die Analysen des Konfigurators durchführen zu können, wurden zunächst die theoretischen Grundlagen der Mensch-Computer-Interaktion untersucht. Das Thema ist sehr facettenreich und beschäftigt sich nicht nur mit den technischen Aspekten der Informationsverarbeitung, sondern auch mit der menschlichen Wahrnehmung der Daten. Es lässt sich sagen, dass die Kommunikation zwischen Menschen und Computer enorm wichtig ist und in der heutigen Arbeitswelt einen sehr hohen Stellenwert hat. Darüber hinaus wurde die Webanalyse der Webanwendung sowie die Analyse der Konfigurationspfade durchgeführt. Die Analysen haben die Entwicklungsmöglichkeiten und das Verbesserungspotenzial des Konfigurators aufgezeigt. Die theoretischen Grundlagen der Webanalyse sowie die aktuellen Methoden zur Optimierung der Webperformanz spielten eine sehr wichtige Rolle. Die Forschungsergebnisse haben es ermöglicht, Optimierungsmaßnahmen einzuführen, die die Benutzerfreundlichkeit der Webanwendung in Zukunft deutlich steigern sollen.
15.10.19	2020	extern	Bachelor	DE	Konzeption und Implementierung einer Webapplikation zur Erfüllung der materiell-rechtlichen Nachweispflicht der Umsatzsteuer-ID für innergemeinschaftliche Lieferungen bei der DATEV eG	Zum Zeitpunkt des grenzüberschreitenden Leistungsaustauschs zwischen zwei Unternehmen innerhalb der EU muss durch den Leistungserbringer sichergestellt werden, dass die UST-ID des Leistungsempfängers gültig ist. Erst dann können die Leistungen durch das rechnungsstellende Unternehmen steuerfrei erbracht werden. Bisher konnte die Inanspruchnahme der Steuerbefreiung auch bei ungültiger USt-ID nicht untersagt werden. Aufgrund neuer gesetzlicher Vorgaben ist es daher notwendig, dass eine dauerhafte Nachweismöglichkeit der Gültigkeit der USt-ID ohne Manipulationsgefahr geschaffen wird. Ansonsten besteht das Risiko, dass bei unvollständigem bzw. fehlendem Nachweis die in Anspruch genommene Steuerbefreiung im Prüfungsfall versagt wird. Daher wurde ein System für die DATEV entwickelt, welches hingegen der bisherigen gesetzlichen Vorschriften bereits bei Anbahnung des innergemeinschaftlichen Leistungsaustauschs zwischen Unternehmen die USt-ID des Leistungsempfängers prüft und die konsistente Speicherung der angefragten USt-ID?s ermöglicht. Um auf diesen Prüfmechanismus zugreifen zu können, wurde ein SOAP Schnittstelle vom Informationsaustauschsystem MIAS der EU-Kommission an programmiert. Mittels einer serverseitigen REST API wurden die An- und Abfragen über einen RESTful Webservice und dessen POST- und GET-Methoden realisiert. Dadurch erfolgte die Kommunikation und Datenübertragung zwischen dem Fontend (Angular), der REST-API und der Datenbank.
15.10.19	2020	intern	Bachelor	DE	Herausforderungen im internationalen agilen Projektmanagement mit Fokus auf Vietnam und Deutschland	Das Ziel dieser Arbeit ist das Aufzeigen und die Analyse der Herausforderungen für agile Projekte mit mehreren verteilen Teams bzw. Teammitglieder in internationaler Umgebung. Dadurch kann die Vorbereitung für die Projektmitglieder geplant und durchführt werden, um die Projekte erfolgreich umsetzen zu können. Zu Beginn werden die grundlegenden relevanten Themenbereiche des Projektmanagement dargestellt. Das Projektmanagement wird aus zwei Blickwinkeln betrachtet: Im Kontext der internationalen Zusammenarbeit und im Kontext der agilen Methoden. Die Arbeit analysiert die typischen Vorteile bzw. Herausforderungen und Lösungsansätze in Bezug auf agile Projekte mit Teams bzw. Teammitglieder, die aus Vietnam und Deutschland kommen. Mithilfe einer quantitativen-empirischen Forschung mittels einer Online-Befragung werden die Herausforderungen in internationalen agilen Projekten in der Praxis zu erläutern und anschließend mit den bekannten Herausforderungen aus der Literaturanalyse in einen Kontext zu setzen. So werden Theorie (Literaturanalyse) und Praxis (Praktische Erfahrungen der Teilnehmer aus der Umfrage) miteinander verglichen. Abschließend wird eine Empfehlung auf weitere mögliche Forschung vorgegeben.
15.10.19	2020	extern	Bachelor	DE	Konzeption und systemtechnische Implementierung eines Kennzahlensystems im Einkauf der Carl Schlenk AG	Die vorliegende Arbeit wurde in Zusammenarbeit mit der Firma Carl Schlenk AG durchgeführt. Diese ist ein international erfolgreicher Hersteller von Metallpigmenten, -pulver und -folien mit Stammsitz in Barnsdorf. In der Bachelorarbeit werden Kennzahlen im Einkaufsbereich mittels eines Kennzahlensystems in einen logischen Zusammenhang gebracht. Berücksichtigung finden strategische und zweckmäßigerweise auch operative Kennzahlen. Die für deren Berechnung benötigten Daten werden systemtechnisch aus den entsprechenden Quellsystemen erhoben, transformiert und unter Einbezug des Kennzahlensystems mit Hilfe des Business-Intelligence-Tools QlikView abgebildet. Ziel soll es sein, dem Einkaufsmanagement durch eine optimale Nachvollziehbarkeit und Visualisierung der Ergebnisse einen hohen Erkenntnisgewinn zu ermöglichen, um daraus Maßnahmen abzuleiten.
15.10.19	2020	intern	Bachelor	DE	Virtueller Assistent zur automatisierten Erstellung von Immobilieninseraten	Problemstellung dieser Arbeit: Bisher entstehen Immobilieninserate häufig über manuell auszufüllende Web-Formulare. Zunächst wird dieser Ist-Stand bzw. die aktuelle Vorgehensweise zur Inseratserstellung per Web-Formular betrachtet, um sie später einer eigenen prototypischen Lösung gegenüberstellen zu können. Die Arbeit soll untersuchen, ob und wie eine automatisierte Füllung oder Erstellung von Immobilieninseraten unter Nutzung von Spracherkennung möglich ist. Es werden verschiedene Aspekte der Thematik betrachtet. Eine prototypische Implementierung zur automatisierten Füllung von Immobilieninseraten per Sprache wird umgesetzt. Anschließend wird der Prototyp erweitert. Es wird eine generalisierte prototypische Implementierung geschaffen, die die Sprachfunktionalität für beliebige Webformulare mit bestimmtem HTML-Aufbau ermöglicht. Die Vor- und Nachteile der Erweiterung werden aufgezeigt. Abschließend wird die Zielerreichung dieser Arbeit betrachtet und ein Fazit gezogen.
15.10.19	2020	extern	Bachelor	DE	Konzeption und Realisierung automatisierter Qualitätsprozesse für maßgeschneiderte Kundenlösungen: Testautomatisierung bei Customizing Personalwirtschaft in der DATEV eG	Maßgeschneiderte Kundenlösungen mit Wartungsverträgen werden manuell getestet, um mögliche Fehler frühzeitig erkennen und beheben zu können. Um zukünftig die regelmäßigen Tests effizienter zu gestalten und somit die Anzahl der Wartungsverträge, die mit den Kunden geschlossen werden können, zu erhöhen, soll der Prozess mit Hilfe einer Testautomatisierung optimiert werden. Das Ziel dieser Bachelorarbeit ist es, ein Konzept zu entwickeln und anhand einer bestehenden Lösung den Prozess so zu automatisieren, dass der Aufwand für Teammitglieder während des Testens minimiert werden kann. Nach der Umsetzung soll ein mit einer Testautomatisierung optimierter Prozess vorhanden sein, der auch auf zukünftige Lösungen bei Wartungsverträgen anwendbar ist.
15.10.19	2020	extern	Master	DE	Automatisierte Echtzeit-Lösungsmitteilung bei Maschinenmeldungen innerhalb verschiedener Produktionslinien	Seit ihrer öffentlichen Bekanntgabe gewinnt die Industrie 4.0 an Popularität und ist heu- te ein essenzieller Treiber der modernen Industrie. Die Optimierung der Produktion ist dabei ein wesentlicher Aspekt. Ein Anwendungsfall ist die Ermöglichung schneller und richtiger Handlungen bei Auftreten von Maschinenfehlern. In Zusammenarbeit mit endo- bit software solutions und der Robert Bosch GmbH soll ein Softwaremodul konzipiert und realisiert werden, das eine Lösungsmitteilung für Maschinenmeldungen binnen einer Sekunde für eine Produktionslinie bekannt gibt. Dazu wurde eine Analyse von Datenhaltungen zur performanten Abfrage und flexiblen Speicherung durchgeführt, bei der sich MongoDB als geeignet herausstellte. Die Ver- zögerung der SQL-Abfrage an den Bestand von 6 Millionen Fehlercodes wurde mittels PL/SQL um rund 50% verringert. Es wurden Ansätze der Cross-Plattform-Entwicklung einer App zur Lösungsmitteilung sowie Konzepte der Gamification untersucht. Als geeig- net ergaben sich das Framework Ionic und ein Gamification-Konzept mit einem kurzen und mittelfristigen Ziel. Bei einer Linie mit 15 Stationen konnte das Ziel einer Verzögerung von unter einer Sekunde erreicht werden, während dies bei 78 Stationen nicht eingehalten werden konnte. Es wurde ein Konzept zur Motivation der Nutzer zur Behebung von Maschinenstörungen umgesetzt. Dieses könnte in zukünftigen Forschungen in einer produktiven Umgebung mit einer Nutzerstudie untersucht werden.
16.10.19	2020	extern	Bachelor	DE	Effiziente Aufbereitung von Energiemanagement-Daten durch Integration eines Elastic Stacks	Während des Betriebs der Energiemanagement-Software IngSoft InterWatt fallen große Mengen zeitaufgelöster Verbrauchsdaten an. Im Rahmen dieser Arbeit soll durch die Integration eines Elastic Stacks die Verarbeitung von Energiedaten effizienter gestaltet und beschleunigt werden, insbesondere das Laden von Daten für graphische Auswertungen. Zudem soll die Verwendung des Elastic Stacks für Datenimport und -visualisierung untersucht werden. Hierzu wurde Elasticsearch mittels .NET-Client an das Software-System angebunden. Die Abbildung der Energiedaten in Elasticsearch erfolgte durch geeignete Indizes, Typen und Mappings, bereits existierende Verbrauchsdaten importierte die Elastic Stack Komponente Logstash. Ein Konzept zur Synchronisation von SQL-Datenbank und Elasticsearch wurde erfolgreich umgesetzt, Visualisierung und Analyse der Daten übernahm die Software Kibana. Messungen an einem Testsystem zeigten, dass Elasticsearch zwar länger zum Laden der angeforderten Daten als der ursprünglich verwendete SQL-Server benötigte, trotzdem bietet Elasticsearch eine Reihe Vorteilen. So ist davon auszugehen, dass Elasticsearch durch die Beantwortung von Leseanfragen den SQL-Server entlastet und Sharding sowie Replikation horizontales Skalieren bei wachsenden Datenmengen erlauben. Weitere Untersuchungen könnten zeigen, ob durch eine Veränderung des Datenmodells sowie Sharding und Replikation eine Verringerung der Verarbeitungszeit von Elasticsearch erreicht werden kann.
16.10.19	2020	intern	Bachelor	DE	Entwicklung, Implementierung und Evaluierung eines WebGL-basierten Volumen-Raycasters	Für die Darstellung, Bewertung und Analyse volumetrischer Daten, wie sie z.B. in der medizinischen Bildgebung anfallen, ist die direkte Volumendarstellung unerlässlich. Die dabei verwendeten Algorithmen werden in der Regel plattformspezifisch implementiert, um möglichst hohe Darstellungsgeschwindigkeiten zu erreichen. Die WebGL-Programmierschnittstelle erlaubt es dabei, die verwendete Grafikhardware des ausführenden Systems plattformunabhängig zu nutzen. Hierfür wurde ein WebGL-basierter Volumen-Raycaster entwickelt, um die Eignung dieser Technologie für direkte Volumen-Rendering-Verfahren festzustellen. Dabei wurde insbesondere auf eine nachvollziehbare und wiederverwendbare Implementierung geachtet.
17.10.19	2020	extern	Bachelor	DE	Konzeption und Implementation einer Contact-Center-Umgebung für einen Kundenservice	Diese Bachelorarbeit thematisiert die Konzeption und Implementierung einer Contact-Center-Umgebung in einem mittelständischen Unternehmen. Die Arbeit soll für zukünftige Contact-Center-Implementationen als technischer Leitfaden dienen, weswegen auf Best Practices eingegangen und die Anwendbarkeit dieser bewertet wird. Nachdem in den Grundlagen auf diverse Voice over IP (VoIP)-Protokolle eingegangen und die Architektur von Cisco Unified Call Manager (CUCM) und Unified Contact Center Express (UCCX) beschrieben werden, folgt die Anforderungsanalyse. In dieser wird anhand der funktionalen Anforderungen die Grundlage für die Implementation geschaffen. In der Implementation werden die im Soll-Konzept entwickelten Punkte umgesetzt. Zusätzlich gibt es allgemeine Erklärungen zu der Funktionsweise der beiden proprietären Systeme, CUCM und UCCX. Anschließend wird ein Verhaltenstest durchgeführt, wofür eine Liste mit den zu erwartenden Ergebnissen erstellt wurde. Zuletzt werden die Ergebnisse beschrieben, diskutiert und ein Fazit gezogen. Es zeigt sich, dass Best Practices nicht in jedem Fall anwendbar sind. Es ist wichtig, dass Best Practices analysiert und je nach Ergebnis auf die eigenen Gegebenheiten angepasst werden sollten. Auch erfolgt die Steigerung der Produktivität nicht einfach mit der Implementierung eines Systems automatisch. Die Kundenservice-Mitarbeiter müssen lernen, mit der neuen und komplexeren Umgebung in der richtigen Art und Weise umzugehen.
17.10.19	2020	extern	Bachelor	DE	Entwicklung und Automatisierung von Testfällen für das Batteriemanagementsystem einer Starterbatterie 	Das Ziel der vorliegenden Bachelorarbeit ist es, Testfälle für den Softwaretest der High-Level-Software eines Batteriemanagementsystems zu entwickeln, zu dokumentieren und mithilfe von Testskripten zu automatisieren. Grundlage für diesen Testprozess sind ein vorliegendes Konzept mit einer Testumgebung sowie die Softwareanforderungen aus dem Lastenheft zur Bestimmung des Batteriezustands. Um die Softwareanforderungen einzugrenzen ist eine Priorisierung nach dem MoSCoW-Verfahren durchgeführt worden. Das Resultat der Priorisierung zeigt, dass die Bestimmung des Batterieladezustands die höchste Priorität hat. Für die Entwicklung der Testfälle wurden die priorisierten Softwareanforderungen einer Analyse unterzogen. Eine Testspezifikation dokumentiert die entwickelten Testfälle schrittweise und dient als Basis für die Automatisierung, bei der die Testfälle auf Skriptcode abgebildet wurden. Ergebnisse der Arbeit sind die Testspezifikation und die Testskripte, die für einen nachfolgenden Softwaretest eingesetzt werden können.
17.10.19	2020	extern	Bachelor	DE	Gesten- und Audioerkennung zur Steuerung einer intelligenten Jukebox 	Moderne leistungsstarke und preiswerte Single-Board-Computer ermöglichen eine Vielzahl von Anwendungen für Künstliche Intelligenz (KI). Dank zahlreicher Open-Source-Projekte und -Bibliotheken, die die mathematischen Grundlagen für unterschiedliche maschinelle Lernverfahren bereitstellen, ist es für Softwareentwickler möglich, KI-Methoden in die eigene Software zu integrieren. Mit dieser Vielzahl an Möglichkeiten stellt sich die Frage, welche davon zu einem bestimmten Problem am besten passt. Es ist ebenso von Interesse herauszufinden, welche Verfahren bzw. Software-Bibliotheken oder API auf einem eingebetteten System mit den begrenzten Speicher- und Leistungskapazitäten für die Anwendung in Echtzeit umsetzbar sind. Während die Spracherkennung mit dem Einsatz von Programmierschnittstellen als eine Lösung aus dem Regal betrachtet werden kann, wird für die Gestenerkennung mit anwendungsspezifischen Gesten ein individueller Ansatz benötigt. Diese Arbeit setzt sich mit dem Aufbau und der prototypischen Entwicklung einer intelligenten Jukebox auseinander. Es wird ebenso untersucht, wie hochwertig die Anwendung der Sprach- und Gestenerkennung auf einem Embedded-Single-Board-Computer sein kann und mit welchem Aufwand deren Einsatz verbunden ist.
17.10.19	2020	extern	Bachelor	DE	Die Fernsignatur als Ersatz für Unterschriften im Rahmen der digitalen Transformation: Eine Machbarkeitsstudie für die DATEV eG	Die vorliegende Bachelorarbeit betrachtet die Fernsignatur im Rahmen der Wirtschaftsprüfung und Steuerberatung und die daraus resultierenden Anwendungsszenarien. Zukünftig werden Prozesse innerhalb der Kanzlei bzw. zwischen Berufsträgern und Mandanten oder Institutionen zunehmend digitalisiert und ohne Medienbruch realisiert. Bereits seit 1997 existiert hierfür das Signaturgesetz und die Signaturverordnung in Deutschland. Bis 2014 war jedoch die einzige elektronische Signatur, die mit einer händischen Unterschrift gleichzusetzen ist, an eine Signaturkarte und ein Lesegerät gebunden. Im Zuge der eIDAS-Verordnung trat eine EU-weite Regelung in Kraft, die den Einsatz von Fernsignaturen gesetzlich ermöglichte. Dadurch entfallen für den Anwender die Hardwarekomponenten Signaturkarte und Lesegerät. Jedoch muss weiterhin eine Identifizierung des Anwenders erfolgen und es wird zukünftig ein Mobiltelefon benötigt. Ziel der Bachelorarbeit war eine Analyse der Anwendungsszenarien und eine Handlungsempfehlung für die Umsetzung bzw. Integration der Fernsignatur in die Softwareanwendungen der DATEV eG. Hierfür wurden ein Interviewleitfaden erstellt und Experteninterviews durchgeführt. Die interviewten Experten - ein Wirtschaftsprüfer, zwei Steuerberater, der Vorstand eines Signatursoftware-Herstellers und eine Mitarbeiterin der DATEV eG - ermöglichen eine praxisnahe Einschätzung und einen Rückschluss auf eine entsprechende Handlungsempfehlung für die DATEV eG.
18.10.19	2020	extern	Bachelor	DE	Analyse von Abhängigkeiten in der Softwareentwicklung der DATEV eG im Geschäftsfeld der Personalwirtschaft und Konzeptionierung von Maßnahmen zur Reduzierung der Durchlaufzeiten von Projekten	Bei der Zusammenarbeit der Komponententeams in der Abteilung LODAS/RZ-Lohn entstehen wechselseitige Abhängigkeiten, die zu höheren Warte- und Liegezeiten führen. Indem die Liege- und Rüstzeiten bei den Initiativen verringert werden, sollen die Durchlaufzeiten reduziert werden. Dadurch soll ein Mehrwert für die Kunden geschaffen werden, da die Software in kürzerer Zeit auslieferungsfertig ist. Ziel der Bachelorarbeit ist es, aufbauend auf ein bereits bestehendes Board, welches die Abhängigkeiten zwischen den beteiligten Teams sichtbar und steuerbar macht, weitere Maßnahmen herauszuarbeiten, die das Board effizient unterstützen können. So soll eine effektive Projektarbeit ermöglicht werden und zudem der Qualitätssicherung ein höherer Stellenwert zugeschrieben werden.
20.10.19	2020	extern	Bachelor	DE	Automatisierte Einordnung von Unternehmen in Wirtschaftszweige anhand deren Internetpräsenz	Die vorliegende Bachelorarbeit gibt einen Einblick in die Möglichkeit der automatisierten Einordnung und Klassifikation von Unternehmen in die Klassifikation der Wirtschaftszweige von 2008. Die Basis für das Vorhaben der Klassifikation, stellen hierbei die Internetauftritte der Unternehmungen dar. Die Klassifikation soll einen Anhaltspunkt zur Vorselektierung von relevanten Unternehmen aus der definierten Wirtschaftsklasse bieten. Um diese Aufgabe zu ermöglichen, wurde zunächst ein geeigneter Trainingsdatensatz, mittels der Methodik des Web Scrapings, erstellt. Im Anschluss an diesen Schritt bildeten die extrahierten Daten die Trainingsgrundlage für verschiedene Algorithmen des maschinellen Lernens. In dieser Arbeit wurde dabei die Methodik des überwachten maschinellen Lernens angewandt. Diese stellt die Algorithmen zur Erstellung eines Entscheidungsbaumes, der logistischen Regression, des mulitnomiellen Naive Bayes, der Support Vector Machine, sowie des Perzeptrons gegenüber. Dabei wird auch deren Performanz berücksichtigt. Bei den Daten wurde zudem der Unterschied der einzelnen Modelle unter der Verwendung der Term Freqency Inverse Document Frequency (TFIDF) gegenüber der Verwendung von 300 dimensionalen Dokumentenvektoren untersucht. Die Untersuchung stellte heraus, dass das Modell der TFIDF, unter der Verwendung der Support Vector Maschine, die für den Anwendungsfall beste Alternative darstellte. Diese ermöglichte eine Vorhersage mit einer Accuracy von 88%.
21.10.19	2020	extern	Bachelor	DE	Vorselektion eines externen Dienstleisters zur Weiterentwicklung der Einkaufsdigitalisierung bei der Nürnberger Versicherung	Das Ziel der vorliegenden Bachelorarbeit war es, eine Vorselektion von externen Dienstleistern für ein neues Einkaufssystem in Form einer Shortlist für die NÜRNBERGER Versicherung zu identifizieren sowie die Erstellung eines Konzepts für eine neue Einkaufsinfrastruktur. In Anlehnung an die Vorgehensweise von De Boer et al. konnte mit dem Anbietervorauswahlprozess die passenden potenziellen externen Dienstleister ausgewählt und eine Shortlist aufgrund der NÜRNBERGER Anforderungen erstellt werden. Diese Vorauswahl konnte mit den Methoden Lieferantengesprächen (inkl. Use Cases), RFI-Fragenkatalogen und einer Bewertungsmatrix erstellt werden. Für die Datenerhebungen der Ist-Situation und für das Soll-Konzept wurde die Einkaufsabteilung mit den Methoden Interviews, Workshops, Fragebögen und Arbeitsplatzanalysen befragt. Die Ergebnisse dieser Abhandlung waren die Erstellung des Soll-Konzepts, die Erstellung der Shortlist und der Kosten-Nutzen-Analyse des strategischen Beschaffungsprozesses als Grundlage für den Business Case. Die Bachelorarbeit ist für Einkäufer, Studierende der Wirtschaftsinformatik sowie für Stakeholder im Bereich des Ausschreibungs- und Anbieterauswahlprozesses interessant. Auf Basis dieser Arbeit kann mit der Endauswahl der externen Dienstleister begonnen werden.
21.10.19	2020	intern	Bachelor	DE	Bewertung bekannter Ad-hoc-Routing-Protokolle zur prototypischen Realisierung einer mobilen Messenger-Applikation	Ziel dieser Arbeit ist die Erstellung einer Messenger-Applikation, welche unabhängig von Internet und Mobilfunk arbeiten kann. Dafür muss ein geeignetes Routing-Protokoll gefunden werden. Es werden verschiedene Routing-Protokolle miteinander verglichen und deren Arbeitsweise untersucht. Anschließend wird mithilfe des gewählten Protokolls ein Prototyp einer Android-Applikation erstellt.
21.10.19	2020	extern	Bachelor	DE	Entwicklung eines Konzepts zur deutschlandweiten Einführung von Business Intelligence bei der Geschäftseinheit Regionalnetze der DB Netz AG	Mit dem Projekt "Einführung von Tableau" sollte Business Intelligence (BI) bei der Geschäftseinheit (GE) Regionalnetze der DB Netz AG eingeführt werden. In dem Projekt fehlte jedoch der strategische Ansatz sowie das nötige Know-how, weshalb das Projektziel nicht erreicht wurde. Das Ziel der Bachelorarbeit ist daher die Entwicklung eines Konzepts zur deutschlandweiten Einführung von BI bei der GE Regionalnetze. Dazu werden die folgenden Forschungsfragen gestellt: Wie kann ein Vorgehensmodell auf die betriebliche Praxis angepasst und für die Einführung von BI angewandt werden? Wie kann eine Organisation zur Bündelung der BI-Aktivitäten aussehen? Wie lassen sich innerhalb dieser Organisation Anforderungs- und Änderungsmanagement umsetzen? Welche Möglichkeiten gibt es, um einen deutschlandweiten Rollout einer BI-Plattform durchzuführen? Um die Forschungsfragen zu beantworten wurde in Fachliteratur zu BI und Analytische Informationssysteme recherchiert. Die Recherche ergab die Empfehlung zur Entwicklung einer BI-Strategie. Hierfür wird ein Vorgehensmodell bereitgestellt. Zur Organisation und Bündelung der BI-Aktivitäten wurde das Konzept des Business Intelligence Competency Center vorgestellt und auf die GE Regionalnetze angepasst. Für das Anforderungs- und Änderungsmanagement wurde die Nutzung eines Systems und die Aufnahme von Anforderungen durch Power-User empfohlen. Zudem erwies sich die funktionsorientierte Sukzessiv-Strategie als beste Vorgehensweise zur Einführung von BI.
22.10.19	2020	intern	Bachelor	DE	Untersuchungen zur Modellierung in der Spracherkennung: Auswirkungen der phonetischen Modellierung im Deutschen auf die Wort- und Silbenfehlerrate	Diese Arbeit befasst sich mit der automatischen Spracherkennung. Sie beinhaltet einen Einstieg, in dem die theoretischen Grundlagen von Spracherkennungssystemen und Grapheme-to-Phoneme-Konvertern erläutert werden. Ein besonderes Augenmerk liegt auf der Phonetischen Modellierung. Im praktischen Teil der Arbeit wird evaluiert, wie effektiv eine Modellierung von Silben in Bezug auf die Wort- und Silbenfehlerrate eingesetzt werden kann.
24.10.19	2020	extern	Bachelor	DE	Entwicklung eines automatisierten Integrationstestverfahrens für graphische Benutzeroberflächen auf Automotive-HMI-Bedienelementen	Die vorliegende Bachelorarbeit befasst sich mit der Entwicklung einer Testsoftware, mit der die Automatisierung des Integrationstests von Steuergeräten eines Automobils ermöglicht werden soll. Ziel dieser Software ist es, Testfälle generieren zu können, welche die Auswertung von Attributen des zu testenden Steuergeräts oder das Simulieren von berührungsbasierten Events auf ebendieses abwickelt. Für die Realisierung dieser Arbeit wurde ein Konzept der Testsoftware entworfen, welches anschließend auf eine spezifische Fallstudie der Firma Preh GmbH angewandt wurde. Das resultierende Konzept soll es ermöglichen, Testfälle für HMI-Software mit vergleichbaren Schnittstellen entwickeln zu können. Voraussetzung ist dabei jedoch, dass das System zur Laufzeit über eine Debug-Umgebung mit dem verbundenen Rechner kommunizieren kann. Weiterhin werden Anforderungen an die Testsoftware gestellt, kategorisiert und nach der MoSCoW-Methode priorisiert. Im Anschluss an die Aufstellung des Konzepts, sowie an die erfolgreiche Implementierung der Testsoftware für die Fallstudie wird die gesamte Arbeit und ihre Ergebnisse reflektiert. Abgeschlossen wird diese Bachelorarbeit mit einem Ausblick für Verbesserungen. Dazu wird Bezug zur Restbussimulation genommen, um die Testmöglichkeiten der Software auf Bussysteme, wie zum Beispiel CAN, zu erweitern.
25.10.19	2020	extern	Bachelor	DE	Behavior Driven Development im Bankenumfeld - Konzeption und Implementierung eines Prozesses zur Testautomatisierung auf Basis des PHP-Frameworks Behat	Die betreuende Firma dieser Arbeit stellt für Bankunternehmen Intranet-Plattformen bereit. Zur einfacheren Zusammenarbeit zwischen Entwicklern und Fachexperten soll Behavior Driven Development über das PHP-Testframework Behat zum Einsatz kommen. Mit diesem können auch Mitarbeiter ohne besondere IT-Kenntnisse Behavior-Driven-Tests im sogenannten Gherkin-Format formulieren. So können die Fachexperten beim Definieren neuer Anforderungen selbst Tests schreiben, welche automatisch ausgeführt werden und ein Reporting beinhalten. Um Behat und die gewünschten Funktionalitäten sinnvoll zu integrieren, wurde im Rahmen der Bachelorarbeit ein Prozess von der Anforderung bis zur Auslieferung der Software konzipiert und implementiert, in welchen Behat vollständig eingebunden ist. Hierzu wurden in der Arbeit eine graphische Oberfläche zum Verwalten der Tests, ein Versionsverwaltungssystem, ein Automationsjob sowie lokale und zentrale Testsysteme umgesetzt.
25.10.19	2020	intern	Bachelor	DE	Analyse der Entscheidungsfaktoren unterrepräsentierter Gruppen bei der Wahl von MINT-Studiengängen durch Methoden des maschinellen Lernens	Trotz steigendem Bedarf nach MINT-Absolventen bleibt die Frauenquote in diesen Fächer gering. Das Ziel dieser Arbeit ist es, die Entscheidungsfaktoren bei der Wahl des Studiengangs herauszufinden, zu analysieren und daraus eine Handlungsempfehlung für die Hochschule abzuleiten. Dazu soll folgende Forschungsfrage untersucht werden: Welche Entscheidungsfaktoren fließen bei unterrepräsentierten Gruppen bei der Wahl des Studiengangs mit ein? Zur Erweiterung der Datengrundlage wird eine Online-Umfrage durchgeführt. Anschließend werden die Daten durch Werkzeuge der Textanalyse und maschinelle Lernmethoden wie Sentiment Analyse aufbereitet, analysiert und ausgewertet. Aus den Ergebnissen lassen sich die wichtigsten Faktoren bei der Wahl des Studiengangs ablesen. Darauf aufbauend können Konzepte gestalten werden, um diese Entscheidungsfaktoren zu beeinflussen.
25.10.19	2020	extern	Bachelor	DE	Gegenüberstellung der Materialflusstechnologien SAP EWM MFS und Dematic MFS - Technische Analyse, Kundenbefragung und Konzeption eines Tools für die Anforderungsanalyse bei Neukunden	Ausgangspunkt dieser Bachelorarbeit ist ein systematischer Vergleich der Materialflusstechnologien von SAP EWM MFS in der Standardversion mit den Eigenentwicklungen des Dematic MFS. Basis ist eine technische Analyse anhand einer typischen Lagerkonstellation und den wichtigsten Kundenanforderungen. Diese werden bei Kundenbefragungen ermittelt und sollen verdeutlichen, welche Komponenten aus den beiden MFS-Systemen in welchen Situationen eher vorgezogen werden. Anhand dieser Erkenntnisse wird ein Tool zur Anforderungsanalyse entwickelt, mit dessen Hilfe Neukunden die passende Technologie oder Technologiekombination vorgeschlagen werden kann, damit die bestmögliche Lösung aus Kunden- und Entwicklersicht entsteht.
27.10.19	2020	intern	Master	DE	Identifikation von Entscheidungsfaktoren auf die Studienwahl in der Fachrichtung MINT auf Basis von Datenerhebungen in Form von Befragungen und deren statistischer Auswertungen	Ziel dieser Arbeit ist die Identifikation von Einflussfaktoren auf die Entscheidung für oder gegen ein MINT-Studium. Hierzu erfolgte neben einer Betrachtung aller Studierenden in den Hypothesen eins bis zehn eine Fokussierung auf unterrepräsentierte Gruppen in den Hypothesen elf bis 21. Zur Datenerhebung wurde eine Online-Befragung durchgeführt. Die Auswertung und Analyse erfolgte mit deskriptiven Statistiken, wie Häufigkeitsberechnungen und den Assoziationsmaßen Chi Quadrat sowie Cramer?sche V. Als generelle Einflussfaktoren auf die Studienfachwahl konnten das persönliche Interesse sowie Zukunftserwartungen vollständig bestätigt werden. Teilweise nachgewiesen wurde der Einfluss durch das soziale und schulische Umfeld, durch finanzielle Aspekte, Zugangsvoraussetzungen, den Hochschulstandort, Erwartungen und Einschätzungen bezüglich der MINT-Studiengänge sowie persönliche Informations- und Inspirationsquellen. Hinsichtlich eines besonderen Einflusses auf die Entscheidung für ein MINT-Studium durch unterrepräsentierte Studierendengruppen konnten Teilbereiche aus vier überprüften Entscheidungsfaktoren bestätigt werden. Dies betraf Erwartungen und Einschätzungen bzgl. MINT-Studiengängen hinsichtlich Frauen, die familiäre Situation im Zusammenhang mit Studierenden der ersten Generation, das soziale Umfeld im Bezug zu Studierenden mit Migrationshintergrund und finanzielle Aspekte in Verbindung mit finanzschwachen Studierenden.
31.10.19	2020	intern	Bachelor	DE	Entwicklung eines grundlegenden sensomotorischen Prozesses für das Greifen und Verlagern einfacher Objekte auf dem Robotersystem Pepper	In dieser Arbeit geht es darum dem Robotersystem Pepper den grundlegenden Prozess des Greifens und Verlagerns eines einfachen Objektes beizubringen. Der erste Schritt im Prozess der Implementierung soll die Erkennung einfacher Gegenstände mit Hilfe der Kombination aus einem Farberkennungs-und Kreiserkennungsalgorithmus sein. Für die weiteren Schritte wird zur Bewegungskontrolle des Roboters eine Image Based Visual Servoing Steuerung verwendet. Anhand der vorher programmierten Objekterkennung soll der Roboter dann den Raum nach einem Zielgegenstand in Form eines Balles absuchen und auf diesen zusteuern. Dort bleibt er in Greifdistanz davor stehen. Der Gegenstand soll dann mit dem eye-to-hand System gegriffen werden. Sind diese Schritte erfolgt, soll der Roboter sich wieder etwas zurück bewegen und den Raum erneut absuchen, um die Zielmarkierung zu finden. Hat er das Ziel entdeckt, soll er auf dieses zusteuern und in Greifdistanz davor stehen bleiben. Der Roboter soll dann den Ball auf die Markierung legen (eye-to-hand System). Resultat der Arbeit ist, dass der Roboter Pepper in naher Distanz (1.5m) den Ball erkennt, darauf zusteuert und diesen greifen kann. Dieses Ergebnis kann als Grundlage für weitere Forschungen und Projekte im Game-Tech-Labor verwendet werden.
31.10.19	2020	extern	Bachelor	DE	Konzeption und prototypische Umsetzung einer minimalen API-Management Umgebung um Unternehmen aus dem Finanzsektor den Einstieg in die API Economy zu erleichtern.	Viele Unternehmen im Finanzsektor öffnen ihre IT-Landschaft, um sich im aktuellen Onlinemarkt zu integrieren. Dabei werden Application Programming Interfaces veröffentlicht. Das Veröffentlichen der APIs erweitert die Angriffsfläche der Unternehmen. Ohne zusätzliche Absicherung können Angreifer die Schwachstellen der Infrastruktur ausnutzen (vgl. S.111 [De 17]). Um den Problemen entgegenzuwirken, kann man bereits etablierte API-Management-Produkte verwenden. Das Ziel dieser Bachelorarbeit ist es eine Wissensbasis für den Themenbereich API-Management zu schaffen und eine prototypische API-Management-Umgebung umzusetzen. Zu diesem Zweck werden die Anforderungen von Unternehmen des Finanzsektors an eine API-Management-Umgebung mit Hilfe verschiedener Methoden des Requirement-Engineerings erarbeitet. Auf Basis der ermittelten Ergebnisse werden die Schlüsselfunktionalitäten einer minimalen API-Management-Umgebung identifiziert und ein API-Developer-Portal konzipiert. Dieses wird in Form eines Click-Prototyps umgesetzt. Zusätzlich wird ein in Frage kommendes API-Management-Produkt evaluiert. Auf dem Produkt aufbauend wird eine API-Management-Umgebung erstellt. Die fertige Umgebung wird auf der Container-Plattform der Firma adorsys bereitgestellt und anschließend im Rahmen der Umsetzung von Entwicklern durch einen Usability-Test auf das Erfüllen der Anforderungen geprüft.
01.11.19	2020	extern	Bachelor	DE	Konzeptionierung und Implementierung eines Webservice für ein MES System von verfahrenstechnischen Anlagen 	In automatisierten Produktionsanlagen entstehen täglich Unmengen an Informationen. Dazu gehören Daten zu Aufträgen, zu Materialbewegungen, zu Lagerbeständen und viele mehr. Dadurch entsteht die Problematik, dass die entscheidenden Informationen oft nicht mehr erkannt werden können, was die Produktivität und Effizienz negativ beeinflussen kann. Die Aufbereitung, Analyse und Überwachung der Daten im korrekten Kontext ist essentiell für die optimale Steuerung von Produktionsanlagen. Hierzu werden oft MES-Systeme eingesetzt, welche die einzelnen Prozesse sichtbar und vor allem nach verfolgbar machen. Um diese Anwendungen zentral bedienen zu können muss eine geeignete Schnittstelle für das MES-System existieren. In dieser Arbeit wird das Konzept und die Implementierung eines Webservice vorgestellt, welcher die Kommunikation eines MES-Systems mit der Datenbank gewährleistet und für die korrekte Abarbeitung der anfallenden Daten aus diesem System sorgt. Der Service soll den Grundstein dafür legen, weitere Anwendungen erstellen zu können, die rein im Web laufen und über HTTP-Requests mit diesem kommunizieren können.
04.11.19	2020	intern	Bachelor	DE	Prototypische Entwicklung eines Empfehlungssystems zur Unterstützung von Absolventen bei der Job-Suche	In der Bachelorarbeit mit dem Titel "Prototypische Entwicklung eines Empfehlungssystems zur Unterstützung von Absolventen bei der Job-Suche" geht es grob darum, dass mithilfe von verschiedensten Tools ein prototypischer Chatbot konzeptioniert wurde. Der Bot soll Studenten in den finalen Semestern bei der Job findung helfen. Er gibt basierend auf den Antworten der Studenten Berufe aus welche für eben diese passen könnten. Aktuell ist der Prototyp auf Twitter erreichbar.
04.11.19	2020	extern	Bachelor	DE	Steigerung der Kundenservice-Exzellenz durch KI-basiertes Output-Management 	Am Anwendungsbeispiel des Kundenservice der N-ERGIE AG, Sitz in Nürnberg, wird geprüft, ob durch den Einsatz maschineller Lernverfahren im Output Management die Kundenservice Exzellenz gesteigert werden kann. Kundenservice Exzellenz beschreibt hierbei zum einen einen wirtschaftlichen Einsatz der für einen positiven Kundenkontakt verwendeten Ressourcen, als auch die allgemeine Qualität, welche dem Kunden geboten wird, um diesem ein positives Erlebnis im Kontakt mit dem Unternehmen bieten zu können. Als mögliche Verfahren wurde hierbei die Klassifikation mittels Methoden aus dem supervised Learning in Absprache mit der N-ERGIE AG identifiziert. Mithilfe der Klassifikatoren NaiveBayes, SupportVector Machines und dem k-Nearest-Neighbor-Algorithmus werden an den Kunden ausgehende Nachrichten kategorisiert. Hierfür wurden über 1300 Kundenschreiben vorklsasifiziert. Ein seitens der N-ERGIE AG bereitgestellter Gesprächsleitfaden dient hierbei als Grundlage, um die Nachrichten im Sinne des Kundenservice zu kategorisieren und die identifizierten Modelle zu trainieren. Mithilfe der Metriken Accuracy, Precision, Recall und F1-Score wird die Güte der Klassifikation bewertet. Abschließend wird mithilfe eines User-Interfaces geprüft, ob neue E-Mails durch die Modelle eine hinreichende Klassifikation Erfahren. Es stellt sich heraus, dass durch einen Einsatz dieser Methoden unnötige Fehler wie Fehlerhafte Nachrichten oder fehlender Pflicht-textbestandteile vermieden werden können.
08.11.19	2020	extern	Bachelor	DE	Integration des User Centered Design in das Model-Based Systems Engineering für die Entwicklung gebrauchstauglicher Cyber-physischer Systeme.	In einer immer stärker werdenden Vernetzung unseres Lebens, besitzen die heutigen entwickelten Produkte eine zunehmende Produktkomplexität. Neben den mechanischen und mechatronischen Komponenten enthält ein sogenanntes Cyberphysisches System (CPS) Softwarekomponenten. Auf Grund der zusätzlichen Komponenten sind Unternehmen gefordert, eine interdisziplinäre Produktentwicklung als Prozess zu implementieren. Dabei müssen nicht nur die funktionalen Eigenschaften und die stetig steigende Komplexität des Produktes berücksichtigt werden. Der Umstand der Gebrauchstauglichkeit, wie Nutzer zukünftig mit Hilfe des Systems effektiv und effizient ihre Ziele erreichen können, muss ebenfalls berücksichtigt werden. Wird allerdings bei der Entwicklung der Nutzer vergessen, steigt die Wahrscheinlichkeit einer Abneigung des Nutzers gegenüber dem Produkt. Entgegenwirken kann hier die Gestaltungsmethode des Human-Centered Design. Dabei wird der Nutzer eines Produktes mit seinen Zielen, Einstellungen und Eigenschaften in den Fokus des Entwicklungsprozesses gestellt.
13.11.19	2020	extern	Bachelor	DE	Einführung von ITIL Operation Prozessen im Service Desk	Der Titel der Arbeit lässt bereits erkennen, was im Folgenden erarbeitet wird. In dieser Arbeit wird insbesondere darauf eingegangen inwieweit durch die Effektivitätssteigerung des Problem Managements das Incident Management entlastet werden kann, ohne die Effizienz zu beeinträchtigen. In der Theorie des IT Service Managements (ITSM) wurde im Jahr 2011 die dritte Version des IT Infrastucture Library Frameworks veröffentlicht. Dieses hat das Ziel ITSM Prozesse innerhalb des Unternehmens zu optimieren, um somit eine effizientere und effektivere Arbeitsweise zu gewährleisten. Dies wird zu Beginn der Arbeit erläutert und für ausgewählten Prozesse spezifiziert. Außerdem wird auf die ISO 20000 Zertifizierung eingegangen und die standardisierte Notation BPMN 2.0 aufgezeigt. Für das Unternehmen SanData ist die betriebliche Umsetzung, in der sich die Theorie unter Einflüssen der Praxis beweisen muss, entscheidend. In dieser Arbeit werden die einzelnen Prozesse durch Workshops erarbeitet und die Ergebnisse erläutert. Abschließend werden ein Fazit sowie ein Ausblick darüber gezogen.
18.11.19	2020	intern	Master	DE	Entwicklung eines optimierten Punkte-Containers für das k-nearest-neighbor-Problem	In dieser Arbeit wurde untersucht, wie das K-Nearest-Neighbor-Problem im dreidimensionalen Raum unter Verwendung des Euklidischen Abstandes als Abstandsmaß effizient gelöst werden kann. Neben der Antwortzeit für eine Abfrage ist die Antwortzeit für das Einfügen von Punkten in den Punktecontainer wichtig. Unter den untersuchten Strukturen hat sich der K-D-B-Tree als die effizienteste Struktur herausgestellt. Als Wert für die Kapazität einer Region Page wurde 4 gewählt, 64 für die Kapazität einer Point Page. Die Strategie zum Teilen eines Knotens teilt eine Point Page bei der Überlauf zyklisch nach der Höhe des Baumes, Läuft der Elternknoten des übergelaufenen Blattknotens ebenfalls über, wird dieser nach derselben Achse geteilt, dies setzt sich solange fort, bis der der Elternkoten des aktuell betrachteten Knotens nicht überläuft. Als Verfahren für das Durchführen einer K-Nearest-Neighbor-Abfrage dient eine Adaption des Henrich-Verfahrens auf den K-D-B-Tree.
19.11.19	2020	intern	Bachelor	DE	Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters	Entwicklung eines Verfahrens zur Erkennung beweglicher Objekte mit Hilfe eines Lidar-Scanners auf einem mobilen Roboter. Ziel ist es, durch Literaturrecherche zu prüfen, ob ein SLAM-Verfahren existiert, der für die Erkennung von dynamischen Objekten optimiert ist. Falls ein optimiertes Verfahren vorhanden ist, wird dieses für den 'Carbot' Roboter implementiert. Anderenfalls wird der bisherige SLAM-Algorithmus (ICP) soweit weiterentwickelt, dass dynamische Objekte erkannt und kartographiert werden können.
19.11.19	2020	extern	Bachelor	DE	Verortung von Platinenbauteilen durch Parsen von Schaltplänen anhand eines Embedded Evaluation Boards	Die vorliegende Bachelorarbeit verfolgt das Ziel die Konfiguration eines Evaluation Boards für den Entwickler zu erleichtern sowie teilweise zu automatisieren. Die Unterstützung fokussiert sich insbesondere auf die Darstellung einzelner Pinbezeichnungen des Mikrocontrollers und den damit verknüpften Bauteilen des Evaluation Boards. Um dieses Ziel zu erreichen, gilt es relevante Informationen aus dem entsprechenden Schaltplan zu entnehmen und in einer geeigneten Form aufzubereiten und anschließend darzustellen. Hierfür werden zunächst Methoden der Mustererkennung verwendet, um die benötigten Informationen aus dem Dokument zu extrahieren. Die Ergebnisse dieser Ansätze entsprechen jedoch nicht den Erwartungen und werden verworfen. Um eine korrekte Abbildung des Schaltplanes zu erreichen, wird dieser direkt aus dem XML-Format geparst und danach strukturiert in Form einer XML-Datei abgelegt. Die Darstellung der aufbereiteten Daten erfolgt durch eine mobile Anwendung, welche für die Verwendung auf einem Tablet geeignet ist. In dieser wird das Evaluation Board mithilfe der Objekterkennung erfasst und anschließend das erstellte XML-Dokument deserialisiert, um dem Entwickler detaillierte Informationen bezüglich des Evaluation Boards darstellen zu können.
20.11.19	2020	intern	Bachelor	DE	Konzeption und Evaluation einer Testumgebung zur Erkundung virtueller taktiler Karten	Für Menschen mit Sehbehinderung ist es schwierig sich in neuen Umgebungen zurechtzufinden. Eine Möglichkeit für den Aufbau eines mentalen Bildes ist der Einsatz von taktilen Karten. Die Herstellung dieser ist jedoch sehr zeitaufwendig. Virtuelle taktile Karten nutzen haptisches Feedback, um taktile Karten mithilfe von VR-Technologien virtuell darzustellen. Diese Arbeit beschreibt Anforderungen und ein Konzept zum automatischen Erstellen von virtuellen taktilen Karten. Eine Benutzerstudie für einfache geometrische Grundrisse kam zu dem Ergebnis, dass die Darstellung virtueller taktiler Karten mithilfe von Datenhandschuhen prinzipiell möglich ist. Die Präzision der Technik und Handhabung der Geräte kann jedoch durch weitere Forschung verbessert werden.
20.11.19	2020	intern	Bachelor	DE	Einsatz maschineller Lernverfahren zur automatischen Erkennung psycho-sozialer Kategorien in Forenbeiträgen	Die Menschen nutzen unterschiedliche Beratungsmöglichkeiten, um persönliche Probleme zu bewältigen und richtige Entscheidungen zu treffen. In den letzten Jahren wurde in vielen Kontexten Online-Beratung eingesetzt. Als Kommunikationsform kann E-Mail-Beratung, Chatberatung oder Beratung in Foren genutzt werden. In den Beratungsforen können zu gegebener Problemstellung des Ratsuchenden sowohl die professionellen Berater als auch andere Forenbenutzer Ratschläge erteilen. Professionelle Berater setzen etablierte Beratungsmethoden und -techniken ein. Die Untersuchung der Vorgehensweise auch anderer Berater und ihres Beitrags zur erfolgreichen Beratung könnte zur Verbesserung der Beratungsstrategien von professionellen Beratern eingesetzt werden. Ziel dieser Arbeit ist es zu untersuchen, ob und in welchem Umfang die Maschine die vorgegebenen psycho-soziale Kategorien in den Beiträgen der Berater erkennen kann. Um Ziel zu erreichen, wurden zunächst die Grundlagen der Textanalyse und die Klassifizierungsalgorithmen erläutert. Danach wurden die überwachten maschinellen Lernverfahren zur automatischen Kategorisierung der Beiträge eingesetzt und bewertet. Abschließend wurden die Ansatzpunkte für die Verbesserung ermittelt.
21.11.19	2020	extern	Bachelor	DE	Evaluation verschiedener Tools zum automatisierten Einrichten einer skalierbaren Testinstanz sowie Prüfung der Testergebnisse zur Qualitätsverbesserung des bpanda-Produkts der MID GmbH	Das Ziel dieser Bachelorarbeit ist die Implementierung eines Testsystems mit Hilfe einer Last- und Performancetestsoftware. Mit diesem System lässt sich die Qualität des Produkts Bpanda bewerten. Bpanda ist dabei eine Cloud-Anwendung für das Prozessmanagement im Unternehmen. Im Rahmen dieser Arbeit soll eine Nutzwertanalyse durchgeführt werden um eine Auswahl zwischen verschiedene Last- und Performancetestsoftwares zu treffen. Diese Software soll in der Lage sein, die vordefinierten Datenmenge in einer bestimmten Zeit zu erzeugen. Nach der Auswahl der Software sowie die Durchführung von Tests soll bestimmt werden, ob die vordefinierten Datenmenge aktuell vom Bpanda-Produkt erarbeitet werden konnten oder nicht.
22.11.19	2020	extern	Bachelor	DE	Optimierung einer Webanwendung zur Verbesserung der Termintreue in der Schaeffler AG im Rahmen eines Six-Sigma-Projekts	Bei der Zentralisierung des Transportmanagements entsteht eine Informations- und Kommunikationslücke zwischen dem Customer Service, zuständig für Aufträge einzelner Werke und dem Transport Management, zuständig für die Transporte zu Kunden für die Schaeffler Gruppe. Um diese Wissenslücke zu schließen gibt es das Avisierungstool. Hier legt der Customer Service Lieferungen an und das Transportmanagement kann für die Lieferungen dem Spediteur beauftragen, den Kunden die anstehenden Lieferungen mitteilen und das Verladebüro des jeweiligen Werks benachrichtigen, welche Sendungen voraussichtlich abgeholt werden. Im Rahmen der Bachelorarbeit sollen wichtige Ergänzungen hinzugefügt werden. Ob diese Veränderungen zu Verbesserung der Termintreue im Werk Lahr führen soll mit einem Six Sigma Prozess gemessen werden. Hierzu wird die Termintreue vor und nach der Veränderung beobachtet.
25.11.19	2020	intern	Bachelor	DE	Analyse der IT-Strategien der bayrischen Hochschulen und der Studierendenanforderungen für die Entwicklung der IT-Strategie der Technischen Hochschule Nürnberg	Der Einsatz von Informationstechnologie (IT) ist heutzutage in fast jedem Lebensbereich vertreten. Ein Beispiel liefern deutsche Hochschulen, an denen IT zur Erfüllung zahlreicher Aufgaben angewendet wird. Um die IT-Unterstützung der Hochschulen effektiv und effizient auszurichten, werden externe und interne Umfeldanalysen durchgeführt. Die Aufgabe der Umfeldanalyse ist es, dem IT-Management für ihre IT-Strategieentwicklung, wichtige Informationen über die Stakeholder und die Trends der stetig wachsenden Branche zur Verfügung zu stellen. Im Rahmen dieser Arbeit wurde eine Umfeldanalyse für eine Aktualisierung der IT-Strategie der Technische Hochschule Nürnberg durchgeführt. Aufgrund des großen Umfangs einer vollständigen Analyse beschränkt sich die vorliegende Arbeit auf zwei Bereiche, das interne und externe Umfeld. Als externes Umfeld wurden dabei die staatlichen Hochschulen in Deutschland, mit Hauptfokus auf das Bundesland Bayern, untersucht. Die Analyse des internen Umfelds bezog sich auf die Studierenden der Technischen Hochschule Nürnberg. Die untersuchten Fragestellungen, abgeleitet aus den Zielen der Umfeldanalyse, konnten unter Einsatz einer strategischen Wettbewerbsanalyse für das externe Umfeld, sowie mit den Methoden der empirischen Sozialforschung für das interne Umfeld, teilweise beantwortet und die eingesetzten Methoden evaluiert werden.
28.11.19	2020	extern	Bachelor	DE	Erstellen eines prototypischen Systems zur Empfehlung von Finanzmarktnachrichten auf Basis von Benutzerdaten	Die vorliegende Bachelorarbeit untersucht, wie Finanzmarktnachrichten auf Basis von Benutzerdaten empfohlen werden können und wie dieses Empfehlungssystem als firmeninterner Dienst zur Verfügung gestellt werden kann. Im Rahmen dieser Arbeit wird aufgrund fehlender Nachrichtennutzungsdaten ein alternativer Ansatz mit der Prognose der Kaufwahrscheinlichkeit von Aktien als Ersatz für den Empfehlungswert verwendet. Es wird geprüft, ob dieser Ansatz gute Ergebnisse liefern kann, welche der ausgewählten Algorithmen für diesen Ansatz die passendsten Empfehlungen liefert und wie das endgültige Produkt in die Systemlandschaft integriert werden kann. Zur Prüfung der Algorithmen wird eine Simulationsstudie mit unterschiedlichen Klassifizierern und verschiedenen Datensatzkombinationen aus Nutzer, Objekt und Attributen durchgeführt. Zur Bewertung werden die verschiedene Metriken und die Laufzeiten gewichtet verwendet. Die Arbeit zeigt, dass die Prognose der Kaufwahrscheinlichkeit für Aktienempfehlungen verwendet werden kann. Aus der Studie lässt sich ableiten, dass Neuronale Netze und Random Forests gute Metrikwerte und gleichzeitig gute Laufzeiten bieten, wohingegen der Gaussische Prozess zwar die besten Metrikwerte aber eine der schlechtesten Laufzeiten hat. Die Verwendung der Attribute hat die Metriken minimal verschlechtert, woraus sich schließen lässt, dass es nicht relevant ist, ob die verwendeten Attribute oder Attribute im Allgemeinen eingesetzt werden.
02.12.19	2020	extern	Bachelor	DE	Evaluierung und Vergleich verschiedener Open Source DeepLearning-Frameworks	Ein Ziel der Arbeit ist es, einen Einblick zu gewinnen, welche DL-Frameworks aktu-ell im Umlauf sind und wie diese verwendet werden. Daraus soll ein Vergleichskata-log für verschiedene Anforderungen erstellt und die Frameworks mithilfe dieser Kri-terien analysiert werden. Dies soll die Entscheidungsphase bei der Einführung ei-nes KI-Frameworks für ein Unternehmen verkürzen. Vergleiche verschiedener Frameworks existieren bereits (siehe zum Beispiel die Winterausgabe des iX-Developer Fachmagazins mit dem Thema "Machine Learn-ing"). Viele der im Netz im Umlauf befindlichen Vergleiche sind jedoch häufig mehr für den privaten Interessenten geeignet als für eine betriebliche Entscheidungshil-fe. Diese Arbeit soll sich auf einen vergrößerten Kriterienkatalog stützen, welcher zum Beispiel die unterstützen Sprachen oder die Anforderungen an die Infrastruk-tur eines Unternehmens enthält. Weitere exemplarische Kriterien wären das benö-tigte Know-how für die Entwickler und den Betrieb, sowie die Unterstützung durch die Community des jeweiligen Frameworks. Zusätzlich sollen die zur Verfügung gestellten Algorithmen, die Performance und die Einsteigerfreundlichkeit analysiert und bewertet werden.
02.12.19	2020	intern	Bachelor	DE	Konzeption und Entwicklung eines Web-Crawlers zur Ermittlung von Veröffentlichungen von Professoren der TH Nürnberg	Im Rahmen dieser Arbeit wurde ein funktionierender Web-Crawler implementiert, der Publikationen von Autoren der Technischen Hochschule Nürnberg sammelt. Das System bezieht die Veröffentlichungsmetadaten aus drei Quellen und persistiert diese in einer eigenen Datenbank. Für die Vermeidung von Duplikaten werden probabilistische Matching-Algorithmen eingesetzt, die sowohl Autoren als auch Publikationen vergleichen und harmonisieren. Als Schnittstelle für die Nutzer der Daten, beispielsweise die Hochschulkommunikation und -entwicklung, besteht eine Webanwendung, welche die Metadaten anzeigt und eine Suchfunktionalität bereitstellt. Des Weiteren wurde im Rahmen der Bachelorarbeit ein Betriebskonzept erarbeitet, welches das Deployment der einzelnen Softwarekomponenten via Docker umsetzt. Die regelmäßige Ausführung wird zudem mit Hilfe eines Cronjobs ermöglicht, sodass wöchentlich neue oder geänderte Publikationen gesammelt und eingepflegt werden. Auf diese Weise bleibt der Datenbestand aktuell.
02.12.19	2020	extern	Bachelor	DE	Design und Umsetzung eines Windows Programms zum Auslesen und Interpretieren von Diagnosedaten über das UDS Diagnose Protokoll eines CAN Steuergerätes in C#	Diese Arbeit beschäftigt sich mit dem Entstehungsprozess einer Anwendung im Auto- mobilbereich. Ziel ist die Entwicklung eines firmeninternen Diagnosetools in C#. Dieses kommuniziert aufbauend auf dem Unified Diagnostic Services Protokoll (UDS) mit einem KFZ Steuergerät. Das Kommunikationsmedium ist hierbei das Controller Area Network (CAN) Bussystem. Mithilfe des ISO Transportprotokolls sollen diverse Diagnosedienste an das Steuergerät gesendet werden. Diese werden nach Erhalt ausgeführt und eine ent- sprechende Antwort zurück gesandt. Rückgaben werden entgegengenommen, interpre- tiert und passend dargestellt. Hierzu gehört neben einer passenden Benutzeroberfläche auch die optionale Erzeugung einer HTML Datei mit den Ergebnissen. Im Rahmen der Arbeit werden die Dienste Fehlerspeicher löschen und Fehlerspeicher lesen implementiert.
12.12.19	2020	intern	Bachelor	DE	Untersuchung aktueller maschineller Lernverfahren zur Erkennung von Emotionen in Beratungsverläufen	Im Rahmen dieser Arbeit wurde untersucht, mit welcher Qualität sich Wörterbuchverfahren zur Emotionsanalyse in Forentexten einsetzen lassen und welche Probleme dabei identifiziert werden können. Für weitgefasste, oberflächliche Analysen, wie Unterschiede vom durchschnittlichen Emotionsgehalt zwischen verschiedenen Foren konnten Erfolge erzielt werden. Der Versuch, Bezeichner wie "sehr hoher" oder "mittelhoher" Emotionsgehalt durch Vergleich mit dem gesamten Datensatz abzuleiten, war nicht erfolgreich. Eines der drei verwendeten Wörterbücher, das nur durch automatische Übersetzung aus dem Englischen entstanden ist, konnte im Vergleich zu den anderen beiden keine zuverlässigen Ergebnisse liefern. Die anderen zwei Wörterbücher waren im Gegensatz dazu von deutschsprachigen Experten kuriert. Als Probleme konnten in dieser Arbeit unter anderem die niedrige Textqualität von Forentexten identifiziert werden. Darüber hinaus wird gerade in Foren für psychische Probleme teilweise eine domänenspezifische Sprache verwendet, die die Wörterbücher nicht immer abbilden. Auch die Betrachtung einzelner Worte ohne Berücksichtigung des Kontexts gehört zu den Nachteil dieses Verfahrens.
13.12.19	2020	extern	Bachelor	DE	Entwicklung einer GUI zur Konfiguration von IoT Systemen mit RDF Graphen	Das Ziel der Bachelorarbeit ist es, den Einsatz von Geräten, aus dem Bereich Internet der Dinge (IoT), zu vereinfachen. Berücksichtigt werden hierbei nur IoT-Geräte, welche Daten zur Kommunikation über das Hypertext Transfer Protocol versenden und mit dem, vom World Wide Web Consortium eingeführten, SOSA Vokabular beschreiben. Umgesetzt wird dies, durch die Implementierung einer grafischen Oberfläche auf der mit Ziehen und Ablegen von Blöcken, das Application Programing Interface (API) eines IoT-Systems bedient wird. Als konkretes Anwendungsszenario wird ein System zur Verwaltung eines Postbehälterkreislaufs genutzt. Anwender sollen in der Lage sein, ohne Fachwissen, durch Anordnen von grafischen Elementen Abfragen, in der Abfragesprache SPARQL, zu schreiben. Dabei sollen sie Bedingungen für den Postbehälterkreislauf festlegen können wie beispielsweise "Behälter ist an Poststelle X", "Behälter hat Standort X verlassen" oder "Behälterstandort seit Y Stunden unbekannt". Zusätzlich sollen Anwender, abhängig von diesen Bedingungen, Aktionen ausführen können. ZB. könnte die Anwendung eine Nachricht ausgeben, wenn eine Bedingung erfüllt ist. Diese Aufgaben werden abschließend in einer Evaluation von der Zielgruppe durchgeführt. Dabei wird die implementierte Anwendung hinsichtlich der Bedienbarkeit ohne oder mit nur wenig Fachwissen anhand der System Usability Scale, einem standardisiertem Fragebogen, bewertet. Die Anwendung erreicht hier einen überdurchschnittlichen Wert von 81.4.
17.12.19	2020	intern	Bachelor	DE	Didaktische Aufbereitung eines autonom fahrenden Modellfahrzeuges auf Basis einer Arduino Plattform	In dieser Bachelorarbeit wird ein autonom fahrendes Roboterauto (Artur) basierend auf dem UNO AT 328 R3 und dem Mega AT 2560 R3 (+ESP8266 WiFi-Modul) auf der Arduino-Plattform gebaut, das mit einer geeigneten Sensorik ausgestattet wird. Durch mechanische Notendschalter im vorderen und hinteren Bereich des Roboters wird die Sicherheit gewährleistet. Zusätzlich wird eine Konzeption zu einer Lernbaukasten für die Altersgruppe ?Sekundarstufe 1? konstruiert, mit dem die Problematiken in dem Themenbereich ?autonomes Fahren? vorgestellt werden. Eine softwaretechnische Konzeption und Umsetzung eines Vorprototyps (BB09) auf der Basis von Artur macht einen wesentlichen Teil der Abschlussarbeit aus. Die Programmiersprache basiert auf C und umfasst C++-Erweiterungen. Die Arduino-IDE stellt alle notwendigen Tools zur Verfügung. Die Herausforderung besteht bei einem solchen Projekt darin, die Bauteile selber zu planen, zu bestellen und zusammenzubauen. Die Empfindlichkeit der Sensoren hat in unterschiedlichen Umgebungen Auswirkung auf die Funktionsfähigkeit, die durch intelligente Auswertungsalgorithmen verbessert werden kann. Im Zusammenhang damit werden unterschiedliche Ressourcen benötigt. Dazu zählen beispielsweise zusätzlicher Programmcode, mehr Komplexität zwischen den Softwareblöcken und mehr Datenspeicher. Im nächsten Schritt sollte eine künstliche Intelligenz in den Entscheidungsprozess involviert werden.
21.01.20	2020	extern	Bachelor	DE	Erweiterung einer App um eine Nutzerauthentifizierung am Beispiel "Das Telefonbuch"	Die IT2Media GmbH entwickelt im Auftrag der Deutsche Tele Medien GmbH eine kostenlose iOS- und Android-Applikation mit dem Namen "Das Telefonbuch?, in der jegliche Firmen und Personen einen Telefonbucheintrag erhalten, die gegen eine Eintragung nicht widersprochen haben. In dieser App werden alle vorhandenen Daten zu einem Telefonbucheintrag angezeigt. Im Moment ist das Buchen von weiteren Zusatzinformationen oder Service-Funktionalitäten für einen Telefonbucheintrag über die App nicht möglich. Damit solche Transaktionen in der Zukunft über die Applikation geführt werden können, wird eine Nutzerauthentifizierung benötigt. Das Ziel dieser Arbeit ist das Entwickeln eines mobilen Prototyps, welcher mit einem Server kommuniziert, der es dem User ermöglicht, sich schnell und leicht innerhalb der App anzumelden, um zukünftig gebührenpflichtige Services und weitere Zusatzinformationen für seinen Eintrag in der Applikation zu buchen. Derzeit existieren keine User-Accounts, um eine Anmeldung durchzuführen. Dazu wurde der Ist-Zustand der mobilen Applikation "Das Telefonbuch? analysiert und die verschiedenen existierenden Kaufprozesse geschildert, die momentan genutzt werden, um diese Transaktionen zu tätigen. Auf Basis der erfolgten Analyse des Ist-Zustands wurde ein Konzept für die Authentifizierung der User entwickelt, die in der Zukunft für die App entwickelt wird.Neben dem Konzept und dem Prototypen soll auch ein Backend-System entwickelt werden, welches für die Authentifizie
29.01.20	2020	intern	Bachelor	DE	3D Kartografierung mit einer Time-of-Flight-Kamera	Damit sich ein Roboter in einer ihm fremden Umgebung orientieren kann, muss er diese erst erkunden. Allein durch die Daten seiner Sensoren soll er gleichzeitig seine Umgebung Kartografieren, als auch seine räumliche Lage und Orientierung bestimmen. In der Forschung wird diese Herausforderung auch als Simultaneous Localization and Mapping (SLAM) bezeichnet. Hiefür können Time-of-Flight Kameras eingesetzt werden. Das sind Digitalkameras, die in den Pixeln statt der Farbinformation die Entfernung eines Objektes erfassen. Damit kann pro Aufnahme eine 3D Punktwolke dieses Ausschnittes generiert werden. Setzt man diese mit einem SLAM Verfahren richtig zusammen, ensteht eine dreidimensionale Karte der Umgebung. Diese Arbeit erläutert die Funktionsweise von SLAM Systemen, die nur mit Bilddaten aus einer Time-of-Flight Kamera versorgt werden. Im Auswahlprozess wurde sich für das ORB SLAM 2 System entschieden und dieses für die 3D Kartografierung mit einer dichten Punktwolke erweitert. Mittels einer JavaRos Schnittstelle wurde versucht, die SLAM Implementierung in die Bugbot-Plattform zu integrieren.
29.01.20	2020	intern	Master	DE	Einsatz von dynamischen Multilevel-Multitheory-basierten Modellen zur Analyse digitaler Wissensnetzwerke am Beispiel einer interdisziplinären wissensintensiven Organisation	Die digitalen Infrastrukturen moderner Unternehmen stellen Mitarbeiterinnen und Mitarbeitern mehrere IT-Applikationen zur Verfügung, die bei Nutzung zur Entstehung informeller digitaler sozialer Netzwerke neben der formellen Aufbauorganisation führen. Diese im Organisationskontext entstandenen Netzwerke sind ? trotz zahlreicher Theorien und statistischer Werkzeuge ? nicht erschöpfend erforscht. Dabei können solche Netzwerke wertvolle Einblicke in die Wissensaustausche sowie Unternehmensstrukturen und -dynamiken gewähren. Mit dieser Arbeit sollen anhand des Wissensnetzwerks einer interdisziplinären wissensintensiven Organisation Hypothesen zur Netzwerkdynamik und -struktur aufgestellt und mithilfe eines dynamischen Multilevel-Multitheorie-basierten Modells auf mehreren Netzwerkebenen simultan geprüft werden. Dabei wird überprüft, inwiefern dieses Modell ein ganzheitliches Verständnis eines Netzwerks ermöglicht und inwiefern es eine Grundlage für das Erkennen von Stärken und Schwächen liefert. Zunächst soll eine Literaturrecherche im Bereich der Netzwerkanalyse mit Fokus auf modellbasierte Analysen stattfinden. Darauffolgend werden die Daten des Wissensnetzwerks erhoben, systematisiert und formatiert. Anschließend soll das Netzwerk mithilfe des ausgewählten Modells analysiert und nach Stärken und Schwächen untersucht werden. Abschließend werden eine Zusammenfassung zu dem Modelleinsatz und ein Ausblick auf die Perspektiven der Modellierung gegeben.
31.01.20	2020	extern	Master	DE	Empfehlung von Führungsmethoden in der Softwareentwicklung unter Einbeziehung unterrepräsentierter Gruppen	Im Bereich der Softwareentwicklung haben sich in den letzten Jahren die agilen Führungsmethoden immer mehr etabliert. Leadership wird immer wichtiger für Personen mit Führungsverantwortung. Hinzu kommt, dass die Diversität in der Gesellschaft zu einer immer größeren Vielfalt an Personen in der Softwareentwicklung führt. Diese Personengruppe besteht aus verschiedenen Clustern unterrepräsentierter Gruppen. Dazu zählen insbesondere Alleinerziehende, ältere Personen, Arbeiterkinder bzw. Bildungsaufsteiger, Frauen, Menschen mit Behinderung, Personen mit Migrationshintergrund und Quereinsteiger. Diese unterrepräsentierten Gruppen stellen unterschiedliche Ansprüche und setzen unterschiedliche Schwerpunkte bezüglich der Führungsrollen. Um dies beurteilen zu können, wird eine Umfrage durchgeführt. Hierbei werden die Antworten bezüglich der verschiedenen Führungsausprägungen analysiert. Besonderheiten jeder Gruppe werden in jedem Bereich näher betrachtet. Anschließend wird eine zusätzliche Expertenbefragung auf Grundlage der Umfrage durchgeführt. Die erste Frage an die Experten zielt darauf ab, die Akzeptanz der Rolleninhaber genauer zu hinterfragen. Die zweite Frage ermittelt die Meinung der Experten zur persönlichen Mitbestimmung bei Neueinstellungen im Team und deren Rolleninhaber. Anschließend werden die Expertenantworten mit den Umfrageergebnissen zusammengeführt und die Besonderheiten der einzelnen unterrepräsentierten Gruppen herausgearbeitet.
01.02.20	2020	intern	Master	DE	Echtzeit-Raytracing mit modernen GPUs	Diese Arbeit beschäftigt sich mit der Implementation und Evaluation eines Raytracingalgorithmus auf Basis zweier Methoden zur Hardwarebeschleunigung. Zunächst werden zwei Applikationen konzipiert und entwickelt, welche anschließend mithilfe von Benchmarks auf Unterschiede in der Performance verglichen werden. Die Grundlage hierfür ist zum einen NVIDIA RTX und zum anderen die Computing-Schnittstelle CUDA, welche in der Industrie bereits produktiv im Einsatz ist. Die Messergebnisse bestätigen, dass die Hardwarebeschleunigung der NVIDIA Grafikkarten einen signifikanten Sprung der Performance für Anwendungen der Computergrafik ermöglichen. Allerdings deuten einige Messergebnisse darauf hin, dass dieser Vorteil für eigens definierte Geometrie verloren geht. Für Anwendungen, welche die Geometrie nicht auf eine Ansammlung von Dreiecken zurückführen können, wird den hier vorgestellten Messergebnissen zufolge weiterhin CUDA die schnellere und flexiblere Alternative darstellen.
13.02.20	2020	extern	Master	DE	Ermittlung der Wertschöpfung im System Engineering durch Anwendung der im Supply Chain Management vorhandenen Methoden	Ziel dieser Forschungsarbeit ist die Entwicklung eines Modells zur Bewertung der Wertschöpfungskette in einem Unternehmen basierend auf den Prinzipien einer schlanken und agilen Wertschöpfungskette. Der Fokus liegt hier auf erfolgreichem Prozessmanagement in Unternehmen aus dem Bereich des Systems Engineering. Zusätzlich wurde eine gesonderte Version mit allgemein gültigen Kriterien ausgearbeitet, die für alle Unternehmen anwendbar ist. Zur Ermittlung der wichtigsten Prinzipien und Schwerpunkte wurde eine Expertenbefragung online durchgeführt und ausgewertet. Die wichtigsten Ergebnisse sind der Fokus auf den Kundenerfolg, kontinuierliche Verbesserung der Prozesse, Zusammenarbeit und Vereinfachung entlang der Wertschöpfungskette, Verschwendungsreduktion und Flexibilität der Wertschöpfungskette. Basierend auf diesen Punkten wurden im Hinblick auf Kundenorientierung Kundenanforderungen durch eine unternehmensinterne Befragung erhoben und diesen Prinzipien zugeordnet sowie gewichtet. Es entstand ein Punktesystem basierend auf Kennzahlen, die die Hauptkriterien beschreiben. Das Gesamtmodell liegt in Form einer Excel-Datei vor und kann zur internen Messung der Qualität der Wertschöpfungskette verwendet werden.
17.02.20	2020	extern	Bachelor	DE	Prototypische Umsetzung einer Anwendung zur Durchführung, Dokumentation und Auswertung der Reifegradmodell-Bewertung im BMW Werk Regensburg	Der Prozess der Reifegradmodell-Bewertung im BMW Werk Regensburg wird aufgrund des hohen manuellen und zeitlichen Aufwands, der wenig benutzerfreundlichen Durchführung sowie der eingeschränkten Auswertungsmöglichkeiten als nicht zufriedenstellend angesehen. Daraus ergab sich der Bedarf, diesen mit Hilfe der Digitalisierung effektiver und effizienter zu gestalten. Das Ziel dieser Arbeit bestand darin, eine digitale Lösungsmöglichkeit auf Basis von Oracle APEX zu erarbeiten, deren Effektivität und Effizienz sowie deren Übertragbarkeit auf das Mini-Werk Oxford zu überprüfen. Als wissenschaftliche Grundlage diente die Design Science Research, welche die Entwicklung eines Artefakts zur Lösung eines Problems aus der beruflichen Praxis zum Ziel hat. Dieses Artefakt gilt es mittels geeigneter Methoden zu entwickeln, regelmäßig zu evaluieren und einer breiten Öffentlichkeit zugänglich zu machen. Ausgehend von einer Ist- und Schwachstellenanalyse wurden die Anforderungen an eine Anwendung zur Reifegradmodell-Bewertung in Form von User Stories entwickelt. Darauf folgten Konzeption, Implementierung sowie Test und Evaluation. Die im Rahmen dieser Arbeit entwickelte Anwendung "PS RGM" wurde von der relevanten Zielgruppe als effektiv und effizient angesehen, was die Ergebnisse einer Umfrage bestätigt hat. Die Anwendung wird bereits zur diesjährigen Durchführung der Reifegradmodellbewertung eingesetzt und soll künftig auf das gesamte BMW-Netzwerk ausgeweitet werden.
18.02.20	2020	intern	Master	DE	Analyse der Ist-Situation und der Stakeholder-Anforderungen an ein Dokumentenmanagementsystem und Ableitung der technischen Systemanforderungen am Beispiel der TH Nürnberg	Das Ziel dieser Arbeit ist festzustellen, welche Anforderungen die Technische Hochschule Nürnberg an ein neues Dokumentenmanagementsystem hat. Dazu stellt sich die Frage, welche Anforderungen aus dem aktuellen Dokumentenmanagementsystem der Technischen Hochschule Nürnberg entstehen und welche weiteren Anforderungen die Technische Hochschule Nürnberg stellt. Um die Anforderungen zu ermitteln wurde ein Requirements Engineering durchgeführt. Nachdem mit einer IST-Analyse ein Überblick über die im Dokumentenmanagement vorhandenen Inhalte gewonnen wurde, folgte die Ermittlung der Stakeholder und ihrer Anforderungen durch einen Fragebogen. Mit Hilfe von Interviews und E-Mails konnten die Anforderungen verfeinert werden. Aus diesen fachlichen Anforderungen wurden die technischen Anforderungen abgeleitet. Das Requirements Engineering hat ergeben, dass die im aktuellen Dokumentenmanagementsystem gespeicherten Inhalte zum großen Teil in Zukunft in anderen Systemen abgelegt werden sollen. Es wurden einige neue Anforderungen ermittelt, darunter eine Ablage für elektronische Studierendenakten, eRechnungen und die Registratur. Das Ergebnis ist eine Dokumentation der fachlichen und der technischen Anforderungen in Form von User-Storys. Auf dieser Basis kann die Technische Hochschule Nürnberg ein für sie passendes Dokumentenmanagementsystem auswählen. Um einen objektiven Vergleich von Produkten zu ermöglichen, wurden die Herstelleranforderungen in einer Bewertungsmatrix zusammengefasst.
10.03.20	2020	intern	Bachelor	DE	Entwicklung eines patternbasierten Game-Design-Prozesses auf Basis generischer Design-Misfit-Graphen	Ziel ist es, herauszufinden, ob und wie die in Alexanders "Notes on the Synthesis of Form" beschriebene Heuristik auf den bereits bestehenden Problemgraphen bei Empamos angewendet werden kann. Ziel ist also, die im Buch beschriebene Methodik von Christopher Alexander anzuwenden. Die Probleme sollen designtechnisch so dargestellt werden, dass Spieleentwicklern ein Schritt-für-Schritt-Vorgehen an die Hand gegeben wird, welches ihnen hilft, die während der Spieleentwicklung entstehenden Entwurfsprobleme zu lösen.
13.03.20	2020	intern	Bachelor	DE	Untersuchen der Folgen von Digitalisierung, Fachkräftemangel und demographischen Wandel auf Unternehmen der IT-Branche - Literaturstudie und eine Gegenüberstellung von Lösungsmöglichkeiten 	Digitalisierung, Fachkräftemangel und demographischer Wandel. Drei Schlagworte die im heutigen Sprachgebrauch zunehmend zu finden sind und welche die Arbeitswelt in allen Bereichen vor große Herausforderungen stellt. Ziel der Arbeit ist es auf die Digitalisierung, den Fachkräftemangel und den demografischen Wandel einzugehen und deren Folgen für die Unternehmen der IT-Branche aufzuzeigen. Innerhalb der Arbeit werden zudem Lösungsansätze vorgestellt und diese mittels einer Nutzwertanalyse gegenübergestellt. Des Weiteren zeigt eine für die Arbeit durchgeführte Onlineumfrage die gegenwärtige Ist-Situation, wie die Unternehmen der IT-Branche die Digitalisierung, den Fachkräftemangel und den demographischen Wandel für sich einschätzen.
15.03.20	2020	extern	Master	DE	Clustering von Berufen anhand der Identifikation von Ähnlichkeiten	Diese Arbeit beschäftigt sich mit dem Clustering von Berufen anhand der Identifikation von Ähnlichkeiten. Die Vorgehensweise hierzu umfasst verschiedene Methoden des Data-Mining ? insbesondere der Cluster-Analyse ? sowie der natürlichen Sprachverarbeitung. Nach einer umfassenden Vorverarbeitung der vorliegenden Datenbestände werden relevante Merkmale identifiziert, die Ähnlichkeit zwischen Berufsgruppierungen anhand dieser Features ermittelt und eine kombinierte Distanzmatrix als Grundlage für den nachfolgenden Clustering-Prozess generiert. Zur Clusterbildung werden zwei Verfahren verglichen: Das Clustering mit DBSCAN-Algorithmus sowie die Clusterbildung mithilfe eines hierarchischen bzw. agglomerativen Verfahrens. Die hierbei generierten Cluster werden abschließend durch einen Nachverarbeitungsprozess auf den Kontext dieser Arbeit angepasst.
20.04.20	2020	extern	Bachelor	DE	Neukonzeption, Usability Evaluierung, Entwicklung und iterative Verbesserung eines Features für ein Projektvermittlungsportal	Die benutzerfreundliche Gestaltung von Webseiten spielt eine immer bedeutendere Rolle im Entwicklungsprozess. Da viele Unternehmen jedoch in dem Glauben sind, dass frühzeitiges Entwerfen und Testen einer Software einen höheren Zeit- und Kostenaufwand mit sich bringt, wird sich dagegen entschieden. In dieser Arbeit sollen neue Feature für das "Suppliance Tool" der Suppliance AG identifiziert, konzipiert und anschließend prototypisch implementiert werden. Dabei stellt sich die Frage, welche Features dabei helfen, die Nutzung des Tools zu erleichtern. Es soll demonstriert werden, welche Vorteile eine Entwicklung durch Berücksichtigung von Usability Richtlinien mit sich bringt.
20.04.20	2020	extern	Bachelor	DE	Entwicklung einer performanten und linguistisch hochwertigen query auto completion 	Als query auto completion wird das Vorschlagen von möglichen Suchanfragen bei der Eingabe einiger Buchstaben in eine Suchleiste verstanden. Im Optimalfall wird dabei an oberster Stelle in der Vorschlagsliste die Suchanfrage, welche zur Zufriedenstellung des Informationsbedürfnisses des Suchenden führt, angezeigt. Dies kann dem Anwender dabei helfen, Rechtschreibfehler zu vermeiden, Tastenanschläge zu reduzieren und neue Schlüsselwörter zur Suche seines Problems zu identifizieren. Somit kann die Einführung einer query auto completion sowohl zum schnelleren Suchen als auch zu besseren Ergebnissen für den Anwender führen. Vorsicht ist bei der Qualität der Vorschläge geboten, da eine schlecht implementierte query auto completion den Anwender zu schlechten Suchergebissen führen kann. Im Rahmen dieser Bachelorarbeit wird eine query auto completion für die Internetseite der DATEV e.G. entwickelt. Hierbei wir das Augenmerk einerseits auf die Performance der Implementierung und andererseits auf die Qualität der Vorschläge gelegt. Um die bestmögliche Lösung für eine query auto completion für die Internetseite der DATEV e.G. zu finden, werden verschiedene Ansätze zur Ermittlung der vorzuschlagenden Suchanfragen implementiert und verglichen. Darüber hinaus werden verschiedene Rankingverfahren auf ihre Tauglichkeit bei einer query auto completion untersucht.
20.04.20	2020	extern	Bachelor	DE	Adaption eines SoC an ein SIMATIC-Peripheriesystem unter Echtzeit-Aspekten	Für ein neues Konzept soll ein SIMATIC-Peripheriesystem mit einem SoC, der als Betriebssystem eine Linux-Distribution verwendet, erweitert werden. Dazu muss grundlegende Software entwickelt und erprobt werden. Ziel dieser Arbeit ist es, einen Treiber in Form eines Linux-Kernel-Moduls zu entwickeln, der die zyklische und azyklische Kommunikation mit dem SIMATIC-Peripheriesystem übernimmt. Zusätzlich ist eine C-Bibliothek zu entwickeln, mit der man in einem Anwendungsprogramm einfach auf die Daten des Peripheriesystems zugreifen kann. Abschließend gilt es zu untersuchen, welche Echtzeitkriterien für den zyklischen Datenaustausch zwischen dem Peripheriesystem und einem Raspberry Pi 3 erreichbar sind. Die Schnittstelle des Treibers zum User-Space wurde mittels Gerätedateien umgesetzt. Das Linux-System verwendet für den Zugriff auf das SIMATIC-System die proprietäre Schnittstelle sSLI. Die C-Bibliothek für den Anwender abstrahiert das Arbeiten mit den Gerätedateien des Treibers. Für eine möglichst allgemeine Aussage bzgl. der Echtzeitfähigkeit wurde diese Untersuchung mit einem entworfenen Worst-Case-Szenario durchgeführt. Es hat sich gezeigt, dass harte Echtzeit mit dem angestrebten Übertragungsintervall von 4 ms mit der verwendeten Hardware nicht möglich ist. Weiche Echtzeit mit einer Übertragung von min. 99% der zyklischen Daten ist möglich. In den Tests reduzierte der Preempt-RT Patch die Anzahl der verpassten zyklischen Daten.
20.04.20	2020	intern	Bachelor	DE	Automatische Generierung von Titeln und Abstracts	In der vorliegenden Bachelorarbeit soll erörtert werden, inwiefern es möglich ist, aus dem Abstract einer Abschlussarbeit den dazugehörigen Titel zu generieren. Hierfür soll das Bidirectional Encoder Representations from Transformers (BERT) Model von Google verwendet werden. Das BERT Modell kann mit mehreren Sprachen umgehen, darunter auch Deutsch. Als Datensatz für das englische System werden die Abstractbooks der Interspeech Konferenz der letzten 5 Jahre verwendet. Bei dem Datensatz in Deutsch handelt es sich um eine Sammlung von 935 Abschlussarbeiten der Fakultät Informatik. Es soll evaluiert werden, ob BERT für den gegebenen Zweck das passende Model ist. Für das Training wird das BERTSUM Modell verwendet, das speziell für Textzusammenfassungen ausgelegt ist. Die Evaluierung wird mit Recall-Oriented Understudy for Gisting Evaluation (ROUGE) und Word Error Rate (WER) durchgeführt. Die Ergebnisse von ROUGE und WER zeigen, dass BERT diese Aufgabe nicht ohne weitere Anpassungen bewältigen kann. Es werden noch mehr Experimente und Anpassungen im Nachgang dieser Arbeit benötigt, um eine genauere Aussage zu treffen.
20.04.20	2020	intern	Bachelor	DE	Paralinguistische Analyse mittels Residual und Time Delay Neural Network	Die vorliegende Arbeit befasst sich mit einer paralinguistischen Analyse mittels zweier Typen künstlicher Neuronaler Netze (KNN), dem Residual Neural Network (ResNet) und dem Time Delay Neural Network (TDNN). Dabei werden folgende Fragen beantwortet: Wie präzise können die Daten durch die verschiedenen neuronalen Netze klassifiziert werden? Welcher Netzwerktyp eignet sich auf Basis der vorhandenen Daten besser für die Klassifikation von Sprachdaten? Bei Durchführung der Analyse werden vier bereits vorhandene und gelabelte Datensätze analysiert und kategorisiert. Der erste Datensatz beinhaltet dabei Sprachdaten alkoholisierter und nüchterner Personen, der zweite umfasst den Dialekt, der dritte und vierte den Akzent von Personen. Mit Hilfe des Alkoholdatensatzes und des Dialektdatensatzes werden mehrere neuronale Netze trainiert. Anschließend werden durch die trainierten Netze Embeddings erzeugt, um auf dieser Basis weitere Klassifikatoren zu trainieren und deren Genauigkeit zu bestimmen. In der Alkoholerkennung wird zudem eine Analyse nach einzelnen Kategorien durchgeführt. Dabei wird davon ausgegangen, dass bei anspruchsvolleren Aufgaben (z. B. das Vorlesen von "Zungenbrechern") eine höhere balancierte Genauigkeit als bei einfacheren Aufgaben (z. B. das Vorlesen von Nummern) erreicht wird. Mit Hilfe des Akzentdatensatzes werden vortrainierten neuronalen Netzen Embeddings erzeugt und anschließend durch Dimensionsreduktionsmethoden die Dimension der Embedding-Vektoren auf ...
20.04.20	2020	intern	Bachelor	DE	Visualisierung der in einer Hochschule eingesetzten IT-Systeme in Form von IT-Bebauungsplänen und Ableitung von Handlungsempfehlungen	An Hochschulen kommen heutzutage immer mehr IT-Systeme zum Einsatz. Durch diese immer größer werdende Flut an IT-Systemen geht allerdings der Überblick über die IT-Landschaft verloren. Um den Überblick wiederherstellen zu können werden im Rahmen dieser Arbeit zwei IT-Bebauungspläne für die Technische Hochschule erstellt. Außerdem wird geprüft ob mithilfe dieser Pläne Redundanzen in der IT-Landschaft einer Hochschule aufgedeckt und Handlungsempfehlungen zu deren Beseitigung ausgesprochen werden können. Um den wiederhergestellten Überblick auch fortlaufend gewährleisten zu können beschäftigt sich diese Arbeit zudem mit der Frage, welche EAM-Tools sich für den Einsatz an der Hochschule eignen. Bei der Analyse der erstellten Bebauungspläne fiel auf, dass die Erkennung einer Redundanz allein durch einen Bebauungsplan nicht möglich ist. Hierfür werden weitere Beschreibungen zu den einzelnen Systemen benötigt. Allerdings konnte festgestellt werden, dass Bebauungspläne die Transparenz einer IT-Landschaft entscheidend erhöhen. Im Anschluss werden im Rahmen dieser Arbeit zwei kostenlose Enterprise Architecture Management Tools vorgestellt und anhand einer prototypischen Umsetzung und eines festgelegten Kriterienkatalogs gegeneinander evaluiert. Hierbei ging das Tool ADOIT:CE als der Sieger hervor. Es wurde die Empfehlung ausgesprochen dieses Tool sukzessive auf mehr Fakultäten und Abteilungen zu erweitern und hochschulweit einzusetzen.
20.04.20	2020	extern	Master	DE	Evaluation von State-of-the-Art-Ansätzen der Relation Extraction zur Erzeugung von Knowledge Graphen	Diese Masterarbeit ist Teil des Forschungsprojekts Future Engineering des Fraunhofer Instituts Supply Chain Services und der Technischen Hochschule Nürnberg, welches sich mit der automatisierten Wissensextraktion aus unstrukturierten Textdaten beschäftigt. Die Arbeit behandelt dabei die Frage, welcher der aktuellen State-of-the-Art-Ansätze im Bereich der Relation Extraction die beste Möglichkeit der Verwendung zur Erzeugung eines Knowledge Graphen im Rahmen des Future-Engineering-Projekts bietet. Zur Beantwortung dieser Frage wurde eine Auswahl verschiedener State-of-the-Art-Ansätze im Bereich der Relation Extraction evaluiert. Dies geschah durch den Vergleich der Ansätze mit Hilfe von Evaluationsszenarien auf Basis unterschiedlicher Datengrundlagen. Dazu wurde ebenfalls ein eigener Trainings- und Evaluationsdatensatz aus Daten des Future-Engineering-Projekts erzeugt. Zusätzlich wurde ein Prozess zur einheitlichen Verwendung unterschiedlicher Relation-Extraction-Ansätze mit nicht annotierten Daten definiert. Die Ergebnisse dieser Arbeit liefern Erkenntnisse über die Probleme und spezifische Verhaltensweisen der betrachteten Relation-Extraction-Ansätze und erlauben eine Bewertung über die Eignung der Ansätze zur Erzeugung von Knowledge Graphen im Future-Engineering-Projekt. Dabei lassen sich deutliche Unterschiede in den Ergebnissen erkennen, wobei der Ansatz R-BERT die besten Resultate aufweist und sich für den Einsatz in der Praxis empfehlen lässt.
20.04.20	2020	extern	Master	DE	Auditive Landmarken für blinde Menschen zur Integration in VR-Umgebungen	Diese Arbeit identifiziert in virtuellen Umgebungen automatisch Bereiche, die für blinde Menschen wichtig sind. In diesen Bereichen werden für eine virtuelle Trainingsumgebung auditive Landmarken platziert. Insbesondere ist die Identifizierung von Treppen relevant. Die Arbeit zeit auf, wie das Modelle vorverarbeitet werden müssen, damit relevante Bereiche erkannt werden können. Zur Klassifizierung von Objekten wurden zwei Ansätze genauer untersuchen. Die Erkennung kann durch semantische Segmentierung durchgeführt werden. Außerdem wurden Lösungsansätze evaluiert und bewertet, die mit machine learning arbeiten.
20.04.20	2020	intern	Master	DE	Klassifikation psycho-sozialer Äußerungen mittels tiefer neuronaler Netze	Durch die zunehmende Beliebtheit und Nutzung öffentlicher Onlineberatungsforen stehen heutzutage noch nie dagewesene Mengen an frei einsehbaren Daten über Beratungsgespräche im Internet zur Verfügung. Eine manuelle qualitative Inhaltsanalyse dieser Daten ermöglicht es, Stärken und Schwächen im Vorgehen bei Onlineberatungsgesprächen aufzudecken. Da diese manuellen Untersuchungen jedoch sehr zeitaufwendig sind und ein umfangreiches Wissen benötigt wird, ist es häufig nicht möglich, qualitative Inhaltsanalysen auf großen Datenmengen durchzuführen. Um diesem Problem entgegenzuwirken, werden in dieser Arbeit die Einsatzmöglichkeiten neuronaler Klassifikationsverfahren zur automatisierten Kategorisierung psycho-sozialer Aussagen von Onlineberatenden untersucht. Neben einer einfachen Support Vector Machine als Baseline wurden hierzu insgesamt fünf neuronale Modelle in unterschiedlichen Ausprägungen erzeugt, in ihrer Güte bewertet und mit der Klassifikationsleistung menschlicher Codierenden verglichen.
20.04.20	2020	extern	Bachelor	DE	"Entwicklung und Verifizierung von Testkonzepten für Machine Learning Modelle am Beispiel von Datendrifts in den Eingangsdaten eines Modells"	This thesis describes the development and verification of test concepts with which machine learning models can be tested. It is shown how data drifts have a negative impact on the reliability of machine learning models and how data drifts can be detected by drift detectors. This is demonstrated practically by training machine learning models with a data set from the industry. Afterwards predictions for another data set, which contains data drifts, are made. The experiment shows that machine learning models predict less reliably on input data, that contains data drifts, compared to input data, which does not contain data drifts. Drift detectors are used in the experiment to show how they can be applied to show differences in the value distribution of two data sets. Based on these results, it can be seen that it is necessary to perform data-related tests on machine-learning models before their deployment in order to improve the reliability of their predictions.
20.04.20	2020	extern	Bachelor	DE	Analyse zur effizienten Kopplung heterogener Systemlandschaften unter der besonderen Berücksichtigung der Datentransformation	Im Rahmen der Bachelorarbeit wird die effiziente Kopplung heterogener Systemlandschaften analysiert. Spezialisiert auf kleine und mittelständische Unternehmen im Kontext der Digitalisierung, wird die Relevanz des effizienten Datenaustauschs sowie die Einordnung des Datenaustausches in den betrieblichen Rahmen (Stammdaten, Bewegungsdaten) behandelt. Es sollen Datenaustauschformate im Bereich B2B (CSV, EDIFACT, Fortras, BMEcat etc.) verglichen, sowie die Besonderheiten von INHOUSE-Formaten (auch zum innerbetrieblichen Datenaustausch) dargestellt werden. Der Fokus der Arbeit liegt auf dem generischen Ansatz des Datenaustausches der anhand des Common Data Models von Microsoft abgebildet wird. Es sollen Stärken, Schwächen sowie Grenzbereiche dieser Plattform analysiert und ausgearbeitet werden.
20.04.20	2020	intern	Bachelor	DE	Prototypische Implementierung eines Chatbots zur Administration einer Wissensdatenbank	Das Ziel der vorliegenden Arbeit ist es, die Frage zu beantworten, ob Conversational User Interfaces für die Administration von Wissensdatenbanken geeignet sind. Dazu wird ein Chatbot-Prototyp mit dem Framework Rasa zur Administration der Wissensbasis eines bereits bestehenden Chatbots entwickelt. Grundlage der Entwicklung bilden eine durchgeführte System- sowie eine Anforderungsanalyse mit dem Ziel, die Funktionalitäten des Systems aufzudecken und das System nach außen abzugrenzen. Basierend auf den Ergebnissen der Analysen wird ein Konzept für den Prototypen ausgearbeitet, welches beschrieben und anschließend implementiert wird. Dabei werden sowohl der Design- als auch der Entwicklungsprozess erläutert. Die Tauglichkeit des Chatbots für das vorliegende Anwendungszenario kann in einer ausführlichen Evaluation des Prototypen bestätigt werden.
20.04.20	2020	intern	Master	DE	Integration eines zentralen Assistenzsystems in Webanwendungen	Die Nutzung von Assistenten in Form von Sprachassistenten und Chatbots nimmt zu. Ein Grund dafür ist, dass sich die virtuellen Helfer zunehmend auf Smartphones und Smart Devices befinden. Ein weiterer Grund ist, dass sie zum aktuellen Stand der Technik alltagstauglich Aufgaben erledigen können, wie Nachrichten formulieren, Wecker stellen und Smarthome-Geräte steuern. Das Anwendungspotenzial wird jedoch noch nicht vollständig genutzt. Die Idee ist daher Assistenten mit Webanwendungen zu verknüpfen, um die Anwendungsfälle zu erweitern und Vorteile für die Nutzung von Webanwendungen zu bieten, wie einen barrierefreieren Zugang. Ein Problem für Betreiber von Webanwendungen mit angebundenem Assistenzsystem ist die große Menge an zu unterstützenden Assistenten auf dem Markt. Ein paar Beispiele sind die Sprachassistenten Alexa, Siri und der Chatbot Telegram Bot. Das Ziel der Arbeit ist es dieses Problem durch die Integration eines zentralen Assistenzsystems in Webanwendungen zu lösen. Das entworfene Konzept der Arbeit sieht dazu vor, dass vorhandene Schnittstellen von Webanwendungen zur Anbindung des Assistenzsystems verwendet werden. Zusätzlich wird das zentrale Assistenzsystem von intelligenten Agenten bei der Ausführung von Aufträgen unterstützt. Durch eine Verknüpfung der genannten Technologien ergibt sich folgender Weg für einen Auftrag in menschlicher Sprache. Ein Befehl in menschlicher Sprache wird über angebundene Kommunikationskanäle zu einer Schnittstelle übermittelt, ...
20.04.20	2020	intern	Bachelor	DE	Implementierung einer erweiterbaren Webanwendung zur interaktiven Textvisualisierung	Durch die stetig steigende Menge an digital verfügbaren Textdaten steigt auch das Interesse an der effektiven Auswertung ebendieser. Der Themenbereich der computergestützten Datenanalyse bietet unterschiedliche Verfahren an, welche unter anderem zur Extraktion verborgener Zusammenhänge und Informationen genutzt werden können. Im Bereich der Sozialberatung kann von solchen Verfahren stark profitiert werden, da die Analysen meist händisch durchgeführt werden. Deshalb wurde in dieser Bachelorarbeit eine Webanwendung zur interaktiven Textanalyse und -visualisierung entwickelt. Sie stellt die Schnittstelle zu einer vorhandenen Datenbasis dar, mit der unter anderem ausgewählte Diagramme erstellt werden können. Der Fokus der Entwicklung lag auf der erweiterbaren Softwarearchitektur der Anwendung, welche auf etablierten Designprinzipien basiert. Im Laufe der Arbeit konnte somit eine Grundlage für die besprochenen Erweiterungsmöglichkeiten geschaffen werden.
20.04.20	2020	intern	Bachelor	DE	Emotionsanalyse von automatisch übersetzten Texten mithilfe maschineller Lernverfahren	maschineller Lernverfahren wurde bereits mehrfach mit vielversprechenden Ergebnissen im englischsprachigen Bereich angewandt. Im Deutschen gibt es allerdings kaum Bemühungen, Emotionen in Texten zu erkennen und auch keine verwendbaren Datensätze. Für das CaSoTex Projekt der Technischen Hochschule Nürnberg soll die Emotionsanalyse im Deutschen durchgeführt werden, um Emotionen in deutschsprachigen Beiträgen innerhalb Beratungsforen erkennen zu können. Das Erkennen der Emotionen in dieser Arbeit erfolgt deshalb auf vom Englischen ins Deutsche übersetzten Texten. Es werden vier englischsprachige Datensätze (ISEAR, Märchentexte, TEC und SemEval-2018) mittels eines hierarchischen Emotionsmodells kombiniert. Die Übersetzung der Daten ins Deutsche erfolgt automatisch mit Google Translate. Die durch die maschinellen Lernverfahren zu erkennenden Emotionen sind 5 der 6 Basisemotionen von Ekman: Angst, Freude, Traurigkeit, Wut und Erstaunen. Als Baseline dient die Implementierung mithilfe einer Support Vector Machine, welche im Deutschen eine Accuracy von 58,2% und im Englischen von 61,1% erzielte. Eine Verbesserung der Accuracy erreichte das maschinelle Lernen mit BERT. Im Deutschen wurde damit eine Accuracy von 64,1% und im Englischen von 69,5% erreicht. Dies zeigt, dass die Emotionsanalyse im Deutschen schlechtere Ergebnisse erzielt.
20.04.20	2020	extern	Bachelor	DE	Mehrwert eines virtuellen Assistenten zur Nutzung von Microsoft Dynamics 365 Business Central: Analyse geeigneter Frameworks, Konzeption und prototypische Realisierung	In Kooperation mit der KUMAVISION AG soll ein virtueller Assistent erstellt werden, der an das ERP-System Microsoft Dynamics 365 Business Central (BC) angebunden wird. Dieser soll Mitarbeitern eines Unternehmens bei ihren Aufgaben assistieren. Dabei wird untersucht, welchen Mehrwert ein virtueller Assistent mit BC hat. Im virtuellen Assistenten sollen zunächst möglichst einfache Funktionen erstellt werden, um Daten und Sachverhalte aus dem System abzurufen. Dann sollen wiederkehrende Prozesse im System bequemer durchzuführen sein, indem deren Abbildung durch den virtuellen Assistenten assistiert wird. Die Untersuchung des Mehrwerts eines solchen virtuellen Assistenten wird anhand der Ressourcenplanung durchgeführt. Dafür wird zunächst der Prozess darin beschrieben, welche Defizite und Schwachstellen die aktuelle Lösung hat und daraus die Anforderungen für den virtuellen Assistenten erstellt. Folglich wird eine Analyse erstellt, welche Botframeworks in Frage kämen, um auf ihren Funktionsumfang sowie insbesondere auf die Integrierbarkeit mit BC zu prüfen. Das Ergebnis dieser Analyse soll das geeignetste Framework sein. Dann wird eine Konzeption für den virtuellen Assistenten erstellt, um eine prototypische Umsetzung zu realisieren. Abschließend wurde eine kritische Reflexion des Ergebnisses gemacht. Dabei zeigt sich, dass der Mehrwert eines virtuellen Assistenten in den einfachen Aufgaben liegt. Für die Zukunft wird überlegt, für welche Bereiche dieser noch genutzt werden kann.
20.04.20	2020	intern	Bachelor	DE	Progressive Web Apps - Möglichkeiten und Grenzen moderner Web-Anwendungen	Die vorliegende Arbeit untersucht die Technologie der Progressive Web Apps anhand von zwei Imple-mentierungen. Zunächst werden die Möglichkeiten und Grenzen moderner Web-Anwendungen auf der Grundlage einer technischen Umsetzung als Web-App untersucht. Diese ist mit JavaScript und node.js als Laufzeitumgebung realisiert. Als Gegenstück, um die nativen Grenzen der PWA-Technologie zu erforschen, wird ebenso eine Implementation in Java als Android App dokumentiert und beschrieben. Das Anwendungsszenario für beide Fallstudien ist "Instagram-Klon, ein Fotoalbum der TH Nürnberg". Bei PWA?s eröffnet sich der Gedanke der Plattformunabhängigkeit für mobile Applikationen, da die Programme vom Browser interpretiert werden und die Lauffähigkeit auf verschiedenen Zielsystemen gewährleistet ist. Ebenso stellt dies die Untersuchungsfrage der Arbeit dar, ob die Technologie den nativen Apps, um deren App Stores und Gerätehersteller, auf gleicher Höhe begegnen kann und inwieweit die Performance einer im Browser ausgeführten App mit einer nativen Umsetzung, über Android Studio, zu vergleichen ist. Das Ergebniskapitel befasst sich mit der Erläuterung der Unterschiede in der Systemarchitektur, das ist zum Beispiel die maschinen-nahe Kompilation in Java Byte Code, sowie einer Gegenüberstellung von Java und JavaScript. Außerdem wird die PWA-Tauglichkeit verschiedener Browser-Anbieter erörtert und ein wesentlicher Kernfaktor der Technologie, das Progressive Enhancement, anhand der Apps untersucht.
20.04.20	2020	extern	Bachelor	DE	Metriken als Mittel zur Verbesserung von agilen Teamprozessen am Beispiel eines Softwareentwicklungsteams bei DATEV eG	In der vorliegenden Arbeit wird ein Experiment betrachtet, das im Auswerten-Team eingeführt und anhand einer Metrik verfolgt wurde. Es war das Ziel, die Lead- und Cycle Time durch die Begrenzung paralleler Arbeit zu optimieren. Dabei wurde ein Work-In-Progress Limit von eins pro Person eingeführt, welches der Theorie zur Folge die Durchlaufzeiten verbessern kann. Es stellte sich die Frage, ob ein WIP Limit die Durchlaufzeiten beeinflusst. Das Experiment wurde vom 08. Juni 2020 bis zum 28. August 2020 durchgeführt und am Ende eines Fragebogens und einer Metrik ausgewertet. Es konnte konstatiert werden, dass die Lead Time im Auswerten-Team nicht beeinflussbar war, weil sie am Anfang zu sehr variiert. Jedoch konnte bei der Cycle Time ein positiver Einfluss gemessen werden. Die Gründe dafür waren mitunter, dass sich bei der Arbeitsweise die Fokussierung und die Effizienz der Mitarbeiter verbesserten. Diese positiven Effekte wurden durch die Befragung der Teilnehmer am Ende des Experiments bestätigt.
20.04.20	2020	extern	Master	DE	Visualisierung der Customer Journey in einer Online-Bank: Abbildung sämtlicher Website-Interaktionen in Form eines Netzwerkgraphen	Ziel dieser Masterarbeit ist es, die komplexe Struktur der Website einer großen deutschen Direktbank und seiner Unterseiten auf eine übersichtliche Art und Weise in Form eines Netzwerkgraphen mit einer Echtzeitdatenanbindung als Dashboard darzustellen. Augenmerk der Visualisierung sind hierbei die Customer Journeys sowie das Benutzerverhalten, die sich aus den Online-Kundenaktivitäten ableiten lassen. Dabei ist es nicht nur das Ziel, die besuchten Seiten anzuzeigen, sondern zu erforschen, in welcher Art und Weise Netzwerke am besten dargestellt und diese auf die wesentlichen Informationen heruntergebrochen werden können. Zudem soll erörtert werden, inwiefern Darstellungsweisen aus anderen Forschungsgebieten wie der Medizin auf den genannten Anwendungsfall übertragen werden können.
20.04.20	2020	intern	Bachelor	DE	Intelligente Analyse des betriebswirtschaftlichen Jahresabschlusses: Konzeption und prototypische Implementierung	In ihrer Funktion der Informationsvermittlung und als Instrument der Rechenschaftslegung für Bilanzadressaten und -empfänger bedienen Jahresabschlüsse vielfältige und oftmals widersprüchliche Interessenlagen und es kann sowohl zur Überschneidung von Interessentengruppen kommen als auch keine eindeutige Zuordnung interner sowie externer Adressaten getroffen werden. Nach einem manuellen Aufbau von multifunktionalen Informationssystemen wird neben dem OLAP- und DWH-Konzept eine zusätzliche Softwarelösung erforderlich, um Medienbrüchen im Zusammenhang mit vertikaler Integration entgegenzutreten. Im Rahmen der Arbeit erfüllt diese Aufgabe das dokumentenorientierte, verteilte Datenbanksystem HCL Notes. Dabei steht der Lotus Domino Server im Mittelpunkt in den dazu sämtliche relevanten Anwendungen und Systeme über Extraktion und Transformation integriert werden. Somit ermöglicht das vorbezeichnete Konzept über den Einsatz von HCL Notes die Datenerfassung, deren Sortierung und Filterung sowie jede beliebige Darstellung. Um den Aufbau multidimensionaler Controlling-Systeme innerhalb des betrieblichen Rechnungswesens zu stützen, könnten künftig KI-getriebene Lösungen entscheidende Impulse im Rahmen des externen Rechnungswesens (Jahresabschluss) oder für Branchen-, Trend- und Wettbewerbsanalysen geben. Gleiches gilt für die auf ihnen gründenden Software-Ansätze und einhergehenden Algorithmen, um das Controlling und die Weitergabe von adressatenspezifischen Informationen zu vereinfachen.
20.04.20	2020	intern	Master	DE	Auswahl und Implementierung von Explainable-Artificial-Intelligence-Frameworks für einen Klassifikator im Text Mining	Die grundlegende Problemstellung dieser Arbeit ist, es die Frage zu beantworten, wie Black-Box-Verfahren besser beurteilt werden können. Es soll offengelegt werden, was die Entscheidung der Vorhersage eines Spiel-Design-Elements bei einem Text beeinflusst. Hierzu wurde eine systematische Suche nach Methoden durchgeführt und anschließend XAI-Frameworks detailliert untersucht, die den Anforderungen der Systemumgebung entsprachen. Die Untersuchung ergab, dass fünf der Frameworks angewendet werden sollten. Dabei nutzen zwei der Frameworks die Erklärungstechnik der Merkmalsrelevanz und drei der Frameworks die kontrafaktische Erklärungstechnik. Neben der Implementierung der Frameworks wurde zusätzliche eine Darstellungskomponente geschaffen, um die generierten Ergebnisse präsentieren zu können. Eine Experten-Evaluierung zeigte, dass beide Merkmalsrelevanz-Frameworks ähnliche Ergebnisse liefern. Zudem ergab die Evaluierung der kontrafaktischen Algorithmen, dass eines der Frameworks geringfügig bessere Ergebnisse als die anderen Frameworks erzielt. Diese Arbeit stellt ein Novum dar. Die Ergebnisse offenbaren, dass es mittels der implementierten XAI-Frameworks möglich ist, die semantische Ausgestaltung von Spiel-Design-Elementen in einzelnen Spielanleitungen zu erfassen.
20.04.20	2020	extern	Bachelor	DE	Konzeption einer Informations-Cockpit-Architektur für missionskritische Systeme	In dieser Arbeit wird eine leicht erweiterbare Architektur für ein Informations-Cockpit vorgestellt. Diese wird in Form eines Architekturbildes dargestellt. Grundlage für die Architektur ist die Containerisierung der einzelnen Bestandteile auf der Serverseite mittels Docker. Der Client, basierend auf Angular, ist über einen aktuellen Browser erreichbar. Grundlage für die Architektur sind Anforderungen und Konzepte, welche im Rahmen dieser Arbeit diskutiert werden. Die Architektur stützt sich dabei auf Payara als Applikationsserver für Java, Redis als Key-Value-Datenbank, Traefik als interne Lastenverteilung sowie einem auf Gunicorn und Flask basierenden Analyse Service zur Aggregierung von Daten. Die Kommunikation zwischen dem Client und dem Server wird mit REST und JSON realisiert. Ein Prototyp der Architektur zeigt die Funktionsfähigkeit.
22.04.20	2020	extern	Master	DE	Vergleich von traditioneller und End-to-End Modellierung sowie Regel und Slot-basierte Ansätze für Sprachassistenten im juristischen Kontext.	ie Deutsche Anwaltshotline AG (DAHAG) bietet Kunden die Möglichkeit mit einem Anwalt zu telefonieren. Wenn kein Anwalt verfügbar ist, beantwortet ein Sekretariatsservice den Anruf, um einen Rückruf mit dem Kunden zu vereinbaren. Dabei müssen verschiedene Kundendaten, wie beispielsweise Name und Telefonnummer, erfragt werden. Dieser Service funktioniert jedoch nicht gut. Für eine solche abgeschlossene Aufgabe bietet sich ein Sprachassistent an. Deshalb stellt sich die Frage, welcher Ansatz für ASR- und Dialogsysteme sich am besten im juristischen Kontext eignet. Dafür werden in dieser Arbeit traditionelle und End-to-End ASR-Ansätze sowie regel- und slotbasierte Dialogsysteme miteinander verglichen. Zum Vergleich der ASR-Modelle werden beide Ansätze auf Basis des Common Voice Datensatzes trainiert und anhand von aufgenommen und transkribierten Sekretariatsanrufen evaluiert. Die Gegenüberstellung wird mithilfe von Word Error Rate und Slot Error Rate durchgeführt. Dabei stellt sich heraus, dass traditionelle Ansätze, auf Basis von HMM-DNN etwas besser abschneiden. Allgemein erkennen ASR-Ansätze Nummern sehr gut, Namen hingegen nicht. Auf Grundlage dieser Erkenntnisse wurde ein Prototyp entworfen, welcher ausgebaut in der Praxis angewendet werden kann.
29.04.20	2020	intern	Master	DE	Automatische Generierung von synchronisierten Liedtextdateien zu korrespondierenden Audioinhalten auf Basis vorhandener Liedtexte aus dem Internet	Eine Vielzahl an Streaming-Diensten und Anwendungen zur Musikverwaltung integrieren Songtextanzeigen in die Benutzeroberfläche des Musik-Players. Dabei wird häufig neben der normalen eine zusätzliche zeitsynchrone Darstellung verwendet. Der Nutzer kann somit den Text zum aktuell gesungen Vers live mitverfolgen (Karaoke-Prinzip). Diese zeitgenauen Darstellungen existieren oftmals nur bei bekannten Titeln. Ziel dieser Arbeit war daher die Konzeptionierung und Implementierung eines automatisier- ten Karaoke-Automaten, der im Rahmen einer Offline-Nutzung eingesetzt werden kann. Hier hat sich mitunter das LRC -Dateiformat durchgesetzt, das neben den eigentlichen Songtext- versen noch den Zeitstempel für den gesungenen Text einer korrespondierenden Audiodatei im MP3 oder FLAC -Format enthält. Notwendige Verfahren aus der Automatischen Spracherkennung wurden mit Hilfe des Open- Source-Toolkits Kaldi modular in eine Entwicklungspipeline integriert. Grundlage bildete ein vorab vorhandenes akustisches Kaldi-Modell, das mit Telefonmitschnitten trzu spätai- niert wurde. Für Musikstücke aus dem Genre Hip-Hop (Sprechgesang) konnten u.a. bessere LRC -Resultate erzielt werden, als mit Titeln aus anderen Genres. Schlechtere Ergebnisse gab es häufiger bei Musiktiteln, die ausschließlich Gesang beinhalteten und deren Songtextkorpus verhält- nismäßig kleiner war, gepaart mit einer geringeren Wortvariabilität.
29.04.20	2020	intern	Bachelor	DE	Konzeption und prototypische Umsetzung der In-App-Werbung am Beispiel der Notenapp	Die Notenapp ermöglicht es Schülern, aber auch deren Eltern, den Schulalltag einfacher und effizienter zu planen. Der digitale Schulassistent bietet verschiedene Module an, die von der Gestaltung eines Stundenplans, einem Prüfungsplaner mit Notenmanagement, einem papierlosen Hausaufgabenheft bis hin zur Berechnung des aktuellen Gesamtnotendurchschnitts reichen. Ein standardisiertes Verfahren zur In-App-Werbung ist die Basis für eine Finanzierungsstrategie der Notenapp. Hierbei spielen eine effektive Umsetzung eines Werbebudgets und ein Konzept zur automatisierten Integration der Werbung innerhalb der App eine Rolle. In dieser Arbeit werden bereits auf dem Markt existierende Lösungen zur Integration und Verwaltung von In-App-Werbung im Gegensatz zur Entwicklung eines eigenen Konzepts diskutiert und evaluiert. Letztendlich soll ein einfaches Verfahren entstehen, mit dem eine Finanzierungsgrundlage über zukünftige Kooperationspartner umgesetzt werden kann.
01.05.20	2020	intern	Bachelor	DE	Prozessoptimierung, Automatisierung durch Software-Roboter oder Outsourcing: Entwicklung eines Handlungsrahmens für Einkaufsleiter zur digitalen Transformation der betrieblichen Beschaffung.	Ergebnis dieser Arbeit soll ein Entscheidungspattern sein, welches dazu beiträgt, aufgrund finanzieller und struktureller Kennzahlen einen Handlungsrahmen für Einkaufsleiter zu schaffen, in dem sie einen Prozess outsourcen, automatisieren oder die Kompetenz im eigenen Unternehmen behalten können. Das Entscheidungspattern soll Empfehlungen für das weitere Vorgehen geben, auf welche Art und Weise der Prozess am effektivsten durchgeführt werden kann.
01.05.20	2020	extern	Master	DE	Konzeption und prototypische Implementierung eines Blockchain-basierenden Systems zur Sicherung des Urheberrechtes sowie dem Übertragen und Überprüfen von Nutzungsrechten an digitalen Bildern	Niemals zuvor war es so einfach Informationen zu teilen, wie in der heutigen Zeit. So werden über das Internet täglich Milliarden von Bilder versendet, heruntergeladen oder anderweitig zugänglich gemacht. Dies geschieht jedoch oft zum Nachteil der Bild Urheber, denn das Urheberrecht stößt im digitalen Bereich an seine Grenzen. Das Ziel der Arbeit ist zu prüfen, ob die Konzeption eines Systems zur Sicherung des Urheberrechtes, sowie dem Übertragen und Überprüfen von Nutzungsrechten an digitalen Bildern mittels Blockchain Technologie möglich ist. Um diese Frage zu beantworten, ist im Zuge der Arbeit das Konzept zu einem solchen System erarbeitet worden. Dies wurde daraufhin prototypisch mittels der Smart Contract Plattform Ethereum implementiert. Wobei auch ein Augenmerk aus die Bildverarbeitung im Zuge von komprimierten Hashes gelegt, die einen Bildvergleich ermögliche. Wichtige Evaluationsmetriken wurden anschließend identifiziert und ausgewertet. Dabei wurde festgestellt, dass die Blockchain Technologie sowie Smart Contract ein hohes Potenzial bieten. Jedoch sind die technischen Voraussetzungen noch nicht gegeben, um den Prototyp im konzipierten Maße zu betreiben.
01.05.20	2020	extern	Master	DE	Fehlerklassifizierung und Entwicklung einer Software zur Prävention von Produktivitätsverlusten bei vollautomatisierten Bestückungslinien	Im Zuge der konzernweiten Standardisierung wird im Fertigungsbereich der Continental Automotive GmbH in Regensburg ein neues Fertigungsmanagementsystem integriert. Neben dem enormen Verbesserungspotenzial verbergen sich in den neuen Prozessen noch viele Fehlerquellen und Störungen, welche zu Linienstillständen führen. Das wesentliche Ziel der Arbeit ist es, diese Fehler zu klassifizieren. Um recht-zeitig fehlerhafte Aufträge erkennen zu können, soll auf Basis eines erarbeiteten Maßnahmenkonzepts ein automatisierter Service und ein Tool zur Selbstkontrolle entwickelt werden. Die erarbeiteten, softwaregestützten Maßnahmen sollen dazu beitragen, den Prozess der Fehlererkennung und der Fehlerbeseitigung bei Fertigungsaufträgen so weit wie möglich zu automatisieren. Sollte sich dieses Vorgehen bewähren, kann dieses Konzept auch für andere Produktionssysteme innerhalb von Continental verwendet werden. Die Fehler konnten durch eine dokumentierte Fehlerliste erfolgreich klassifiziert werden. Durch den verwendete Diagrammtyp zeigte sich klar der Mensch als Ursachenschwerpunkt. Bei der Erarbeitung des Maßnahmenkonzepts wurde der Fokus deshalb auf die menschlichen Fehler gelegt. Eine ausführliche Phase der Anforderungsanalyse führte zu einer sehr effizienten Konzeptentwicklung. Die prototypische Implementierung und eine erste Evaluierung zeigten, dass die entwickelten Software-Lösungen und das damit verbundene Vorgehen als erfolgreich eingestuft werden kann.
01.05.20	2020	intern	Bachelor	DE	"Entwicklung und Untersuchung künstlicher neuronaler Netze zur Erstellung von Lastprognosen für Gebäude"	Um eine effiziente Gebäudesteuerung zu realisieren, werden möglichst genaue Vorhersagen benötigt. In dieser Arbeit wird der Ansatz untersucht diese Lastprognosen mit Hilfe künstlicher neuronaler Netze zu erstellen. Es wird dabei auf die Abschätzung des Bedarfs an Elektrischer Energie, Trinkwarmwasser und Heizenergie eingegangen. Die Lastprognosen sollen für einen Zeitraum von 24 Stunden in die Zukunft mit Zeitintervallen von 15 Minuten erstellt werden. Aus den Prognosen sollen sowohl kurzfristige als auch langfristige Entscheidungen abgeleitet werden. Zur Erstellung dieser Modelle werden reale Messwerte aus acht Reihenhäusern verwendet. Es werden sowohl univariate als auch multivariate Vorhersagen unter Einbeziehung aller erhobenen Verbrauchswerte untersucht. Für eine weitere Verbesserung der Prognosen wird zusätzlich eine Abhängigkeit in Bezug auf Wettereinflüsse untersucht. Als Wetterdaten kommen Außentemperatur und Sonneneinstrahlung zum Einsatz. Die Ergebnisse der künstlichen neuronalen Netze wurden mit denen autoregressiver Modelle verglichen. Nach Gegenüberstellung und Auswertung beider Methoden zeigen sich deren Stärken und Schwächen. Durch die gegebenen Daten konnte keine Abschätzung zukünftiger Lastspitzen getroffen werden. Auch spielten Wetterdaten und Wetterprognosen für den Bedarf an Elektrischer Energie und rinkwarmwasser keine Rolle. Eine spürbare Auswirkung der Wetterdaten zeigte sich lediglich im Bezug auf die Prognose der Heizleistung.
05.05.20	2020	intern	Bachelor	DE	Implementierung eines Telegram-Chatbots zur Automatisierung eines Verständlichkeitstests basierend auf dem Post-Laryngektomie Telefon Tests	Im Rahmen dieser Arbeit wurde ein Chatbot entwickelt, der basierend auf früheren Arbeiten einen Post-Laryngektomie Telefon Verständlichkeitstest durchführen kann. Nach einer kurzen Einführung in die heutigen technologischen Fortschritte und die möglichen Vorteile, die im medizinischen Bereichen genutzt werden können, wurde der PLTT im Detail erklärt. Desweiteren wurden die Komponenten der Architektur des genutzten Spracherkennungssystems näher erläutert und mit dem früheren System verglichen. Um die Reproduzierbarkeit der früheren Ergebnisse zu belegen, wurden die gleichen Berechnugsgrundlagen und Experimente durchgeführt. Belegt wurde durch die Korrelationskoeffizienten nur die relative Performanz vom früheren und aktuellen Spracherkennungssystem, jedoch nicht die absolute. Ebenfalls liegt eine sehr niedrige Korrelation zwischen Mensch und Maschine vor. Anschließend wurde der Ablauf eines PLTT Schritt für Schritt erklärt. Abschließend wurden mangelnde Bereiche aufgelistet und Verbesserungsvorschläge aufgezählt.
07.05.20	2020	intern	Bachelor	DE	Konzeption und Implementierung eines gamifizierten Systems zur Generierung von Trainings- und Testdaten für die Erkennung von Spieldesignelementen in Brettspielanleitungen	Im Forschungsprojekt EMPAMOS (empirische Analyse motivierender Spielelemente) der TH Nürnberg werden, in Zusammenarbeit mit dem Deutschen Spielearchiv Nürnberg, motivierende Spieldesignelemente erforscht. Das Vorgehen beinhaltet mehrere Schritte: es werden Brett- und Gesellschaftsspiele gespielt, deren Spieldesignelemente untersucht und zum Schluss mit einer Mustersprache beschrieben. Auf deren Grundlage sollen angewandte Forschungsprojekte realisiert werden, die motivierende Spielideen und Gamification-Lösungen entwickeln und testen. Es werden dazu Spielanleitungen digitalisiert und analysiert. Ein Schritt in diesem Vorgehen ist, verschiedene Spieldesignelemente in den Spielanleitungen von Brett- und Gesellschaftsspielen zu suchen und mit Tags zu markieren, um Trainings- und Testdaten zu erstellen. Da dieses Tagging von Spieldesignelementen zu Spielen eine langwierige und repetitive Arbeit ist, bietet sie die Möglichkeit Methoden zur Gamifizierung anzuwenden. Es werden basierend auf der EMPAMOS Gamification-Methode drei Gamification-Konzepte erarbeitet. Eine davon soll anschließend implementiert werden.
08.05.20	2020	intern	Master	DE	Entwicklung eines Framework zur semi-automatisierten Informationsextraktion für Knowledge Graphen	Das Thema dieser Arbeit ist die Konzeption und Umsetzung eines Frameworks für die semi-automatisierte Informationsextrahierung unstrukturierter Daten, zur Generierung eines Knowledge Graphen (dt. Wissensgraph). Die generelle Entwicklung eines Knowledge Graphen ist mit erheblichem manuellem Aufwand eines Domänenexperten verbunden. Um diese zukünftig zu semi-automatisieren und somit zu vereinfachen, vereint das Konzept dieser Arbeit die Methoden der maschinellen Sprachverarbeitung mit dem Expertenwissen des Anwenders der jeweiligen Domäne. Die Herausforderung dabei ist, das Framework domänenunabhängig zu gestalten. Basierend auf dem Framework wird eine Webanwendung realisiert, mit der das halbautomatische Verfahren von einem Experten der jeweiligen Domäne gesteuert wird. Aus unstrukturierten Daten werden in der Anwendung kontextunabhängige Vorschläge zu den einzelnen Bestandteilen eines Knowledge Graphen generiert und zur Bewertung als auch zur Bearbeitung bereitgestellt. Das Ergebnis ist eine domänenunabhängige Webanwendung, die den Domänenexperten durch den Prozess der Erstellung eines Wissensgraphen leitet und am Ende der Bearbeitung einen vollständigen Knowledge Graphen bereitstellt.
13.05.20	2020	extern	Bachelor	DE	Konzeption und Implementierung eines Content Management Systems und Integration in das bestehende Webportal eines Beratungs- und IT-Dienstleistungsunternehmens	Ziel der Bachelorarbeit ist die Betrachtung existierender Content Management Systeme (CMS) im Hinblick auf Faktoren, wie Technologien, Aufbau, Trends, Anpassbarkeit an ein bestehendes Portal und nachträgliche Implementierbarkeit. Anhand der Erkenntnisse soll ein passgenaues CMS für das Webportal "adessini" konzipiert und schließlich implementiert werden. Erschwert wird die Suche nach einem passenden System durch die Tatsache, dass das Webportal bereits produktiv verwendet wird und über ein eigenes Java Backend, Angular Frontend und eine MySQL Datenbank verfügt. Das CMS ermöglicht technisch nicht versierten Administratoren des Webportals Inhalte zu veröffentlichen, ohne tiefergehendes HTML-Wissen zu besitzen. Dadurch wird eine Entlastung der Entwickler erreicht und zugleich die kontinuierliche Bereitstellung von neuen Inhalten ermöglicht.
15.05.20	2020	extern	Bachelor	DE	Beispiele zur Umsetzung ausgewählter Empfehlungen von Sicherheitsstandards für Kritische Infrastrukturen im Sektor Wasser & Abwasser	Unternehmen aus der Wasserbranche erbringen als Kritische Infrastruktur (KRITIS) für die Bevölkerung zwingend notwendige Leistungen wie die Aufbereitung und Versorgung mit Trinkwasser. Durch den Einsatz von Automatisierungs- und Steuerungssystemen sowie die Vernetzung derer bieten Anlagen ein Ziel für Hacker und Schadsoftware. Dadurch ist eine gleichbleibend hohe Qualität und Stabilität der zu erbringenden Leistung gefährdet. Damit Unternehmen im Sektor Wasser, sowie allgemein im Bereich von KRITIS, einen geeigneten Schutz ihrer Systeme gegenüber Cyberangriffen bieten, gibt es Sicherheitsanforderungen seitens des Bundesamt für Sicherheit in der Informationstechnik (BSI) sowie von internationalen Normen wie der DIN ISO/IEC 27000 Reihe. Diese gelten als Empfehlung, bei Unternehmen im Bereich KRITIS sind diese teilweise verpflichtend umzusetzen. Einige Anforderungen lassen sich dabei durch Softwarelösungen umsetzen, z.B. durch Asset-Inventory-Systeme, Monitoring-Lösungen oder Anomalieerkennung. Eine einzelne Software-Lösung allein reicht jedoch nicht aus, um alle Anforderungen zu erfüllen. Eine Kombination aus unterschiedlichen Software-Paketen, die sich im besten Falle ergänzen, ist daher zu empfehlen. Des Weiteren ist die Expertise der Mitarbeiter für die Implementierung, aber auch Beurteilung im Falle von Cyberangriffen sowie zur Einleitung von Gegenmaßnahmen notwendig.
15.05.20	2020	intern	Bachelor	DE	Software-gestützte, kollaborative Planung pädagogischer Events	Pädagogische Eventplanung, also die Gestaltung einer kindgerechten Veranstaltung, findet meist nur im Rahmen herkömmlicher Kinderbetreuungsstellen, wie zum Beispiel Kindergärten oder Kindertagesstätten statt. In solchen Einrichtungen bestehen meist feste Teams mit regelmäßigen Besprechungsterminen und planbaren An- sowie Abwesenheiten der einzelnen Teammitglieder. Diese Kalkulierbarkeit fällt bei eigenständigen Anbietern für Kinderbetreuung oder ehrenamtlichen Teams in verschiedenen Jugendorganisationen weg. Das liegt daran, dass es sich hierbei in der Regel um große, lose Teams handelt. Um bei solchen Angeboten die pädagogische Qualität einer herkömmlichen Betreuungsstelle zu erreichen, ist es notwendig, gewisse Bestimmungen einzuhalten. Außerdem kollaborieren für Veranstaltungen meist unterschiedliche Teammitglieder, basierend auf deren Qualifikation und Verfügbarkeit. In dieser Arbeit soll anhand eines konkreten Anwendungsfalls das Potenzial untersucht werden, das die Digitalisierung von Planungsabläufen im Kontext dieser Problemstellung innehält. Dazu werden zunächst die besonderen Anforderungen aus der Pädagogik in Zusammenarbeit mit relevanten Stakeholdern eines Start-ups zur professionellen Kinderbetreuung erarbeitet. Darauf basierend werden konzeptuelle Ideen erörtert und ein Prototyp implementiert. Um die Einsatztauglichkeit des Prototypen bewerten zu können, soll zudem eine Evaluation innerhalb des Start-ups mit anschließender Ergebnisdiskussion stattfinden.
18.05.20	2020	intern	Bachelor	DE	Agiles Lernen an der Technischen Hochschule Nürnberg ? Konzeption von agilen Handlungsempfehlungen für die Technische Hochschule Nürnberg	Die vorliegende Arbeit behandelt die Fragestellung, wie ein agiles Konzept am Beispiel der Technischen Hochschule Nürnberg aussehen kann. Es werden die theoretischen Grundlagen zu agilen Methoden bzw. zum agilen Lernen näher erläutert. Darauf basierend erfolgt eine theoretische Literaturanalyse des agilen Lernens im Hochschulkontext. Insbesondere wird in diesem Teil der Arbeit das Regelwerk für das agile Lernen aufgestellt, das anschließend mithilfe von Experteninterviews evaluiert wird. Des Weiteren werden die Herausforderungen bei der Durchführung agiler Lehrpraktiken dargestellt. Abschließend werden basierend auf den Erkenntnissen Handlungsempfehlungen anhand von zwei Fallstudien aufgezeigt. Die erste Fallstudie bezieht sich dabei auf eine Lehrveranstaltung im agilen Umfeld, die zweite auf die Studienbegleitung im agilen Umfeld.
25.05.20	2020	intern	Bachelor	DE	"Herausforderung Covid 19: Gestaltung von IT-Beratungsprojekten unter den Rahmenbedingungen einer Pandemie"	Das Ziel dieser Forschung ist es, den Status Quo der Corona Krise, aus Sicht der IT-Beratungsbranche aufzuzeigen und daraus Problemfelder, Verbesserungspotentiale und zukunftsorientierte Chancen für die Gestaltung von IT-Beratungsprojekten abzuleiten. Zur Beantwortung der Forschungsfragen, wurde sowohl quantitative Forschungsarbeit in Form einer Umfrage als auch qualitative Experteninterviews innerhalb der Capgemini Deutschland GmbH durchgeführt. Die Studie zeigt, dass die COVID-19 Pandemie trotz Problemfeldern und Verbesserungspotentialen, vor allem die Chance einer rascheren Digitalisierung innerhalb der deutschen Kunden von Capgemini eröffnet. Es zeigt sich, dass die Aussicht für die Gestaltung von IT-Beratungsprojekten positiv ausfallen könnte, wenn die aktuellen Kenntnisse über Problemfelder während IT-Beratungstätigkeiten, überdacht und interne sowie externe Verbesserungspotentiale ausgeschöpft werden.
26.05.20	2020	intern	Bachelor	DE	Entwicklung eines Konzeptes zur Überführung von browserbasierten Anwendungen im Bankenumfeld in ein OpenShift-Cluster	Immer mehr Unternehmen setzen bei ihrer IT-Infrastruktur auf Cloud Computing. Ein wichtiges Grundkonzept bei dieser Art von IT-Betrieb ist die Containerisierung. Container ermöglichen den einfachen Betrieb von Anwendungen in der Cloud, da sie die Flexibilität und Portabilität sowohl in der Entwicklung, als auch in der Produktion erhöhen. Um den Betrieb einer Vielzahl von Containern zu bewerkstelligen, werden Plattformen wie Kubernetes und OpenShift benötigt. Es existieren mehrere gängige Technologien und Werkzeuge, mit denen die Bereitstellung von Anwendungen bewerkstelligt werden kann. Das Ziel der Arbeit ist, diese miteinander zu vergleichen und deren optimalen Anwendungsfälle zu erarbeiten. Dazu werden die typischen Einsatzgebiete der Container-Plattformen in Kategorien eingeteilt. Das Konzept der Operatoren ermöglicht den vollautomatischen Betrieb von Anwendungen in der Cloud. Es werden verschiedene Frameworks verglichen, welche als Basis für einen Operator dienen. Zusätzlich wird im Rahmen der Arbeit ein Operator implementiert, um eine mögliche Umsetzung zu demonstrieren.
27.05.20	2020	extern	Bachelor	DE	Konzeption einer Personaleinsatzplanung zur Prozessoptimierung des firmeninternen Projektmanagements 	Das Ziel der Arbeit ist es, die Anforderungen des Unternehmens an die Personaleinsatzplanung zu erheben und eine Anwendung zu konzipieren, die diese umsetzt. Es wird bei einer systematischen Feststellung des IST-Zustands begonnen, bei dem Mitarbeiter verschiedener Positionen mittel Online-Umfrage befragt wurden. Die Anforderungen wurden iterativ anhand eines Ausschnitts der Nutzergruppe ermittelt. Zur visuellen Veranschaulichung und Erarbeitung des Konzepts wurde ein UX Prototyp erstellt. Die Ergebnisse der Umfrage ergaben einen Bedarf einer zentralen Personaleinsatzplanung, mit integrierter Verwaltung der Mitarbeiterprofile. Dieser Aspekt wurde in die Konzeption einbezogen und am Ende der Arbeit bewertet. Das Feedback der Evaluation des Prototypen, am Ende der Arbeit, zeigte ein hohes Interesse der Teilnehmer an einer zentralen Personaleinsatzplanung.
27.05.20	2020	extern	Master	DE	Entwicklung einer REST-API für das Dokumenten-Management-System der DATEV eG	REST ist in aller Munde. Unternehmen wie DATEV entwickeln langfristige Strategien, Softwarelösungen mit Hilfe dieser Technologie zu öffnen und zu vernetzen. Bevor die Öffnung jedoch erfolgen kann stellt sich die Frage "Wie wird eine robuste REST-Schnittstelle für eine bestehende On-Premise Anwendung entworfen?". Kern einer jeden REST-Schnittstelle ist das Ressourcenmodell, welches in der Wahrnehmung der Verwender einer Benutzeroberfläche gleich kommt. Daher soll in dieser Arbeit ein allgemeingültiger von DATEV losgelöster Transformationsprozess eines Domänenmodells in ein robustes Ressourcenmodell vorgeschlagen werden. Dieser Prozess kann sowohl für den vollständigen Neuentwurf als auch für die Erweiterung eines bestehenden Ressourcenmodells angewendet werden. Der vorgeschlagene Prozess wird im Anschluss bei dem Entwurf der DATEVConnect für Dokumentenmanagement-API praktisch erprobt und abschließend evaluiert.
28.05.20	2020	extern	Master	DE	Threat Modeling - Ausarbeitung verschiedener Bedrohungsmodellierungen und deren Integration in die agilen Entwicklungsprozesse der DATEV	In der DATEV werden durch das Manifest "Agile Security" verschiedene Sicherheitsaspekte bereits in den Entwicklungsprozess involviert. Die Anwendung einer Bedrohungsmodellierung ist ein Teil davon. Demnach werden Bedrohungsanalysen durchgeführt, welche aber bisher nicht nach einem Leitfaden ablaufen und auch kein Standard in der Entwicklungs-Guideline sind. Daher werden diese nur vereinzelt und nicht einheitlich ausgeführt. Um Software-Schwachstellen vorab zu identifizieren, statt nur Sicherheitslücken nachjustieren zu können, wird ein Konzept für die Bedrohungsmodellierung benötigt. Der beschriebenen Ausgangslage in der DATEV entsprechend wird folgende Forschungsfrage gestellt: Ist es möglich eine Bedrohungsmodellierung effektiv in den Entwicklungsprozess der DATEV zu integrieren? Dementsprechend wird eine Übersicht von vorhandenen Bedrohungsmodellen erarbeitet, jeweilige Probleme identifiziert und gegenübergestellt. Des Weiteren werden Gespräche mit Sicherheitsexperten geführt, um diese als zusätzliche Beratung zur Seite zu nehmen. Parallel dazu werden spielerische Ansätze, sogenannte Gamification-Ansätze, für eine Bedrohungsmodellierung DATEV-intern durchgeführt. Es werden Gespräche mit relevanten Stakeholder geführt, um ein notwendiges Gesamtverständnis für die Konzepterstellung zu erarbeiten. Es wird anhand der erlangten Informationen und in Zusammenarbeit mit Sicherheitsexperten ein generisches Konzept erarbeitet, welches in Zukunft auf verschiedene Anwendungsbereiche
29.05.20	2020	intern	Bachelor	DE	Analyse technologischer Lösungen zur Bekämpfung der Riffverschmutzung	Die Arbeit handelt von der Analyse technologischer Lösungen zur Bekämpfung der Riffverschmutzung. Die technologischen Lösungen bestehen spezifischer gefasst aus Internet-Kampagnen, welche auf einer globalen Skala digital die Ursachen und Konsequenzen der Riffverschmutzung bekämpfen. Die zweite der drei Technologien stellt Dive Against Debris dar. Dieses von einer gemeinnützigen Organisation entwickeltes Programm bietet Tauchern die Möglichkeit, während des Tauchgangs Müll von Riffen aufzusammeln, diesen einzuschicken und zu dokumentieren. Die letzte Lösung heißt Biorock. Diese Lösung umfasst eine Methode zum manuellen Aufbau von Riffen durch Platzierung von menschengemachten Strukturen im Meer, durch welche Strom geleitet wird. Dies induziert Korallenwachstum. Nachdem theoretische Grundlagen wie das Ökosystem Riff und die Ursachen und Konsequenzen der Riffverschmutzung erklärt wurden, folgt eine Beschreibung der drei Technologien anhand von vier bestimmten Kriterien: Ökologische Effizienz, ökonomische Effizienz, sozialer Mehrwert und anfängliche Startschwierigkeit. Anhand dieser Kriterien wird im späteren Verlauf der Arbeit eine Nutzwertanalyse durchgeführt, die bestimmt, welche der Technologien am meisten Potenzial hat, Riffverschmutzung zu bekämpfen. Nach der Durchführung der Nutzwertanalyse und unter Einbezug von Ergebnissen eines Fragebogens kommt die Arbeit zum Ergebnis, dass Biorock unter den genannten Kriterien die beste Lösung darstellt.
31.05.20	2020	intern	Bachelor	DE	Ausgewählte Aspekte des Risikomanagement bei internationalen agilen Projekten mit Fokus auf Türkei und Deutschland 	Im Rahmen dieser Bachelorarbeit soll untersucht werden, welche Herausforderungen in agilen Projekten in Zusammenarbeit mit der Türkei bestehen. Diese werden anhand des Kulturmodells von Hofstede überprüft. Mit dieser Analyse werden typische Eigenschaften der deutschen und türkischen Kultur sowie die Unterschiede der beiden Länder dargestellt. Zusätzlich wird aus dem agilen Projektmanagement der Scrum-Prozess genauer erläutert, weil einige Aspekte des Risikomanagementprozesses implizit dort auftreten. Die Beobachtung vermittelt einen Einblick, an welchen Stellen des Scrum-Prozesses das Risikomanagementprozess angewendet wird. Zudem wird ein kurzer Überblick über Risikoarten in Projekten gegeben und es werden Empfehlungen für Projektleitende aufgeführt, wie diese mithilfe der Risikosteuerung aus dem Risikomanagementprozess interkulturelle Risiken vermeiden können. Dafür wurde die Risikostrategie "Risikoverminderung" angewendet. Der Schwerpunkt der Arbeit ist die empirische Untersuchung, mit der untersucht wird, ob die Scrum-Methode aus dem agilen Projektmanagement in der Türkei angewendet werden kann. Außerdem soll erforscht werden, ob eine effektive Risikokommunikation trotz kultureller Unterschiede gewährleistet werden kann.
02.06.20	2020	extern	Master	DE	Rendering Glyphs on the GPU with OpenGL	Mit der zunehmenden Digitalisierung von Fahrzeugen erhalten neue Konzepte wie Head-up-Displays oder Augmented Reality Einzug in die Automobile. Diese Technologien erfordern die textuelle Darstellung von Informationen für Navigations- und Assistenzsysteme in einer dreidimensionalen Umgebung und in Echtzeit. Klassische Texture-Mapping-Ansätze haben hierbei den Nachteil, dass jedes Skalieren, Drehen und Bewegen von Text eine Neuberechnung der Textur auf der CPU erfordert. Aus diesem Grund wird für diese Anwendungen ein GPU-basierter Ansatz gesucht. Die beiden Textrendering-Ansätze, multi-channel signed distance fields und Slug, wurden mit Glyphen aus OpenType-Fonts und Vektorgrafiken als mögliche Lösungen untersucht. Daher wurde der Slug-Algorithmus um einen Präprozessor für kubische Bézier-Kurven und die Unterstützung mehrfarbiger Glyphen erweitert. Die Experimente haben gezeigt, dass sowohl der Slug-Algorithmus als auch die multi-channel signed distance fields für dieses Text-Rendering-Szenario geeignet sind. Allerdings ist der Slug-Algorithmus nicht performant genug und hängt zudem stark von der Größe und Komplexität der darzustellenden Glyphen ab. Daher wird der Ansatz der multi-channel signed distance fields als Lösung für das Echtzeit-Textrendering in einer dreidimensionalen Umgebung in Betracht gezogen.
11.06.20	2020	extern	Master	DE	Evaluation eines Modells zur Priorisierung von Geschäftsprozessen bezüglich des Automatisierungspotenzials am Beispiel der prototypischen Implementierung im Bereich von Robotic Process Automation	Ziel dieser Arbeit ist die Erstellung eines Modells zur Bewertung der Automatisierungstauglichkeit von Geschäftsprozessen, anhand dessen automatisierbare Prozesse im Unternehmen identifiziert werden. Das Framework dient als Entscheidungsgrundlage für die Verantwortlichen, um Prozesse priorisiert zu automatisieren oder davon auszuschließen. Durch die prototypische Implementierung der Roboter mittels der Technologie Robotic Process Automation soll der Erfolg der Automatisierung gemessen werden. In einer Literaturrecherche werden Ansätze und Kriterien für die Automatisierungstauglichkeit ermittelt, welche als Basis für die Modellaufstellung verwendet werden. Drei Geschäftsprozesse aus dem Unternehmen werden anhand des ausgewählten Rating-Modells bewertet und eine Entscheidung für die Automatisierung abgegeben. Durch eine prototypische Implementierung wird das Bewertungsmodell zusätzlich evaluiert und Empfehlungen für die Optimierung des Modells aufgeführt. Im Ergebnis hat sich gezeigt, dass das theoretische Bewertungsmodell um die Besonderheiten des Unternehmens ergänzt werden muss. Ein standardisiertes Datenformat, ein transparent definierter Prozessdurchlauf und eine häufige Ausführung des Prozesses sind zentrale Erfolgskriterien für eine Automatisierung durch Robotic Process Automation. Die Roboter erbringen eine hohe Zeitersparnis und arbeiten effektiver verglichen mit der manuellen Durchführung. Die Prozessqualität steigert sich durch die Prozessautomatisierung.
12.06.20	2020	extern	Bachelor	DE	Weiterentwicklung des Prozesses des Bestandsmanagements im IT-Infrastruktur Controlling der DATEV eG	Die Abschlussarbeit gibt einen Überblick über den aktuellen Prozess des Bestandsmanagements des Rechenzentrums der DATEV eG. Das Bestandsmanagement des IT-Infrastruktur Controllings verwaltet alle Hard- und Softwarekomponenten und überwacht diese während ihres kompletten Lebenszyklusses. Adressaten der erhobenen Daten sind interne Stakeholder. Durch diese Arbeit soll das Tätigkeitsprofil eines Bestandsmanagers transparent dargestellt und das Verständnis der relevanten Prozesse intern erhöht werden. Somit ist die Bachelorarbeit für alle Stakeholder und Entscheidungsträger der DATEV eG, welche in Kontakt mit dem Rechenzentrum stehen, interessant. Zum Bestandsmanagement zählen die Prozesse Bestandsführung, Abnahme der Komponenten, Rechnungsfreigabe sowie Verschrottung. Diese werden in der Abschlussarbeit dargestellt, überprüft und durch Handlungsempfehlungen optimiert. Für die Datenerhebung der IST-Analyse waren Beobachtungen und das Wissen der Prozessbeteiligten grundlegend. Die Handlungsempfehlungen wurden durch eine Analyse des bestehenden Ablaufes und auf Basis der Anforderungen der Stakeholder erstellt.
17.06.20	2020	extern	Bachelor	DE	DATEV-Cloud-Sourcing: Analyse und Optimierung der Produktwechselprozesse	Das Ziel dieser Abschlussarbeit besteht darin, ein prozessuales Konzept mit Optimierungsmaßnahmen für Produktwechselprozesse zu erstellen. Die Prozesse des Produktwechsels werden erfasst, auf Schwachstellen untersucht und gegebenenfalls auch Optimierungsvorschläge erarbeitet. Dabei wird zunächst der aktuelle BPM-Workflow analysiert. Danach werden zahlreiche Interviews mit den involvierten Mitarbeitern durchgeführt und die Checklisten für Wechselprozesse überprüft. Die Erarbeitung eines Soll- Konzeptes diente der verbesserten Darstellung der Produktwechselprozesse. Die erstellten Modelle können als Basis für die Implementierung eigener BPM-Workflows verwendet werden. Am Ende dieser Abschlussarbeit werden alle vorgeschlagenen Verbesserungsmaßnahmen zusammengefasst. Die Umsetzungsprüfung dieser Maßnahmen erfolgt mittels einer Aufwand-Nutzen-Analyse. Die Ergebnisse der Abschlussarbeit sollen den Vorgesetzten als Entscheidungsgrundlage dienen. Unabhängig von der Entscheidung, welche Verbesserungsmaßnahmen umgesetzt werden, kann das Ergebnis dieser Bachelorarbeit zum einen für die Dokumentation der Produktwechselprozessen und eine Einarbeitung der neuen Mitarbeiter verwendet werden. Zum anderen können die erarbeiteten Ergebnisse als Informationsquelle und Grundlage für weitere zukünftige Prozessoptimierungen verwendet werden.
01.07.20	2020	intern	Master	DE	Konzeption und Entwicklung einer Benutzeroberfläche für die prozedurale Generierung von virtuellen Indoor-Welten mittels des Levelgraph-Verfahrens	Prozedurale Levelgenerierung ist ein wichtiger Aspekt der Spieleentwicklung. Für diesen Themenbereich wurde ein inkrementelles halbautomatisches Verfahren namens Levelgraph entwickelt, mit dessen Hilfe 2D/3D Flur- und Raumsysteme durch eine iterative prozedurale Verarbeitungskette konstruiert werden können. Der Algorithmus wird dabei durch eine komplexe und umfangreiche Parametermenge gesteuert, für die Vorwissen im Bereich der Graphentheorie und Leveldesign vorausgesetzt und lange Einarbeitungszeit benötigt wird. Dieses Verfahren kann über ein in der Game-Engine Unity bereits entwickelten prototypischen Plugin angewendet werden. Auf dieser Grundlage wird in dieser Arbeit eine Oberfläche in Unity entwickelt, welche die Einstellung der Parameter sowie die Anwendung und Steuerung des Verfahrens für Anwender ohne technisches Expertenwissen ermöglicht. Zur verständlichen sowie nachvollziehbaren Darstellung der oben genannten technischen Parameter werden diese umfassend analysiert und überarbeitet. Darauf aufbauend wird in dieser Arbeit ein Konzept erstellt und anschließend als grafische Benutzeroberfläche (prototypisch) umgesetzt. Mittels der prototypisch realisierten grafischen Benutzeroberflächen wird im Rahmen dieser Arbeit außerdem eine Benutzerstudie hinsichtlich der Usability durchgeführt. Das Ergebnis dieser Arbeit ist ein Unity-Plugin, welches von Leveldesignern für die Generierung von 2D/3D-Flur- und Raumsystemen effizient genutzt werden kann.
02.07.20	2020	extern	Bachelor	DE	Entwicklung einer effizienten Parallelisierungsstrategie zur Rekonstruktion von 3D Volumendaten mit Multi-GPU Systemen	Ziel dieser Arbeit ist die Entwicklung und Implementierung einer Softwarearchitektur, welche eine effiziente Rekonstruktion von Volumendaten aus Röntgenaufnahmen auf Multi-GPU Systemen ermöglicht. Als Rekonstruktionsalgorithmus wird die gefilterte Rückprojektion für Kreis- und Helixaufnahmegeometrien verwendet. Hierfür wird ein Überblick über die Algorithmen sowie über die OpenCL-API, welche zur Programmierung der Grafikkarten verwendet wird, gegeben. Der Haupteil befasst sich mit einer Analyse der bestehen Lösung und der Beschreibung der neuen Architektur. Die Evaluation wurde mit simulierten Datensätzen mit verschiedenen Aufnahmeparametern durchgeführt. Im Vergleich zur bestehenden Lösung erzielt die Implementierung der neue Architektur geringere Laufzeiten.
09.07.20	2020	extern	Bachelor	DE	Visualisierung von (Code-)Analyse Daten mittels Graphdatenbanken	Im Rahmen meiner Bachelorarbeit sollen unterschiedliche 2D Visualisierungen mittels einer Web-Anwendung evaluiert werden. Grundlage für die Visualisierung sind Codeanalyse Daten, die in einer Graphdatenbank gespeichert sind. Diese Daten werden über eine .NET Core Server-Anwendung per REST API bereitgestellt. Die Evaluation soll zeigen, in wie weit die verschiedenen Ansichten eine Codeanalyse unterstützen können.Unter den 2D Visualisierungen, die im Rahmen der Bachelorarbeit bearbeitet sind, sind TreeMaps, Circle-Packing, Chord-Diagramm, und Tree. Hierzu muss eine Implementierungsstrategie und 2D Engine ausgewählt werden, die mehrere tausend Objekte flüssig darstellen kann. Im Rahmen der Arbeit soll die bestehende REST API des Servers entsprechend den Anforderungen angepasst werden und ein webfähiger Client mittels TypeScript und JavaScript implementiert werden. Für die Implementierung der Visualisierung wird die JavaScript-Bibliothek "D3.js" benutzt und für das User Interface (UI) wird die JavaScript-Bibliothek "React.js" verwendet.
15.07.20	2020	intern	Bachelor	DE	Konzeption und prototypische Umsetzung eines Segeltrimm-Assistenten auf Basis von NMEA2000-Daten	Ziel dieser Arbeit ist die Konzeption und Entwicklung einer prototypischen Applikation (App), welche auf Basis von NMEA2000-Daten eine visuelle Darstellung empfohlener Trimmeinstellungen des Haupt- und des Vorsegels auf einem Segelboot ausgibt. Zur Datenbereitstellung dient ein Einplatinencomputer, der unter Einsatz eines Adapters, der als Schnittstelle zwischen NMEA2000- und seriellen Daten die Sensordaten eines Segelbootes empfängt. Für einen plattformunabhängigen Einsatz der App, wird die Entwicklung mittels eines Cross-Plattform Frameworks realisiert werden. Als Resultat der Implementierung, liefert die App dem Anwender visuell aufbereitete Daten und gibt grafische Empfehlungen für einen passenden Segeltrimm aus.
28.07.20	2020	extern	Master	DE	Domänenwissen-basierte Erkennung komplexer Ereignisse in Messdaten verteilter Sensoren	Mit der zunehmenden Verbreitung digitaler Sensoren wächst auch die generierte Datenmenge stetig an. Gerade der Einsatz von Sensornetzen ermöglicht, dank einer Vielzahl verteilter Sensoren, eine großflächige Überwachung von Gebieten. Erhobene Daten enthalten Informationen über Vorgänge der realen Welt und können Rückschlüsse auf komplexe Abläufe liefern. Deren Erkennung wird vereinfacht, wenn vorab eine Zuordnung der Messdaten zu bestimmten komplexen Ereignissen erfolgt. Grundlage hierbei ist Domänenwissen, über welches die Kombinations- und Interpretationsweise der Messdaten und die resultierenden Ereignisse definiert werden können. Ziel dieser Arbeit ist die Entwicklung und Implementierung einer Anwendung, welche basierend auf Domänenwissen und Messdaten verteilter Sensoren abstrakte Ereignisse ableiten kann. Aufgrund der vielfältigen Einsatzszenarien liegt das Augenmerk auf einer hohen Flexibilität und einer einfachen Verwendungs- und Integrationsweise in bestehende Systeme. Hierbei wird auch eine Schnittstelle entwickelt, welche die Verwendung bestehender Komponenten als Teil des Erkennungsablaufs ermöglicht. Die Funktionsfähigkeit der Anwendung wird abschließend in verschiedenen Szenarien evaluiert.
14.08.20	2020	extern	Bachelor	DE	Entwicklung einer touch orientierten Oberfläche nach MVVM für die Auftragsliste	Das Ziel dieser Arbeit ist es eine neue Oberfläche für die Auftragsliste zu erstellen. Die Auftragsliste ist hierbei ein Teil eines Prozessleitsystems. Die neue Oberfläche soll in C# WPF geschrieben und nach dem MVVM-Muster aufgebaut werden. Die erstellte UI soll darauf ausgelegt sein auf einem Windows-Tablet mittels Toucheingaben bedient zu werden. Außerdem soll bei der Erstellung des Backends der Anwendung besonders auf Modularität geachtet werden. Für die Umsetzung des Layouts der Oberfläche konnte sich auf ein vorhandenes Konzept gestützt werden. Zuvor musste dieses aber hinsichtlich der Grundsätze aus der ISO 9241-110 Norm verifiziert werden, da es sich bei diesem Konzept nur um einen ersten Entwurf handelte. Im Konzept wurden kleinere Kritikpunkte gefunden, welche ausgebessert wurden. Aufbauend auf das verifizierte Konzept konnte ein konkreter Plan für die Umsetzung der Oberfläche in C# WPF ausgearbeitet werden. Zugehörig zum zuvor vorhandenen UI-Konzept gab es eine Testanwendung, welche bereits in C# WPF geschrieben war. In dieser waren schon Grundstrukturen, wie grundlegende Datenbankabfragen, vorhanden. Aufbauend auf dieser Anwendung, wurde ein Konzept für die Datenstrukturen und das Zusammenspiel dieser im Backend der Anwendung ausgearbeitet. Abschließend wurde die erarbeitete Anwendung noch einigen Tests unterzogen. Das Ergebnis ist ein erster Schritt der Neuentwicklung der Auftragsliste, auf welche in Zukunft weiter aufgebaut werden wird.
01.09.20	2020	intern	Bachelor	DE	Null Safety in modernen Programmiersprachen	Ein häufiger Laufzeitfehler bei Anwendungen ist der NullPointerError, welcher vor allem durch unaufmerksames Programmieren entsteht. Da viele Compiler die Zusammenhänge von Null-Zuweisungen und Dereferenzierungen nicht statisch erkennen können, bleiben diese Fehler bis zur Laufzeit unbemerkt. Deswegen kommen immer mehr Programmiersprachen mit ihren eigenen Konzepten auf, um Programmabstürze durch leere Referenzen zu vermeiden. Diese Arbeit untersucht die allgemeinen Möglichkeiten, wie moderne Programmiersprachen Null Safety zu Compilezeit umzusetzen können oder bereits umsetzen. Dabei wird im Detail auf die Null Safety in Java und Kotlin eingegangen und überprüft, wie eine Übersetzung nach Kotlin ein Java-Programm null-sicherer machen kann. Diese Übersetzung wird klassenweise zuerst durch eine automatische Konvertierung von Android Studio und dann durch manuelle Anpassungen zu einem kotlin-idiomatischen Code durchgeführt. Daraus resultierend wird eine stichpunktartige Guideline angefertigt, die das allgemeine Vorgehen bei einer null-sicheren Übersetzung von Java nach Kotlin beschreibt.
01.09.20	2020	intern	Bachelor	DE	Konzeption einer Gamification - Lösung für das Qualitätsmanagement	Da die Qualität von Produkten und Dienstleistungen einen entscheidenden Wettbewerbsfaktor darstellt und für Zertifizierungen erforderlich sein kann, entscheiden sich viele Unternehmen für die Einführung eines Qualitätsmanagementsystems. Eine klassische Aufgabe beim Aufbau von Qualitätsmanagementsystemen ist die Dokumentation der Prozesse. Diese Teilaufgabe wird von den betroffenen Personen aufgrund des hohen Aufwands oft als demotivierend wahrgenommen. Insofern stellt sich die Frage, wie Mitarbeiter zu dieser Tätigkeit motiviert werden können. Gamification ist ein vieldiskutierter Trend der zunehmend Einzug in die Arbeitswelt findet. Darunter versteht man den Einsatz von Spielelementen in nicht-spielerischen Kontexten. Gamification wird zur Steigerung der Motivation eingesetzt, mit dem Ziel eine Verhaltensänderung herbeizuführen. Um diesen Mehrwert zu generieren, ist es jedoch erforderlich die Bedürfnisse und Präferenzen der Zielgruppe zu kennen. Ziel der Arbeit ist die Konzeption einer Gamification-Lösung für die Einführung eines Qualitätsmanagementsystems. Hierbei sollen die Mitarbeiter eines Betriebs dazu motiviert werden, sich aktiv bei der Dokumentation von Prozessen zu beteiligen. Die Vorgehensweise zur Erstellung des Konzepts orientiert sich an einem Gamification-Designprozess, im Rahmen dessen eine Analyse des Kontexts und der Nutzer erfolgt, um eine angepasste Lösung zu entwickeln.
03.09.20	2020	extern	Bachelor	DE	Software-Lifecycle Management bei der Datev eG: Konzeption und Implementierung einer maßgeschneiderten Lösung	Ziel dieser Arbeit ist die konstruktive Überarbeitung der bereits bestehenden Software-Lifecycle Management Prozesse und Rollen der DATEV unter Einbezug der technologischen Entwicklungen und den neu geschaffenen Funktionen durch einen sogenannten Software Cataloges. Zudem soll ein technischer Einblick in die Funktionsweise und die zukünftigen Einsatzszenarien durch mögliche Erweiterungen des Software Cataloges gegeben werden.
07.09.20	2020	extern	Bachelor	DE	Konzeption und prototypische Überführung von Jenkins-Pipelines in ein Kubernetes-Umfeld sowie Rückführung der Ergebnisse	Das Ziel der vorliegenden Bachelorarbeit war es, ein Konzept zur Überführung von Jenkins- Pipelines in Tekton-Pipelines zu erstellen. Diese Pipelines werden in einem Kubernetes- Cluster ausgeführt. Das Konzept wurde anhand der prototypischen Überführung einer standardisierten Maven-Pipeline angewendet. In diesem Konzept wurde besonderer Wert darauf gelegt, keine Änderung für den Endanwender herbeizuführen. Demnach soll keine Änderung am Vorgehen beim Start und bei der Auswertung der Pipeline erforderlich sein. Hierfür ist es nötig, die Ergebnisse der Tekton-Pipeline auf den Jenkins zurückzuführen sowie den Start der Pipeline gleich zu gestalten. Ein weiterer wichtiger Punkt ist, die Konfigurierbarkeit der Pipeline weiterhin zu gewährleisten. Die Rückführung konnte durch die Verarbeitung von CloudEvents mittels eines RESTServices gestaltet werden. Dieser sendet alle notwendigen Informationen an den Jenkins, welcher diese sichert und anschließend darstellt. Der Start der Pipeline wird über den Aufruf einer Webhook, welche durch tekton-triggers bereitgestellt wird, ermöglicht. Diese Webhook kann sowohl manuell über den Jenkins als auch automatisch bei Änderungen am Repository durch Bitbucket aufgerufen werden. Die Konfigurierbarkeit wurde durch eine dynamisch erzeugte ConfigMap erreicht. Diese wird auf Basis einer Datei im Git-Repository eines jeden Projektes, welches die Pipeline nutzt, erstellt.
07.09.20	2020	intern	Master	DE	Prototypische Konzeption und Implementierung eines Chatbots zur Unterstützung von Studierenden und Studieninteressenten	Diese Arbeit befasst sich mit der prototypischen Konzeption und Implementierung einer Chatbot-Anwendung zur Unterstützung von Studierenden und Studieninteressenten. Die Anwendung wurde in Zusammenarbeit mit psychologischen Fachkräften an der TH Nürnberg realisiert. Beginnend mit der Aufgabenstellung und der Erfassung der Anforderungen, werden zunächst die technischen Grundlagen zur Realisierung einer solchen Anwendung dargelegt. Dabei wird insbesondere auf das Natural Language Understanding (NLU), die Typisierung von Chatbots, sowie auf das Chatbot-Framework Rasa eingegangen. Zudem werden die Studiengangstests der Technischen Hochschule Nürnberg, sowie das zugehörige Interventionsangebot zur Unterstützung der Nutzer erläutert. Die zentrale Aufgabe der Chatbot-Anwendung besteht darin, zwischen den Studiengangstests und dem Interventionsangebot individuell zu vermitteln und den Prozess langfristig zu begleiten. Auf diesen Erkenntnissen aufbauend, wird das Softwaredesign der Chatbot-Anwendung, sowie die anschließende Realisierung erörtert. Dabei wird der Fokus insbesondere auf die Wahl des Chatbot-Frameworks und die Formalisierung der Regeln gelegt. Anschließend wird der Prototyp evaluiert und die Ergebnisse der Evaluation detailliert diskutiert. Des Weiteren werden Herausforderungen bei der Konzeption und Realisierung einer solchen Chatbot-Anwendung separat herausgearbeitet. Abschließend werden mögliche Erweiterungen erörtert und eine Zusammenfassung der Arbeit gegeben.
14.09.20	2020	extern	Bachelor	DE	Evaluation von skalierbaren Technologien für Build-Infrastrukturen in großen IT-Unternehmen und Konzeptionierung der Umsetzung am Fallbeispiel der DATEV eG	Aufgrund des schnellen Wachstums und somit auch steigender Mitarbeiterzahl vieler Unternehmen der Softwareentwicklung benötigen diese eine Build-Infrastruktur, die dynamisch auf die steigende Last reagieren kann. Da die Auslieferung der Software von der Build-Infrastruktur abhängig ist, stellt dies einen essenziellen Aspekt der Wertschöpfungskette jedes Softwareentwicklungsunternehmen dar. Oft ist eine Build-Infrastruktur mit statischen Kapazitäten vorhanden, die unflexibel bezüglich Strukturänderungen und steigender Nutzerzahl ist. Im Kontext der Bachelorarbeit wird eine Infrastruktur mit ca. 1000 Nutzern und 5000 täglichen Builds betrachtet. Bei steigender Nutzerzahl ist manueller Personaleinsatz notwendig. Ziel der Arbeit ist passende architektonische Prinzipien zu ermitteln und eine Lösung zu gestalten, wie am Markt verfügbare Buildtechnologien zu einer flexiblen, dynamischen Infrastruktur verbaut werden können, die sowohl hinsichtlich Last als auch geänderter Anforderungen flexibel ist. Das Ergebnis wird ein Kriterienkatalog mit praxisnahem Anwendungsbeispiel sein, in dem sich alle wichtigen Aspekte und Eigenschaften hinsichtlich der oben genannten Zielsetzung der verschiedenen Technologien befinden. Die ermittelten Prinzipien werden mittels Gestaltung eines Konzepts praxisnah am Fallbeispiel des Unternehmens DATEV eG dargestellt. Die Konzeptionierung der Umsetzung dient zur späteren Validierung im realen Umfeld.
14.09.20	2020	extern	Bachelor	DE	Konzeption und prototypische Anbindung eins cloudbasierten JavaScript Monitoring Tools	Die steigende Anzahl von JavaScript Anwendungen und die derzeit fehlenden Möglichkeiten echtzeitnah und ressourcenschonend bei der Sopra Financial Technogoly (SFT) Performanz und Fehler zu erfassen, ist der Ausgangspunkt für diese Arbeit. Durch eine nutzerorientierte Anforderungsanalyse wurde für die Firma wichtige Kriterien an ein mögliches Error Monitoring Tool eruiert. Mit Hilfe einer Nutzwertanalyse wird ein geeignetes Produkt ausgewählt. Dieses wird mit Hilfe einer minimalen Javascript-Anwendung für den Einsatz in der Sopra Financial Technogoly (SFT) erprobt.
14.09.20	2020	intern	Bachelor	DE	Einflüsse der Digitalisierung in der Pathologie auf die Wirtschaftlichkeit und die Arbeitsabläufe im Labor 	Aus Unternehmenssicht einer Pathologie ist es das Ziel, ihre Kunden, die einsendenden Ärzte, bestmöglich mit zuverlässigen Befunden zu versorgen. Als Herausforderung dabei bestehen nicht nur sinkende Laborbudgets und steigender Kostendruck, sondern auch ein zunehmender Fachkräftemangel. Verbesserungen erwarten Laborleiter und Geschäftsführer hier mit Hilfe der Digitalisierung durch die Reduktion manueller Tätigkeiten. In der Arbeit sollen die prozessualen, personellen und wirtschaftlichen Einflüsse der wachsenden Digitalisierung auf das pathologische Labor sowie die Befunderstellung dargestellt und kritisch betrachtet werden. Zudem sollen Lösungsansätze für das Problem des Fachkräftemangels aufgezeigt werden. Darüber hinaus erfolgt eine wirtschaftliche Gegenüberstellung der Investitionen in Bezug auf die Digitalisierung. Informationen aus der Praxis werden durch Interviews mit Laborberatern und Pathologen erhoben.
21.09.20	2020	intern	Bachelor	DE	Konzeption, Design und Entwicklung einer nativen iOS App zur Untersuchung von responsive Design und Internationalisierung	Zur Untersuchung von responsive Design und Internationalisierung wurden für diese Arbeit drei native iOS Apps erstellt. Sie wurden mit dem UIKit Framework, dem Storyboard des Interface Builders von Xcode und dem seit September 2020 neu eingeführten SwiftUI Framework erstellt. Da sich jede dieser drei Varianten bei der Erstellung einer App unterscheidet wird zuerst auf die Grundlagen eingegangen. Responsive Design wird auch bei nativen Apps benötigt, da sich die Bildschirmauflösungen der einzelnen Modelle unterscheiden. Deshalb wird das Auto Layout, Adaptive Layout und das neue SwiftUI Layout System erklärt und miteinander verglichen. In Zusammenhang mit dem responsive Design steht die Internationalisierung einer App. Es wird beschrieben, wie diese unter iOS funktioniert und welche Vor- und Nachteile sich für die jeweiligen Varianten ergeben.
21.09.20	2020	extern	Bachelor	DE	Konzeption und prototypische Implementierung eines Tools zur Kennzahlenvisualisierung im Serviceprozess bei der Dematic GmbH 	Dematic ist einer der führenden Intralogistik-Innovatoren, der automatisierte Lösungen für Fertigungs-, Lager- und Vertriebsumgebungen entwickelt, baut und betreut. Die Realisierung von Lagersystemen für Kunden beinhaltet vertraglich vereinbarte Service- und Supportdienstleistungen zur Wartung und Betreuung der Lagerverwaltungssoftware. Das Ziel der Arbeit ist, ein Tool zur Darstellung von Kennzahlen eines entsprechenden Serviceprozesses auszuwählen. Mit der Visualisierung von Kennzahlen können die richtigen Informationen in der richtigen Qualität den richtigen Adressaten zur richtigen Zeit zur Verfügung gestellt werden. Mittels einer Kosten-Nutzen-Analyse sowie einer quantitativen Befragung der späteren Softwareanwender wird ein geeignetes Software-Tool zur nutzerfreundlichen Visualisierung von Ticketdaten ausgewählt. Die Untersuchung des Serviceprozesses folgt einem systemtheoretischen Lösungsansatz zur Ermittlung von wesentlichen Komponenten eines Systems und stellt als Ergebnis ein Kennzahlensystem für die Serviceleistungen des SAP Support-Bereichs dar. Mit dem Software-Tool werden die ermittelten Kennzahlen visualisiert und automatisiert bereitgestellt.
22.09.20	2020	extern	Bachelor	DE	Konzeptionierung einer agilen Softwareentwicklung im IT-Systemhaus der Bundesagentur für Arbeit	Die vorliegende Bachelorarbeit, die in Kooperation mit dem IT-Systemhaus der Bundesagentur für Arbeit geschrieben wurde, beschreibt Konzepte für die Softwareentwicklung und das Anforderungsmanagement im Servicebereich BAS1. Die Konzepte versuchen, Lösungsansätze für die Herausforderungen des Servicebereichs aufzuzeigen. Das konzipierte Modell für eine agile Softwareentwicklung mit interdisziplinären Teams und einer testgetriebenen Entwicklung basiert auf der Methode Scrum und wurde an die Prozesse und Vorgaben des Servicebereichs angepasst. Gleichzeitig wird das entwickelte Konzept für das Anforderungsmanagement in den Softwareentwicklungsprozess integriert. Hiermit wird das Anforderungsmanagement neu ausgerichtet, durch ein teamübergreifendes, virtuelles Team durchgeführt und somit von den Teams losgelöst. Obwohl die Konzepte individualisiert sind, zeigen sie, wie eine agile Softwareentwicklung mit interdisziplinären Entwicklerteams und einem cross-funktionalen Anforderungsmanagement in IT-Abteilungen eingesetzt werden kann und können daher als Vorlage für andere Abteilungen dienen.
25.09.20	2020	extern	Bachelor	DE	Analyse und Visualisierung der Datenqualität innerhalb eines Data Warehouse	Für Banken ist für das Treffen von korrekten, finanzspezifischen Entscheidungen insbesondere eine hohe Datenqualität erforderlich. Diese Arbeit zeigt, dass Datenqualität mehr als nur korrekte Daten bedeutet. Zur Analyse von Datenqualität existieren aktuell wenige praktische Verfahren, die ohne manuellen Aufwand angewendet werden können. Anhand einer Stakeholder-Analyse werden drei zentrale Probleme eines Finanzdienstleisters skizziert und Methoden zur Analyse vorgeschlagen. Hierfür werden beispielhaft die Daten des Risikoscorings verwendet und anhand der Methoden untersucht. Basierend auf einer entsprechenden Evaluation erweisen sich diese Verfahren für den Finanzdienstleister als nützlich und geben erste Einblicke in die Datenqualität. Ein in der Arbeit evaluiertes Programm und dessen Visualisierungen zeigen praktisch umgesetzte Verfahren zur Analyse der Datenqualität.
28.09.20	2020	extern	Bachelor	DE	Konzeptionierung und Implementierung einer Performance Analytics Plattform für Managed Services bei einem IT-Dienstleister.	Der Titel dieser Arbeit lässt im Grunde schon das erahnen, was im Fortlauf durchleuchtet und bewertet wird: Wie lässt sich eine Performance Analytics Plattform für Managed Services bei einem IT-Dienstleister konzeptionieren und implementieren? Die Theorie die sich in der umfangreichen Literatur ergründet, bietet einem Unternehmen zahllose Möglichkeiten sein IT-Servicemanagement zu strukturieren. Viele Rahmenwerke beschreiben mithilfe von generischen Modellen die Struktur, welche jedoch auf die Bedürfnisse und Anforderungen des Unternehmens angepasst werden müssen. Anhang der Struktur des IT-Servicemanagements und den Zielen der Organisation können Kennzahlen definiert werden, um den Betrieb steuern und die Unternehmensziele erreichen zu können. Das Ziel ist es letztendlich ein erstes System aus aussagekräftigen Kennzahlen zu entwickeln und zu implementieren, um die Qualität der Services und die Performance der erbrachten Dienstleistung bei einem skalierbaren Wachstum sicherzustellen.
29.09.20	2020	extern	Bachelor	DE	Konzeption und prototypische Realisierung einer Softwarekomponente zur Direktkommunikation von Pick-by-Light-Komponenten mit einem SAP-System	Für Ein- und Auslagerungen von Waren benötigen Unternehmen effiziente Lösungen, um im Wettbewerb bestehen zu können. Einer dieser Lösungsansätze ist die Dematic Pick-By-Light Komponente zur beleglosen Kommissionierung. Auf alte Systemhierarchien begründet ist die Komponente nicht direkt mit SAP EWM verbunden, sondern über das Zwischensystem Dematic SubDriver, welches in diesem Fall als vermittelnder Server fungiert. Aktuelle Änderungen an der Pick-By-Light Komponente ermöglichen deren Konfiguration als Server, weswegen die Funktion des SubDrivers nicht mehr benötigt wird. Gegenstand der hier vorgestellten Arbeit ist die Konzeption und prototypische Implementierung einer Pick-By-Light Komponente zur direkten Kommunikation mit dem SAP-EWM System.
29.09.20	2020	intern	Master	DE	Analyse der Auswirkungen der Corona-Pandemie auf E-Government	Die vorliegende Masterarbeit steht im Kontext zur Corona-Pandemie und betrachtet hierbei das E-Government. Die Arbeit beschäftigt sich konkret mit der Forschungsfrage nach den Auswirkungen der Corona-Pandemie auf das E-Government, welche aufgrund des Umfangs in fünf Teilbereiche untergliedert ist. Für die Beantwortung der Forschungsfrage werden drei Methoden zurate gezogen. Diese sind neben der Literaturrecherche ein Experteninterview sowie eine Umfrage, die im Rahmen der Arbeit durchgeführt wurden. Zentrale Ergebnisse der Arbeit sind neue Online-Services, eine gesteigerte Nutzung digitaler Angebote wie auch eine Weiterentwicklung des Interaktionsgrades derartiger Services. Die Bedeutung digitaler Angebote im öffentlichen Sektor ist durch Kontaktbeschränkungen, die pandemische Lage und geschlossene Dienststellen deutlich gewachsen. In vielen Bereichen des E-Governments hat die Corona-Pandemie so zu einer Express-Digitalisierung geführt, die es ohne die Pandemie in dieser Form nicht gegeben hätte. Dennoch führen föderale Strukturen sowie regulatorische Rahmenbedingungen dazu, dass der Stand des E-Governments auch weiterhin durchaus unterschiedlich sein kann. Die meisten der erhobenen Auswirkungen haben über die Corona-Pandemie hinaus Einfluss auf das E-Government. Damit kann die Corona-Pandemie als neuer Schub für eine beschleunigte Digitalisierung im öffentlichen Sektor dienen und das E-Government in Deutschland weiter vorantreiben.
01.10.20	2021	extern	Bachelor	DE	Integration und Evaluierung eines Werkzeugs zur automatischen Klassifikation von Textinhalten in das Redaktionssystem SCHEMA ST4	Das Ziel dieser Arbeit war es, Plusmeta, ein Tool zur automatischen Klassifikation von Textinhalten in das Redaktionssystem ST4 zu integrieren. Es wird zuerst ein Konzept erstellt, um Plusmeta in ST4 zu integrieren. Dieses Konzept wird anschließend umgesetzt. Nachfolgend werden in Plusmeta mithilfe von Daten aus ST4 verschiedene KIModelle trainiert. Hierbei werden Klassen unterschiedlicher Kategorien verwendet, um nachfolgend zu evaluieren, inwiefern die Qualität der Klassifikationsergebnisse sich unterscheidet. Hierfür werden mithilfe von Stichproben die Klassifikationsergebnisse geprüft und grafisch dargestellt. Abschließend werden Probleme identifiziert, die die Arbeit mit Plusmeta entweder zeitaufwändiger machen oder schlechtere Ergebnisse hervorrufen. Für diese Probleme werden Lösungsvorschläge unterbreitet.
01.10.20	2021	extern	Bachelor	DE	Simulation einer HDR-Rohdaten-Kamera für Closed-Loop-HiL-Anwendungen im automotive Bereich 	Diese Bachelorarbeit thematisiert die Analyse und Realisierung einer Bild-Encodier-Funktionalität für Closed-Loop-HiL-Systeme in ROS 2 (Robot Operating System). Ziel des Softwareentwicklungsprojekts ist es, synthetische High Dynamic Range (HDR) Farbbilder in sensorspezifische Rohdatenformate zu konvertieren und diese Daten an ein automotive Steuergerät zu übertragen. Die Erzeugung der Rohbilddaten aus Farbbildern wird hierbei von Grund auf neu implementiert, da gängige Bildverarbeitungsframeworks ihren Fokus auf der Bilddekodierung von Rohbilddaten in Farbbildern gerichtet haben. Besonders thematisiert wird die Analyse und Implementierung des Bayering der HDR-Farbbilder in RGGB-Bilddaten, die Farbkorrektur und die Erzeugung sensorspezifischer HDR-Formate. Zur Anpassung der Rohdatenformate erfolgt die Realisierung dieser Bildvorverarbeitungsschritte generisch und erweiterbar.
01.10.20	2021	intern	Bachelor	DE	Integration von Wissensmanagement in Content Delivery Systeme am Beispiel des SCHEMA CDS	Ein Wissensportal stellt in einem Unternehmen eine Form des Wissensmanagements dar, da Informationen gesammelt und verteilt werden können. In der Content-Delivery liegt der Fokus auf dem Sammeln und Verteilen von Informationen, speziell im Kontext der technischen Dokumentation. Diese Arbeit untersucht, wie ein Wissensportal in ein Content-Delivery-System am Beispiel des SCHEMA CDS integriert werden kann. Dabei werden die grundsätzlichen Ansätze der Content-Delivery und eines Wissensportals aufgezeigt und miteinander verglichen. Daraus werden die Anforderungen für die Integration definiert und eine prototypische Anwendung konzipiert. Die Implementierung dieser Anwendung wird schrittweise beschrieben, wobei auf die Wahl der Technologien und Erwägungen bei der Architektur und Umsetzung des Programms eingegangen wird. Abschließend wird die Implementierung mithilfe eines Experteninterviews mit bestehenden Formen des Wissensmanagements in der Quanons Content Solutions GmbH verglichen.
01.10.20	2021	extern	Bachelor	DE	Skalierung serverseitiger Module eines CMS mit Aktoren und Microservices	ST4 ist ein Enterprise Content-Management-System, das auf Technische Dokumentation ausgerichtet ist. Die Anzahl der Nutzer, die auf einer ST4 Installation arbeiten, steigt. Dadurch wird der Server zunehmend stark belastet. Um bei Kunden mit vielen Redakteuren angemessene Performance zu erreichen, gibt es momentan nur die Möglichkeit der vertikalen Skalierung. Um den steigenden Anforderungen gerecht zu werden, benötigt ST4 die Möglichkeit horizontal zu skalieren. Bisher wurde für serverseitige Operationen eine Architektur basierend auf dem Aktormodell verwendet. Durch Implementationsdetails ist es nicht möglich mit dem verwendeten Aktorsystem horizontal zu skalieren. Um eine horizontale Skalierung trotzdem zu ermöglichen, wird heutzutage häufig eine Microservice Architektur verwendet. Ob diese Architektur sinnvoll oder überhaupt umsetzbar in ST4 ist, soll anhand eines Moduls analysiert werden. Für diese Analyse wurde das Übersetzungsmodul gewählt. Es muss zuerst ermittelt werden, welche Teile des Moduls als Microservice umgesetzt werden können. Anschließend muss die Schnittstelle zwischen dem Microservice und der vorhandenen Architektur untersucht werden. Mit den hieraus gesammelten Erkenntnissen soll dann ein Proof-of-Concept erstellt werden, um möglicherweise versteckte Schwierigkeiten bei der Entwicklung zu erkennen. Anhand dieser beispielhaften Implementierung können dann die tatsächlichen Vor- und Nachteile gegenüber der Aktor-basierten Alternative festgestellt werden.
01.10.20	2021	extern	Bachelor	DE	Konzeption und Entwicklung eines Tools zur Validierung der Schnittstellenkommunikation zwischen ERP-Systemen und dem internen Warehouse Management System im Entwicklungsprozess bei der Dematic GmbH 	Die Dematic GmbH ist einer der führenden Anbieter für automatisierte Intralogistik. Die Tests für die Schnittstelle zwischen dem internen Warehouse Management System DiQ und den externen ERP-Kundensystemen werden aktuell manuell für jedes Projekt angelegt und durchgeführt. Teile der Schnittstelle können ohne einen Kommunikationspartner gar nicht getestet werden. In dieser Bachelorarbeit wird ein Problemlösungskonzept für ein Testsystem entwickelt. Anhand dessen wird ein Prototyp des Tools implementiert, der bereits erste Testfunktionalitäten abdeckt. Zudem wird die Frage geklärt, ob für alle kommenden Projekte in der Dematic ein universales Test-Tool genutzt werden kann, das den Entwicklern ein effizientes Testen der Schnittstelle ermöglicht.
01.10.20	2021	intern	Bachelor	DE	Genauigkeit von Verschriftungen - Vergleich zwischen automatischer, Laien und professioneller Verschriftung	Transkription ist die Übertragung von einem gesprochenen Text in Schrift. Dabei geht es jedoch nicht um die sinngemäße Verschriftung, sondern darum, dass jedes Wort exakt niedergeschrieben wird. Fehler, die bei der Transkription passieren, werden in Word Error Rate (WER) gemessen. Dies ist ein prozentualer Wert, welcher angibt, wie viele Wörter in dem transkribierten Text falsch sind. Fehler entstehen zum Beispiel durch ungenaues Zuhören eines Laien oder durch eine Maschine, welche das zu übertragene Wort nicht kennt. Es werden zwei Korpora von Sprachaufnahmen untersucht. Für diese wurden jeweils menschliche (professionelle und Laien) und automatische Verschriftungen angefertigt. In der Bachelorarbeit soll untersucht werden, wie weit diese voneinander abweichen und ob bestimmte Wörter oder Redewendungen besonders gut oder schlecht erkannt werden.
01.10.20	2021	extern	Bachelor	DE	Analyse, Konzeption und Implementierung eines barrierefreien Teilbereichs der "Banking to go" App für Android mit Fokus auf der Darstellung von Aktien-Charts bei der ING	In der Arbeit wird untersucht, wie der Investieren-Bereich der Banking-to-go App der ING für Android barrierefrei gestaltet werden kann. Dazu wird erläutert, wie Barrierefreiheit durch das Betriebssystem Android ermöglicht wird und an welchen Stellen Entwickler und Entwicklerinnen eigene Erweiterungen schreiben können. Anhand einer Übertragung der Web Content Accessibility Guidelines auf mobile Anwendungen wird analysiert, welche Lücken es in der aktuellen Implementierung des Investieren-Bereichs gibt. Ein besonderer Fokus liegt hierbei auf den Aktien-Charts: Es werden Anforderungen der Nutzer und Nutzerinnen an den Chart festgelegt und recherchiert, welche bestehenden Lösungen existieren. Anschließend werden drei Konzepte (Textdarstellung, Sonification und Erkundungsseite) erstellt, mit denen die vielen Informationen des Charts barrierefrei zur Verfügung gestellt werden können. Die Konzepte und eine Auswahl der bei Analyse gefundenen Lücken wird in die Banking-to-go App implementiert. Die meisten Mängel sind dadurch entstanden, dass die Android Accessibility APIs mit zu wenigen Informationen befüllt wurden. Anschließend wird ein Test zur Bewertung der Chartkonzepte mit einem blinden Nutzer durchgeführt. Es zeigt sich, dass die entwickelten Konzepte nützlich sind, es aber noch Bedarf für Verbesserungen gibt.
01.10.20	2021	intern	Bachelor	DE	Spielen von "Sonic the Hedgehog" mit Reinforcement Learning	Ziel dieser Arbeit ist ein Vergleich drei verschiedener Reinforcement Learning Algorithmen anhand des Computerspiels Sonic the Hedgehog. Zunächst wurden hierfür die theoretischen Grundlagen des Reinforcement Learning, sowie der drei konkreten Algorithmen erläutert. Damit die Algorithmen im Kontext des Spiels analysiert werden können, wurde sowohl der Ablauf des Spiels als auch dessen spezifische Schwierigkeiten erörtert. Weiterhin wurde betrachtet, wie Reinforcement Learning bei Sonic the Hedgehog umgesetzt wurde. Damit die Leistung der drei Algorithmen verglichen werden konnte, wurde eine einheitliche Strategie zur Durchführung des Trainings festgelegt. Dabei wurde ebenfalls untersucht, ob und inwieweit das Training beschleunigt werden kann. Es stellte sich hierbei heraus, dass Training auf einer GPU im Vergleich zu einer CPU schneller war. Zum Trainieren wurden zwei ähnliche Level aus Sonic the Hedgehog verwendet, wobei das zweite Level zur Validierung der Ergebnisse des ersten Levels diente. Bei der Analyse der Trainingsdaten wurde ersichtlich, dass nur einer der drei Algorithmen beide Level innerhalb weniger Minuten Trainingszeit lösen konnte, während die anderen beiden Algorithmen das Ziel generell nicht erreichten. Einer der beiden Algorithmen zeigte während des Trainings jedoch eine stetige Verbesserung der Belohnungen. Im Gegensatz dazu pendelte sich der andere Algorithmus auf einen bestimmten Belohnungswert ein, welchen er nicht weiter verbessern konnte.
01.10.20	2021	extern	Bachelor	DE	Digitalisierung der Jahresabschlussprüfung am Beispiel von Journal Entry Testing mithilfe des Tools Analytics4Audit	Der Bereich der Jahresabschlussprüfung durchläuft auch bei der Wirtschaftsprüfungsgesellschaft Rödl & Partner den Prozess der Digitalisierung. Möglichst viele Prozesse und Prüfungshandlungen sollen dabei optimiert werden. Auch die Analyse des Buchungsjournals, das Journal Entry Testing, welches ein wesentlicher Bestandteil der Jahresabschlussprüfung ist, folgte einem ineffizienten Prozess. Dieser wurde mit der Entwicklung des Tools Analytics4Audit an die Herausforderungen und Potentiale durch die Digitalisierung angepasst. Die Arbeit beschäftigt sich mit der Frage, ob und inwiefern die Anpassung des Prozesses mit Unterstützung des Tools Analytics4Audit einem bisherigen Vorgehen überlegen ist. Um die Unterschiede der Vorgehen herauszuarbeiten, wurden beide Möglichkeiten genauer beschrieben und anhand wesentlicher Vergleichsaspekte untersucht. Aus der Arbeit ergab sich, dass eine Verbesserung der internen Prozesse durch Analytics4Audit möglich ist.
02.10.20	2021	extern	Bachelor	DE	Untersuchung einer Korrelation von Steuerfachbegriffen und betriebswirtschaftlichen Dokumenten durch maschinellem Lernen	Das Ziel dieser Arbeit ist es zu bestimmen, welche natürlichsprachigen Algorithmen man für ein textgetriebenes Empfehlungssystem nutzen kann. Das System soll hierbei anhand der Suchanfrage und den ersten zurückgelieferten Texten Empfehlungen für neue, auch interessante Dokumente machen. Dazu wird zuerst die Forschungsfrage gestellt, welche textbasierten Algorithmen für ein Empfehlungssystem infrage kommen und als zweites, wie man die empfohlenen Dokumente aufgrund einer Ähnlichkeitsanalyse in eine Rangordnung bringen kann. Um die Forschungsfrage zu beantworten, wurden verschiedene Verfahren aus dem Information Retrieval und dem maschinellen Lernen hergenommen, um Schlüsselwörter aus den zuerst zurückgelieferten Texten zu extrahieren. Mit word2vec, T F -IDF und BERT sollen die Schlüsselwörter gefunden werden. Mit diesen Schlüsselwörtern werden wieder neue Texte gefunden. Durch eine Ähnlichkeitsanalyse sollen anschließend die neuen Texte in eine Ordnung zu dem erstgefundenen Dokument gebracht werden. Hierfür wird doc2vec verwendet. Eine qualitative Studie zeigte, dass word2vec und T F -IDF die besseren Dokumente durch die Schlüsselwortextraktion findet. Mit BERT ist das Empfehlungssystem weniger erfolgreich. Zusätzlich hat sich gezeigt, dass durch den Einsatz von doc2vec die weiteren Dokumente in eine brauchbare Rangordnung gebracht werden können.
05.10.20	2021	extern	Bachelor	DE	Erweiterung von DATEV SmartLogin zum WebAuthN Medium	Das Ziel dieser Arbeit ist es die DATEV SmartLogin App zum WebAuthN Medium zu erweitern, da die DATEV zukünftig mehr die Standards der Industrie setzt. Die Frage, ob eine Implementierung des FIDO2 Standards für die Authentifizierung von Daten der Vertraulichkeitsklasse 3 dienen kann, wird mittels einer Gegenüberstellung mit den bestehenden DATEV Anmeldeverfahren untersucht. Um die Frage zu beantworten, wurde die FIDO2 Schnittstelle untersucht und nativ in der App implementiert. Die Implementierung und weitere Anpassungen wurden dem SmartLogin-Team vorgestellt und mit ihnen diskutiert. Das Ergebnis der Implementierung und der Diskussion zeigte, dass der FIDO2 Standard geringfügig angepasst werden muss um eine Tauglichkeit zu gewährleisten. Diese Anpassungen wurden bereits teilweise durchgeführt, können jedoch erst mit einem neuen Identitätsmanagement System der DATEV komplett umgesetzt werden. Die Arbeit zeigt, dass die DATEV SmartLogin App zukünftig auch als WebAuthN Medium genutzt werden kann. Auf dieser Grundlage kann das neue Identitätsmanagement System bereits für die Nutzung angepasst werden, um eine schnelle Einführung zu garantieren.
07.10.20	2021	extern	Bachelor	DE	Automatisierte Erzeugung von Headerdateien für Embedded Automotive Systeme mit AUTOSAR	Konzeptentwurf und Implementierung eines Codegenerators für die Erzeugung von Komponenten- Headern in der Programmiersprache C für eine an AUTOSAR angelehnte Architektur und Interfacedefinition. Die generierten Header sollen die abgekapselte Deklaration von AUTOSAR Client/Server sowie Sender/Receiver Interfaces ermöglichen, die das bisherige Verfahren nicht unterstützt. Weiterhin sollen UML-Diagramme basierend auf dem Architekturmodell generiert werden, die im nachgelagerten ASPICE-Prozess zum Software Detailed Design genutzt werden. Die Lösung soll anhand eines aktiven Produktentwicklungsprojektes evaluiert werden. Dabei ist insbesondere die Konformität zu MISRA-C (2012) sicherzustellen. Aktuell wird von Microsoft Excel VBA-Macros (schlecht erweiterbar) ein zentrales Header-File mit RTE Interface Funktionen generiert. Diese Vorgehensweise ist jedoch nicht kompatibel mit Full-AUTOSAR Projekten, da diese komponentenweise erzeugte RTE-Header erfordern. Es wird aktuell eine Anwendung (Windows Forms, C#) implementiert, die die Verwaltung der RTE-Header erleichtern soll. Als neues Modul soll ihm Rahmen dieser Bachelorarbeit die automatisierte Generierung von komponentenweisen RTE-Headern hinzugefügt werden. Weiterhin wird während des Entwicklungsprozesses Git (hier: Bitbucket) mit CI/CD eingesetzt.
08.10.20	2021	extern	Bachelor	DE	Automatische Klassifikation von virus-, bakterien- und Covid-19 induzierten Lungenentzündungen auf Basis von Röntgenbildern	An Lüngenentzündungen sterben laut WHO jährlich etwa 2.5 Millionen Menschen. Wie gefährlich Lungenentzündungen sind, zeigte sich auch seit Anfang 2020, als die Covid-19 Pandemie ihren Lauf nahm und bis heute mehr als zwei Millionen Tote verursachte. Die Behandlung von Lungenentzündungen ist erfolgsversprechender, je früher sie diagnostiziert wird, hierbei kann ein automatisches Verfahren, das Röntgenbilder der Lunge mit Hilfe von Machine Learning klassifiziert, helfen, diese Diagnose schneller und einfacher bereitzustellen. Im ersten Teil der Arbeit wird auf Basis von Röntgenbildern ein Klassifikator trainiert und evaluiert, der zwischen nicht infizierten, bakteriell- und viral- induzierten Lungenentzündungen unterscheiden kann. Im zweiten Teil der Arbeit wird der Klassifikator auf einem zweiten Datensatz getestet. Dieser enthält nicht infizierte, infizierte und durch Covid-19-induzierte Lungenentzündungen. Hierbei wird überprüft, inwieweit der Ansatzeines Machine Learning basierten Klassifikators auf ähnliche, aber nicht genau gleiche, Pro-bleme möglich ist. Im letzten Teil der Arbeit wird geklärt, inwieweit der Transfer-Learning Ansatz für ein Problem dieser Art verwendet werden kann. Dazu wird auf Basis des im ersten Teil der Arbeit trainierten Klassifikators ein für den zweiten Datensatz verwendbarer Klassifikator trainiert. Weitere mittels Transfer-Learning trainierte Klassifikatoren werden außerdem auf Basis der als ImageNet bekannten CNN trainiert.
09.10.20	2021	extern	Bachelor	DE	Verfahren zur ganzheitlichen Offline-Fähigkeit von Single Page Applications	Das Ziel dieser Arbeit ist es, durch Integration eines Service-Workers Verfahren zur Umsetzung der Offlinefähigkeit für eine Webanwendung zu untersuchen und in einem exemplarischen Projekt zu verproben. Dabei werden grundlegende Vorgehensweisen anhand der Patterns Offline-First und Optimistic-UI aufgezeigt. Die daraus resultierende Notwendigkeit der lokalen Datenhaltung wird zunächst im Thema Caching aufgegriffen. Anschließend erfolgte eine Evaluierung weiterer Datenspeicher zum Persistieren und Modifizieren dynamischer Anwendungsdaten, um die offline Bedienbarkeit zu gewährleisten. Den Abschluss des Theorieteils bildet die Synchronisation vorgenommener Änderungen mit dem Server gemäß der Methode Request-Queuing. Die Ergebnisse der theoretischen und praktischen Untersuchung zeigen, dass mit der Umsetzung von Offlinefähigkeit in einer Webanwendung, durch Integration eines Service-Workers in Kombination mit den vorgestellten Speichertechnologien, die Verwendbarkeit und Benutzerfreundlichkeit progressiv verbessert werden kann. Das Ziel der Implementierung einer ganzheitlich offlinefähigen Webanwendung wurde für das Projekt erreicht, allerdings zeigten sich mögliche Probleme bei komplexeren Webanwendungen, beispielsweise im Hinblick auf die Sicherheit. Dennoch empfiehlt sich die frühzeitige Orientierung an Offline-First im Entwicklungsprozess, da selbst eine teilweise Umsetzung der Prinzipien zahlreiche Vorteile, lediglich in geringerem Maße, mit sich bringt.
11.10.20	2021	extern	Bachelor	DE	Visualisierung der Corona-Verbreitung in Europa mit Data-Science- und 3D-Verfahren	Die weltweit permanent wachsende Menge an Daten stellt Analysten und Interessierte im Hinblick auf Datenverständnis und Datentransparenz vor immer größere Herausforderungen. Aus diesem Grund müssen zwangsläufig neue Verfahren entwickelt werden, durch die den großen Datenmengen mit möglichst wenig Aufwand enthaltene Informationen entzogen werden können. Ein Beispiel, welches eine solche Datenmenge liefert, ist die Corona-Pandemie, die Deutschland, Europa und die ganze Welt seit über einem Jahr beschäftigt. Auch wenn es viele Quellen gibt, die Daten und Visualisierungen der Pandemie zur Verfügung stellen, so sind diese nicht immer einfach verständlich. Zumeist können außerdem nicht alle Informationen aufgrund der gewählten Darstellungsform entnommen werden. Um alle Informationen einsehen zu können, muss auf die Datenquelle zurückgegriffen werden. Diese besteht meist aus unübersichtlichen und umfangreichen Datentabellen. Die enthaltenen Informationen, wie Trends und Zusammenhänge, können aus diesen Tabellen ebenfalls nur schwer auf einen Blick entzogen werden. Die vorliegende Bachelorarbeit zeigt, wie am Beispiel der Corona-Pandemieverbreitung in Europa ein dreidimensionales und hochauflösendes Visualisierungsverfahren entwickelt wird. Mithilfe von Python und Blender soll dem Anwender die Möglichkeit gegeben werden, Daten zu importieren, sie zu verarbeiten und anschließend eine Grafik zu generieren, die eine übersichtliche und einfach verständliche Visualisierungsform liefert.
11.10.20	2021	intern	Bachelor	DE	Interpolation von Panoramen	Grundlage Bewegungen zwischen Rundumsichten, z.B. der "Wuusch" in Google-Streetview, sind oft nur ungenau interpoliert. Bibliotheken wie OpenCV enthalten Funktionen, um charakteristische Punkte zu erzeugen und zuzuordnen. Mittels dieser Merkmale soll anschließend ein optischer Fluss zwischen zwei Bildern erzeugt werden, welcher die Interpolation von Zwischenbildern ermöglicht. Es erscheint naheliegend, diesen Ansatz auf 2 oder 3 Dimensionen zu erweitern, so dass man zwischen 3 Punkten in der Fläche oder 4 Punkten im Raum interpolieren kann. Aufgabe Der Ansatz wird in C++ mit der OpenCV-Bibliothek implementiert. Dann sollen mit einer vorhandenen 360°-Kamera Panoramen an 2 oder 3 Punkten in einem Raum, z.B. einem Hörsaal, aufgenommen werden. Mithilfe der Implementierung sollen zwischen diesen Punkten interpolierte Bilder errechnet werden. Als zukünftige Erweiterung soll der errechnete optische Fluss in Kombination mit der Computergrafik einen virtuellen Rundgang ermöglichen. Man soll sich virtuell zwischen den Punkten bewegen und umschauen können.
12.10.20	2021	extern	Bachelor	DE	Automatisiertes Deployment von Webanwendungen in eine OpenShift Cloud-Computing-Plattform bei der NÜRNBERGER Versicherung 	In der Softwareentwicklung spielt die Qualitätssicherung eine wichtige Rolle. Um die Qualität eigenentwickelter Software, die der Auftragsabwicklung von Versicherungspolicen dient, zu erhöhen, hat sich die NÜRNBERGER Versicherung dazu entschieden, nur noch automatisierte Deployments zu erlauben. Dies gelingt mithilfe einer für die Software Jenkins entwickelten Continuous Delivery Pipeline. Das Ziel der vorliegenden Bachelorarbeit ist es, die vorhandene Pipeline so zu erweitern, dass ein automatisiertes Deployment in ein Kubernetes Cluster ermöglicht wird. Um dieses Ziel zu erreichen, muss ein Konzept erstellt werden, das sicher stellt, das innerhalb des Clusters ein Container-Image erzeugt und auf Sicherheitslücken geprüft werden kann. Abschließend soll das resultierende Container-Image automatisiert in ein Kubernetes Cluster deployed werden können. Der Vergleich verschiedener Werkzeuge für die Image-Erstellung hat gezeigt, dass für die NÜRNBERGER Versicherung die Software Kaniko am besten geeignet ist. Neben dem Werkzeug für die Image-Erstellung wurden auch drei Werkzeuge für das Scannen von Container-Images untersucht. Dabei hat sich heraus gestellt, dass Anchore für den Automatisierungs-Prozess verwendet werden soll. Das automatisierte Deployment erfolgt über ein vom Entwickler erstelltes Helm-Chart. Helm dient dabei als Paket-Manager und Deployment-Werkzeug für Kubernetes.
12.10.20	2021	extern	Bachelor	DE	Konzeption und Einsatz von Wake on LAN im Systemmanagement eines mittelständigen Unternehmens	Die Bachelorarbeit soll sich mit der Technologie Wake on LAN beschäftigen. Sie soll eine Betrachtung der Technologie im Allgemeinen beinhalten, auch mit entsprechenden Vor- und Nachteilen in Bezug auf die Nutzung innerhalb eines Unternehmens. Anschließend soll eine Umsetzungsanalyse der Technologie in Kombination mit den bereits eingesetzten Technologien, wie beispielsweise 802.1.x stattfinden. Dies soll in einem "inkrementellen" Nachbau der Unternehmensinfrastruktur geschehen, um auch Aussagen über eventuell vorhandene Grenzen treffen zu können. Diese können sich z.B. aus der komplexen Netzwerkinfrastruktur ergeben, weshalb diese Herangehensweise gewählt wird. Sofern die entsprechenden Ergebnisse für eine Einführung der Technologie sprechen, soll darauf aufbauend in einem bestimmten Unternehmensbereich eine Beispielumsetzung durchgeführt werden. Auch sollen eventuell weitere Umsetzungsalternativen beleuchtet werden und diese gegeneinander abgewägt werden. Die Integration in bereits vorhandene Prozesse, in erster Linie mit dem Fokus auf das Patchmanagement, des Unternehmens soll außerdem betrachtet werden. Für die einzelnen Alternativen sollen Tests durchgeführt werden, um Aussagen über die Performanz und ihre Zuverlässigkeit treffen zu können.
12.10.20	2021	extern	Bachelor	DE	Entwicklung und Ergebnis eines Kriterienkatalogs für den Einsatz von Low Code in Projekten.	Das Ziel in der vorliegenden Bachelorarbeit ist die theoretischen Konzepte des Low Code Ansatzes zu erforschen. Diese Grundlagen dienen dafür, einen Kriterien-Katalog zur Überprüfung der Praxistauglichkeit von Low Code aufzustellen. Der Katalog deckt hauptsächlich die Kriterien der aspektorientierten Prozessmodellierung ab. Für die Evaluation wurde eine prozessbasierte Webanwendung mit Low Code Tools entwickelt. Zur Auswertung wurden zwei Low Code Plattformen, Bonitasoft und die Canvas Apps von Microsoft, miteinander verglichen. Es stellt sich heraus, dass beide Plattformen geeignet zum Entwickeln für prozessbasierten Anwendungen sind. Bonitasoft eignet sich eher für technische Entwickler während Canvas Apps mehr den Citizen Developern zusagt.
13.10.20	2021	extern	Bachelor	DE	Konzeption und Umsetzung einer Datenintegration zwischen einem touristischen Reservierungssystem und der CRM-Lösung Salesforce für den Austausch von Kunden- und Reiseauftragsdaten.	In der Bachelorarbeit wird die Datenübertragung von Salesforce genauer betrachtet. Die Schnittstellen für die Datenübertragung werden analysiert und bewertet. Es wird ein Prototyp für den Datenaustausch zwischen Salesforce und Pacific implementiert.
14.10.20	2021	extern	Bachelor	DE	Entwicklung einer Softwarelösung mit grafischer Bedienoberfläche zur Parametrierung von Steuergeräten anhand deren Binärcode	Kurzdarstellung Bei der Softwareentwicklung von Steuergeräten im Automobilbereich ist es notwendig im Rahmen von Softwaretests Anpassungen an den Initialwerten von Parametern vorzunehmen. Die Werte dieser Parameter befinden sich zur Laufzeit im RAM und können während der Softwaretests manipuliert, aber nicht abgespeichert werden. Eigentlich könnten die resultierenden Werte der Softwaretests den jeweiligen Variablen im Quellcode neu zugewiesen werden. Allerdings ergeben sich dabei zwei Schwierigkeiten. Es soll dem Kunden ermöglicht werden selbstständig Parametrierungen der Steuergeräte vorzunehmen. Der Quellcode unterliegt jedoch der Geheimhaltung und kann deshalb nicht ausgeliefert werden. Außerdem würde ein erneutes Kompilieren einen erneuten Softwarequalifizierungsprozess erfordern, welcher einen großen Aufwand mit sich bringt. Um Anpassungen an den Parametern effektiv zu gestalten soll im Rahmen dieser Bachelorarbeit eine Lösung erarbeitet werden, um mithilfe einer grafischen Bedienoberfläche eine Möglichkeit zu erschaffen, die geänderten Parameterwerte direkt in die Hex-Dateien der Software zu übernehmen. Dabei muss eine Lösung gefunden werden, die Speicheradressen der Parameter herauszufinden. Sind die Stellen der Parameterwerte in der Hex-Datei lokalisiert, soll es anschließend möglich sein, diese zu verändern. Sowohl jede Zeile als auch die gesamte Hex- Datei sind mit einer Prüfsumme versehen, welche schließlich noch angepasst werden müssen.
14.10.20	2021	extern	Bachelor	DE	Untersuchung und Konzeption der Softwaresysteme Ansible und Terraform für die Provisionierung virtueller Maschinen	DATEV betreibt ein Projekt zum Aufbau eines Cloud-Rechenzentrums. Um die Self-Service-Charakteristik einer Cloud zu erfüllen, wird ein Softwaresystem für die automa-tische Provisionierung virtueller Maschinen benötigt. Es ist jedoch nicht klar, welches Softwaresystem am besten zu diesem Anwendungsfall passt, weswegen im Rahmen dieser Arbeit eine Evaluierung der Softwaresysteme Ansible und Terraform durchge-führt wird. Außerdem wird auf Basis der Ergebnisse der Evaluierung ein Konzept für die Provisionierung virtueller Maschinen erarbeitet. Für die Evaluierung der beiden Softwaresysteme werden anfangs durch eine struktu-rierte Literaturrecherche in der Wissenschaft bekannte Kriterien zur Auswahl eines Softwaresystems identifiziert. Anschließend werden die gefundenen Kriterien durch eine Onlinebefragung der Projektteilnehmer für die Provisionierung virtueller Maschinen validiert sowie priorisiert. Die Ergebnisse der Befragung dienen als Grundlage für die Evaluierung der Softwaresysteme. Die Evaluierung zeigt, dass Terraform für den Einsatzzweck bei DATEV besser geeig-net ist. Eine vollautomatische Provisionierung ist jedoch nicht allein durch Terraform realisierbar. Ansible bietet Funktionalitäten, um die nicht automatisierbaren Vorgänge von Terraform zu ergänzen. Daher ist ein Konzept erarbeitet worden, das eine Kombi-nation beider Technologien verwendet.
15.10.20	2021	intern	Bachelor	DE	Untersuchung maschineller Lernverfahren zur Übersetzung natürlicher Sprache in SQL	Viele Unternehmen nutzen Datenbanken um jegliche Art von Informationen zu speichern. Das Problem dabei ist jedoch, dass die Abfrage dieser Daten komplex sein kann. Es ist schlichtweg nicht immer möglich mit den zur Verfügung gestellten Suchfunktionen alle Bedingungen zu übergeben. Mithilfe von künstlicher Intelligenz können Computer die Anliegen von Nutzern besser verstehen, da sie in der Lage sind natürliche Sprache zu interpretieren. Ein Beispiel hierfür ist der Google Assistent. Dieser kann viele allgemeine Wissensfragen beantworten. Um diese Fähigkeiten auch auf unternehmensspezifische Daten zu übertragen gibt es neuronale Netze, welche natürliche Sprache in Datenbankbefehle übersetzen. Der Zweck dieser Übersetzungen ist es, dass ein Endanwender nun ohne spezielles Fachwissen einer Datenbanksprache komplexe Datenbankabfragen vollziehen kann. Damit werden Zeit und Kosten für einen Programmierer gespart und Unternehmen können somit effizienter arbeiten. In dieser Arbeit wird untersucht, welche Methoden es gibt, um natürliche Sprache in Datenbankbefehle umzuwandeln, sowie eine prototypische Implementierung einer Weboberfläche basierend auf einem Open-Source neuronalen Netzwerk zu erstellen. Zuletzt wird das neuronale Netzwerk auf Klausuren des Faches Datenbanken angewandt und die Ergebnisse dessen erläutert.
15.10.20	2021	extern	Bachelor	DE	Wissenstransfer in Softwareentwicklungsteams - eine praxisbezogene Analyse bei DATEV eG	Diese Arbeit umfasst die Ausarbeitung einer effektiven Vorgehensweise für den Wissenstransfer in Softwareentwicklungsteams um Lösungen zu finden, welche den Prozess des Wissenstransfers im Team nachhaltig verbessern können. Im ersten Teil der Arbeit werden die theoretischen Grundlagen des Wissenstransfers beleuchtet, wobei eine Brücke zwischen dem theoretischen Wissenstransfer und der Anwendung in einem IT-basiertem Unternehmen geschlagen wird. Danach folgt eine Ist-Analyse, in der vorwiegend durch Mitarbeiterinterviews herausgefunden wird, wie der Wissenstransfer in Softwareentwicklungsteams aktuell im Unternehmen durchgeführt wird. Aus dieser Ist-Analyse werden Schwachstellen abgeleitet, die kategorisiert und priorisiert werden. Für die optimierbarsten Schwachstellen werden darauffolgend Anforderungen an deren Lösungen definiert. Die vielversprechendsten und umsetzbarsten erarbeiteten Lösungen werden am Ende umgesetzt und evaluiert.
15.10.20	2021	intern	Bachelor	DE	DeepFake-Videos: Stand der Technik und praktische Evaluation	DeepFake-Videos können durch gezieltes Streuen von Falschinformationen zu einer Gefahr für die Demokratie werden. Deshalb ist es notwendig herauszufinden, welche Möglichkeiten der aktuelle Stand der Technik bietet und wie überzeugend die generierten Videos sind. Für die Untersuchungen wurden die Frameworks DeepFaceLab und First Order Model for Image Animation verwendet. Hierbei wurde untersucht, welche Ausgangsdaten für das Training des künstlichen neuronalen Netzwerkes und dem Erstellen der DeepFake-Videos für die beiden ausgewählten Verfahren benötigt werden. Die Ergebnisse aus den Experimenten wurden anschließend auf Qualität und Überzeugungsfähigkeit untersucht. Hierfür wurde zusätzlich eine Umfrage durchgeführt. Es zeigte sich, dass mit dem Framework First Order Model for Image Animation einfache überzeugende DeepFake-Videos generiert werden können. Allerdings war es hiermit nur möglich die Person von den Schultern aufwärts darzustellen. Die erzeugten Videos mit DeepFaceLab waren weniger überzeugend. Dieses DeepFake-Video wurde deshalb von fast allen Befragten als Fälschung erkannt. Wie allerdings aus den Experimenten hervorgeht, bietet DeepFaceLab im Vergleich zum anderen Framework mehr Optionen. Aus diesem Grund besteht mit dem DeepFaceLab Framework die Möglichkeit, dass mit geändertem Ausgangsmaterial und anderen Einstellungen ebenfalls ein überzeugendes DeepFake-Video erzeugt werden kann.
16.10.20	2021	extern	Bachelor	DE	Information Extraction aus Suchanfragen bei der DATEV	Die vorliegende Arbeit beschäftigt sich mit einer Möglichkeit, Suchmaschinen in Unternehmen wie der Datev zu verbessern. Dabei wird gezielt versucht, komplexe Suchanfragen beantwortbar zu machen. Vor allem für die Beantwortung von komplexen Suchanfragen werden meistens viele Informationen aus verschiedenen Quellen benötigt. Ein Problem dabei ist, dass die bestehenden Suchmaschinen nicht auf die benötigten Informationen zugreifen können. Darüber hinaus fehlt den Unternehmen die Möglichkeit, das Verhalten von Suchmaschinen aktiv zu beeinflussen. Demnach ergibt sich die Forschungsfrage, wie die Trefferqualität einer Suchmaschine mit Information Extraction (IE) bei der Datev verbessert werden kann. Mithilfe von IE aus den Suchanfragen und zusätzlichen Daten, Informationen und Wissen sollen neue Antwortmöglichkeiten ermöglicht werden. Aufbauend auf den Grundlagen der Suchmaschinen wird die Methodik vorgestellt, welche für die Implementation des Prototyps benötigt wird. Dabei wird hauptsächlich das Forschungsgebiet Natural Language Processing (NLP) betrachtet. NLP hilft einer Maschine die Suchanfragen zu verstehen und zu bearbeiten. Im Anschluss an die Implementation wird eine Evaluation in Form einer Primäranalyse durchgeführt. Dabei wird der Prototyp systematisch analysiert und evaluiert. Ebenso werden auch die Grenzen und die Trefferqualität des Prototyps bewertet. Abschließend werden alle notwendigen weiteren Schritte für eine produktive Version des Prototyps zusammengefasst.
18.10.20	2021	intern	Bachelor	DE	Kamerabasierte Visualisierung von 3D-gedruckten Objekten	Durch die gute Verfügbarkeit von 3D-Druckern im Hobbybereich und auch der Industrie erfreut sich der 3D-Druck immer größer werdender Beliebtheit. Erhebliche Probleme bestehen jedoch noch in der Qualitätskontrolle gedruckter Objekte. Daher ist es notwendig, Methoden zur Fehlererkennung und Nachvollziehbarkeit eines Druckes einzusetzen. Das Ziel dieser Arbeit ist, die Qualitätskontrolle im 3D-Druck zu vereinfachen. Dazu wird eine gesamtheitliche Visualisierungsanwendung konzipiert und als Prototyp umgesetzt. Eingehend werden die Anforderungen an eine breit einsetzbare Anwendung erörtert. Dabei liegt besonderes Augenmerk in der nahtlosen Integration in bestehende Druckprozesse. Die für das Gesamtsystem gewählte Mircoservice-Architektur, ermöglicht eine Vielzahl verschiedener Einsatzszenarien und deckt den kompletten Visualisierungsprozess des Druckes ab. Begonnen wird mit der Aufnahme von Schichtbildern eines 3D-Druckes. Anschließenden erfolgt die Datenanalyse und Reproduktion des gedruckten Objektes. Dem Anwender wird eine App zur Verfügung gestellt, mit der die einzelnen Komponenten der Anwendung steuerbar sind. Weiterführende Forschung im Bereich der Analyse von Schichtbildern, könnte auf das Potential einer vollautomatischen Bewertung von Fehlern in gedruckten Objekten auf Basis der geschaffenen Datengrundlage ausgerichtet sein.
19.10.20	2021	extern	Bachelor	DE	Konzept für die künftige IT-Unterstützung von Mitarbeitern im mobilen Einsatz	Am Anfang des Jahres 2020 ist eine weltweite Coronapandemie ausgebrochen. Die Arbeitgeber wurden von der Bundesregierung darin bestätigt, ihren Mitarbeitern das Arbeiten von zu Hause zu ermöglichen, da in engen Büroräumen die Ansteckungsgefahr stark erhöht ist. Das Ziel dieser Abschlussarbeit ist es, die derzeit verwendete Softwareausstattung eines mittelständischen Unternehmens zu erläutern und neue Alternativen zu erarbeiten. Diese Arbeit kann dazu verwendet werden, Entscheidungen der Führungskräfte über Anpassungen der Ausstattung für den mobilen Einsatz zu erleichtern. Für ein aussagekräftiges Ergebnis wurde eine Mitarbeiterumfrage durchgeführt. Hierbei wurden 300 zufällig ausgewählte Mitarbeiter über die derzeitig verwendete Software befragt. Die Umfrage lies auch Raum für eigene Anregungen und Verbesserungsvorschläge der Teilnehmer. Die Ergebnisse zeigten, dass die Kommunikation über Microsoft Teams stark verbreitet ist. Durch eine Kopplung dieser Software mit der Telefonanlage OpenScape Voice könnten externe Gespräche mit z.B. Kunden oder Lieferanten ebenso über Teams abgewickelt werden. In der Arbeit wurden verschiedene Alternativen der Umsetzung erörtert. Als zusätzliche Software wurde das Produkt Miro vorgestellt. Diese Software ist ein Online-Whiteboard, welches beispielsweise für Projektarbeit genutzt werden kann.
26.10.20	2021	intern	Bachelor	DE	Konzipierung und Implementierung eines Smarthomeplaners 	Die vorliegende Arbeit beschäftigt sich mit der Konzipierung eines Smarthomeplaners, der das Thema Sicherheit und Datenschutz in Smart Home Geräten während der Konfigurationsphase eines Smarthomes verbinden soll. Um das Konzept zu erstellen, wurden einige Smarthomeplaner näher betrachtet und eine kurze Recherche durchgeführt, die zu einigen ausgewählten Smarthome Geräten Sicherheitslücken sowie Datenschutzinformationen zusammenfasst und damit die Problematik zeigt, dass Smarthome Geräte oft Sicherheitslücken besitzen, die teilweise auch lange Zeit nicht behoben werden. Das Konzept wurde anschließend in Form eines Prototyps implementiert, der das Django-Webframeworks in Kombination mit dem Frontend Framework Vue.js sowie der Javascript HTML5 canvas Bibliothek fabric.js nutzt. Anschließend wurde eine Nutzer-Evaluation durchgeführt, um zu überprüfen, wie der Smarthomeplaner von Benutzern bewertet wird. Das Ergebnis der Nutzer-Evaluation hat dabei einen ersten Einblick geben können, dass der Smarthomeplaner insgesamt als Benutzerfreundlich angesehen werden kann und die zusätzlichen sicherheitsrelevanten Funktionen des Smarthomeplaner von den Benutzern positiv aufgenommen wurden.
26.10.20	2021	extern	Bachelor	DE	Service Design und Service Transition gemäß ITIL - Konzeption eines Self-Service-Portals unter dem Aspekt der Performanceoptimierung 	Durch den Wandel der Digitalisierung verändert sich die Nachfrage und die Anforderungen an die IT innerhalb der Unternehmen. Die Betriebsabläufe und Dokumente werden teilweise lückenhaft digitalisiert. Um die Nachfrage und die Anforderungen für den fortlaufenden Betrieb an die IT sicher stellen zu können, müssen die internen IT-Serviceleistungen strukturiert und gebündelt für die internen Anwender zur Verfügung stehen. In der NÜRNBERGER Versicherung sollen die internen IT-Serviceleistungen in einem Self-Service-Portal verwaltet werden, diese sind bereits in einem hierfür entwickelten IT-Servicekatalog für den Anwender abgebildet. Das Self-Service-Portal soll die einheitliche Anfrage bzw. Beantragung ermöglichen. Hierfür musste eine Analyse des IST-Zustandes durchgeführt werden und ein Konzept für die umzusetzenden IT-Serviceleistungen erarbeitet werden. Um den IST-Zustand des bestehenden IT-Servicekatalogs zu ermitteln, wurde der Entwicklungsstand durch einen Schemavergleich mit einem Reifegradmodell ermittelt und die Bestell- bzw. Beantragungsarten der IT-Serviceleistungen betrachtet. Mit Hilfe einer empirischen Untersuchung wird ein Konzept erarbeitet, bei dem das in der IT genutzte System OMNITRACKER betrachtet wird. Anschließend wird eine Machbarkeitsanalyse durchgeführt und die Umsetzungsreihenfolge festgelegt. Hierfür werden in Interviews die IT-Serviceketalogverantwortlichen und die für das System OMNITRACKER zuständigen Mitarbeiter befragt. ...
29.10.20	2021	extern	Bachelor	DE	Konzeption und Implementierung von Metriken zur Auswertung von IT-Infrastrukturdaten	Im Rahmen eines internen Projektes der DATEV eG ergab sich die Anforderung, IT-Infrastrukturdaten aus einer Configuration Management Datenbank zu analysieren. Diese Datenbank wird in regelmäßigen Abständen mit Daten aus zahlreichen aktiven Systemen befüllt. Das geschieht, indem die Infrastruktur mit verschiedenen Discovery Mechanismen ausgelesen wird. Durch die hochdynamische und heterogene Natur der Datenquellen ist es eine große Herausforderung, die Integrität der Daten zu gewährleisten. Mittels der Vernetzung dieser Daten entstehen Metainformationen, die nur schwer mit den vorhandenen Mitteln visualisierbar und nur mit Fachwissen interpretierbar sind. Ziel der Bachelorarbeit ist es, Metriken zu finden, die diese Infrastrukturdaten auswerten und klassifizieren. Zusätzlich ist eine passende Visualisierung dieser Metriken gefordert. Schwerpunkt der Arbeit wird es sein, die Relevanz der Daten zu analysieren, Klassifizierungen einzuführen und vorzunehmen sowie Aussagen über die Vollständigkeit der Daten zu treffen. Die Metriken sollen dabei helfen, einen Überblick der Zusammenhänge unterschiedlicher Daten zu erlangen, welche auf den ersten Blick nicht erkennbar sind. Dazu wird im Rahmen dieser Bachelorarbeit ein Tool zur Auswertung der genannten Daten entwickelt. Durch das Tool sollen Visualisierungen möglich sein, mit denen auf einen Blick eine Übersicht über die Zusammenhänge und Menge der Daten generiert werden kann.
01.11.20	2021	extern	Master	DE	Analyse und Optimierung der Einrichtung produktiver Laufzeitumgebungen im Unternehmensumfeld 	Das Aufsetzen kundenseitiger Produktivumgebungen ist in der Praxis zeitintensiv und führt dazu, dass Entwickler sich nicht auf die Implementierung von Systemfunktionalitäten konzentrieren können. Im Bereich der Intralogistik speziell als Dienstleister für Intralogistik-Software ist die Anzahl von verschiedenen Kunden groß, was ein regelmäßiges Aufsetzen der Produktivumgebung beim jeweiligen Kunden zur Folge hat. Durch die Optimierung dieser Konfiguration können Zeit und Kosten gespart werden. Zusätzlich werden durch entsprechende Verbesserungen menschliche Fehler bei der Konfiguration minimiert und der Aufwand des Entwicklers für die Einrichtung verringert. Die Masterarbeit behandelt die Untersuchung der aktuellen Vorgehensweise für das Aufsetzen der produktiven Laufzeitumgebungen. Anschließend sollen Schwachstellen identifiziert und priorisiert werden. Zur Behebung der dringlichsten Schwachstellen wird eine Anwendung zur automatischen Paketierung und Installation von Produktivumgebungen konzipiert und umgesetzt. In einer durchgeführten quantitativen Studie wird die entwickelte Anwendung auf dessen Funktionsfähigkeit in der Praxis geprüft. Die Ergebnisse zeigen, dass der zeitliche Aufwand für das Aufsetzen von produktiven Laufzeitumgebungen bei der Dematic GmbH um 94 % reduziert und das Fehlerrisiko verringert werden konnte.
01.11.20	2021	extern	Bachelor	DE	Anbindung der betrieblichen Infrastruktur an Cloud-Anwendungen am Beispiel von E-Mail und Workday HCM	Inhalt bzw. Ziel der Bachelorarbeit soll es im Allgemeinen sein, die verschiedenen Möglichkeiten der Anbindung von Email-Servern an Cloud-Software darzustellen. Als Praxisbeispiel wird hierfür in Kooperation mit der DATEV eine geeignete Möglichkeit gesucht, um einen DATEV Email-Server an die in 2019 eingeführte Cloudsoftware Workday anzubinden. Hierfür wird speziell eine Lösung gefordert, die in das bestehende Sicherheitskonzept der DATEV passt. Bei Workday handelt es sich um ein cloudbasiertes System, welches unter anderem zur Personalverwaltung innerhalb der DATEV eingesetzt wird. Durch die Verlagerung von externen auf interne Server soll es ermöglicht werden Bouncebacks zu erhalten sowie den E-Mails verschiedene Tags zuordnen zu können. Zu Beginn soll diese Umstellung für das Recruiting durchgeführt werden.
01.11.20	2021	extern	Bachelor	DE	Anomalieerkennung mittels Autoencoder in cyber-physischen Produktionssystemen	Methoden und Anwendungen der künstlichen Intelligenz und des maschinellen Lernens stellen eine aussichtsreiche Möglichkeit zur Beherrschung der wachsenden Komplexität automatisierter technischer Systeme in der produzierenden Industrie dar. Anwendungsfälle umfassen dabei die modellbasierte Optimierung, Überwachung und technische Diagnose. Insbesondere der Schritt der Modellbildung kann durch maschinelle Lernverfahren unterstützt werden. In der vorliegenden Abschlussarbeit wird die Eignung von Autoencodern am Beispiel von drei disjunkten industriellen Anwendungsfällen in diesem Kontext bewertet. Einen Schwerpunkt stellt dabei die Erkennung von Anomalien im Betrieb von Produktionsanlagen unter Zuhilfenahme von Autoencodern dar. Die Datengrundlage umfasst hierbei diskrete binäre Steuerungssignale, kontinuierliche Prozessvariablen sowie deren Kombination. Für die Modellierung werden verschiedene Netz Topologien untersucht und verglichen.
01.11.20	2021	intern	Bachelor	DE	Untersuchung verschiedener Ansätze des Dynamic Topic Modeling zur Analyse thematischer Trends	In der vorliegenden Arbeit sollen die unterschiedlichen Ansätze des zeitabhängigen Topic Modellings evaluiert werden. Hierfür werden unterschiedliche theoretische Ansätze untersucht, mittels derer eine Grundlage für die Evaluation der öffentlich verfügbaren Programmiercodes zu zeitabhängigen Topic Models möglich ist. Für die Arbeit mit den unterschiedlichen Modellen werden zwei Datensätze verwendet. Der erste Datensatz der UN-Debatten von 1970 bis 2015 liegt in Englisch vor und umfasst 7.507 Dokumente mit Erscheinungsjahr. Der zweite Datensatz wurde im Laufe der Arbeit aus der Webseite des FOCUS Online Archivs zusammengestellt und umfasst insgesamt 134.614 Artikel in Deutsch von 1993 bis Januar 2021 mit dem entsprechenden Erscheinungsdatum des dazugehörigen Magazins. Um die Ergebnisse der Modellcodes auszuwerten, wurden zudem nach unterschiedlichen Visualisierungsmöglichkeiten gesucht. Hierbei wurde hauptsächlich auf gängige Visualisierungsformen des allgemeinen Topic Models zurückgegriffen und eine zeitliche Darstellung in Form eines Diagramms, in dem die unterschiedlichen Kernpunkte der jeweiligen Modelle visualisiert werden konnten. Zum Schluss der Arbeit wurden die Modelle und deren Programmiercodes auf Basis selbstgewählter Evaluationspunkte bewertet und ein Fazit zur Arbeit mit diesen Modellen gezogen.
01.11.20	2021	extern	Bachelor	DE	Supervoxel-Clustering zur Reduktion von Übersegmentierung in der Instanz-Segmentierung großvolumiger CT-Volumen	Mittels XXL-Computertomographie (XXL-CT) können großvolumige Datensätze von gescannten Objekten generiert und mittels nachfolgender Bildverarbeitung und Instanz-Segmentierung in ihre Teilobjekte zerlegt werden. Unbekannte und unterschiedliche Eigenschaften, wie Form, Dichte, Material, oder Zusammensetzung dieser Entitäten, führen jedoch bei automatischen Segmentierungen nach aktuellem Stand der Technik, zum Beispiel mittels Deep Neural Networks, zu Übersegmentierungen. Im Rahmen dieser Arbeit wird ein auf Affinity Propagation basierendes Clustering-Verfahren untersucht, welches diese Übersegmentierungen als Supervoxel interpretiert, und zu deren Reduktion innerhalb einer Bildverarbeitungs-Kette beitragen soll. Unter Verwendung verschiedener Ähnlichkeitsmerkmale zur Clusterung konnte eine Reduktion der gegebenen Übersegmentierung bei nur geringer zusätzlicher Untersegmentierung erreicht werden.
01.11.20	2021	intern	Bachelor	DE	Konzeption und prototypische Umsetzung eines Freemium-Modells zur Monetarisierung einer App im Bildungsbereich	Im deutschen Schulalltag sind die Potentiale der Digitalisierung noch nicht ausreichend ausgeschöpft. In der vorliegenden Arbeit werden leistungsfähige Zukunftsmodelle der Notenapp dargestellt. Die Notenapp ermöglicht schon heute Schülern, ihre digitalen Kompetenzen, welche die Generation Z auszeichnet, im Schulalltag einzusetzen. Sie hilft diesen zu organisieren, den Überblick zu behalten und alles rund um Schule in der Hosentasche mit sich zu tragen. Die Arbeit gibt Anregungen für eine Monetarisierung der App, um sich das Potential der rückständigen Digitalisierung langfristig zu Nutzen zu machen. Ein Konzept für ein Freemium-Modell wird entwickelt. Dieses wird durch umfangreiche Nachforschung, einer Befragung und durch Analysen anderer Marktteilnehmer im Bildungsmarkt gestützt und entworfen. Dabei wird ein Anreiz zur Gestaltung einer Umfrage mit Ideen für mögliche Fragen, dem Aufbau und Ablauf, sowie zur Auswertung gegeben. Hierdurch werden wichtige Aspekte zur Auswahl möglicher Premium-Funktionen, der Preisgestaltung und den damit entstehenden Chancen und Risiken aufgezeigt. Anschließend wird das entwickelte Konzept voll funktionsfähig als Proof-of-Concept implementiert. Die Vorgehensweise und Learnings des Prozesses sind dabei auf andere Apps im Bildungssektor übertragbar. Abschließend wird es mit dem aktuell angewandten Werbemodell verglichen, um die Leistungsfähigkeit des Freemium-Modells zu verdeutlichen.
01.11.20	2021	intern	Bachelor	DE	Visuelle Emotionserkennung durch Deep Learning	Meine Bachelorarbeit beschäftigt sich mit der Analysierung der in Videos vorhandenen Emotionen. Quellen des Inputs werden sowohl Video-Dateien, als auch Live-Kameras sein. Aus den Eingaben sollen in Echtzeit Gesichter extrahiert und zum vortrainierten Model übergeben werden. Das Model kennt 6 Emotionen als Ausgabe und erzielt eine Vorhersage, welche Emotion auf dem Gesicht ausgedrückt wird. Die Trainings/Test-Daten stammen aus 2 Datensätzen: "CMU-Mosei Dataset" und "Kagle Dataset". Um Gesichter zu extrahieren bzw. Gesichtspunkte zu finden wird OpenCV verwendet. Das Neuronale Netz wird in PyTorch gebaut. Es werden insgesamt 2 Modelle erstellt. Das eine bekommt die Eingabe mit Pixeldaten und das andere bekommt die Gesichtsmerkmale. Das komplette Projekt wird in Python und den dazugehörigen Bibliotheken/Frameworks Programmiert.
02.11.20	2021	extern	Bachelor	DE	Einführung einer Pipeline für Continous Integration und Continous Deployment in einer Kubernetes-Umgebung im Kontext der Zertifizierung als Medizinprodukt	Diese Bachelorarbeit beschäftigt sich mit dem Aufbau und der Einführung einer Pipeline für Continuous Integration und Continuous Deployment für eine als Medizinprodukt zu zertifizierende Software der Firma O.Meany Medical Data & Project Management GmbH. Es wurde untersucht, inwieweit die Einführung der Pipeline den Entwicklungs-, Auslieferungsund Genehmigungsprozess im Sinne der Zertifizierung unterstützt. Im Einzelnen wurde auf die Zertifizierungsanforderungen eingegangen und welche Vorgaben hiervon für den Entwicklungsablauf entstehen. Speziell wurde die Nachvollziehbarkeit der Softwareentstehung von der Idee über die Implementierung bis zum Test und in diesem Zusammenhang die Integration der CI/CD-Pipeline mit dem bestehenden Versionsverwaltungssystem (Bitbucket) betrachtet. Als Technologie für die Pipeline wurden Kubernetes für die Container- Orchestrierung und Rancher für das Cluster-Management ausgewählt. Mit diesen Tools wurden Laufzeitumgebungen für die unterschiedlichen Entwicklungsstufen erstellt und betrieben. Somit erwies sich die Pipeline, die die formale Beschreibung eines zusammenhängenden Prozesses darstellt, als Unterstützung des sowohl für den Entwicklungsablauf als auch für die angestrebte Zertifizierung.
04.11.20	2021	intern	Bachelor	DE	Einfluss der Covid-19 Pandemie auf das Wissensmanagement und die Geschäftsprozesse der Hoffmann Group in Nürnberg	Das Ziel dieser Bachelorarbeit ist es, die Geschäftsprozesse und den stattfindenden Wissenstransfer bei der Hoffmann Group in Nürnberg zu analysieren und daraus Ergebnisse für die zentrale Frage abzuleiten, welchen Einfluss die COVID-19 Pandemie auf das Unternehmen in diesen Bereichen hat. Der Wissenstransfer wird im operativen Geschäft mit den Methoden und Techniken des Wissensmanagements stringent untersucht, um daraus Erkenntnisse und Schwachstellen zu erarbeiten. Um das Ziel zu erreichen, werden Umfragen bei den Angestellten durchgeführt und Geschäftsvorfälle untersucht. Die durch COVID-19 standortspezifisch bedingten Änderungen, vor allem im Hinblick auf das Hygiene- und Arbeitskonzept, die der Standort in Nürnberg erfahren hat, sind in dieser Arbeit immanent. Opportun werden präventive Maßnahmen betrachtet, mit denen man Herausforderungen einer Pandemie im Voraus bewerkstelligen kann.
06.11.20	2021	extern	Bachelor	DE	Agilität außerhalb der Softwareentwicklung - Konzeption für die agile Transition der Abteilung IT-Infrastruktur Services (T233) der DATEV eG 	Die Bachelorarbeit behandelte das Thema: "Agilität außerhalb der Softwareentwicklung ? Konzeption für die agile Transition der Abteilung IT-Infrastruktur Services (T233) der DATEV eG". Hierbei war folgende Forschungsfrage zu beantworten: "Kann die Abteilung IT-Infrastruktur Services (T233), in eine agile Arbeitsweise transitiert werden?" Im ersten Schritt war der aktuelle Wissenstands der Forschung zu erläutern. Außerdem wurde der aktuelle Einsatz von Agilität in der Wirtschaft präsentiert. Die Thematik dieser Arbeit wurde mit Hilfe der empirischen Forschung geprüft. Diese beinhaltete zwei quantitative, sowie zwei qualitative Befragungen. Die Umfragevarianten dienten zum einen für die Erfragung der Problemfelder einer agilen Transition und zum anderen der Erfragung der Lösungsmethoden für eine agile Transition. Zuzüglich wurde innerhalb der qualitativen Befragungen, bezogen auf die Lösungsmethoden eine Expertise erhoben. Die Prüfung, ob eine agile Transition möglich ist, wurde mit drei Hypothesen untermauert. Die erste Hypothese bezog sich auf das Wissen über Agilität, die zweite Hypothese bezog sich auf die Unterstützung von höheren Hierarchien und die dritte Hypothese fordert das Tätigkeitsfeld an sich heraus. Die Hypothese 1 wurde durch die gesamte empirische Forschung bestätigt. Die Hypothese 2 wurde durch die gesamte empirische Forschung widerlegt. Die dritte Hypothese wurde widerlegt. Demnach ist eine agile Transition von T233 möglich.
06.11.20	2021	extern	Bachelor	DE	Flexible Einlagerung mit Multishuttle: Konzeption und prototypische Umsetzung in SAP EWM	Das Multishuttle von Dematic dient zur effizienten Einlagerung von Waren. Die Lagerplätze, die das Shuttle anfährt, sind dabei standardmäßig statisch festgelegt, d.h. die anzufahrenden Koordinaten sind festgelegt und unveränderbar. Seit geraumer Zeit gibt es die "Flex" Erweiterung für das Shuttle. Im Flex werden lediglich Bereiche definiert und die anzufahrende Koordinaten ergeben sich dynamisch auf Basis der Abmessungen der Ware und der Lagersituation. Diese Koordinaten müssen vom übergeordneten Warehouse-System übergeben werden. Das Warehouse-System ist also für die Berechnung eines optimalen Platzes in einem Lagerplatz zuständig. Hierfür muss eine Einlagerungsstrategie mit einer Vielzahl von Restriktionen ausgearbeitet und implementiert werden.
09.11.20	2021	extern	Bachelor	DE	Datenvisualisierung in Virtual Reality	Die Server der Rechenzentren der DATEV generieren während ihrer Laufzeit jeden Tag mehrere Terabytes an Logfiles, deren Daten zur Überwachung und Optimierung der Server analysiert werden. Gegenstand der Arbeit ist es, neue Herangehensweisen an diesen Prozess zu erforschen. Der Fokus liegt dabei auf der Datenvisualisierung über Virtual Reality und damit in Verbindung stehenden, intuitiven Herangehensweisen an die Analyse von Daten. Ziel der Arbeit ist es, neue Perspektiven für die generierten Daten zu erhalten und damit die Überwachung der Server effektiver zu gestalten. Zu Beginn der Arbeit wurden die Logfiles mittels Datenmanipulation in neue Strukturen modelliert, die visualisiert werden sollen. Als nächster schritt wurde eine Anwendung entwickelt, die diese Daten einliest und damit Datenvisualisierungen erstellt, deren einzelne Datenpunkte greif- und bewegbar sind. Weiterhin wurden Features implementiert, die die Filterung und Neuanordnung der Datenpunkte vereinfachen Übersicht im Angesicht vieler Daten zu schaffen. Nach Fertigstellung des Prototyps wurden an Testpersonen außerhalb des Fachgebiets der Datenanalyse Tests durchgeführt. Diese Tests sollten abprüfen, wie intuitiv Daten mit der Anwendung von Menschen analysiert werden können, die in diesem Feld nicht bewandert sind. Eine der Testpersonen hatte bereits Erfahrungen mit der Nutzung einer VR-Brille. Der entwickelte Prototyp stellt eine Basis dafür dar, Menschen beliebiger Fachrichtung Datenanalyse zu ermöglichen.
10.11.20	2021	intern	Bachelor	DE	Analyse und Design eines barrierefreien Interfaces mit Flutter, zur Unterstützung stark sehbeeinträchtigter Personen.	Das Ziel der vorliegenden Bachelorarbeit ist es, ein barrierefreies und plattformübergreifendes Interface für sehbeeinträchtigte Menschen zu analysieren, gestalten und zu entwickeln. Dieses Interface soll ebenfalls als Vorlage dienen, damit bei weiteren Entwicklungen die Barrierefreiheit von Applikationen ohne großen Aufwand gewährleistet werden kann. Der zu programmierende Lösungsvorschlag wird sich auf bereits aus der Forschung entstandene Erkenntnisse beziehen, außerdem wird auf diese Erkentnisse mittels einer iterativen Konzeption, begleitet durch einen Test, aufgebaut. Die Umsetzung der Applikation sowie die plattformübergreifende Entwicklung werden mit dem von Google bereitgestellten Framework Flutter unternommen. Dieses Framework wird auf Deployment, Besonderheiten, Funktionsweisen sowie im Bezug auf die barrierefreie Zielsetzung betrachtet. Des Weiteren werden gestengesteuerte Funktionalitäten für die Applikation konzeptioniert und implementiert. Die Oberfläche wird ebenfalls durch eine Sprachausgabe für sehbeeinträchtigte Nutzer zugänglich gemacht. Um das entwickelte Interface zu evaluieren, wird eine kleine Testgruppe von Sehbeeinträchtigten gebildet und auf den entstandenen Ergebnissen aufgebaut.
13.11.20	2021	extern	Bachelor	DE	Auswahl und Evaluierung von Verfahren zur Identifikation von Dubletten am Beispiel der Ersatzteilbereitstellung bei Siemens Mobility GmbH	Zur Erleichterung der Ersatzteilbereitstellung sucht die Siemens Mobility GmbH nach einer Möglichkeit Materialien automatisiert als Ersatzteile zu klassifizieren. Hierfür sollen noch nicht klassifizierte Materialien mit ähnlichen und schon klassifizierten Materialien abgeglichen werden und ab einem gewissen Ähnlichkeitsgrad die Ersatzteilklassifizierung vererbt bekommen. Dafür sollen Verfahren der Dublettenerkennung verwendet werden, die im Rahmen einer Datenbereinigung oder Datenintegration durchgeführt werden. Unter Dubletten versteht man alle Datensätze, die das gleiche Realweltobjekt repräsentieren. Große Schwierigkeiten bei der Erkennung von Duplikaten sind Nicht-Eindeutigkeiten von Identifikationsnummern und inkonsistente Attributwerte beziehungsweise Darstellungen. Da ähnliche Materialien die gleiche Problematik mit eventuell höheren Abweichungen aufweisen, können sie als Duplikate angesehen werden. Eine weitere Schwierigkeit ist die Menge der abzugleichenden Datensätze. Wenn jeder Datensatz mit jedem anderen abgeglichen wird, folgt dies zum einen zu vielen unnötigen Vergleichen und zum anderen zu hohen Laufzeiten, die bei entsprechend hohen Datensatzmengen wirtschaftlich nicht sinnvoll sind. Als solches werden Ähnlichkeitsmaße und Klassifikationsansätze zur Erkennung von Duplikaten und Blocking-Algorithmen zur Adressierung der hohen Laufzeit untersucht und zur Eignung der Problemstellung der Siemens Mobility GmbH evaluiert.
15.11.20	2021	intern	Bachelor	DE	Konzeption und Implementierung einer Web-Applikation für die interaktive Filterung und Visualisierung textueller Daten	Diese Bachelorarbeit befasst sich mit CASOVIS, einer Web-Anwendung und Teilprojekt von CASoTex zur Visualisierung von textuellen Daten. Die Web-Anwendung bietet in ihrer ersten Version nur die Möglichkeit der Generierung von einfachen Linien-, Balkendiagrammen und Wordclouds. Mit den bisherigen Funktion können bisher nur allgemeingültige Erkenntnisse über die Daten gezogen werden. Das Ziel dieser Bachelorarbeit ist die Konzeption und Weiterentwicklung von CASOVIS. Um detaillierte Informationen über die Daten in Erfahrung bringen zu können, sollen weitere geeignete Visualisierungsfunktionen implementiert werden sowie eine Freitext-Suche und Filterung integriert werden. Außerdem soll die Möglichkeit geschaffen werden dynmisch Topic Modelle zu erstellen. Für den Betrieb der Anwendung wird in dieser Bachelorarbeit noch eine moderne Identity-and-Access-Managementlösung implementiert.
15.11.20	2021	extern	Bachelor	DE	Entwicklung einer Webanwendung, die mit Hilfe von modernen Technologien einen internen Prozess im Umfeld der Gehaltsberatung automatisiert.	Ein Mal pro Nacht werden innerhalb der DATEV in einem Batch-Lauf alle Berater- und Mandantenüberträge des Vortages verarbeitet und die Informationen dazu an das Rechenzentrum gesendet. Durch technische Probleme entstehen dabei aber oft fehlgeschlagene Überträge. Diese sollen im Umfeld der Gehaltsberatung in einer Oberfläche aufgelistet und manuell nachbearbeitet werden können. In diesem Projekt ist eine Webanwendung mit einer dazugehörigen Schnittstellenbeschreibung entwickelt worden, welche die manuelle Nachbereitung dieser fehlgeschlagenen Überträge und Löschungen automatisiert. Die Oberfläche wurde mit dem Framework Angular umgesetzt und wird später im internen Produktivbetrieb Cloud Foundry laufen.
23.11.20	2021	extern	Bachelor	DE	Neukonzeption eines Monitoring-Tools für den Einzelhandel auf der Basis von Microsoft 365 Business Central	In dieser Bachelorarbeit wird der Einfluss der Cloud-Technologien auf die Weiterentwicklung der ERP-Lösung von Microsoft untersucht. Die kundenspezifischen Geschäftsprozessanpassungen, die für klein- und mittelständische Unternehmen von Bedeutung sind, werden im Zuge dieser Transformation auf eine andere Weise vom Dienstleister entwickelt und bereitgestellt. Die folgenden Forschungsfragen sind zu beantworten: 1. Wie sehen die neuen Prozesse für die Bereitstellung der kundenspezifischen Anpassungen für die Cloud-Lösung aus und wie können sie effektiv und effizient gestaltet werden? 2. Wo geht der Trend im Einzelhandel hin und welche Funktionalitäten werden im Einzelhandel gebraucht? In der Abschlussarbeit wird gezeigt, dass das Bereitstellungsmodell Software-as-a- Service in der ERP-Welt an Bedeutung zunimmt. Prozesse und neue Denkweisen müssen vom Dienstleister in den Unternehmensalltag integriert werden. Flexibilität, schnelle Anpassungsfähigkeit und der interne Wissensaustausch sind gefordert, um den Bereitstellungs- und Verwaltungsprozess zu standardisieren und wenn möglich zu automatisieren.
27.11.20	2021	extern	Bachelor	DE	Untersuchung von Decentralized Identifiern, deren Auswirkung auf den Datenschutz sowie ihre Anwendung in einem Prototyp eines digitalen Geldbeutels	Klassische Authentifizierungsverfahren wie z.B. Single Sign-On, speichern Daten des Benutzers, beispielsweise den Benutzername und das Passwort, in der Regel auf firmeninternen Servern ab. Dieses Konzept entzieht dem eigentlichen Dateninhaber allerdings die volle Kontrolle über seine Daten. Beispielsweise wären mit einem Hackerangriff die Daten gefährdet oder sogar weitere Daten des Users mit einem Löschen der Webseite nicht mehr verfügbar. Im Rahmen dieser Bachelorarbeit wird ein dezentralisiertes Verfahren vorgestellt, das keine Speicherung von Identitätsdaten, z.B. für eine Anmeldung, beim Webseitenbetreiber benötigt. Des Weiteren wird eine Möglichkeit vorgestellt, wie physikalische Identitätsnachweise, wie z.B. ein Personalausweis, durch ein digitales Pendant ersetzen werden können. Darauf aufbauend werden Strategien vorgestellt, die es gestatten den Informationsaustausch mit Dritten auf ein Minimum zu beschränken und so nur ausgewählte Daten zu teilen. Durch eine lokale Speicherung dieser Identitätsnachweise in einem digitalen Wallet, kann der Benutzer künftig selber entscheiden was und wieviel von seiner Identität preisgegeben werden kann.
30.11.20	2021	intern	Bachelor	DE	Konzeption einer Entity Linking-Pipeline zur Disambiguierung von Unternehmensentitäten in unstrukturierten Texten	Die Disambiguierung von Unternehmensentitäten ist durch den bisherigen Entity Linking-Ansatz stark limitiert. Das zugrundeliegende Wissen kann außerdem nur schwer erweitert werden und ist auf spezifische Datenbanken beschränkt. Das Ziel der vorliegenden Arbeit ist daher, die Disambiguierung von Unternehmensentitäten in unstrukturierten Texten zu verbessern. Dazu werden insgesamt drei Forschungsfragen gestellt, die sich mit der Erweiterbarkeit der Wissensba- sis, der zuverlässigen Erkennung von ungesehenen Entitäten und dem Vergleich verschiedenener Entity Linking-Ansätze beschäftigen. Um diese Forschungsfragen zu beantworten, wurde ein Prototyp für eine NEL-Pipeline erarbeitet. Zuerst wurde eine Wissensdatenbank konstruiert und mit Entitäten aus Textdaten befüllt. Daraufhin wurden verschiedene Entity Linking-Ansätze aus der Literatur gegenübergestellt und bewertet. Auf Basis dieser Bewertung wurden geeignete Verfahren ausgewählt, exemplarisch implementiert und schließlich auf den annotierten Textdaten evaluiert. Damit eine umfangreiche Ergebniseinschätzung möglich ist, wurde zusätzlich ein Vergleich mit der vorherigen Lösung und einem kommerziellen Tool gezogen. Die Ergebnisse der Evaluation zeigten, dass die Disambiguierung durch die Verwendung der konzipierten Wissensdatenbank erheblich verbessert werden konnte. Auch der anschließende Vergleich mit anderen Tools offenbarte eine deutliche Steigerung der Erkennungsrate.
30.11.20	2021	extern	Bachelor	DE	Prozessverbesserung durch Methoden des maschinellen Lernens am Beispiel der Kategorisierung von Artikeln im E-Commerce	Die Integration von Machine-Learning-Anwendungen in bestehende Arbeitsabläufe gestaltet sich häufig schwierig. Um einen Anstoß für die Lösung dieses Problems zu geben, wurde in dieser Arbeit eine Kombination von Methoden des Prozessmanagements und des Machine Learning Engineerings auf ein Fallbeispiel aus der betrieblichen Praxis angewendet. Dabei handelte es sich, um die Kategorisierung von Artikeln im Artikelpflegeprozess eines Onlineshops aus dem Einzelhandel. Ausgehend von einer konkreten Problemstellung wurde festgestellt, wie eine Machine-Learning Anwendung zur Kategorisierung von Artikeln den bestehenden Arbeitsablauf verbessern könnte, wie sie in ihn integriert werden könnte und wie ihr Erfolg gemessen werden könnte. Des Weiteren wurde für das dabei entwickelte Verbesserungskonzept ein Proof of Concept über die Entwicklung relevanter Softwarekomponenten erbracht.
30.11.20	2021	intern	Bachelor	DE	Semi-automatische Erstellung von Wissensdatenbanken für Question-Answering-Systeme	Ziel dieser Arbeit ist es, einen Prozess für die schrittweise Erweiterung der Wissensdatenbank von Chatbots zu entwerfen. Der Fokus liegt dabei auf unstrukturierten Daten, wie beispielsweise Textdokumenten oder E-Mails. Es liegt ein großer Bestand an E-Mail-Protokollen vor, welcher im Rahmen dieser Arbeit aufbereitet und als Datenbasis für den Prozess verwendet wird. Weiterhin wird dieser Prozess in Form einer Webanwendung prototypisch implementiert.
01.12.20	2021	intern	Bachelor	DE	Entwicklung eines Konzepts zur kontinuierlichen Verbesserung der Usability einer Online-Beratungssoftware	Eine effektive, effiziente und zufriedenstellende Nutzung von Softwareprodukten bedarf einer guten Usability. Diese Bachelorarbeit befasst sich mit der Identifikation und Beseitigung von Usability-Schwachstellen in der Berater-Nutzeroberfläche der Online-Beratungssoftware des Instituts für E-Beratung. In einem ersten Schritt werden in Anlehnung an die Vorgehensmethodik des Usability Engineering sowohl der Ist-Zustand der Software analysiert als auch ihre Schwachstellen mittels UX-Tagebuchstudie und standardisiertem Fragebogen identifiziert. Anschließend wird ein Usability-Konzept entwickelt, welches Handlungsempfehlungen zum Beheben der aufgedeckten Schwachstellen beinhaltet. Zudem wird eine Guideline erarbeitet, die auf wichtige, zu beachtende Aspekte der Gebrauchstauglichkeit hinsichtlich zukünftiger Erweiterungen der Software aufmerksam macht. Durch die kontinuierliche Umsetzung dieser Handlungsempfehlungen soll die Zufriedenheit der Nutzer*innen dieser Software gesteigert werden.
01.12.20	2021	intern	Bachelor	DE	Konzeption und protypische Implementierung einer Suchmaschine für Stellenangebote der Hochschuljobbörse	Ziel dieser Arbeit ist die Entwicklung einer Suchfunktion für die Plattformen der Hochschuljobbörse. Mit einer vorher ausgewählten Software soll ein Index über bestehende und neue Inserate erstellt werden, der sowohl vorher festgelegte Parameter als auch den Inhalt des Inseratstextes beinhaltet. Dieser Index wird für eine Freitextsuche verwendet, die an die bekannten Suchmaschinen angelehnt ist. Weiterhin können über diesen Suchvorschläge generiert werden. Interessierten soll diese Suche auch über die angegebenen Parameter hinaus passende Vorschläge liefern können, für Inserierende können die Daten aus Index und bestehenden Suchanfragen Informationen über die Interessen der jeweiligen Zielgruppe liefern.
17.12.20	2021	intern	Bachelor	DE	Einfluss von Transkriptionen auf die Leistungsfähigkeit von Methoden des maschinellen Lernens am Beispiel USOMS	Der Geisteszustand (SOM) eines Menschen kann sich durch Emotionen verändern. Die geistige Gesundheit wird von der gewohnheitsmäßigen Anpassung oder Fehlanpassung des SOM beeinflusst. In der Studie von Rathner et al. konnte gezeigt werden, dass der SOM durch persönliche Erzählungen (Narrative) beeinflusst werden kann und SOM sowie Sentiment (positiv, negativ) können durch die Analyse des Wortgebrauches vorhergesagt werden. Für ihre Analyse zogen sie den USoM Datensatz heran, der studentische Verschriftungen von persönlichen Narrativen enthält. Es ist wenig bekannt darüber, welchen Einfluss die Art und Genauigkeit von Verschriftung auf die Ergebnisse dieser Art von Analysen hat. Für diese Studie wird eine Version des Ulm State-of-Mind Datensatzes verwendet, die um weitere Verschriftungsarten, studentisch, von einem professionellen Transkriptionsservice (wortgetreu) und durch ein kommerzielles state-of-the-art Spracherkennungssystem, ergänzt wurde. Die vorgestellte Studie soll aufzeigen, inwiefern die Art der Transkription Auswirkungen auf die Genauigkeit und Aussagekraft des Ergebnisses von maschinellen Lernverfahren hat. Außerdem kann ein Beitrag dazu geleistet werden, die Frage zu beantworten, ob automatische Spracherkennung gut genug funktioniert, um in einem voll automatisierten System, vergleichbare Ergebnisse liefern zu können. Dafür wird experimentell der Einfluss der unterschiedlichen Verschriftungsarten auf die Leistungsfähigkeit von Klassifikatoren untersucht.