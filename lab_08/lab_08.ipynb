{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"hsg_logo.png\">\n",
    "\n",
    "##  Lab 8: Summarization using Transformers\n",
    "\n",
    "GSERM'21 course \"Deep Learning: Fundamentals and Applications\", University of St. Gallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers are powerful attention-based models that evidently generalize well.\n",
    "Googles T-5 is a popular and very recent text-to-text transformer that, in contrast to eg. BERT, has been pre-trained on many different tasks, ranging from inference to summarization (read more about T5 on [Googles AI.blog](!https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html).\n",
    "\n",
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"//1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s640/image3.gif\">\n",
    "\n",
    "T-5 is supposedly able to handle all kinds of NLP tasks like summarization, question answering, and text classification.\n",
    "The [original paper](!https://arxiv.org/abs/1910.10683) sheds some light on what they actually wanted to achieve.\n",
    "For this lab, we will be using a pre-trained T-5, specifically the [MT-5](https://github.com/google-research/multilingual-t5) that was trained on multi-lingual input data, ie. the model \"speaks\" many languages; here, we will work with a model that's already been fine-tuned to perform German summarization: The `ml6team/mt5-small-german-finetune-mlsum` model, that can be downloaded from Huggingface <https://huggingface.co/ml6team/mt5-small-german-finetune-mlsum> (or via the `transformers` library, see below)\n",
    "\n",
    "Today, we want to address the question: Can we use a pre-trained transformer model to summarize abstracts of student theses so that the result comes close to their original titles?\n",
    "\n",
    "We'll start with the downloaded model to get a feeling for how transformers work and behave.\n",
    "We'll then go on and fine-tune the model to our task at hand to improve the results.\n",
    "You can find the `theses.tsv` file on the files section on [Canvas](https://learning.unisg.ch/courses/9425).\n",
    "\n",
    "\n",
    "### Hints\n",
    "\n",
    "- You need sentencepiece installed (pip install sentencepiece)\n",
    "- For a starter, make sure to only retain German thesis abstracts and titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on colab, you will have to install transformers and sentencepiece\n",
    "%%bash\n",
    "pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Summarization, out of the box\n",
    "\n",
    "Let's see if we can use the downloaded model to summarize our thesis abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# huggingface\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data logistics: load theses title and abstract\n",
    "# limit_title_len=[4,10] restricts to titles in between 4 and 10 tokens\n",
    "def load_thesis_data(path='res/theses.tsv', limit_title_len=None):\n",
    "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "    # limit to 'Sprache'==DE and title_len if necessary\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "\n",
    "    if limit_title_len:\n",
    "        df['title_length'] = df['Titel'].apply(lambda x: len(x.split()))\n",
    "        df = df[df['title_length'].between(limit_title_len[0], limit_title_len[1])] # pick your numbers or use std dev\n",
    "    \n",
    "    return df[df['Sprache'] == 'DE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the models; they will download on first time use but this will take some time (1.2 GB)\n",
    "# https://huggingface.co/transformers/model_doc/auto.html?highlight=autotokenizer#transformers.AutoTokenizer.from_pretrained\n",
    "# https://huggingface.co/transformers/model_doc/auto.html?highlight=autotokenizer#transformers.AutoModelForSeq2SeqLM.from_pretrained\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ml6team/mt5-small-german-finetune-mlsum\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ml6team/mt5-small-german-finetune-mlsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anmeldedatum</th>\n",
       "      <th>JahrAkademisch</th>\n",
       "      <th>Art</th>\n",
       "      <th>Grad</th>\n",
       "      <th>Sprache</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.07.16</td>\n",
       "      <td>2016</td>\n",
       "      <td>extern</td>\n",
       "      <td>Master</td>\n",
       "      <td>DE</td>\n",
       "      <td>Untersuchung und Konzeption des Einsatzes von ...</td>\n",
       "      <td>Im Fokus dieser Arbeit steht der Einsatz von C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.08.16</td>\n",
       "      <td>2016</td>\n",
       "      <td>intern</td>\n",
       "      <td>Master</td>\n",
       "      <td>DE</td>\n",
       "      <td>Objekterkennung mit Convolutional Neural Netwo...</td>\n",
       "      <td>Im Rahmen dieser Masterthesis wird die Klassif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04.10.16</td>\n",
       "      <td>2017</td>\n",
       "      <td>extern</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>DE</td>\n",
       "      <td>Analyse von Technologien zur Desktopbereitstel...</td>\n",
       "      <td>Viele Unternehmen verfügen über etablierte Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05.10.16</td>\n",
       "      <td>2017</td>\n",
       "      <td>extern</td>\n",
       "      <td>Master</td>\n",
       "      <td>DE</td>\n",
       "      <td>Konzeption und Implementierung einer mobilen A...</td>\n",
       "      <td>Ziel der Masterarbeit ist es, eine mobile Anwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.10.16</td>\n",
       "      <td>2017</td>\n",
       "      <td>extern</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>DE</td>\n",
       "      <td>Konzeptionierung und Realisierung einer Anwend...</td>\n",
       "      <td>Das Ziel dieser Bachelorarbeit ist die Konzept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Anmeldedatum  JahrAkademisch     Art      Grad Sprache  \\\n",
       "0     28.07.16            2016  extern    Master      DE   \n",
       "1     01.08.16            2016  intern    Master      DE   \n",
       "2     04.10.16            2017  extern  Bachelor      DE   \n",
       "3     05.10.16            2017  extern    Master      DE   \n",
       "4     10.10.16            2017  extern  Bachelor      DE   \n",
       "\n",
       "                                               Titel  \\\n",
       "0  Untersuchung und Konzeption des Einsatzes von ...   \n",
       "1  Objekterkennung mit Convolutional Neural Netwo...   \n",
       "2  Analyse von Technologien zur Desktopbereitstel...   \n",
       "3  Konzeption und Implementierung einer mobilen A...   \n",
       "4  Konzeptionierung und Realisierung einer Anwend...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Im Fokus dieser Arbeit steht der Einsatz von C...  \n",
       "1  Im Rahmen dieser Masterthesis wird die Klassif...  \n",
       "2  Viele Unternehmen verfügen über etablierte Des...  \n",
       "3  Ziel der Masterarbeit ist es, eine mobile Anwe...  \n",
       "4  Das Ziel dieser Bachelorarbeit ist die Konzept...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main program\n",
    "df = load_thesis_data()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for summary generation, using the global model and tokenizer\n",
    "def generate_summary(model, abstract, num_beams, repetition_penalty,\n",
    "                    length_penalty, early_stopping, max_output_length):\n",
    "    # source_encoding = tokenizer(...)\n",
    "    source_encoding = tokenizer(\n",
    "        abstract,\n",
    "        max_length=784,  # this comes from the\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "    # generated_ids = model.generate(...)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=source_encoding[\"input_ids\"],\n",
    "        attention_mask=source_encoding[\"attention_mask\"],\n",
    "        num_beams=num_beams,\n",
    "        max_length=max_output_length,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        length_penalty=length_penalty,\n",
    "        early_stopping=early_stopping,\n",
    "        use_cache=True)\n",
    "\n",
    "    # ...map to string using tokenizer.decode and return\n",
    "    preds = [tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) \n",
    "         for gen_id in generated_ids]\n",
    "\n",
    "    return \"\".join(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Im Rahmen dieser Bachelorarbeit wurde ein Framework zur Erzeugung und Darstellung von Phantomen innerhalb einer Anwendung entwickelt, die einen Computertomographen simuliert. Die Ausgangsanalyse ergab, dass die aktuell verwendete Implementierung nicht geeignet war um kommende Anforderungen an Phantome gerecht zu werden. Neue Phantome konnten nur unter großem Zeitaufwand entwickelt werden. Die Entwicklung des Konzepts begann mit der Idee, die einzelnen Elemente eines Phantoms als geometrische Objekte zu definieren. Dadurch wird es ermöglicht, ein Phantom als ein Objekt aus einzelnen Bauteilen zu betrachten. Die einzelnen Elemente können für neue Phantome wiederverwendet werden und bieten mathematische Operationen um sich im Raum zu positionieren. Um diese Elemente zu gestalten, werden zunächst zwei primäre Grundobjekte verwendet: Quader und Kreis. Aus diesen Objekten lassen sich alle aktuell verwendeten Bauteile zusammensetzen. Die Objekte bieten eine umfangreiche Parametrisierung für ihre Dimensionen und ihre Zusammensetzung. Sollten in der Zukunft noch weitere Objekte benötigt werden, bietet das Framework ausreichend Schnittstellen um Erweiterungen einzubauen. Das Framework wird in der Programmiersprache C# von Microsoft entwickelt. Die beispielhafte Implementierung eines Phantoms sowie Schnittstellen und ausgewählte Klassen werden vorgestellt und erläutert. Schlussendlich werden die Bilder eines realen und simulierten Phantomes verglichen.</td></tr>\n",
       "    <tr><td>generated:</td><td>Die neue Phantome entwickeln sich künftig als geometrische Objekte. Jetzt entwickelt Microsoft ein Framework zur Erzeugung und Darstellung von Phantomen.</td></tr>\n",
       "    <tr><td>reference:</td><td>Konzeptionierung und Implementierung eines Frameworks zur Darstellung von Phantomen innerhalb einer Simulationskomponente für Computertomographen</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Das Ziel dieser Masterarbeit ist es, die Detektion von Gesichtern in Bilddateien mittels Region-based Convolutional Neural Networks (R-CNNs) zu untersuchen. Zunächst werden die theoretischen Grundlagen von R-CNNs vorgestellt und diese Methoden sowohl gegenübergestellt als auch verglichen. Anschließend werden aktuelle Methoden zur Detektion von Gesichtern in Bildern mit Gesichtsdetektoren auf Basis von neuronalen Netzen verglichen. Im praktischen Teil der Arbeit wird ein Region-based CNN für die Detektion und Lokalisierung von Gesichtern in Bildern erstellt und trainiert. Anhand einer oder mehrerer geeigneter Teststichproben wird die Erkennungsrate und der benötigte Rechenaufwand der Verfahren ermittelt und verglichen. Zusätzlich wird ein Vergleich mit einem klassischen Gesichtsdetektor wie dem Viola-Jones-Algorithmus durchgeführt.</td></tr>\n",
       "    <tr><td>generated:</td><td>Das Ziel dieser Masterarbeit ist es, die Detektion von Gesichtern in Bilddateien mittels Region-based Convolutional Neural Networks (R-CNNs) zu untersuchen.</td></tr>\n",
       "    <tr><td>reference:</td><td>Gesichtsdetektion in Bildern mittels Region-based Convolutional Neural Networks</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>In der vorliegenden Bachelorarbeit soll erörtert werden, inwiefern es möglich ist, aus dem Abstract einer Abschlussarbeit den dazugehörigen Titel zu generieren. Hierfür soll das Bidirectional Encoder Representations from Transformers (BERT) Model von Google verwendet werden. Das BERT Modell kann mit mehreren Sprachen umgehen, darunter auch Deutsch. Als Datensatz für das englische System werden die Abstractbooks der Interspeech Konferenz der letzten 5 Jahre verwendet. Bei dem Datensatz in Deutsch handelt es sich um eine Sammlung von 935 Abschlussarbeiten der Fakultät Informatik. Es soll evaluiert werden, ob BERT für den gegebenen Zweck das passende Model ist. Für das Training wird das BERTSUM Modell verwendet, das speziell für Textzusammenfassungen ausgelegt ist. Die Evaluierung wird mit Recall-Oriented Understudy for Gisting Evaluation (ROUGE) und Word Error Rate (WER) durchgeführt. Die Ergebnisse von ROUGE und WER zeigen, dass BERT diese Aufgabe nicht ohne weitere Anpassungen bewältigen kann. Es werden noch mehr Experimente und Anpassungen im Nachgang dieser Arbeit benötigt, um eine genauere Aussage zu treffen.</td></tr>\n",
       "    <tr><td>generated:</td><td>Das Bidirectional Encoder Representations from Transformers (BERT) Model von Google verwendet werden.</td></tr>\n",
       "    <tr><td>reference:</td><td>Automatische Generierung von Titeln und Abstracts</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Ziel der vorliegenden Arbeit ist es, Anwendungsfelder künstlicher Intelligenz (kurz KI) für den Bereich des Privatkundenservice zu identifizieren, zu konzeptionieren und zu evaluieren. Anhand derer soll anschließend aufgezeigt werden, wie mithilfe von KI die dem Kundenservice zur Verfügung stehenden Ressourcen möglichst qualitätssteigernd und gewinnbringend eingesetzt werden können. Adressaten der Arbeit sind dabei strategische Mitarbeiter sowie Projektverantwortliche der IT und des Kundenservice. Zur Zielerreichung wird zunächst der theoretische Rahmen erarbeitet. Darauf aufbauend werden branchen- und unternehmensübergreifende Analyseerkenntnisse in einem Gesamtbild zusammengefasst, spezifische Kundenreisen der N-ERGIE evaluiert und kundenservicespezifische Anwendungsmöglichkeiten von KI definiert. Auf Basis dessen erfolgt anschließend die Formulierung einer Vision für den Kundenservice der Zukunft sowie die Ableitung von Transformationsprojekten zur Umsetzung dieser. Abschließend wird zur Verifizierung der ermittelten Erkenntnisse der Anwendungsfall der Auswertung von Kundenmails exemplarisch hinsichtlich Sprache, Kundenstimmung und Inhaltskategorie erprobt. Im Ergebnis wird deutlich, dass zur Etablierung eines zukunftsfähigen Kundenservice eine Entlastung von nicht wertschöpfenden Tätigkeiten durch KI unabdingbar ist.</td></tr>\n",
       "    <tr><td>generated:</td><td>Der Kundenservice soll künftig qualitätssteigernd und gewinnbringend eingesetzt werden.</td></tr>\n",
       "    <tr><td>reference:</td><td>Anwendungsfelder künstlicher Intelligenz zur Schaffung eines exzellenten Kundenservice</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Trotz steigendem Bedarf nach MINT-Absolventen bleibt die Frauenquote in diesen Fächer gering. Das Ziel dieser Arbeit ist es, die Entscheidungsfaktoren bei der Wahl des Studiengangs herauszufinden, zu analysieren und daraus eine Handlungsempfehlung für die Hochschule abzuleiten. Dazu soll folgende Forschungsfrage untersucht werden: Welche Entscheidungsfaktoren fließen bei unterrepräsentierten Gruppen bei der Wahl des Studiengangs mit ein? Zur Erweiterung der Datengrundlage wird eine Online-Umfrage durchgeführt. Anschließend werden die Daten durch Werkzeuge der Textanalyse und maschinelle Lernmethoden wie Sentiment Analyse aufbereitet, analysiert und ausgewertet. Aus den Ergebnissen lassen sich die wichtigsten Faktoren bei der Wahl des Studiengangs ablesen. Darauf aufbauend können Konzepte gestalten werden, um diese Entscheidungsfaktoren zu beeinflussen.</td></tr>\n",
       "    <tr><td>generated:</td><td>Das Ziel dieser Arbeit ist es, die Entscheidungsfaktoren bei der Wahl des Studiengangs herauszufinden und daraus eine Handlungsempfehlung für die Hochschule abzuleiten.</td></tr>\n",
       "    <tr><td>reference:</td><td>Analyse der Entscheidungsfaktoren unterrepräsentierter Gruppen bei der Wahl von MINT-Studiengängen durch Methoden des maschinellen Lernens</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Die Server der Rechenzentren der DATEV generieren während ihrer Laufzeit jeden Tag mehrere Terabytes an Logfiles, deren Daten zur Überwachung und Optimierung der Server analysiert werden. Gegenstand der Arbeit ist es, neue Herangehensweisen an diesen Prozess zu erforschen. Der Fokus liegt dabei auf der Datenvisualisierung über Virtual Reality und damit in Verbindung stehenden, intuitiven Herangehensweisen an die Analyse von Daten. Ziel der Arbeit ist es, neue Perspektiven für die generierten Daten zu erhalten und damit die Überwachung der Server effektiver zu gestalten. Zu Beginn der Arbeit wurden die Logfiles mittels Datenmanipulation in neue Strukturen modelliert, die visualisiert werden sollen. Als nächster schritt wurde eine Anwendung entwickelt, die diese Daten einliest und damit Datenvisualisierungen erstellt, deren einzelne Datenpunkte greif- und bewegbar sind. Weiterhin wurden Features implementiert, die die Filterung und Neuanordnung der Datenpunkte vereinfachen Übersicht im Angesicht vieler Daten zu schaffen. Nach Fertigstellung des Prototyps wurden an Testpersonen außerhalb des Fachgebiets der Datenanalyse Tests durchgeführt. Diese Tests sollten abprüfen, wie intuitiv Daten mit der Anwendung von Menschen analysiert werden können, die in diesem Feld nicht bewandert sind. Eine der Testpersonen hatte bereits Erfahrungen mit der Nutzung einer VR-Brille. Der entwickelte Prototyp stellt eine Basis dafür dar, Menschen beliebiger Fachrichtung Datenanalyse zu ermöglichen.</td></tr>\n",
       "    <tr><td>generated:</td><td>Die Server der Rechenzentren der DATEV generieren während ihrer Laufzeit jeden Tag mehrere Terabytes an Logfiles, deren Daten zur Überwachung und Optimierung der Server analysiert werden. Gegenstand der Arbeit ist es, neue Herangehensweisen an diesen Prozess zu erforschen.</td></tr>\n",
       "    <tr><td>reference:</td><td>Datenvisualisierung in Virtual Reality</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Kurzzusammenfassung Die vorliegende Arbeit befasst sich mit der Konzeption und Entwicklung eines Dashboards zur dynamischen Visualisierung von Protokollbäumen bei Siemens Healthcare GmbH. Den Hauptteil dieser Arbeit bildet ein Vergleich der Levenshtein Distanz, Jaro Distanz, Longest Common Subsequence und Longest Common Substring Algorithmen für Zeichenkettenvergleiche. Ziel hierbei ist es diese Algorithmen zu klassifizieren und zu vergleichen, um den geeignetsten Algorithmus für Vergleichsanalysen zu finden. Ein weiterer Fokus liegt auf der Suche nach Implementierungsmöglichkeiten des ausgewählten Algorithmus für eine dynamische Ausführung spontaner Benutzerabfragen. Im praktischen Teil dieser Abschlussarbeit wurde ein Dashboard im Business Intelligence Tool QlikView implementiert. Nach einer Ausgangssituationsanalyse wurden zunächst die Anforderungen festgelegt, die im Dashboard erfüllt werden sollten. Um die benötigten Daten zu integrieren, wurde ein ETL-Prozess verwendet. Für benutzerfreundliche Datenauswertungen wurden verschiedene Visualisierungsmöglichkeiten in das Dashboard eingesetzt.</td></tr>\n",
       "    <tr><td>generated:</td><td>Die vorliegende Arbeit befasst sich mit der Konzeption und Entwicklung eines Dashboards zur dynamischen Visualisierung von Protokollbäumen.</td></tr>\n",
       "    <tr><td>reference:</td><td>Konzeption und Entwicklung eines Dashboards zur Visualisierung von Protokollbäumen bei Siemens Healthcare</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Im Rahmen eines größeren Softwareentwicklungsprojekts stellt die Voigtmann GmbH eine Rahmeninfrastruktur für ein Softwaremodul eines Kunden bereit. Diese beinhaltet die Programmierung einer App als Benutzerschnittstelle für mobile Endgeräte, eines webbasierten Backend als Benutzerschnittstelle zur Administration und den Betrieb der hierfür pro Mandant (Kunde des Kunden) benötigten Server. Die Vorliegende Arbeit beschäftigt sich im Kern mit der Automatisierung der Bereitstellung der benötigten Infrastruktur zum Betrieb des Backend für verschiedene Kunden in Form von Speziell angepassten Linuxservern. Es wurden hierzu Kriterien erarbeitet, anhand derer verschiedene Methoden des automatisierten Deployment bewertet werden konnten. Die präferierte Methode wurde im Anschluss umgesetzt.</td></tr>\n",
       "    <tr><td>generated:</td><td>Die Voigtmann GmbH stellt eine Rahmeninfrastruktur für ein Softwaremodul eines Kunden bereit.</td></tr>\n",
       "    <tr><td>reference:</td><td>Ermittlung und Umsetzung einer Methode zur automatisierten Bereitstellung kundenspezifischer Linuxserver im Rahmen eines Entwicklungsprojektes</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Die Arbeit mit dem Titel \"Evaluation von Werkzeugen zur Testautomatisierung von mobilen Android-Applikationen\" wird sich letztendlich mit der Untersuchung und Bewertung von Tools zur Testautomatisierung von mobilen Anwendungen befassen. In Anbetracht dessen, dass der Markt für mobile Anwendungen sich in einem rasanten Wachstum befindet und zufriedene Nutzer unabdingbar für wirtschaftlich erfolgreiche Apps sind, sollte die Qualitätssicherung keineswegs vernachlässigt werden. Testautomatisierungs-Tools sollen dabei die Aufgabe erleichtern und beschleunigen. Im ersten Schritt der Arbeit sollen geeignete Tools ermittelt werden und diese dann anhand eines Anwendungsbeispiels getestet und bewertet werden. Hierfür wurden zunächst geeignete Tools ermittelt und miteinander verglichen. Daraufhin wurden, mithilfe einer Beispiel-App, Testfälle entworfen und implementiert. Schließlich wurde die Eignung der einzelnen Tools bewertet. Die Evaluation hat gezeigt, dass sich das offizielle Werkzeug Espresso für single-platform-Apps am besten eignet. Für cross-platform-Apps ist eine Kombination aus Espresso und Appium denkbar.</td></tr>\n",
       "    <tr><td>generated:</td><td>Die Arbeit mit dem Titel \"Evaluation von Werkzeugen zur Testautomatisierung von mobilen Android-Applikationen\" wird sich letztendlich mit der Untersuchung und Bewertung von Tools zur Testautomatisierung von mobilen Anwendungen befassen.</td></tr>\n",
       "    <tr><td>reference:</td><td>Evaluation von Werkzeugen zur Testautomatisierung von mobilen Android-Applikationen</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Entwicklung eines Verfahrens zur Erkennung beweglicher Objekte mit Hilfe eines Lidar-Scanners auf einem mobilen Roboter. Ziel ist es, durch Literaturrecherche zu prüfen, ob ein SLAM-Verfahren existiert, der für die Erkennung von dynamischen Objekten optimiert ist. Falls ein optimiertes Verfahren vorhanden ist, wird dieses für den 'Carbot' Roboter implementiert. Anderenfalls wird der bisherige SLAM-Algorithmus (ICP) soweit weiterentwickelt, dass dynamische Objekte erkannt und kartographiert werden können.</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now use the pre-trained model to generate some short summaries from the \n",
    "# abstracts, and compare them to the reference titles\n",
    "\n",
    "# adjust these values as desired\n",
    "num_beams = 8\n",
    "repetition_penalty = 2.0\n",
    "length_penalty = 2.0\n",
    "max_output_length = 120\n",
    "\n",
    "early_stopping = True\n",
    "\n",
    "# sample from dataset, using abstracts as input to generate short summary (~title)\n",
    "from IPython.display import HTML, display\n",
    "def displaysum(summarize, generated, reference):\n",
    "    display(HTML(f\"\"\"<table>\n",
    "    <tr><td>summarize:</td><td>{summarize}</td></tr>\n",
    "    <tr><td>generated:</td><td>{generated}</td></tr>\n",
    "    <tr><td>reference:</td><td>{reference}</td></tr>\n",
    "    </table>\n",
    "    <hr>\n",
    "    \"\"\"))\n",
    "\n",
    "for i in [random.randint(0, len(df) - 1) for _ in range(10)]:\n",
    "    # load the values\n",
    "    summarize = df.iloc[i].Abstract\n",
    "    reference = df.iloc[i].Titel\n",
    "\n",
    "    # generated = generate_summary(...)\n",
    "    generated = generate_summary(model, \"summarize: \" + str(df.iloc[i].Abstract),\n",
    "                                 num_beams, repetition_penalty,\n",
    "                                 length_penalty, early_stopping, 120)\n",
    "\n",
    "    displaysum(summarize, generated, reference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Fine-tuning\n",
    "\n",
    "The big strength of those huge transformer model is that they can be fine tuned on specific tasks.\n",
    "So lets try that for our ***abstract to thesis title*** summarization.\n",
    "\n",
    "After fine tuning try out the summarization and check qualitatively if you're content with the results.\n",
    "Check the [documentation](!https://huggingface.co/transformers/model_doc/t5.html) for what you need to do.\n",
    "This [notebook](!https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb) might also come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2: Fine-tuning\n",
    "\n",
    "# As you could see, the summary quality is pretty much hit-or-miss. Let's use\n",
    "# a good share of the data to fine-tune the pre-trained model to our task.\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThesisDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_input_len, max_output_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_len = max_input_len\n",
    "        self.summ_len = max_output_len\n",
    "        self.Titel = df.Titel\n",
    "\n",
    "        # T5 requires us to prepend the task\n",
    "        self.Abstract = 'summarize: ' + df.Abstract\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Titel)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        abstract = str(self.Abstract[index])\n",
    "        title = str(self.Titel[index])\n",
    "\n",
    "        # use tokenizer.batch_encode_plus to also get the masking\n",
    "        source_tok = self.tokenizer.batch_encode_plus([abstract],\n",
    "                                                      max_length=self.source_len, \n",
    "                                                      truncation=True,\n",
    "                                                      padding=True,\n",
    "                                                      return_tensors='pt')\n",
    "        label_tok = self.tokenizer.batch_encode_plus([title],\n",
    "                                                     max_length=self.summ_len,\n",
    "                                                     truncation=True,\n",
    "                                                     padding=True,\n",
    "                                                     return_tensors='pt')\n",
    "\n",
    "        input_ids = source_tok['input_ids'].squeeze()\n",
    "        input_mask = source_tok['attention_mask'].squeeze()\n",
    "        label_ids = label_tok['input_ids'].squeeze()\n",
    "        label_mask = label_tok['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids.to(dtype=torch.long), \n",
    "            'input_mask': input_mask.to(dtype=torch.long), \n",
    "            'label_ids': label_ids.to(dtype=torch.long),\n",
    "            'label_mask': label_mask.to(dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for each point in the data loader, compute the forward pass, loss and\n",
    "# backward pass\n",
    "\n",
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        y = data['label_ids'].to(device, dtype=torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "\n",
    "        # set the padding symbols to -100 to be ignored by torch\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        inputs = data['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['input_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "        # compute forward pass\n",
    "        outputs = model(input_ids=inputs, attention_mask=mask,\n",
    "                        decoder_input_ids=y_ids, labels=lm_labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print({\"Training Loss\": loss.item()})\n",
    "\n",
    "        # reset optimizer, do backwards pass and optimizer step    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for validation, set the model to eval mode and compute all predictions\n",
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            y = data['label_ids'].to(device, dtype=torch.long)\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['input_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "            # make prediction\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask,\n",
    "                max_length=150,\n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.5,\n",
    "                length_penalty=1.0,\n",
    "                early_stopping=True\n",
    "                )\n",
    "            \n",
    "            # use tokenizer.decode to get predicted and target string\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f'Completed {i}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    \n",
    "    return predictions, actuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df=(619, 7), train=(495, 7), vali=(124, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# defining some parameters that will be used later on in the training  \n",
    "# hint: on colab, you may need to reduce this to batch_size_train=2 and batch_size_vali=1 to not exceed memory limits\n",
    "batch_size_train = 2\n",
    "batch_size_vali = 1\n",
    "\n",
    "max_input_len = 512\n",
    "max_output_len = 120\n",
    "\n",
    "# set random seeds and deterministic pytorch for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# TODO verify: tokenizer and df still loaded and current?\n",
    "\n",
    "# split the dataframe into training and validation\n",
    "df_train = df.sample(frac=0.8, random_state=seed)\n",
    "df_vali = df.drop(df_train.index).reset_index(drop=True)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "print(f\"df={df.shape}, train={df_train.shape}, vali={df_vali.shape}\")\n",
    "\n",
    "# Creating the Training and Validation dataset for further creation of Dataloader\n",
    "ds_train = ThesisDataset(df_train, tokenizer, max_input_len, max_output_len)\n",
    "ds_vali = ThesisDataset(df_vali, tokenizer, max_input_len, max_output_len)\n",
    "\n",
    "# create data loaders for training and validation\n",
    "from torch.utils.data import DataLoader\n",
    "dl_train = DataLoader(ds_train, shuffle=True, num_workers=0, batch_size=batch_size_train)\n",
    "dl_vali = DataLoader(ds_vali, shuffle=True, num_workers=0, batch_size=batch_size_vali)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we'll start from the same ml6team/mt5-small-german-finetune-mlsum that we\n",
    "# used before in our baseline experiment; we will reload it below so that we\n",
    "# maintain the base model\n",
    "base = model\n",
    "\n",
    "# this time, we'll load it explicitly as a T5ForConditionalGeneration; the\n",
    "# tokenizer will be the same\n",
    "\n",
    "from transformers import T5ForConditionalGeneration\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"ml6team/mt5-small-german-finetune-mlsum\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2105: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Training Loss': 4.358883857727051}\n",
      "{'Training Loss': 3.9416675567626953}\n",
      "Epoch: 0, Loss:  3.4910881519317627\n",
      "{'Training Loss': 3.577577829360962}\n",
      "{'Training Loss': 3.386929988861084}\n",
      "Epoch: 1, Loss:  3.481137990951538\n",
      "Completed 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Training Loss': 3.3831934928894043}\n",
      "{'Training Loss': 3.2299721240997314}\n",
      "Epoch: 2, Loss:  3.2451138496398926\n",
      "Completed 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>None</td></tr>\n",
       "    <tr><td>generated:</td><td>Der SLAM-Algorithmus zeigt, ob ein SLAM-Verfahren existiert, der für die Erkennung beweglicher Objekte erkannt wird.</td></tr>\n",
       "    <tr><td>reference:</td><td>Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_train = 3\n",
    "epochs_vali = [1, 2, 3]\n",
    "\n",
    "models = []\n",
    "\n",
    "for epoch in range(epochs_train):\n",
    "    # call the training routine from above\n",
    "    train(epoch, tokenizer, model, device, dl_train, optimizer)\n",
    "\n",
    "    if epoch in epochs_vali:\n",
    "        # call the vali routine from above to generate some summaries\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, dl_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and compare outputs\n",
    "base = AutoModelForSeq2SeqLM.from_pretrained(\"ml6team/mt5-small-german-finetune-mlsum\")\n",
    "fine = model  # or any other checkpoint from res/mt5-small-fine-tune-...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Die Notenapp ermöglicht es Schülern, aber auch deren Eltern, den Schulalltag einfacher und effizienter zu planen. Der digitale Schulassistent bietet verschiedene Module an, die von der Gestaltung eines Stundenplans, einem Prüfungsplaner mit Notenmanagement, einem papierlosen Hausaufgabenheft bis hin zur Berechnung des aktuellen Gesamtnotendurchschnitts reichen. Ein standardisiertes Verfahren zur In-App-Werbung ist die Basis für eine Finanzierungsstrategie der Notenapp. Hierbei spielen eine effektive Umsetzung eines Werbebudgets und ein Konzept zur automatisierten Integration der Werbung innerhalb der App eine Rolle. In dieser Arbeit werden bereits auf dem Markt existierende Lösungen zur Integration und Verwaltung von In-App-Werbung im Gegensatz zur Entwicklung eines eigenen Konzepts diskutiert und evaluiert. Letztendlich soll ein einfaches Verfahren entstehen, mit dem eine Finanzierungsgrundlage über zukünftige Kooperationspartner umgesetzt werden kann.</td></tr>\n",
       "    <tr><td>base:</td><td>Die Notenapp ermöglicht es Schülern, aber auch deren Eltern, den Schulalltag einfacher und effizienter zu planen.</td></tr>\n",
       "    <tr><td>fine:</td><td>Die Notenapp ermöglicht es Schülern, aber auch deren Eltern, den Schulalltag einfacher und effizienter zu planen</td></tr>\n",
       "    <tr><td>reference:</td><td>Konzeption und prototypische Umsetzung der In-App-Werbung am Beispiel der Notenapp</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Um dem Top-Management der Consorsbank einen aktuellen Einblick in die operativen Systeme und die wichtigsten Bereiche des Geschäfts zu ermöglichen, ist die Anforderung des Chief Data Officer, ein Kennzahlendashboard für die neue Management Area bereitzustellen. Mittels der Software TIBCO Spotfire sollen verschiedene Metriken der Produkteröffnungsprozesse, der Besucheranzahl auf den Plattformen, der Auslastung des Kundendialogs sowie des Tradings in diversen Diagrammen dargestellt und mit historischen Werten verglichen werden. Hierfür ist es notwendig, Daten aus verschiedenen Quellen wie dem Data Warehouse und den operativen Systemen mithilfe des ETL-Prozesses anzubinden. Die einzelnen Phasen dieses Prozesses gestalten sich je nach Integrationsweise unterschiedlich und erfordern verschiedene Softwarelösungen. Zusätzlich wird das Projekt einer kaufmännischen Betrachtung unterzogen. Es wird im Nachgang eine Total-Cost-of-Ownership-Analyse durchgeführt, um die angefallenen und noch anfallenden Kosten des Vorhabens zu beziffern.</td></tr>\n",
       "    <tr><td>base:</td><td>Die Software TIBCO Spotfire sollen verschiedene Metriken der Produkteröffnungsprozesse dargestellt und mit historischen Werten verglichen werden.</td></tr>\n",
       "    <tr><td>fine:</td><td>Die Software TIBCO Spotfire sollen verschiedene Metriken der Produkteröffnungsprozesse und die wichtigsten Bereiche des Geschäfts zu ermöglichen</td></tr>\n",
       "    <tr><td>reference:</td><td>Implementierung eines Management-Dashboards bei einer Direktbank zur Visualisierung von Unternehmenskennzahlen in Echtzeit</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Diese Arbeit befasst sich mit der Konzeption eines digitalen Magazins für die Fakultät Infor-matik der Technischen Hochschule Nürnberg. Dieses wird mit dem Content Management System WordPress prototypisch umgesetzt. Im Rahmen der Konzeption werden aktuelle Websites analysiert, um ein modernes und für die Fakultät passendes Erscheinungsbild zu kreieren. Weiterhin thematisiert die Arbeit die Informationsarchitektur. Die Informationsar-chitektur beschreibt die Strukturierung einer Website und umfasst die Bereiche Organisati-onssystem, Navigationsstruktur und Suchsystem. Es werden jeweils mehrere Lösungsansätze vorgestellt und bewertet. Weiterhin erfolgt die Dokumentation der Umsetzung einiger aus-gewählter Strategien. Daraus ergibt sich der Prototyp eines digitalen Magazins, das den Jah-resbericht der Fakultät ablöst und um einige weitere Inhaltsbereiche erweitert.</td></tr>\n",
       "    <tr><td>base:</td><td>Die Konzeption eines digitalen Magazins für die Fakultät Infor-matik der Technischen Hochschule Nürnberg befasst sich mit der Konzeption eines digitalen Magazins für die Fakultät Infor-matik.</td></tr>\n",
       "    <tr><td>fine:</td><td>Die Konzeption eines digitalen Magazins für die Fakultät Infor-matik der Technischen Hochschule Nürnberg Konzeption eines digitalen Magazins für die Fakultät Infor-matik der Technischen Hochschule Nürnberg</td></tr>\n",
       "    <tr><td>reference:</td><td>Konzeption und prototypische Umsetzung eines digitalen Magazins für die Fakultät Informatik</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>In der aktuellen Vorverarbeitung tauchen immer wieder Probleme im Ablauf auf. Diese treten aufgrund von heterogenen Daten auf und gehen mit anderen Problemen wie dasVerwenden von zwei Betriebssystemen einher, was eine automatischen Ablauf verhindert. Es wurde die Vermutung aufgestellt, dass die Probleme mit der Verwendung von Apche Spark als zentrale Infrastruktur für die Vorverarbeitung zu lösen sind, was im Laufe der Arbeit diskutiert wird. Anfangs werden die Probleme der aktuellen Vorverarbeitung diskutiert um einen Einblick zu geben weshalb die Arbeit nötig wurde. Weiter werden grundlegende Kenntnisse im Zusammenhang mit Apache Spark und anschließend das Prinzip der RDDs erklärt. Weiter wird ein Einblick über die Komponenten der Open- Source-Software und deren Funktionen dargestellt. Abschließend zum theoretischen Teil wird die Architektur einer Anwendung von Spark und dessen Komponenten erklärt. Zudem werden die möglichen Datenbanken erwähnt und auf Apache Cassandra, welche aktuell verwendet wird, mit dem HDFS in Kontrast gesetzt. Danach werden die Skripte für die Vorverarbeitung nach Python übersetzt, Optimierungen vorgenommen und zur Verwendung in Spark angepasst. Abschließend wird über die sich ergebenden Vor- und Nachteile durch die Verwendung von Spark diskutiert und eine Wertung über Spark als zentrale Infrastruktur abgegeben. Weiter werden die noch offenen Möglichkeiten, die Spark für das Projekt bietet angesprochen und Zum Schluss ein persönliches Resümee gezogen</td></tr>\n",
       "    <tr><td>base:</td><td>Die aktuellen Vorverarbeitung tauchen immer wieder Probleme im Ablauf auf. Diese treten aufgrund von heterogenen Daten auf und gehen mit anderen Problemen wie dasVerwenden von zwei Betriebssystemen einher.</td></tr>\n",
       "    <tr><td>fine:</td><td>In der aktuellen Vorverarbeitung tauchen immer wieder Probleme im Ablauf auf.</td></tr>\n",
       "    <tr><td>reference:</td><td>Analyse und Bewertung des Einsatzes von Apache Spark als zentrale Infrastruktur für die Vorverarbeitung und Analyse von Textdaten am Beispiel von Brettspielanleitungen</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Das Ziel der vorliegenden Arbeit war es, eine zukunftsfähige Softwarelösung zur Ana-lyse der syngo.via Installed-Base zu erarbeiten. Dazu wurden die wichtigsten Anforde-rungen spezifiziert und die Daten, die von einer solchen Softwarelösung ausgewertet werden sollen, im Detail analysiert. Auf dieser Basis wurden zunächst die zwei bereits existierenden Lösungen zur Analyse der syngo.via Installed-Base evaluiert. Diese zwei Softwarelösungen basieren beide auf einer klassischen Data-Warehouse-Architektur. Im Anschluss wurde der Einsatz eines Big-Data-Systems zur Analyse der syngo.via In-stalled-Base untersucht. Dazu wurde ein auf Big-Data-Technologien basierender Proto-typ zur Analyse der syngo.via Installed-Base konzipiert und entwickelt. Um die richti-gen Entscheidungen bei der Technologie-Auswahl zu treffen, wurden auf Basis von den zuvor definierten Anforderungen die verschiedenen in Frage kommenden Big-Data-Technologien evaluiert und miteinander verglichen. Das Ziel dabei war, die Tauglichkeit eines Big-Data-Systems zur Analyse der syngo.via Installed-Base nachzuweisen und gleichzeitigt zu veranschaulichen, wie so ein System bestmöglich umzusetzen ist. Der so entstandene Prototyp zeigt auf, wie eine zukunftsfähige Softwarelösung zur Analyse der syngo.via Installed-Base umgesetzt werden kann und auf welche Punkte bei der Umsetzung geachtet werden muss.</td></tr>\n",
       "    <tr><td>base:</td><td>Das Ziel der vorliegenden Arbeit war es, eine zukunftsfähige Softwarelösung zur Ana-lyse der syngo.via Installed-Base zu erarbeiten. Dazu wurden die wichtigsten Anforde-rungen spezifiziert.</td></tr>\n",
       "    <tr><td>fine:</td><td>Das Ziel der vorliegenden Arbeit war es, eine zukunftsfähige Softwarelösung zur Ana-lyse der syngo.via Installed-Base zur Ana-lyse der syngo.via Installed-Base zu erarbeiten.</td></tr>\n",
       "    <tr><td>reference:</td><td>Evaluation verschiedener Softwarelösungen zur Analyse der syngo.via Installed-Base</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Eine effektive, effiziente und zufriedenstellende Nutzung von Softwareprodukten bedarf einer guten Usability. Diese Bachelorarbeit befasst sich mit der Identifikation und Beseitigung von Usability-Schwachstellen in der Berater-Nutzeroberfläche der Online-Beratungssoftware des Instituts für E-Beratung. In einem ersten Schritt werden in Anlehnung an die Vorgehensmethodik des Usability Engineering sowohl der Ist-Zustand der Software analysiert als auch ihre Schwachstellen mittels UX-Tagebuchstudie und standardisiertem Fragebogen identifiziert. Anschließend wird ein Usability-Konzept entwickelt, welches Handlungsempfehlungen zum Beheben der aufgedeckten Schwachstellen beinhaltet. Zudem wird eine Guideline erarbeitet, die auf wichtige, zu beachtende Aspekte der Gebrauchstauglichkeit hinsichtlich zukünftiger Erweiterungen der Software aufmerksam macht. Durch die kontinuierliche Umsetzung dieser Handlungsempfehlungen soll die Zufriedenheit der Nutzer*innen dieser Software gesteigert werden.</td></tr>\n",
       "    <tr><td>base:</td><td>Eine neue Bachelorarbeit befasst sich mit der Identifikation und Beseitigung von Usability-Schwachstellen in der Berater-Nutzeroberfläche der Online-Beratungssoftware des Instituts für E-Beratung.</td></tr>\n",
       "    <tr><td>fine:</td><td>Eine effektive, effiziente und zufriedenstellende Nutzung von Softwareprodukten bedarf einer guten Usability</td></tr>\n",
       "    <tr><td>reference:</td><td>Entwicklung eines Konzepts zur kontinuierlichen Verbesserung der Usability einer Online-Beratungssoftware</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Durch ein EMG-Armband ist es möglich Muskelbewegungen, welche durch Gesten mit der Hand, dem Arm oder auch bei Fingerbewegungen auftreten, zu erfassen. Hierdurch kann eine Anwendung realisiert werden, die ohne Berührungen mit Standard-Eingabegeräten auskommt. Ein äußerst interessanter Anwendungsfall ist hierbei die Verwendung bei Computersystemen in Reinräumen oder ähnlich stark hygienisch reglementierten Standorten, bei denen darauf Wert gelegt wird, möglichst wenige Oberflächen mit den Händen berühren zu müssen. Im Speziellen können dies labor- oder medizintechnische Umgebungen sein. Dieses Konzept wird hierbei anhand eines exemplarischen Showcases in Zusammenarbeit mit der infoteam Software AG umgesetzt.</td></tr>\n",
       "    <tr><td>base:</td><td>Ein EMG-Armband ist es möglich Muskelbewegungen, welche durch Gesten mit der Hand, dem Arm oder auch bei Fingerbewegungen auftreten, zu erfassen. Hierdurch kann eine Anwendung realisiert werden, die ohne Berührungen mit Standard-Eingabegeräten auskommt.</td></tr>\n",
       "    <tr><td>fine:</td><td>Ein EMG-Armband ist es möglich Muskelbewegungen, welche durch Gesten mit der Hand, dem Arm oder auch bei Fingerbewegungen auftreten, erfassen und erfassen</td></tr>\n",
       "    <tr><td>reference:</td><td>Gestenerkennung und virtuelle Eingabemöglichkeiten mittels Myo-Armband in labor- und medizintechnischen Umgebungen</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Für den Carbot existiert die Navigationskomponente GAA (Grid-based A* Advanced), die eine Punkt-zu-Punkt-Wegeplanung vorbei an Hindernissen durchführt. In dynamischen Umgebungen ändert sich die wahrgenommene Umwelt ständig, alleine schon dadurch, dass während der Fahrt neue Hindernisse erfasst werden (z.B. weil sie in den Sichtbereich der Kamera kommen). Klassische A*-Ansätze müssen bei Änderung der Hinderniskarte die Planung komplett neu durchführen. Im Gegensatz dazu versuchen inkrementelle Ansätze soviel wie möglich aus einer alten Planung wiederzuverwenden und berechnen eine neue Route auf der Basis der inkrementellen Änderungen. Das kann Ressourcen schonen, allerdings ist die Planung komplexer. In dieser Arbeit sollen in der Literatur beschriebene inkrementelle Ansätze (z.B. D*, Focussed D*, D* Lite) analysiert und teilweise implementiert werden. Eine Auswertung soll diese dann mit nicht-inkrementellen Ansätzen (A* oder GAA) vergleichen.</td></tr>\n",
       "    <tr><td>base:</td><td>In dynamischen Umgebungen ändert sich die wahrgenommene Umwelt ständig, alleine schon dadurch, dass neue Hindernisse erfasst werden.</td></tr>\n",
       "    <tr><td>fine:</td><td>In dynamischen Umgebungen ändert sich die wahrgenommene Umwelt ständig, alleine schon dadurch, dass neue Hindernisse erfasst werden.</td></tr>\n",
       "    <tr><td>reference:</td><td>Analyse von inkrementellen, rasterbasierten Navigationsverfahren für autonome, mobile Roboter</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Im Rahmen dieser Arbeit werden merkmalsbasierte Verfahren des maschinellen Sehens zur Objektwiedererkennung auf Robotersystemen untersucht. Die Herausforderung besteht dabei, Objekte auch aus verschiedenen Blickwinkeln und Perspektiven, sowie unter verschiedenen Lichtverhältnissen zu erkennen. Ziel ist es durch Vorverarbeitung durch Gaußfilter, merkmalbasierte sowie histogrammbasierte Verfahren mithilfe von OpenCV eine wiederverwendbare C++-Bibliothek zur Objektwiedererkennung zu implementieren. Die Grundfunktionalität soll anschließend auf einer Testanwendung auf dem Robotersystem Pepper demonstriert werden. Damit sollen Objekte gelernt und wiedererkannt werden. Zum Erlernen eines Objektes wird dieses in der Kameramitte platziert und durch ein Sprechkommando mit einem Textlabel versehen. Zur Wiedererkennung werden Objekte zunächst zweidimensional betrachtet. Aus der zweidimensionalen Darstellung der Objekte werden durch SIFT- bzw. SURF-Verfahren Merkmale ermittelt und anschließend Merkmalskorrespondenzen zu den abgespeicherten Objekten gebildet. Das Textlabel des Objektes mit den meisten Korrespondenzen wird als Ergebnis ausgegeben. Um Objekte auch aus verschiedenen Blickwinkeln zu erkennen, werden außerdem histogrammbasierte Verfahren angewendet. Als Ergebnis soll eine echtzeitfähige Lösung entstehen, die als Softwarebasis für zukünftige Forschungsprojekte, wie z.B. die visuelle Selbstlokalisierung von Robotern, dienen könnte.</td></tr>\n",
       "    <tr><td>base:</td><td>Das Verfahren des maschinellen Sehens zur Objektwiedererkennung auf Robotersystemen untersucht.</td></tr>\n",
       "    <tr><td>fine:</td><td>Im Rahmen dieser Arbeit werden merkmalsbasierte Verfahren des maschinellen Sehens zur Objektwiedererkennung auf Robotersystemen untersucht</td></tr>\n",
       "    <tr><td>reference:</td><td>Merkmalsbasierte Wiedererkennung von Objekten mit Anwendung für die Robotik</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><td>summarize:</td><td>Durch die zunehmende Beliebtheit und Nutzung öffentlicher Onlineberatungsforen stehen heutzutage noch nie dagewesene Mengen an frei einsehbaren Daten über Beratungsgespräche im Internet zur Verfügung. Eine manuelle qualitative Inhaltsanalyse dieser Daten ermöglicht es, Stärken und Schwächen im Vorgehen bei Onlineberatungsgesprächen aufzudecken. Da diese manuellen Untersuchungen jedoch sehr zeitaufwendig sind und ein umfangreiches Wissen benötigt wird, ist es häufig nicht möglich, qualitative Inhaltsanalysen auf großen Datenmengen durchzuführen. Um diesem Problem entgegenzuwirken, werden in dieser Arbeit die Einsatzmöglichkeiten neuronaler Klassifikationsverfahren zur automatisierten Kategorisierung psycho-sozialer Aussagen von Onlineberatenden untersucht. Neben einer einfachen Support Vector Machine als Baseline wurden hierzu insgesamt fünf neuronale Modelle in unterschiedlichen Ausprägungen erzeugt, in ihrer Güte bewertet und mit der Klassifikationsleistung menschlicher Codierenden verglichen.</td></tr>\n",
       "    <tr><td>base:</td><td>Die zunehmende Beliebtheit und Nutzung öffentlicher Onlineberatungsforen stehen heutzutage noch nie dagewesene Mengen an frei einsehbaren Daten über Beratungsgespräche im Internet zur Verfügung.</td></tr>\n",
       "    <tr><td>fine:</td><td>Eine qualitative Inhaltsanalyse der Daten über Onlineberatungsgespräche im Internet zur Verfügung.</td></tr>\n",
       "    <tr><td>reference:</td><td>Klassifikation psycho-sozialer Äußerungen mittels tiefer neuronaler Netze</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick some random theses and compare the two models\n",
    "thesis_picks = [random.randint(0, len(df_vali) - 1) for _ in range(10)]\n",
    "\n",
    "num_beams = 8\n",
    "repetition_penalty = 3.0\n",
    "length_penalty = 1.0\n",
    "max_output_length = 120\n",
    "\n",
    "early_stopping = False\n",
    "\n",
    "for num, i in enumerate(thesis_picks):\n",
    "    print()\n",
    "    # generate a summary with each of the models\n",
    "    s0 = generate_summary(base, 'summarize: '+df_vali.iloc[i].Abstract,\n",
    "                          num_beams, repetition_penalty,\n",
    "                          length_penalty, early_stopping, max_output_len)\n",
    "    s1 = generate_summary(fine, ('summarize: '+df_vali.iloc[i].Abstract),\n",
    "                          num_beams, repetition_penalty,\n",
    "                          length_penalty, early_stopping, max_output_len)\n",
    "    display(HTML(f\"\"\"<table>\n",
    "    <tr><td>summarize:</td><td>{df_vali.iloc[i].Abstract}</td></tr>\n",
    "    <tr><td>base:</td><td>{s0}</td></tr>\n",
    "    <tr><td>fine:</td><td>{s1}</td></tr>\n",
    "    <tr><td>reference:</td><td>{df_vali.iloc[i].Titel}</td></tr>\n",
    "    </table>\n",
    "    <hr>\n",
    "    \"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "1. Revisit part 1 of this notebook.\n",
    "    - Describe the sampled summaries; what's weird about them?\n",
    "    - How do `beamsize`, `repetition_penalty` and `length_penalty` affect the summaries?\n",
    "    - What happens, if you apply the model repeatedly to the text, with decresing lengths?\n",
    "2. Experiment with the parameters in part 2 of this worksheet.\n",
    "    - Can you adjust the hyperparameters to mitigate some of the oddities from the downloaded model?\n",
    "    - Brainstorm: How could you get to an actual title instead of a short summary?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
